{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Preprocessing: Actually the feature input used in this model is generated by other notebooks. There exists some models using the same data input to reduce unnecessary duplication of work. After all, we aim to evaluate whether the structure of model is useful for classification."
      ],
      "metadata": {
        "id": "E0W4LfjY2w-V"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is code from other notebooks."
      ],
      "metadata": {
        "id": "D7TEgdYg3P_u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "pd.plotting.register_matplotlib_converters()\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, Flatten, Dense, MaxPool2D, Dropout\n",
        "from tensorflow.keras.utils import to_categorical \n",
        "import os,glob,skimage,librosa\n",
        "import librosa.display\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")    \n",
        "root=\"/content/drive/MyDrive/Thesis_Keras/\"        \n",
        "csvPth = '/content/drive/MyDrive/Thesis_Keras/UrbanSound8K/metadata/UrbanSound8K.csv'\n",
        "examplePath = '/content/drive/MyDrive/Thesis_Keras/UrbanSound8K/audio/fold6/85249-2-0-79.wav'"
      ],
      "metadata": {
        "id": "oOnHN7Rb2wRt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "0aNYGpii3VOd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import librosa\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "import keras\n",
        "from scipy import signal\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tqdm import tqdm\n",
        "from tqdm._tqdm import trange\n",
        "from keras.utils import np_utils\n",
        "\n",
        "def readFromCsv(csvpth):\n",
        "    # 生成数据列表\n",
        "    # 读取wav文件函数\n",
        "    #data = pd.read_csv('metadata/UrbanSound8K.csv')\n",
        "    data = pd.read_csv(csvpth)\n",
        "    valid_data = data[['slice_file_name', 'fold', 'classID', 'class']][data['end'] - data['start'] >= 2]\n",
        "    valid_data['path'] = 'fold' + valid_data['fold'].astype('str') + '/' + valid_data['slice_file_name'].astype(\n",
        "        'str')\n",
        "    return valid_data\n",
        "\n",
        "\n",
        "def splitData(current):\n",
        "  \n",
        "  D=[]\n",
        "  i=1\n",
        "\n",
        "  for row in tqdm(current.itertuples(),total=current.shape[0]):\n",
        "        #print(row.path)\n",
        "        #print(row.classID)\n",
        "        #print(f\"{i} out of {len(current)}\")\n",
        "        X, sample_rate = librosa.load(\"/content/drive/MyDrive/Thesis_Keras/UrbanSound8K/audio/\" + row.path, res_type='kaiser_fast', duration=2.97)\n",
        "\n",
        "\n",
        "        mels = librosa.feature.melspectrogram(X, sr=sample_rate,n_mels=40)\n",
        "\n",
        "        if mels.shape != (40, 128): \n",
        "          continue\n",
        "        feature = mels\n",
        "        label = row.classID\n",
        "        D.append((feature,label))\n",
        "  dataset = D\n",
        "  X,y=zip(*dataset)\n",
        "  \n",
        "  print(\"type of X is:\",type(X))\n",
        "  y=np.array(y).astype(np.int64)\n",
        "  y = np.array(np_utils.to_categorical(y, 10))\n",
        "\n",
        "  return  X,y\n",
        "\n",
        "\n",
        "def save_npy(nparr,modelName,featureName,subDataset,fold):\n",
        "    import os\n",
        "    dirs = \"drive/MyDrive/Thesis_Keras/TenFoldDataset/datasetnpy\"+'/'+modelName+'/'+featureName+'/'+fold\n",
        "    \n",
        "    #Create a directory to place the dataset npy files.\n",
        "    if not os.path.exists(dirs):\n",
        "        os.makedirs(dirs)\n",
        "        print(f\"Created directory:{dirs}\")\n",
        "    \n",
        "    subDataset+='.npy'\n",
        "    print(subDataset)\n",
        "    subsetPth=os.path.join(dirs,subDataset)\n",
        "    #with open(subsetPth, 'w') as f:\n",
        "    np.save(subsetPth, nparr)\n",
        "    print(f\"save {subDataset} done\")\n",
        "    print(f\"Path:{subsetPth}\")\n",
        "\n",
        "def Ten_fold():\n",
        "    csvPth = '/content/drive/MyDrive/Thesis_Keras/UrbanSound8K/metadata/UrbanSound8K.csv'\n",
        "    #df=pd.read_csv(csvPth)\n",
        "    valid_data=readFromCsv(csvPth)\n",
        "    #valid_data = df[['slice_file_name', 'fold', 'classID', 'class']][df['end'] - df['start']]\n",
        "    # valid_data['path'] = 'fold' + valid_data['fold'].astype('str') + '/' + valid_data['slice_file_name'].astype(\n",
        "    #     'str')\n",
        "    for i in range(10):#Folder : \"fold1\" to \"fold10\"\n",
        "        print(f\"fold:{i+1} out of 10\")\n",
        "        current=valid_data[valid_data['fold'] == i+1]\n",
        "        X,y = splitData(current)\n",
        "        print(\"Dataset split done!\")\n",
        "        print(\"Saving subsets to .npy files!\")\n",
        "        \n",
        "        save_npy(X, 'MelConv1', 'mel', 'X',f\"fold{i+1}\")\n",
        "        save_npy(y, 'MelConv1', 'mel', 'y',f\"fold{i+1}\")"
      ],
      "metadata": {
        "id": "YgF2dFno3XEY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Ten_fold() # generate 10-fold training and test data packed in .npy files. Easier to be used in later experiments."
      ],
      "metadata": {
        "id": "pYU4DtF93k48"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "10-fold"
      ],
      "metadata": {
        "id": "H2MqCyiZJOBA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L5_FgHr9JNb8",
        "outputId": "8fe40ddb-75f4-4d78-acd7-3663b3811f7d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "def generate_loader(i_val):\n",
        "    train_X = []\n",
        "    train_y=[]\n",
        "    X_test=[]\n",
        "    y_test=[]\n",
        "    for i in range(10):\n",
        "        if i + 1 == i_val:\n",
        "            X_test = np.load(\n",
        "                \"drive/MyDrive/Thesis_Keras/TenFoldDataset/datasetnpy/MelConv1/mel/\"+f\"fold{i + 1}\"+\"/X.npy\"\n",
        "                )\n",
        "            y_test=np.load(\n",
        "                \"drive/MyDrive/Thesis_Keras/TenFoldDataset/datasetnpy/MelConv1/mel/\"+f\"fold{i + 1}\"+\"/y.npy\"\n",
        "            )\n",
        "        else:\n",
        "            X_train = np.load(\n",
        "                \"drive/MyDrive/Thesis_Keras/TenFoldDataset/datasetnpy/MelConv1/mel/\"+f\"fold{i + 1}\"+\"/X.npy\"\n",
        "            )\n",
        "            y_train = np.load(\n",
        "                \"drive/MyDrive/Thesis_Keras/TenFoldDataset/datasetnpy/MelConv1/mel/\"+f\"fold{i + 1}\"+\"/y.npy\"\n",
        "            )\n",
        "\n",
        "            for item in X_train:\n",
        "                train_X.append(item)\n",
        "            for item in y_train:\n",
        "                train_y.append(item)\n",
        "\n",
        "    return np.array(train_X),np.array(train_y),np.array(X_test),np.array(y_test)"
      ],
      "metadata": {
        "id": "J6CXfKMdJUGu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, InputLayer, Dropout, Conv1D, Conv2D, Flatten, Reshape, MaxPooling1D, MaxPooling2D, BatchNormalization, TimeDistributed,AveragePooling1D,AveragePooling2D\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "\n",
        "def build_model(input_length):\n",
        "    # model = Sequential()\n",
        "    # model.add(Reshape((128,40), input_shape=(input_length,128)))\n",
        "    # model.add(Conv1D(32, kernel_size=5, activation='relu', kernel_constraint=tf.keras.constraints.MaxNorm(1), padding='same'))\n",
        "    # model.add(MaxPooling1D(pool_size=2, strides=2, padding='same'))\n",
        "    # model.add(Conv1D(24, kernel_size=3, activation='relu', kernel_constraint=tf.keras.constraints.MaxNorm(1), padding='same'))\n",
        "    # model.add(MaxPooling1D(pool_size=2, strides=2, padding='same'))\n",
        "    # model.add(Conv1D(24, kernel_size=3, activation='relu', kernel_constraint=tf.keras.constraints.MaxNorm(1), padding='same'))\n",
        "    # model.add(MaxPooling1D(pool_size=2, strides=2, padding='same'))\n",
        "    # model.add(Dropout(0.4))\n",
        "    # model.add(Flatten())\n",
        "    # model.add(Dense(10, activation='softmax', name='y_pred'))\n",
        "    model = Sequential()\n",
        "    model.add(Reshape((128,40), input_shape=(40,128 )))\n",
        "    model.add(Conv1D(12, kernel_size=5, activation='relu',kernel_regularizer=tf.keras.regularizers.L2(0.001)))\n",
        "    #model.add(BatchNormalization())\n",
        "    model.add(MaxPooling1D(pool_size=2, strides=2, padding='same'))\n",
        "    model.add(Conv1D(28, kernel_size=5, activation='relu', padding='valid'))\n",
        "    model.add(MaxPooling1D(pool_size=2, strides=2, padding='same'))\n",
        "    model.add(Dense(30, activation='relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(10, activation='softmax', name='y_pred'))\n",
        "    return model\n",
        "\n",
        "def train_model(model,X_train,Y_train,X_test,Y_test,foldNum):\n",
        "  EPOCHS = 100\n",
        "  # this controls the batch size, or you can manipulate the tf.data.Dataset objects yourself\n",
        "  BATCH_SIZE = 32\n",
        "  callbacks = []\n",
        "  # model architecture\n",
        "  \n",
        "  # this controls the learning rate\n",
        "  opt = Adam(learning_rate=0.005, beta_1=0.9, beta_2=0.999)\n",
        "  #callbacks.append(BatchLoggerCallback(BATCH_SIZE, train_sample_count, epochs=EPOCHS))\n",
        "\n",
        "  # train the neural network\n",
        "  model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
        "\n",
        "  model.fit(X_train,Y_train, batch_size=BATCH_SIZE, epochs=EPOCHS, verbose=2,validation_split=0.1,shuffle=True)\n",
        "  print(model.summary())\n",
        "  # Use this flag to disable per-channel quantization for a model.\n",
        "  # This can reduce RAM usage for convolutional models, but may have\n",
        "  # an impact on accuracy.\n",
        "  disable_per_channel_quantization = False\n",
        "  print(\"Result of fold:\"+f\"{foldNum}\")\n",
        "  score = model.evaluate(\n",
        "        x=X_test,\n",
        "        y=Y_test)"
      ],
      "metadata": {
        "id": "hCHmzWCWJVZt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in tqdm(range(10)):\n",
        "  #from tensorflow.compat.v1.keras import backend as K\n",
        "  import tensorflow as tf\n",
        "\n",
        "  import os\n",
        "\n",
        "  X_train,y_train,X_test,y_test = generate_loader(i+1)\n",
        "\n",
        "\n",
        "  input_len=len(X_train[0])\n",
        "  model = build_model(input_len)\n",
        "  if not i==0:\n",
        "    model = build_model(input_len)\n",
        "  \n",
        "  train_model(model,X_train,y_train,X_test,y_test,i+1)\n",
        "  model.save(\"/content/drive/MyDrive/Thesis_Keras/\"+\"model/saved/Lhoest\"+f\"fold{i+1}\"+\".h5\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8GSV9WfNJXHX",
        "outputId": "d3b32f54-eba6-415d-9841-13f121fe3ff5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/10 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "190/190 - 13s - loss: 2.2458 - accuracy: 0.2740 - val_loss: 1.9231 - val_accuracy: 0.2511 - 13s/epoch - 71ms/step\n",
            "Epoch 2/100\n",
            "190/190 - 1s - loss: 1.7353 - accuracy: 0.3747 - val_loss: 1.7020 - val_accuracy: 0.4324 - 681ms/epoch - 4ms/step\n",
            "Epoch 3/100\n",
            "190/190 - 1s - loss: 1.6661 - accuracy: 0.3980 - val_loss: 1.7615 - val_accuracy: 0.2660 - 669ms/epoch - 4ms/step\n",
            "Epoch 4/100\n",
            "190/190 - 1s - loss: 1.5781 - accuracy: 0.4448 - val_loss: 1.6527 - val_accuracy: 0.4309 - 677ms/epoch - 4ms/step\n",
            "Epoch 5/100\n",
            "190/190 - 1s - loss: 1.5328 - accuracy: 0.4673 - val_loss: 1.6986 - val_accuracy: 0.4517 - 676ms/epoch - 4ms/step\n",
            "Epoch 6/100\n",
            "190/190 - 1s - loss: 1.4752 - accuracy: 0.4878 - val_loss: 1.7257 - val_accuracy: 0.3269 - 672ms/epoch - 4ms/step\n",
            "Epoch 7/100\n",
            "190/190 - 1s - loss: 1.4577 - accuracy: 0.4992 - val_loss: 1.6204 - val_accuracy: 0.4235 - 675ms/epoch - 4ms/step\n",
            "Epoch 8/100\n",
            "190/190 - 1s - loss: 1.4289 - accuracy: 0.5073 - val_loss: 1.6059 - val_accuracy: 0.4324 - 681ms/epoch - 4ms/step\n",
            "Epoch 9/100\n",
            "190/190 - 1s - loss: 1.3994 - accuracy: 0.5172 - val_loss: 1.6156 - val_accuracy: 0.4398 - 663ms/epoch - 3ms/step\n",
            "Epoch 10/100\n",
            "190/190 - 1s - loss: 1.3528 - accuracy: 0.5382 - val_loss: 1.6487 - val_accuracy: 0.4606 - 677ms/epoch - 4ms/step\n",
            "Epoch 11/100\n",
            "190/190 - 1s - loss: 1.3306 - accuracy: 0.5496 - val_loss: 1.5375 - val_accuracy: 0.5022 - 683ms/epoch - 4ms/step\n",
            "Epoch 12/100\n",
            "190/190 - 1s - loss: 1.3223 - accuracy: 0.5646 - val_loss: 1.5937 - val_accuracy: 0.4978 - 672ms/epoch - 4ms/step\n",
            "Epoch 13/100\n",
            "190/190 - 1s - loss: 1.2870 - accuracy: 0.5716 - val_loss: 1.6424 - val_accuracy: 0.4577 - 681ms/epoch - 4ms/step\n",
            "Epoch 14/100\n",
            "190/190 - 1s - loss: 1.2527 - accuracy: 0.5846 - val_loss: 1.6223 - val_accuracy: 0.5037 - 682ms/epoch - 4ms/step\n",
            "Epoch 15/100\n",
            "190/190 - 1s - loss: 1.2716 - accuracy: 0.5750 - val_loss: 1.6368 - val_accuracy: 0.4799 - 668ms/epoch - 4ms/step\n",
            "Epoch 16/100\n",
            "190/190 - 1s - loss: 1.2238 - accuracy: 0.5993 - val_loss: 1.8142 - val_accuracy: 0.4681 - 675ms/epoch - 4ms/step\n",
            "Epoch 17/100\n",
            "190/190 - 1s - loss: 1.1999 - accuracy: 0.6060 - val_loss: 1.7461 - val_accuracy: 0.4547 - 686ms/epoch - 4ms/step\n",
            "Epoch 18/100\n",
            "190/190 - 1s - loss: 1.2408 - accuracy: 0.6030 - val_loss: 1.6810 - val_accuracy: 0.4859 - 688ms/epoch - 4ms/step\n",
            "Epoch 19/100\n",
            "190/190 - 1s - loss: 1.2368 - accuracy: 0.5962 - val_loss: 1.7357 - val_accuracy: 0.4502 - 684ms/epoch - 4ms/step\n",
            "Epoch 20/100\n",
            "190/190 - 1s - loss: 1.1800 - accuracy: 0.6187 - val_loss: 1.6224 - val_accuracy: 0.4874 - 673ms/epoch - 4ms/step\n",
            "Epoch 21/100\n",
            "190/190 - 1s - loss: 1.1854 - accuracy: 0.6071 - val_loss: 1.6269 - val_accuracy: 0.5126 - 679ms/epoch - 4ms/step\n",
            "Epoch 22/100\n",
            "190/190 - 1s - loss: 1.1296 - accuracy: 0.6202 - val_loss: 1.6509 - val_accuracy: 0.5082 - 676ms/epoch - 4ms/step\n",
            "Epoch 23/100\n",
            "190/190 - 1s - loss: 1.1686 - accuracy: 0.6240 - val_loss: 1.6825 - val_accuracy: 0.4636 - 678ms/epoch - 4ms/step\n",
            "Epoch 24/100\n",
            "190/190 - 1s - loss: 1.1754 - accuracy: 0.6155 - val_loss: 1.6802 - val_accuracy: 0.4829 - 676ms/epoch - 4ms/step\n",
            "Epoch 25/100\n",
            "190/190 - 1s - loss: 1.1600 - accuracy: 0.6288 - val_loss: 1.5907 - val_accuracy: 0.5007 - 681ms/epoch - 4ms/step\n",
            "Epoch 26/100\n",
            "190/190 - 1s - loss: 1.1269 - accuracy: 0.6314 - val_loss: 1.6958 - val_accuracy: 0.4859 - 683ms/epoch - 4ms/step\n",
            "Epoch 27/100\n",
            "190/190 - 1s - loss: 1.0992 - accuracy: 0.6382 - val_loss: 1.7826 - val_accuracy: 0.4874 - 683ms/epoch - 4ms/step\n",
            "Epoch 28/100\n",
            "190/190 - 1s - loss: 1.1338 - accuracy: 0.6336 - val_loss: 1.7856 - val_accuracy: 0.5067 - 677ms/epoch - 4ms/step\n",
            "Epoch 29/100\n",
            "190/190 - 1s - loss: 1.0891 - accuracy: 0.6488 - val_loss: 1.6908 - val_accuracy: 0.5097 - 670ms/epoch - 4ms/step\n",
            "Epoch 30/100\n",
            "190/190 - 1s - loss: 1.0847 - accuracy: 0.6547 - val_loss: 1.7672 - val_accuracy: 0.4294 - 682ms/epoch - 4ms/step\n",
            "Epoch 31/100\n",
            "190/190 - 1s - loss: 1.1029 - accuracy: 0.6456 - val_loss: 1.7004 - val_accuracy: 0.4710 - 670ms/epoch - 4ms/step\n",
            "Epoch 32/100\n",
            "190/190 - 1s - loss: 1.0718 - accuracy: 0.6479 - val_loss: 1.6769 - val_accuracy: 0.4844 - 682ms/epoch - 4ms/step\n",
            "Epoch 33/100\n",
            "190/190 - 1s - loss: 1.0666 - accuracy: 0.6499 - val_loss: 1.7460 - val_accuracy: 0.4844 - 674ms/epoch - 4ms/step\n",
            "Epoch 34/100\n",
            "190/190 - 1s - loss: 1.0687 - accuracy: 0.6460 - val_loss: 1.6794 - val_accuracy: 0.4636 - 667ms/epoch - 4ms/step\n",
            "Epoch 35/100\n",
            "190/190 - 1s - loss: 1.0194 - accuracy: 0.6683 - val_loss: 1.7169 - val_accuracy: 0.4517 - 676ms/epoch - 4ms/step\n",
            "Epoch 36/100\n",
            "190/190 - 1s - loss: 1.1369 - accuracy: 0.6322 - val_loss: 1.8244 - val_accuracy: 0.4294 - 683ms/epoch - 4ms/step\n",
            "Epoch 37/100\n",
            "190/190 - 1s - loss: 1.1205 - accuracy: 0.6322 - val_loss: 1.7860 - val_accuracy: 0.4368 - 670ms/epoch - 4ms/step\n",
            "Epoch 38/100\n",
            "190/190 - 1s - loss: 1.0634 - accuracy: 0.6526 - val_loss: 1.8608 - val_accuracy: 0.4413 - 673ms/epoch - 4ms/step\n",
            "Epoch 39/100\n",
            "190/190 - 1s - loss: 1.0280 - accuracy: 0.6683 - val_loss: 1.8135 - val_accuracy: 0.4547 - 670ms/epoch - 4ms/step\n",
            "Epoch 40/100\n",
            "190/190 - 1s - loss: 1.0314 - accuracy: 0.6621 - val_loss: 1.8064 - val_accuracy: 0.4621 - 674ms/epoch - 4ms/step\n",
            "Epoch 41/100\n",
            "190/190 - 1s - loss: 1.0006 - accuracy: 0.6729 - val_loss: 1.8520 - val_accuracy: 0.4606 - 680ms/epoch - 4ms/step\n",
            "Epoch 42/100\n",
            "190/190 - 1s - loss: 0.9980 - accuracy: 0.6736 - val_loss: 1.8786 - val_accuracy: 0.4710 - 675ms/epoch - 4ms/step\n",
            "Epoch 43/100\n",
            "190/190 - 1s - loss: 0.9822 - accuracy: 0.6717 - val_loss: 1.7353 - val_accuracy: 0.4681 - 667ms/epoch - 4ms/step\n",
            "Epoch 44/100\n",
            "190/190 - 1s - loss: 1.0392 - accuracy: 0.6618 - val_loss: 1.6536 - val_accuracy: 0.4695 - 691ms/epoch - 4ms/step\n",
            "Epoch 45/100\n",
            "190/190 - 1s - loss: 1.0185 - accuracy: 0.6678 - val_loss: 1.7457 - val_accuracy: 0.4948 - 702ms/epoch - 4ms/step\n",
            "Epoch 46/100\n",
            "190/190 - 1s - loss: 1.0340 - accuracy: 0.6656 - val_loss: 1.7826 - val_accuracy: 0.4829 - 701ms/epoch - 4ms/step\n",
            "Epoch 47/100\n",
            "190/190 - 1s - loss: 0.9874 - accuracy: 0.6792 - val_loss: 1.8447 - val_accuracy: 0.4918 - 695ms/epoch - 4ms/step\n",
            "Epoch 48/100\n",
            "190/190 - 1s - loss: 0.9931 - accuracy: 0.6724 - val_loss: 1.7694 - val_accuracy: 0.4844 - 700ms/epoch - 4ms/step\n",
            "Epoch 49/100\n",
            "190/190 - 1s - loss: 0.9453 - accuracy: 0.6914 - val_loss: 1.7593 - val_accuracy: 0.5067 - 683ms/epoch - 4ms/step\n",
            "Epoch 50/100\n",
            "190/190 - 1s - loss: 0.9344 - accuracy: 0.6944 - val_loss: 1.7951 - val_accuracy: 0.4859 - 690ms/epoch - 4ms/step\n",
            "Epoch 51/100\n",
            "190/190 - 1s - loss: 0.9100 - accuracy: 0.6962 - val_loss: 1.8494 - val_accuracy: 0.4829 - 693ms/epoch - 4ms/step\n",
            "Epoch 52/100\n",
            "190/190 - 1s - loss: 1.0463 - accuracy: 0.6536 - val_loss: 1.8593 - val_accuracy: 0.4502 - 690ms/epoch - 4ms/step\n",
            "Epoch 53/100\n",
            "190/190 - 1s - loss: 0.9776 - accuracy: 0.6884 - val_loss: 1.7925 - val_accuracy: 0.4517 - 691ms/epoch - 4ms/step\n",
            "Epoch 54/100\n",
            "190/190 - 1s - loss: 1.0146 - accuracy: 0.6767 - val_loss: 1.7050 - val_accuracy: 0.5067 - 703ms/epoch - 4ms/step\n",
            "Epoch 55/100\n",
            "190/190 - 1s - loss: 0.9480 - accuracy: 0.6972 - val_loss: 1.7194 - val_accuracy: 0.4874 - 695ms/epoch - 4ms/step\n",
            "Epoch 56/100\n",
            "190/190 - 1s - loss: 0.9437 - accuracy: 0.6874 - val_loss: 1.8594 - val_accuracy: 0.4740 - 705ms/epoch - 4ms/step\n",
            "Epoch 57/100\n",
            "190/190 - 1s - loss: 0.9323 - accuracy: 0.7003 - val_loss: 1.8858 - val_accuracy: 0.4636 - 695ms/epoch - 4ms/step\n",
            "Epoch 58/100\n",
            "190/190 - 1s - loss: 0.9035 - accuracy: 0.7101 - val_loss: 1.8845 - val_accuracy: 0.4770 - 686ms/epoch - 4ms/step\n",
            "Epoch 59/100\n",
            "190/190 - 1s - loss: 0.9312 - accuracy: 0.6979 - val_loss: 2.0539 - val_accuracy: 0.4502 - 691ms/epoch - 4ms/step\n",
            "Epoch 60/100\n",
            "190/190 - 1s - loss: 0.8956 - accuracy: 0.7096 - val_loss: 1.8559 - val_accuracy: 0.4725 - 676ms/epoch - 4ms/step\n",
            "Epoch 61/100\n",
            "190/190 - 1s - loss: 0.9147 - accuracy: 0.7007 - val_loss: 2.0159 - val_accuracy: 0.4354 - 667ms/epoch - 4ms/step\n",
            "Epoch 62/100\n",
            "190/190 - 1s - loss: 0.9460 - accuracy: 0.6912 - val_loss: 1.8222 - val_accuracy: 0.4874 - 673ms/epoch - 4ms/step\n",
            "Epoch 63/100\n",
            "190/190 - 1s - loss: 0.9173 - accuracy: 0.7012 - val_loss: 1.6791 - val_accuracy: 0.5052 - 679ms/epoch - 4ms/step\n",
            "Epoch 64/100\n",
            "190/190 - 1s - loss: 0.8735 - accuracy: 0.7155 - val_loss: 1.8521 - val_accuracy: 0.4948 - 670ms/epoch - 4ms/step\n",
            "Epoch 65/100\n",
            "190/190 - 1s - loss: 0.8679 - accuracy: 0.7157 - val_loss: 1.7838 - val_accuracy: 0.5082 - 668ms/epoch - 4ms/step\n",
            "Epoch 66/100\n",
            "190/190 - 1s - loss: 0.8944 - accuracy: 0.7145 - val_loss: 1.7866 - val_accuracy: 0.4993 - 673ms/epoch - 4ms/step\n",
            "Epoch 67/100\n",
            "190/190 - 1s - loss: 0.8992 - accuracy: 0.7106 - val_loss: 1.8715 - val_accuracy: 0.4577 - 669ms/epoch - 4ms/step\n",
            "Epoch 68/100\n",
            "190/190 - 1s - loss: 0.8776 - accuracy: 0.7102 - val_loss: 1.8348 - val_accuracy: 0.4859 - 672ms/epoch - 4ms/step\n",
            "Epoch 69/100\n",
            "190/190 - 1s - loss: 1.0158 - accuracy: 0.6673 - val_loss: 1.7857 - val_accuracy: 0.4740 - 673ms/epoch - 4ms/step\n",
            "Epoch 70/100\n",
            "190/190 - 1s - loss: 0.9179 - accuracy: 0.7061 - val_loss: 1.8513 - val_accuracy: 0.4755 - 676ms/epoch - 4ms/step\n",
            "Epoch 71/100\n",
            "190/190 - 1s - loss: 0.8652 - accuracy: 0.7217 - val_loss: 1.9029 - val_accuracy: 0.4666 - 671ms/epoch - 4ms/step\n",
            "Epoch 72/100\n",
            "190/190 - 1s - loss: 0.8565 - accuracy: 0.7263 - val_loss: 1.7977 - val_accuracy: 0.4577 - 679ms/epoch - 4ms/step\n",
            "Epoch 73/100\n",
            "190/190 - 1s - loss: 0.8591 - accuracy: 0.7136 - val_loss: 1.8346 - val_accuracy: 0.4681 - 668ms/epoch - 4ms/step\n",
            "Epoch 74/100\n",
            "190/190 - 1s - loss: 0.8575 - accuracy: 0.7185 - val_loss: 1.9743 - val_accuracy: 0.4710 - 664ms/epoch - 3ms/step\n",
            "Epoch 75/100\n",
            "190/190 - 1s - loss: 0.8894 - accuracy: 0.7107 - val_loss: 1.9364 - val_accuracy: 0.4695 - 674ms/epoch - 4ms/step\n",
            "Epoch 76/100\n",
            "190/190 - 1s - loss: 0.8904 - accuracy: 0.7061 - val_loss: 1.7874 - val_accuracy: 0.4874 - 674ms/epoch - 4ms/step\n",
            "Epoch 77/100\n",
            "190/190 - 1s - loss: 0.8744 - accuracy: 0.7167 - val_loss: 1.8826 - val_accuracy: 0.4606 - 676ms/epoch - 4ms/step\n",
            "Epoch 78/100\n",
            "190/190 - 1s - loss: 0.8639 - accuracy: 0.7157 - val_loss: 1.9286 - val_accuracy: 0.4889 - 676ms/epoch - 4ms/step\n",
            "Epoch 79/100\n",
            "190/190 - 1s - loss: 0.8723 - accuracy: 0.7195 - val_loss: 2.0123 - val_accuracy: 0.4577 - 677ms/epoch - 4ms/step\n",
            "Epoch 80/100\n",
            "190/190 - 1s - loss: 0.8949 - accuracy: 0.7112 - val_loss: 1.9470 - val_accuracy: 0.4383 - 665ms/epoch - 3ms/step\n",
            "Epoch 81/100\n",
            "190/190 - 1s - loss: 0.8488 - accuracy: 0.7278 - val_loss: 1.8795 - val_accuracy: 0.4681 - 676ms/epoch - 4ms/step\n",
            "Epoch 82/100\n",
            "190/190 - 1s - loss: 0.8400 - accuracy: 0.7241 - val_loss: 1.9498 - val_accuracy: 0.4844 - 677ms/epoch - 4ms/step\n",
            "Epoch 83/100\n",
            "190/190 - 1s - loss: 0.8822 - accuracy: 0.7188 - val_loss: 1.9188 - val_accuracy: 0.4785 - 666ms/epoch - 4ms/step\n",
            "Epoch 84/100\n",
            "190/190 - 1s - loss: 0.8697 - accuracy: 0.7197 - val_loss: 1.8584 - val_accuracy: 0.4695 - 672ms/epoch - 4ms/step\n",
            "Epoch 85/100\n",
            "190/190 - 1s - loss: 0.8378 - accuracy: 0.7221 - val_loss: 1.8916 - val_accuracy: 0.4636 - 678ms/epoch - 4ms/step\n",
            "Epoch 86/100\n",
            "190/190 - 1s - loss: 0.8227 - accuracy: 0.7344 - val_loss: 1.8808 - val_accuracy: 0.4695 - 681ms/epoch - 4ms/step\n",
            "Epoch 87/100\n",
            "190/190 - 1s - loss: 0.8435 - accuracy: 0.7264 - val_loss: 2.0173 - val_accuracy: 0.4279 - 669ms/epoch - 4ms/step\n",
            "Epoch 88/100\n",
            "190/190 - 1s - loss: 0.8390 - accuracy: 0.7286 - val_loss: 1.8329 - val_accuracy: 0.4859 - 667ms/epoch - 4ms/step\n",
            "Epoch 89/100\n",
            "190/190 - 1s - loss: 0.8606 - accuracy: 0.7207 - val_loss: 1.9681 - val_accuracy: 0.4889 - 689ms/epoch - 4ms/step\n",
            "Epoch 90/100\n",
            "190/190 - 1s - loss: 0.8347 - accuracy: 0.7269 - val_loss: 1.8573 - val_accuracy: 0.4844 - 687ms/epoch - 4ms/step\n",
            "Epoch 91/100\n",
            "190/190 - 1s - loss: 0.8325 - accuracy: 0.7261 - val_loss: 1.9660 - val_accuracy: 0.4889 - 674ms/epoch - 4ms/step\n",
            "Epoch 92/100\n",
            "190/190 - 1s - loss: 0.8108 - accuracy: 0.7354 - val_loss: 1.9819 - val_accuracy: 0.4874 - 672ms/epoch - 4ms/step\n",
            "Epoch 93/100\n",
            "190/190 - 1s - loss: 0.8229 - accuracy: 0.7337 - val_loss: 2.0124 - val_accuracy: 0.4829 - 680ms/epoch - 4ms/step\n",
            "Epoch 94/100\n",
            "190/190 - 1s - loss: 0.7978 - accuracy: 0.7445 - val_loss: 1.9868 - val_accuracy: 0.4993 - 664ms/epoch - 3ms/step\n",
            "Epoch 95/100\n",
            "190/190 - 1s - loss: 0.8373 - accuracy: 0.7245 - val_loss: 1.9657 - val_accuracy: 0.4681 - 666ms/epoch - 4ms/step\n",
            "Epoch 96/100\n",
            "190/190 - 1s - loss: 0.8006 - accuracy: 0.7370 - val_loss: 2.0006 - val_accuracy: 0.4903 - 669ms/epoch - 4ms/step\n",
            "Epoch 97/100\n",
            "190/190 - 1s - loss: 0.7739 - accuracy: 0.7420 - val_loss: 1.8775 - val_accuracy: 0.5022 - 673ms/epoch - 4ms/step\n",
            "Epoch 98/100\n",
            "190/190 - 1s - loss: 0.8207 - accuracy: 0.7331 - val_loss: 1.9894 - val_accuracy: 0.4695 - 666ms/epoch - 4ms/step\n",
            "Epoch 99/100\n",
            "190/190 - 1s - loss: 0.8116 - accuracy: 0.7463 - val_loss: 1.8736 - val_accuracy: 0.4547 - 683ms/epoch - 4ms/step\n",
            "Epoch 100/100\n",
            "190/190 - 1s - loss: 0.8455 - accuracy: 0.7281 - val_loss: 2.0397 - val_accuracy: 0.4577 - 670ms/epoch - 4ms/step\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " reshape (Reshape)           (None, 128, 40)           0         \n",
            "                                                                 \n",
            " conv1d (Conv1D)             (None, 124, 12)           2412      \n",
            "                                                                 \n",
            " max_pooling1d (MaxPooling1D  (None, 62, 12)           0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv1d_1 (Conv1D)           (None, 58, 28)            1708      \n",
            "                                                                 \n",
            " max_pooling1d_1 (MaxPooling  (None, 29, 28)           0         \n",
            " 1D)                                                             \n",
            "                                                                 \n",
            " dense (Dense)               (None, 29, 30)            870       \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 29, 30)            0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 870)               0         \n",
            "                                                                 \n",
            " y_pred (Dense)              (None, 10)                8710      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 13,700\n",
            "Trainable params: 13,700\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Result of fold:1\n",
            "24/24 [==============================] - 0s 5ms/step - loss: 2.3317 - accuracy: 0.4225\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 10%|█         | 1/10 [01:22<12:24, 82.70s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "190/190 - 2s - loss: 2.3361 - accuracy: 0.2629 - val_loss: 1.9859 - val_accuracy: 0.3131 - 2s/epoch - 8ms/step\n",
            "Epoch 2/100\n",
            "190/190 - 1s - loss: 1.7791 - accuracy: 0.3629 - val_loss: 1.7525 - val_accuracy: 0.3338 - 668ms/epoch - 4ms/step\n",
            "Epoch 3/100\n",
            "190/190 - 1s - loss: 1.6390 - accuracy: 0.4171 - val_loss: 1.6981 - val_accuracy: 0.4466 - 676ms/epoch - 4ms/step\n",
            "Epoch 4/100\n",
            "190/190 - 1s - loss: 1.5871 - accuracy: 0.4349 - val_loss: 1.6827 - val_accuracy: 0.3591 - 681ms/epoch - 4ms/step\n",
            "Epoch 5/100\n",
            "190/190 - 1s - loss: 1.5454 - accuracy: 0.4611 - val_loss: 1.5122 - val_accuracy: 0.4926 - 686ms/epoch - 4ms/step\n",
            "Epoch 6/100\n",
            "190/190 - 1s - loss: 1.4656 - accuracy: 0.4875 - val_loss: 1.6017 - val_accuracy: 0.3783 - 674ms/epoch - 4ms/step\n",
            "Epoch 7/100\n",
            "190/190 - 1s - loss: 1.5256 - accuracy: 0.4770 - val_loss: 1.6325 - val_accuracy: 0.3412 - 684ms/epoch - 4ms/step\n",
            "Epoch 8/100\n",
            "190/190 - 1s - loss: 1.4252 - accuracy: 0.5026 - val_loss: 1.6488 - val_accuracy: 0.4570 - 668ms/epoch - 4ms/step\n",
            "Epoch 9/100\n",
            "190/190 - 1s - loss: 1.4347 - accuracy: 0.5238 - val_loss: 1.5293 - val_accuracy: 0.4347 - 677ms/epoch - 4ms/step\n",
            "Epoch 10/100\n",
            "190/190 - 1s - loss: 1.3466 - accuracy: 0.5389 - val_loss: 1.6278 - val_accuracy: 0.4318 - 679ms/epoch - 4ms/step\n",
            "Epoch 11/100\n",
            "190/190 - 1s - loss: 1.3733 - accuracy: 0.5410 - val_loss: 1.6060 - val_accuracy: 0.4332 - 687ms/epoch - 4ms/step\n",
            "Epoch 12/100\n",
            "190/190 - 1s - loss: 1.3278 - accuracy: 0.5603 - val_loss: 1.5307 - val_accuracy: 0.4644 - 685ms/epoch - 4ms/step\n",
            "Epoch 13/100\n",
            "190/190 - 1s - loss: 1.2612 - accuracy: 0.5760 - val_loss: 1.5627 - val_accuracy: 0.5074 - 680ms/epoch - 4ms/step\n",
            "Epoch 14/100\n",
            "190/190 - 1s - loss: 1.2153 - accuracy: 0.5991 - val_loss: 1.6562 - val_accuracy: 0.4481 - 668ms/epoch - 4ms/step\n",
            "Epoch 15/100\n",
            "190/190 - 1s - loss: 1.1947 - accuracy: 0.6057 - val_loss: 1.5034 - val_accuracy: 0.5237 - 668ms/epoch - 4ms/step\n",
            "Epoch 16/100\n",
            "190/190 - 1s - loss: 1.1460 - accuracy: 0.6247 - val_loss: 1.5354 - val_accuracy: 0.5326 - 682ms/epoch - 4ms/step\n",
            "Epoch 17/100\n",
            "190/190 - 1s - loss: 1.2008 - accuracy: 0.6196 - val_loss: 1.5955 - val_accuracy: 0.4214 - 670ms/epoch - 4ms/step\n",
            "Epoch 18/100\n",
            "190/190 - 1s - loss: 1.1712 - accuracy: 0.6197 - val_loss: 1.6015 - val_accuracy: 0.5104 - 676ms/epoch - 4ms/step\n",
            "Epoch 19/100\n",
            "190/190 - 1s - loss: 1.1366 - accuracy: 0.6275 - val_loss: 1.6238 - val_accuracy: 0.4955 - 670ms/epoch - 4ms/step\n",
            "Epoch 20/100\n",
            "190/190 - 1s - loss: 1.1112 - accuracy: 0.6334 - val_loss: 1.6239 - val_accuracy: 0.4674 - 671ms/epoch - 4ms/step\n",
            "Epoch 21/100\n",
            "190/190 - 1s - loss: 1.1126 - accuracy: 0.6364 - val_loss: 1.7117 - val_accuracy: 0.4896 - 675ms/epoch - 4ms/step\n",
            "Epoch 22/100\n",
            "190/190 - 1s - loss: 1.0751 - accuracy: 0.6481 - val_loss: 1.6489 - val_accuracy: 0.4985 - 709ms/epoch - 4ms/step\n",
            "Epoch 23/100\n",
            "190/190 - 1s - loss: 1.0870 - accuracy: 0.6412 - val_loss: 1.7249 - val_accuracy: 0.4718 - 686ms/epoch - 4ms/step\n",
            "Epoch 24/100\n",
            "190/190 - 1s - loss: 1.0358 - accuracy: 0.6607 - val_loss: 1.6596 - val_accuracy: 0.4792 - 690ms/epoch - 4ms/step\n",
            "Epoch 25/100\n",
            "190/190 - 1s - loss: 1.0373 - accuracy: 0.6593 - val_loss: 1.8605 - val_accuracy: 0.4748 - 699ms/epoch - 4ms/step\n",
            "Epoch 26/100\n",
            "190/190 - 1s - loss: 1.0496 - accuracy: 0.6638 - val_loss: 1.6618 - val_accuracy: 0.5000 - 690ms/epoch - 4ms/step\n",
            "Epoch 27/100\n",
            "190/190 - 1s - loss: 1.0488 - accuracy: 0.6618 - val_loss: 1.7310 - val_accuracy: 0.5178 - 704ms/epoch - 4ms/step\n",
            "Epoch 28/100\n",
            "190/190 - 1s - loss: 1.0414 - accuracy: 0.6699 - val_loss: 1.7685 - val_accuracy: 0.5312 - 696ms/epoch - 4ms/step\n",
            "Epoch 29/100\n",
            "190/190 - 1s - loss: 1.0474 - accuracy: 0.6618 - val_loss: 1.5600 - val_accuracy: 0.5163 - 698ms/epoch - 4ms/step\n",
            "Epoch 30/100\n",
            "190/190 - 1s - loss: 1.1829 - accuracy: 0.6219 - val_loss: 1.6355 - val_accuracy: 0.4985 - 682ms/epoch - 4ms/step\n",
            "Epoch 31/100\n",
            "190/190 - 1s - loss: 1.1167 - accuracy: 0.6415 - val_loss: 1.7958 - val_accuracy: 0.4303 - 682ms/epoch - 4ms/step\n",
            "Epoch 32/100\n",
            "190/190 - 1s - loss: 1.0403 - accuracy: 0.6684 - val_loss: 1.8216 - val_accuracy: 0.5193 - 674ms/epoch - 4ms/step\n",
            "Epoch 33/100\n",
            "190/190 - 1s - loss: 1.0081 - accuracy: 0.6815 - val_loss: 1.7487 - val_accuracy: 0.4985 - 673ms/epoch - 4ms/step\n",
            "Epoch 34/100\n",
            "190/190 - 1s - loss: 1.0736 - accuracy: 0.6580 - val_loss: 1.7955 - val_accuracy: 0.4674 - 680ms/epoch - 4ms/step\n",
            "Epoch 35/100\n",
            "190/190 - 1s - loss: 1.0320 - accuracy: 0.6696 - val_loss: 1.7678 - val_accuracy: 0.5104 - 678ms/epoch - 4ms/step\n",
            "Epoch 36/100\n",
            "190/190 - 1s - loss: 1.0198 - accuracy: 0.6729 - val_loss: 1.6802 - val_accuracy: 0.5401 - 690ms/epoch - 4ms/step\n",
            "Epoch 37/100\n",
            "190/190 - 1s - loss: 1.0510 - accuracy: 0.6688 - val_loss: 1.6770 - val_accuracy: 0.5341 - 678ms/epoch - 4ms/step\n",
            "Epoch 38/100\n",
            "190/190 - 1s - loss: 0.9799 - accuracy: 0.6825 - val_loss: 1.8931 - val_accuracy: 0.5015 - 683ms/epoch - 4ms/step\n",
            "Epoch 39/100\n",
            "190/190 - 1s - loss: 0.9825 - accuracy: 0.6892 - val_loss: 1.7871 - val_accuracy: 0.5059 - 674ms/epoch - 4ms/step\n",
            "Epoch 40/100\n",
            "190/190 - 1s - loss: 0.9625 - accuracy: 0.7000 - val_loss: 1.8111 - val_accuracy: 0.5178 - 680ms/epoch - 4ms/step\n",
            "Epoch 41/100\n",
            "190/190 - 1s - loss: 0.9833 - accuracy: 0.6881 - val_loss: 1.6208 - val_accuracy: 0.5282 - 683ms/epoch - 4ms/step\n",
            "Epoch 42/100\n",
            "190/190 - 1s - loss: 0.9148 - accuracy: 0.7069 - val_loss: 1.6904 - val_accuracy: 0.5134 - 680ms/epoch - 4ms/step\n",
            "Epoch 43/100\n",
            "190/190 - 1s - loss: 0.9686 - accuracy: 0.6948 - val_loss: 1.7341 - val_accuracy: 0.4941 - 681ms/epoch - 4ms/step\n",
            "Epoch 44/100\n",
            "190/190 - 1s - loss: 0.9532 - accuracy: 0.6904 - val_loss: 1.7980 - val_accuracy: 0.5282 - 678ms/epoch - 4ms/step\n",
            "Epoch 45/100\n",
            "190/190 - 1s - loss: 0.9813 - accuracy: 0.6955 - val_loss: 1.7010 - val_accuracy: 0.5252 - 672ms/epoch - 4ms/step\n",
            "Epoch 46/100\n",
            "190/190 - 1s - loss: 0.9719 - accuracy: 0.7003 - val_loss: 1.7032 - val_accuracy: 0.5074 - 686ms/epoch - 4ms/step\n",
            "Epoch 47/100\n",
            "190/190 - 1s - loss: 0.9591 - accuracy: 0.6960 - val_loss: 1.7009 - val_accuracy: 0.5134 - 689ms/epoch - 4ms/step\n",
            "Epoch 48/100\n",
            "190/190 - 1s - loss: 0.9396 - accuracy: 0.6973 - val_loss: 1.8046 - val_accuracy: 0.5208 - 681ms/epoch - 4ms/step\n",
            "Epoch 49/100\n",
            "190/190 - 1s - loss: 0.9765 - accuracy: 0.6920 - val_loss: 1.9824 - val_accuracy: 0.4555 - 691ms/epoch - 4ms/step\n",
            "Epoch 50/100\n",
            "190/190 - 1s - loss: 0.9301 - accuracy: 0.7011 - val_loss: 1.7515 - val_accuracy: 0.5223 - 680ms/epoch - 4ms/step\n",
            "Epoch 51/100\n",
            "190/190 - 1s - loss: 0.9253 - accuracy: 0.7090 - val_loss: 1.8436 - val_accuracy: 0.5193 - 684ms/epoch - 4ms/step\n",
            "Epoch 52/100\n",
            "190/190 - 1s - loss: 0.8988 - accuracy: 0.7183 - val_loss: 1.8215 - val_accuracy: 0.4955 - 679ms/epoch - 4ms/step\n",
            "Epoch 53/100\n",
            "190/190 - 1s - loss: 0.9112 - accuracy: 0.7141 - val_loss: 1.8373 - val_accuracy: 0.5030 - 684ms/epoch - 4ms/step\n",
            "Epoch 54/100\n",
            "190/190 - 1s - loss: 0.9289 - accuracy: 0.7046 - val_loss: 1.9026 - val_accuracy: 0.5178 - 680ms/epoch - 4ms/step\n",
            "Epoch 55/100\n",
            "190/190 - 1s - loss: 0.9550 - accuracy: 0.7008 - val_loss: 1.8252 - val_accuracy: 0.4733 - 683ms/epoch - 4ms/step\n",
            "Epoch 56/100\n",
            "190/190 - 1s - loss: 0.9205 - accuracy: 0.7112 - val_loss: 2.0006 - val_accuracy: 0.4955 - 689ms/epoch - 4ms/step\n",
            "Epoch 57/100\n",
            "190/190 - 1s - loss: 0.9183 - accuracy: 0.7132 - val_loss: 1.8482 - val_accuracy: 0.4748 - 677ms/epoch - 4ms/step\n",
            "Epoch 58/100\n",
            "190/190 - 1s - loss: 0.9250 - accuracy: 0.7079 - val_loss: 1.7526 - val_accuracy: 0.5089 - 677ms/epoch - 4ms/step\n",
            "Epoch 59/100\n",
            "190/190 - 1s - loss: 0.9430 - accuracy: 0.6976 - val_loss: 1.9806 - val_accuracy: 0.4585 - 687ms/epoch - 4ms/step\n",
            "Epoch 60/100\n",
            "190/190 - 1s - loss: 0.9461 - accuracy: 0.7041 - val_loss: 1.9542 - val_accuracy: 0.5119 - 686ms/epoch - 4ms/step\n",
            "Epoch 61/100\n",
            "190/190 - 1s - loss: 0.9496 - accuracy: 0.6998 - val_loss: 1.9203 - val_accuracy: 0.5074 - 693ms/epoch - 4ms/step\n",
            "Epoch 62/100\n",
            "190/190 - 1s - loss: 0.9347 - accuracy: 0.7067 - val_loss: 1.9839 - val_accuracy: 0.4985 - 676ms/epoch - 4ms/step\n",
            "Epoch 63/100\n",
            "190/190 - 1s - loss: 0.9116 - accuracy: 0.7150 - val_loss: 1.8292 - val_accuracy: 0.4792 - 678ms/epoch - 4ms/step\n",
            "Epoch 64/100\n",
            "190/190 - 1s - loss: 0.9956 - accuracy: 0.6933 - val_loss: 1.8965 - val_accuracy: 0.4614 - 726ms/epoch - 4ms/step\n",
            "Epoch 65/100\n",
            "190/190 - 1s - loss: 0.9562 - accuracy: 0.6966 - val_loss: 1.6720 - val_accuracy: 0.5045 - 759ms/epoch - 4ms/step\n",
            "Epoch 66/100\n",
            "190/190 - 1s - loss: 0.8961 - accuracy: 0.7107 - val_loss: 2.1177 - val_accuracy: 0.4436 - 775ms/epoch - 4ms/step\n",
            "Epoch 67/100\n",
            "190/190 - 1s - loss: 0.9267 - accuracy: 0.7042 - val_loss: 2.0565 - val_accuracy: 0.4377 - 707ms/epoch - 4ms/step\n",
            "Epoch 68/100\n",
            "190/190 - 1s - loss: 1.1437 - accuracy: 0.6948 - val_loss: 1.8675 - val_accuracy: 0.5326 - 694ms/epoch - 4ms/step\n",
            "Epoch 69/100\n",
            "190/190 - 1s - loss: 0.9302 - accuracy: 0.7141 - val_loss: 1.9254 - val_accuracy: 0.4985 - 687ms/epoch - 4ms/step\n",
            "Epoch 70/100\n",
            "190/190 - 1s - loss: 0.8782 - accuracy: 0.7194 - val_loss: 1.8759 - val_accuracy: 0.4822 - 690ms/epoch - 4ms/step\n",
            "Epoch 71/100\n",
            "190/190 - 1s - loss: 0.8931 - accuracy: 0.7145 - val_loss: 1.9284 - val_accuracy: 0.4911 - 694ms/epoch - 4ms/step\n",
            "Epoch 72/100\n",
            "190/190 - 1s - loss: 0.8585 - accuracy: 0.7211 - val_loss: 1.9036 - val_accuracy: 0.4985 - 688ms/epoch - 4ms/step\n",
            "Epoch 73/100\n",
            "190/190 - 1s - loss: 0.8948 - accuracy: 0.7211 - val_loss: 1.9551 - val_accuracy: 0.4807 - 687ms/epoch - 4ms/step\n",
            "Epoch 74/100\n",
            "190/190 - 1s - loss: 0.8592 - accuracy: 0.7209 - val_loss: 1.9742 - val_accuracy: 0.4748 - 697ms/epoch - 4ms/step\n",
            "Epoch 75/100\n",
            "190/190 - 1s - loss: 0.8698 - accuracy: 0.7242 - val_loss: 2.0609 - val_accuracy: 0.4837 - 684ms/epoch - 4ms/step\n",
            "Epoch 76/100\n",
            "190/190 - 1s - loss: 0.8194 - accuracy: 0.7410 - val_loss: 2.0012 - val_accuracy: 0.4659 - 687ms/epoch - 4ms/step\n",
            "Epoch 77/100\n",
            "190/190 - 1s - loss: 0.9239 - accuracy: 0.7221 - val_loss: 1.9687 - val_accuracy: 0.4822 - 686ms/epoch - 4ms/step\n",
            "Epoch 78/100\n",
            "190/190 - 1s - loss: 0.8821 - accuracy: 0.7277 - val_loss: 2.0414 - val_accuracy: 0.4777 - 686ms/epoch - 4ms/step\n",
            "Epoch 79/100\n",
            "190/190 - 1s - loss: 0.9069 - accuracy: 0.7166 - val_loss: 2.0847 - val_accuracy: 0.4748 - 675ms/epoch - 4ms/step\n",
            "Epoch 80/100\n",
            "190/190 - 1s - loss: 0.8577 - accuracy: 0.7406 - val_loss: 1.9215 - val_accuracy: 0.4629 - 674ms/epoch - 4ms/step\n",
            "Epoch 81/100\n",
            "190/190 - 1s - loss: 0.8878 - accuracy: 0.7273 - val_loss: 1.9490 - val_accuracy: 0.4733 - 679ms/epoch - 4ms/step\n",
            "Epoch 82/100\n",
            "190/190 - 1s - loss: 0.8370 - accuracy: 0.7406 - val_loss: 1.8929 - val_accuracy: 0.4822 - 681ms/epoch - 4ms/step\n",
            "Epoch 83/100\n",
            "190/190 - 1s - loss: 0.8945 - accuracy: 0.7189 - val_loss: 2.0692 - val_accuracy: 0.3872 - 680ms/epoch - 4ms/step\n",
            "Epoch 84/100\n",
            "190/190 - 1s - loss: 1.0362 - accuracy: 0.6775 - val_loss: 1.8998 - val_accuracy: 0.4733 - 675ms/epoch - 4ms/step\n",
            "Epoch 85/100\n",
            "190/190 - 1s - loss: 0.9144 - accuracy: 0.7120 - val_loss: 1.8861 - val_accuracy: 0.4510 - 687ms/epoch - 4ms/step\n",
            "Epoch 86/100\n",
            "190/190 - 1s - loss: 0.8959 - accuracy: 0.7085 - val_loss: 2.0990 - val_accuracy: 0.4718 - 671ms/epoch - 4ms/step\n",
            "Epoch 87/100\n",
            "190/190 - 1s - loss: 0.8769 - accuracy: 0.7264 - val_loss: 1.9212 - val_accuracy: 0.4748 - 675ms/epoch - 4ms/step\n",
            "Epoch 88/100\n",
            "190/190 - 1s - loss: 1.0430 - accuracy: 0.6851 - val_loss: 1.9544 - val_accuracy: 0.4614 - 686ms/epoch - 4ms/step\n",
            "Epoch 89/100\n",
            "190/190 - 1s - loss: 0.9060 - accuracy: 0.7084 - val_loss: 1.9157 - val_accuracy: 0.4763 - 669ms/epoch - 4ms/step\n",
            "Epoch 90/100\n",
            "190/190 - 1s - loss: 1.0241 - accuracy: 0.7023 - val_loss: 1.9477 - val_accuracy: 0.4733 - 683ms/epoch - 4ms/step\n",
            "Epoch 91/100\n",
            "190/190 - 1s - loss: 0.9726 - accuracy: 0.6882 - val_loss: 1.8402 - val_accuracy: 0.4985 - 673ms/epoch - 4ms/step\n",
            "Epoch 92/100\n",
            "190/190 - 1s - loss: 0.9175 - accuracy: 0.7140 - val_loss: 2.0087 - val_accuracy: 0.5074 - 674ms/epoch - 4ms/step\n",
            "Epoch 93/100\n",
            "190/190 - 1s - loss: 0.9018 - accuracy: 0.7234 - val_loss: 2.1860 - val_accuracy: 0.4837 - 666ms/epoch - 4ms/step\n",
            "Epoch 94/100\n",
            "190/190 - 1s - loss: 0.9699 - accuracy: 0.7232 - val_loss: 1.9691 - val_accuracy: 0.4436 - 677ms/epoch - 4ms/step\n",
            "Epoch 95/100\n",
            "190/190 - 1s - loss: 0.9701 - accuracy: 0.6962 - val_loss: 2.0662 - val_accuracy: 0.4614 - 673ms/epoch - 4ms/step\n",
            "Epoch 96/100\n",
            "190/190 - 1s - loss: 0.9361 - accuracy: 0.7014 - val_loss: 2.1383 - val_accuracy: 0.4303 - 674ms/epoch - 4ms/step\n",
            "Epoch 97/100\n",
            "190/190 - 1s - loss: 0.8997 - accuracy: 0.7107 - val_loss: 2.1239 - val_accuracy: 0.4273 - 673ms/epoch - 4ms/step\n",
            "Epoch 98/100\n",
            "190/190 - 1s - loss: 0.8894 - accuracy: 0.7178 - val_loss: 2.1653 - val_accuracy: 0.4970 - 691ms/epoch - 4ms/step\n",
            "Epoch 99/100\n",
            "190/190 - 1s - loss: 0.8454 - accuracy: 0.7305 - val_loss: 2.2472 - val_accuracy: 0.4496 - 695ms/epoch - 4ms/step\n",
            "Epoch 100/100\n",
            "190/190 - 1s - loss: 0.8508 - accuracy: 0.7323 - val_loss: 2.1985 - val_accuracy: 0.4436 - 694ms/epoch - 4ms/step\n",
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " reshape_2 (Reshape)         (None, 128, 40)           0         \n",
            "                                                                 \n",
            " conv1d_4 (Conv1D)           (None, 124, 12)           2412      \n",
            "                                                                 \n",
            " max_pooling1d_4 (MaxPooling  (None, 62, 12)           0         \n",
            " 1D)                                                             \n",
            "                                                                 \n",
            " conv1d_5 (Conv1D)           (None, 58, 28)            1708      \n",
            "                                                                 \n",
            " max_pooling1d_5 (MaxPooling  (None, 29, 28)           0         \n",
            " 1D)                                                             \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 29, 30)            870       \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 29, 30)            0         \n",
            "                                                                 \n",
            " flatten_2 (Flatten)         (None, 870)               0         \n",
            "                                                                 \n",
            " y_pred (Dense)              (None, 10)                8710      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 13,700\n",
            "Trainable params: 13,700\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Result of fold:2\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 1.8076 - accuracy: 0.4443\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 20%|██        | 2/10 [02:33<10:03, 75.48s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "188/188 - 2s - loss: 2.1910 - accuracy: 0.2824 - val_loss: 1.6982 - val_accuracy: 0.4063 - 2s/epoch - 8ms/step\n",
            "Epoch 2/100\n",
            "188/188 - 1s - loss: 1.7049 - accuracy: 0.3761 - val_loss: 1.6377 - val_accuracy: 0.3823 - 661ms/epoch - 4ms/step\n",
            "Epoch 3/100\n",
            "188/188 - 1s - loss: 1.6117 - accuracy: 0.4186 - val_loss: 1.6762 - val_accuracy: 0.3673 - 673ms/epoch - 4ms/step\n",
            "Epoch 4/100\n",
            "188/188 - 1s - loss: 1.6214 - accuracy: 0.4101 - val_loss: 1.6969 - val_accuracy: 0.4078 - 654ms/epoch - 3ms/step\n",
            "Epoch 5/100\n",
            "188/188 - 1s - loss: 1.5163 - accuracy: 0.4640 - val_loss: 1.5941 - val_accuracy: 0.4708 - 663ms/epoch - 4ms/step\n",
            "Epoch 6/100\n",
            "188/188 - 1s - loss: 1.4499 - accuracy: 0.4942 - val_loss: 1.5543 - val_accuracy: 0.4843 - 668ms/epoch - 4ms/step\n",
            "Epoch 7/100\n",
            "188/188 - 1s - loss: 1.4274 - accuracy: 0.4995 - val_loss: 1.6416 - val_accuracy: 0.4438 - 679ms/epoch - 4ms/step\n",
            "Epoch 8/100\n",
            "188/188 - 1s - loss: 1.4132 - accuracy: 0.5135 - val_loss: 1.6902 - val_accuracy: 0.4123 - 659ms/epoch - 4ms/step\n",
            "Epoch 9/100\n",
            "188/188 - 1s - loss: 1.4643 - accuracy: 0.5015 - val_loss: 1.7320 - val_accuracy: 0.4393 - 657ms/epoch - 3ms/step\n",
            "Epoch 10/100\n",
            "188/188 - 1s - loss: 1.3655 - accuracy: 0.5342 - val_loss: 1.6651 - val_accuracy: 0.4678 - 661ms/epoch - 4ms/step\n",
            "Epoch 11/100\n",
            "188/188 - 1s - loss: 1.4013 - accuracy: 0.5309 - val_loss: 1.6327 - val_accuracy: 0.4573 - 662ms/epoch - 4ms/step\n",
            "Epoch 12/100\n",
            "188/188 - 1s - loss: 1.3150 - accuracy: 0.5525 - val_loss: 1.6796 - val_accuracy: 0.4708 - 668ms/epoch - 4ms/step\n",
            "Epoch 13/100\n",
            "188/188 - 1s - loss: 1.2791 - accuracy: 0.5624 - val_loss: 1.6892 - val_accuracy: 0.4228 - 670ms/epoch - 4ms/step\n",
            "Epoch 14/100\n",
            "188/188 - 1s - loss: 1.2445 - accuracy: 0.5797 - val_loss: 1.6246 - val_accuracy: 0.4843 - 671ms/epoch - 4ms/step\n",
            "Epoch 15/100\n",
            "188/188 - 1s - loss: 1.2509 - accuracy: 0.5715 - val_loss: 1.6301 - val_accuracy: 0.5022 - 670ms/epoch - 4ms/step\n",
            "Epoch 16/100\n",
            "188/188 - 1s - loss: 1.1902 - accuracy: 0.5999 - val_loss: 1.8486 - val_accuracy: 0.4498 - 692ms/epoch - 4ms/step\n",
            "Epoch 17/100\n",
            "188/188 - 1s - loss: 1.1804 - accuracy: 0.6077 - val_loss: 1.6983 - val_accuracy: 0.4678 - 667ms/epoch - 4ms/step\n",
            "Epoch 18/100\n",
            "188/188 - 1s - loss: 1.1393 - accuracy: 0.6167 - val_loss: 1.6527 - val_accuracy: 0.4678 - 675ms/epoch - 4ms/step\n",
            "Epoch 19/100\n",
            "188/188 - 1s - loss: 1.1242 - accuracy: 0.6253 - val_loss: 1.6999 - val_accuracy: 0.4633 - 669ms/epoch - 4ms/step\n",
            "Epoch 20/100\n",
            "188/188 - 1s - loss: 1.1124 - accuracy: 0.6346 - val_loss: 1.6624 - val_accuracy: 0.5172 - 671ms/epoch - 4ms/step\n",
            "Epoch 21/100\n",
            "188/188 - 1s - loss: 1.1102 - accuracy: 0.6319 - val_loss: 1.7150 - val_accuracy: 0.4648 - 670ms/epoch - 4ms/step\n",
            "Epoch 22/100\n",
            "188/188 - 1s - loss: 1.1272 - accuracy: 0.6261 - val_loss: 1.6591 - val_accuracy: 0.4573 - 676ms/epoch - 4ms/step\n",
            "Epoch 23/100\n",
            "188/188 - 1s - loss: 1.1134 - accuracy: 0.6338 - val_loss: 1.9049 - val_accuracy: 0.4468 - 675ms/epoch - 4ms/step\n",
            "Epoch 24/100\n",
            "188/188 - 1s - loss: 1.1098 - accuracy: 0.6331 - val_loss: 1.8067 - val_accuracy: 0.4393 - 663ms/epoch - 4ms/step\n",
            "Epoch 25/100\n",
            "188/188 - 1s - loss: 1.1161 - accuracy: 0.6273 - val_loss: 1.6420 - val_accuracy: 0.5022 - 669ms/epoch - 4ms/step\n",
            "Epoch 26/100\n",
            "188/188 - 1s - loss: 1.1420 - accuracy: 0.6224 - val_loss: 1.8708 - val_accuracy: 0.3673 - 665ms/epoch - 4ms/step\n",
            "Epoch 27/100\n",
            "188/188 - 1s - loss: 1.1068 - accuracy: 0.6313 - val_loss: 1.9607 - val_accuracy: 0.4498 - 681ms/epoch - 4ms/step\n",
            "Epoch 28/100\n",
            "188/188 - 1s - loss: 1.1023 - accuracy: 0.6416 - val_loss: 1.6280 - val_accuracy: 0.5142 - 679ms/epoch - 4ms/step\n",
            "Epoch 29/100\n",
            "188/188 - 1s - loss: 1.0999 - accuracy: 0.6424 - val_loss: 1.6846 - val_accuracy: 0.5082 - 672ms/epoch - 4ms/step\n",
            "Epoch 30/100\n",
            "188/188 - 1s - loss: 1.0790 - accuracy: 0.6448 - val_loss: 1.6482 - val_accuracy: 0.5247 - 668ms/epoch - 4ms/step\n",
            "Epoch 31/100\n",
            "188/188 - 1s - loss: 1.0401 - accuracy: 0.6576 - val_loss: 1.6820 - val_accuracy: 0.5172 - 683ms/epoch - 4ms/step\n",
            "Epoch 32/100\n",
            "188/188 - 1s - loss: 1.0400 - accuracy: 0.6581 - val_loss: 1.6329 - val_accuracy: 0.5082 - 656ms/epoch - 3ms/step\n",
            "Epoch 33/100\n",
            "188/188 - 1s - loss: 1.0112 - accuracy: 0.6651 - val_loss: 1.6850 - val_accuracy: 0.5352 - 663ms/epoch - 4ms/step\n",
            "Epoch 34/100\n",
            "188/188 - 1s - loss: 1.0065 - accuracy: 0.6633 - val_loss: 1.6657 - val_accuracy: 0.4903 - 676ms/epoch - 4ms/step\n",
            "Epoch 35/100\n",
            "188/188 - 1s - loss: 1.0602 - accuracy: 0.6631 - val_loss: 1.5936 - val_accuracy: 0.4993 - 670ms/epoch - 4ms/step\n",
            "Epoch 36/100\n",
            "188/188 - 1s - loss: 1.0685 - accuracy: 0.6478 - val_loss: 1.8105 - val_accuracy: 0.4498 - 671ms/epoch - 4ms/step\n",
            "Epoch 37/100\n",
            "188/188 - 1s - loss: 1.0231 - accuracy: 0.6623 - val_loss: 1.7554 - val_accuracy: 0.4633 - 674ms/epoch - 4ms/step\n",
            "Epoch 38/100\n",
            "188/188 - 1s - loss: 1.0090 - accuracy: 0.6661 - val_loss: 1.7666 - val_accuracy: 0.4918 - 669ms/epoch - 4ms/step\n",
            "Epoch 39/100\n",
            "188/188 - 1s - loss: 1.0420 - accuracy: 0.6548 - val_loss: 1.8926 - val_accuracy: 0.4258 - 666ms/epoch - 4ms/step\n",
            "Epoch 40/100\n",
            "188/188 - 1s - loss: 1.0218 - accuracy: 0.6584 - val_loss: 1.9027 - val_accuracy: 0.4738 - 672ms/epoch - 4ms/step\n",
            "Epoch 41/100\n",
            "188/188 - 1s - loss: 1.0018 - accuracy: 0.6689 - val_loss: 1.7682 - val_accuracy: 0.4813 - 669ms/epoch - 4ms/step\n",
            "Epoch 42/100\n",
            "188/188 - 1s - loss: 1.0334 - accuracy: 0.6775 - val_loss: 1.7071 - val_accuracy: 0.4903 - 668ms/epoch - 4ms/step\n",
            "Epoch 43/100\n",
            "188/188 - 1s - loss: 0.9997 - accuracy: 0.6683 - val_loss: 1.9444 - val_accuracy: 0.4693 - 670ms/epoch - 4ms/step\n",
            "Epoch 44/100\n",
            "188/188 - 1s - loss: 0.9699 - accuracy: 0.6815 - val_loss: 1.8831 - val_accuracy: 0.4783 - 666ms/epoch - 4ms/step\n",
            "Epoch 45/100\n",
            "188/188 - 1s - loss: 1.0087 - accuracy: 0.6614 - val_loss: 1.8075 - val_accuracy: 0.4558 - 664ms/epoch - 4ms/step\n",
            "Epoch 46/100\n",
            "188/188 - 1s - loss: 0.9530 - accuracy: 0.6830 - val_loss: 1.9505 - val_accuracy: 0.4243 - 671ms/epoch - 4ms/step\n",
            "Epoch 47/100\n",
            "188/188 - 1s - loss: 0.9781 - accuracy: 0.6790 - val_loss: 1.7812 - val_accuracy: 0.4663 - 679ms/epoch - 4ms/step\n",
            "Epoch 48/100\n",
            "188/188 - 1s - loss: 0.9801 - accuracy: 0.6795 - val_loss: 1.7626 - val_accuracy: 0.4828 - 668ms/epoch - 4ms/step\n",
            "Epoch 49/100\n",
            "188/188 - 1s - loss: 0.9388 - accuracy: 0.6898 - val_loss: 1.8161 - val_accuracy: 0.4648 - 665ms/epoch - 4ms/step\n",
            "Epoch 50/100\n",
            "188/188 - 1s - loss: 0.9662 - accuracy: 0.6776 - val_loss: 1.7811 - val_accuracy: 0.4708 - 665ms/epoch - 4ms/step\n",
            "Epoch 51/100\n",
            "188/188 - 1s - loss: 0.9362 - accuracy: 0.6911 - val_loss: 1.8643 - val_accuracy: 0.4573 - 673ms/epoch - 4ms/step\n",
            "Epoch 52/100\n",
            "188/188 - 1s - loss: 1.0922 - accuracy: 0.6406 - val_loss: 2.0044 - val_accuracy: 0.4543 - 662ms/epoch - 4ms/step\n",
            "Epoch 53/100\n",
            "188/188 - 1s - loss: 0.9791 - accuracy: 0.6721 - val_loss: 1.8374 - val_accuracy: 0.4663 - 656ms/epoch - 3ms/step\n",
            "Epoch 54/100\n",
            "188/188 - 1s - loss: 0.9855 - accuracy: 0.6825 - val_loss: 2.1005 - val_accuracy: 0.4108 - 660ms/epoch - 4ms/step\n",
            "Epoch 55/100\n",
            "188/188 - 1s - loss: 0.9404 - accuracy: 0.6865 - val_loss: 1.7884 - val_accuracy: 0.5052 - 673ms/epoch - 4ms/step\n",
            "Epoch 56/100\n",
            "188/188 - 1s - loss: 0.9456 - accuracy: 0.6863 - val_loss: 1.9134 - val_accuracy: 0.4363 - 659ms/epoch - 4ms/step\n",
            "Epoch 57/100\n",
            "188/188 - 1s - loss: 0.9337 - accuracy: 0.6893 - val_loss: 2.0947 - val_accuracy: 0.4288 - 664ms/epoch - 4ms/step\n",
            "Epoch 58/100\n",
            "188/188 - 1s - loss: 0.9260 - accuracy: 0.6878 - val_loss: 1.9291 - val_accuracy: 0.4543 - 671ms/epoch - 4ms/step\n",
            "Epoch 59/100\n",
            "188/188 - 1s - loss: 0.9496 - accuracy: 0.6896 - val_loss: 1.7532 - val_accuracy: 0.4828 - 676ms/epoch - 4ms/step\n",
            "Epoch 60/100\n",
            "188/188 - 1s - loss: 0.9361 - accuracy: 0.6903 - val_loss: 1.7693 - val_accuracy: 0.4603 - 672ms/epoch - 4ms/step\n",
            "Epoch 61/100\n",
            "188/188 - 1s - loss: 0.9327 - accuracy: 0.6945 - val_loss: 2.0232 - val_accuracy: 0.4408 - 674ms/epoch - 4ms/step\n",
            "Epoch 62/100\n",
            "188/188 - 1s - loss: 0.8932 - accuracy: 0.7128 - val_loss: 1.9248 - val_accuracy: 0.4558 - 663ms/epoch - 4ms/step\n",
            "Epoch 63/100\n",
            "188/188 - 1s - loss: 0.8713 - accuracy: 0.7155 - val_loss: 1.8186 - val_accuracy: 0.4903 - 665ms/epoch - 4ms/step\n",
            "Epoch 64/100\n",
            "188/188 - 1s - loss: 0.8887 - accuracy: 0.7138 - val_loss: 1.9040 - val_accuracy: 0.4813 - 668ms/epoch - 4ms/step\n",
            "Epoch 65/100\n",
            "188/188 - 1s - loss: 0.8745 - accuracy: 0.7105 - val_loss: 1.9660 - val_accuracy: 0.4693 - 668ms/epoch - 4ms/step\n",
            "Epoch 66/100\n",
            "188/188 - 1s - loss: 0.8890 - accuracy: 0.7111 - val_loss: 1.8578 - val_accuracy: 0.4813 - 663ms/epoch - 4ms/step\n",
            "Epoch 67/100\n",
            "188/188 - 1s - loss: 0.8896 - accuracy: 0.7148 - val_loss: 1.8378 - val_accuracy: 0.5037 - 663ms/epoch - 4ms/step\n",
            "Epoch 68/100\n",
            "188/188 - 1s - loss: 0.8773 - accuracy: 0.7096 - val_loss: 1.8390 - val_accuracy: 0.4903 - 670ms/epoch - 4ms/step\n",
            "Epoch 69/100\n",
            "188/188 - 1s - loss: 0.8745 - accuracy: 0.7106 - val_loss: 1.8982 - val_accuracy: 0.4633 - 666ms/epoch - 4ms/step\n",
            "Epoch 70/100\n",
            "188/188 - 1s - loss: 0.8829 - accuracy: 0.7096 - val_loss: 1.8350 - val_accuracy: 0.4573 - 657ms/epoch - 3ms/step\n",
            "Epoch 71/100\n",
            "188/188 - 1s - loss: 0.8871 - accuracy: 0.7098 - val_loss: 1.8288 - val_accuracy: 0.5067 - 662ms/epoch - 4ms/step\n",
            "Epoch 72/100\n",
            "188/188 - 1s - loss: 0.9147 - accuracy: 0.7005 - val_loss: 2.0469 - val_accuracy: 0.4303 - 674ms/epoch - 4ms/step\n",
            "Epoch 73/100\n",
            "188/188 - 1s - loss: 0.9300 - accuracy: 0.6946 - val_loss: 1.8129 - val_accuracy: 0.5022 - 653ms/epoch - 3ms/step\n",
            "Epoch 74/100\n",
            "188/188 - 1s - loss: 0.9216 - accuracy: 0.7041 - val_loss: 2.0439 - val_accuracy: 0.4558 - 657ms/epoch - 3ms/step\n",
            "Epoch 75/100\n",
            "188/188 - 1s - loss: 0.9174 - accuracy: 0.7020 - val_loss: 1.9683 - val_accuracy: 0.4648 - 660ms/epoch - 4ms/step\n",
            "Epoch 76/100\n",
            "188/188 - 1s - loss: 0.9717 - accuracy: 0.6818 - val_loss: 1.9897 - val_accuracy: 0.4378 - 658ms/epoch - 3ms/step\n",
            "Epoch 77/100\n",
            "188/188 - 1s - loss: 0.9022 - accuracy: 0.7063 - val_loss: 1.8445 - val_accuracy: 0.4843 - 666ms/epoch - 4ms/step\n",
            "Epoch 78/100\n",
            "188/188 - 1s - loss: 0.8800 - accuracy: 0.7111 - val_loss: 1.7729 - val_accuracy: 0.5097 - 659ms/epoch - 4ms/step\n",
            "Epoch 79/100\n",
            "188/188 - 1s - loss: 0.8505 - accuracy: 0.7188 - val_loss: 1.8855 - val_accuracy: 0.4828 - 662ms/epoch - 4ms/step\n",
            "Epoch 80/100\n",
            "188/188 - 1s - loss: 0.9302 - accuracy: 0.6960 - val_loss: 1.9918 - val_accuracy: 0.4723 - 659ms/epoch - 4ms/step\n",
            "Epoch 81/100\n",
            "188/188 - 1s - loss: 0.8473 - accuracy: 0.7171 - val_loss: 1.9026 - val_accuracy: 0.4813 - 669ms/epoch - 4ms/step\n",
            "Epoch 82/100\n",
            "188/188 - 1s - loss: 0.8349 - accuracy: 0.7243 - val_loss: 1.9248 - val_accuracy: 0.4468 - 659ms/epoch - 4ms/step\n",
            "Epoch 83/100\n",
            "188/188 - 1s - loss: 0.8636 - accuracy: 0.7168 - val_loss: 2.1157 - val_accuracy: 0.4588 - 659ms/epoch - 4ms/step\n",
            "Epoch 84/100\n",
            "188/188 - 1s - loss: 0.9578 - accuracy: 0.6915 - val_loss: 2.0134 - val_accuracy: 0.4438 - 664ms/epoch - 4ms/step\n",
            "Epoch 85/100\n",
            "188/188 - 1s - loss: 0.8596 - accuracy: 0.7190 - val_loss: 1.8844 - val_accuracy: 0.4768 - 671ms/epoch - 4ms/step\n",
            "Epoch 86/100\n",
            "188/188 - 1s - loss: 0.8560 - accuracy: 0.7263 - val_loss: 1.9420 - val_accuracy: 0.4633 - 657ms/epoch - 3ms/step\n",
            "Epoch 87/100\n",
            "188/188 - 1s - loss: 0.8683 - accuracy: 0.7215 - val_loss: 1.9888 - val_accuracy: 0.4813 - 670ms/epoch - 4ms/step\n",
            "Epoch 88/100\n",
            "188/188 - 1s - loss: 0.8693 - accuracy: 0.7146 - val_loss: 2.1037 - val_accuracy: 0.4303 - 661ms/epoch - 4ms/step\n",
            "Epoch 89/100\n",
            "188/188 - 1s - loss: 0.8819 - accuracy: 0.7106 - val_loss: 1.9145 - val_accuracy: 0.4798 - 659ms/epoch - 4ms/step\n",
            "Epoch 90/100\n",
            "188/188 - 1s - loss: 0.8265 - accuracy: 0.7312 - val_loss: 1.9041 - val_accuracy: 0.4738 - 664ms/epoch - 4ms/step\n",
            "Epoch 91/100\n",
            "188/188 - 1s - loss: 0.8637 - accuracy: 0.7231 - val_loss: 1.9431 - val_accuracy: 0.4633 - 657ms/epoch - 3ms/step\n",
            "Epoch 92/100\n",
            "188/188 - 1s - loss: 0.8770 - accuracy: 0.7105 - val_loss: 1.9002 - val_accuracy: 0.4708 - 663ms/epoch - 4ms/step\n",
            "Epoch 93/100\n",
            "188/188 - 1s - loss: 0.8485 - accuracy: 0.7173 - val_loss: 1.9472 - val_accuracy: 0.4498 - 666ms/epoch - 4ms/step\n",
            "Epoch 94/100\n",
            "188/188 - 1s - loss: 0.8435 - accuracy: 0.7280 - val_loss: 2.0024 - val_accuracy: 0.4513 - 663ms/epoch - 4ms/step\n",
            "Epoch 95/100\n",
            "188/188 - 1s - loss: 0.8542 - accuracy: 0.7198 - val_loss: 2.0722 - val_accuracy: 0.4438 - 663ms/epoch - 4ms/step\n",
            "Epoch 96/100\n",
            "188/188 - 1s - loss: 0.8369 - accuracy: 0.7196 - val_loss: 1.9037 - val_accuracy: 0.4678 - 671ms/epoch - 4ms/step\n",
            "Epoch 97/100\n",
            "188/188 - 1s - loss: 0.8743 - accuracy: 0.7123 - val_loss: 2.0238 - val_accuracy: 0.4573 - 655ms/epoch - 3ms/step\n",
            "Epoch 98/100\n",
            "188/188 - 1s - loss: 0.8686 - accuracy: 0.7121 - val_loss: 1.8936 - val_accuracy: 0.5037 - 662ms/epoch - 4ms/step\n",
            "Epoch 99/100\n",
            "188/188 - 1s - loss: 0.8342 - accuracy: 0.7188 - val_loss: 2.1410 - val_accuracy: 0.4408 - 659ms/epoch - 4ms/step\n",
            "Epoch 100/100\n",
            "188/188 - 1s - loss: 0.8621 - accuracy: 0.7178 - val_loss: 2.0928 - val_accuracy: 0.4273 - 658ms/epoch - 4ms/step\n",
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " reshape_4 (Reshape)         (None, 128, 40)           0         \n",
            "                                                                 \n",
            " conv1d_8 (Conv1D)           (None, 124, 12)           2412      \n",
            "                                                                 \n",
            " max_pooling1d_8 (MaxPooling  (None, 62, 12)           0         \n",
            " 1D)                                                             \n",
            "                                                                 \n",
            " conv1d_9 (Conv1D)           (None, 58, 28)            1708      \n",
            "                                                                 \n",
            " max_pooling1d_9 (MaxPooling  (None, 29, 28)           0         \n",
            " 1D)                                                             \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 29, 30)            870       \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 29, 30)            0         \n",
            "                                                                 \n",
            " flatten_4 (Flatten)         (None, 870)               0         \n",
            "                                                                 \n",
            " y_pred (Dense)              (None, 10)                8710      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 13,700\n",
            "Trainable params: 13,700\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Result of fold:3\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 2.4795 - accuracy: 0.4442\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 30%|███       | 3/10 [03:41<08:27, 72.44s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "188/188 - 1s - loss: 2.2403 - accuracy: 0.2718 - val_loss: 1.8226 - val_accuracy: 0.3153 - 1s/epoch - 8ms/step\n",
            "Epoch 2/100\n",
            "188/188 - 1s - loss: 1.7244 - accuracy: 0.3703 - val_loss: 1.6066 - val_accuracy: 0.4204 - 698ms/epoch - 4ms/step\n",
            "Epoch 3/100\n",
            "188/188 - 1s - loss: 1.6246 - accuracy: 0.4189 - val_loss: 1.6510 - val_accuracy: 0.4985 - 669ms/epoch - 4ms/step\n",
            "Epoch 4/100\n",
            "188/188 - 1s - loss: 1.5479 - accuracy: 0.4321 - val_loss: 1.5640 - val_accuracy: 0.4565 - 661ms/epoch - 4ms/step\n",
            "Epoch 5/100\n",
            "188/188 - 1s - loss: 1.5421 - accuracy: 0.4553 - val_loss: 2.0907 - val_accuracy: 0.3288 - 671ms/epoch - 4ms/step\n",
            "Epoch 6/100\n",
            "188/188 - 1s - loss: 1.4772 - accuracy: 0.4864 - val_loss: 1.5686 - val_accuracy: 0.5135 - 671ms/epoch - 4ms/step\n",
            "Epoch 7/100\n",
            "188/188 - 1s - loss: 1.4285 - accuracy: 0.5023 - val_loss: 1.6744 - val_accuracy: 0.4204 - 665ms/epoch - 4ms/step\n",
            "Epoch 8/100\n",
            "188/188 - 1s - loss: 1.4431 - accuracy: 0.5003 - val_loss: 1.6117 - val_accuracy: 0.4339 - 664ms/epoch - 4ms/step\n",
            "Epoch 9/100\n",
            "188/188 - 1s - loss: 1.2947 - accuracy: 0.5637 - val_loss: 1.6198 - val_accuracy: 0.4685 - 667ms/epoch - 4ms/step\n",
            "Epoch 10/100\n",
            "188/188 - 1s - loss: 1.2367 - accuracy: 0.5856 - val_loss: 1.6028 - val_accuracy: 0.4790 - 658ms/epoch - 4ms/step\n",
            "Epoch 11/100\n",
            "188/188 - 1s - loss: 1.2047 - accuracy: 0.6015 - val_loss: 1.6121 - val_accuracy: 0.4700 - 666ms/epoch - 4ms/step\n",
            "Epoch 12/100\n",
            "188/188 - 1s - loss: 1.2136 - accuracy: 0.6052 - val_loss: 1.5767 - val_accuracy: 0.4865 - 660ms/epoch - 4ms/step\n",
            "Epoch 13/100\n",
            "188/188 - 1s - loss: 1.2487 - accuracy: 0.5684 - val_loss: 1.5850 - val_accuracy: 0.4535 - 658ms/epoch - 3ms/step\n",
            "Epoch 14/100\n",
            "188/188 - 1s - loss: 1.1977 - accuracy: 0.6010 - val_loss: 1.6196 - val_accuracy: 0.4760 - 673ms/epoch - 4ms/step\n",
            "Epoch 15/100\n",
            "188/188 - 1s - loss: 1.1846 - accuracy: 0.6040 - val_loss: 1.7366 - val_accuracy: 0.4910 - 667ms/epoch - 4ms/step\n",
            "Epoch 16/100\n",
            "188/188 - 1s - loss: 1.1389 - accuracy: 0.6165 - val_loss: 1.5102 - val_accuracy: 0.5315 - 662ms/epoch - 4ms/step\n",
            "Epoch 17/100\n",
            "188/188 - 1s - loss: 1.0875 - accuracy: 0.6354 - val_loss: 1.7340 - val_accuracy: 0.4520 - 666ms/epoch - 4ms/step\n",
            "Epoch 18/100\n",
            "188/188 - 1s - loss: 1.0818 - accuracy: 0.6439 - val_loss: 1.6883 - val_accuracy: 0.4730 - 660ms/epoch - 4ms/step\n",
            "Epoch 19/100\n",
            "188/188 - 1s - loss: 1.0391 - accuracy: 0.6593 - val_loss: 1.9665 - val_accuracy: 0.3318 - 664ms/epoch - 4ms/step\n",
            "Epoch 20/100\n",
            "188/188 - 1s - loss: 1.1347 - accuracy: 0.6231 - val_loss: 1.8401 - val_accuracy: 0.4324 - 663ms/epoch - 4ms/step\n",
            "Epoch 21/100\n",
            "188/188 - 1s - loss: 1.0544 - accuracy: 0.6575 - val_loss: 1.6491 - val_accuracy: 0.4429 - 678ms/epoch - 4ms/step\n",
            "Epoch 22/100\n",
            "188/188 - 1s - loss: 1.0043 - accuracy: 0.6728 - val_loss: 1.6740 - val_accuracy: 0.4535 - 656ms/epoch - 3ms/step\n",
            "Epoch 23/100\n",
            "188/188 - 1s - loss: 1.0216 - accuracy: 0.6598 - val_loss: 1.7288 - val_accuracy: 0.4414 - 662ms/epoch - 4ms/step\n",
            "Epoch 24/100\n",
            "188/188 - 1s - loss: 1.0095 - accuracy: 0.6658 - val_loss: 1.6686 - val_accuracy: 0.4474 - 664ms/epoch - 4ms/step\n",
            "Epoch 25/100\n",
            "188/188 - 1s - loss: 0.9749 - accuracy: 0.6787 - val_loss: 1.6935 - val_accuracy: 0.4444 - 662ms/epoch - 4ms/step\n",
            "Epoch 26/100\n",
            "188/188 - 1s - loss: 0.9576 - accuracy: 0.6815 - val_loss: 1.5935 - val_accuracy: 0.4880 - 664ms/epoch - 4ms/step\n",
            "Epoch 27/100\n",
            "188/188 - 1s - loss: 0.9576 - accuracy: 0.6837 - val_loss: 1.7263 - val_accuracy: 0.4505 - 663ms/epoch - 4ms/step\n",
            "Epoch 28/100\n",
            "188/188 - 1s - loss: 1.0368 - accuracy: 0.6668 - val_loss: 1.6064 - val_accuracy: 0.4610 - 667ms/epoch - 4ms/step\n",
            "Epoch 29/100\n",
            "188/188 - 1s - loss: 0.9592 - accuracy: 0.6837 - val_loss: 1.7693 - val_accuracy: 0.4444 - 671ms/epoch - 4ms/step\n",
            "Epoch 30/100\n",
            "188/188 - 1s - loss: 0.9704 - accuracy: 0.6795 - val_loss: 1.6811 - val_accuracy: 0.4730 - 658ms/epoch - 4ms/step\n",
            "Epoch 31/100\n",
            "188/188 - 1s - loss: 0.9671 - accuracy: 0.6817 - val_loss: 1.6618 - val_accuracy: 0.4685 - 652ms/epoch - 3ms/step\n",
            "Epoch 32/100\n",
            "188/188 - 1s - loss: 0.9337 - accuracy: 0.6954 - val_loss: 1.8006 - val_accuracy: 0.4414 - 657ms/epoch - 3ms/step\n",
            "Epoch 33/100\n",
            "188/188 - 1s - loss: 0.9463 - accuracy: 0.6916 - val_loss: 1.8013 - val_accuracy: 0.4384 - 673ms/epoch - 4ms/step\n",
            "Epoch 34/100\n",
            "188/188 - 1s - loss: 0.9429 - accuracy: 0.6944 - val_loss: 1.8197 - val_accuracy: 0.4429 - 684ms/epoch - 4ms/step\n",
            "Epoch 35/100\n",
            "188/188 - 1s - loss: 1.0280 - accuracy: 0.6618 - val_loss: 1.7423 - val_accuracy: 0.4595 - 660ms/epoch - 4ms/step\n",
            "Epoch 36/100\n",
            "188/188 - 1s - loss: 0.9701 - accuracy: 0.6822 - val_loss: 1.7305 - val_accuracy: 0.4535 - 677ms/epoch - 4ms/step\n",
            "Epoch 37/100\n",
            "188/188 - 1s - loss: 0.9174 - accuracy: 0.7031 - val_loss: 1.7145 - val_accuracy: 0.4625 - 659ms/epoch - 4ms/step\n",
            "Epoch 38/100\n",
            "188/188 - 1s - loss: 0.9274 - accuracy: 0.6937 - val_loss: 1.8822 - val_accuracy: 0.4429 - 667ms/epoch - 4ms/step\n",
            "Epoch 39/100\n",
            "188/188 - 1s - loss: 0.9247 - accuracy: 0.7108 - val_loss: 1.7291 - val_accuracy: 0.4580 - 673ms/epoch - 4ms/step\n",
            "Epoch 40/100\n",
            "188/188 - 1s - loss: 0.9017 - accuracy: 0.7081 - val_loss: 1.7446 - val_accuracy: 0.4550 - 665ms/epoch - 4ms/step\n",
            "Epoch 41/100\n",
            "188/188 - 1s - loss: 0.8973 - accuracy: 0.7103 - val_loss: 1.7827 - val_accuracy: 0.4805 - 659ms/epoch - 4ms/step\n",
            "Epoch 42/100\n",
            "188/188 - 1s - loss: 0.8937 - accuracy: 0.7026 - val_loss: 1.8026 - val_accuracy: 0.4489 - 659ms/epoch - 4ms/step\n",
            "Epoch 43/100\n",
            "188/188 - 1s - loss: 0.9674 - accuracy: 0.6859 - val_loss: 1.8508 - val_accuracy: 0.4535 - 674ms/epoch - 4ms/step\n",
            "Epoch 44/100\n",
            "188/188 - 1s - loss: 0.9241 - accuracy: 0.6952 - val_loss: 1.8208 - val_accuracy: 0.4715 - 668ms/epoch - 4ms/step\n",
            "Epoch 45/100\n",
            "188/188 - 1s - loss: 0.9212 - accuracy: 0.6986 - val_loss: 2.0009 - val_accuracy: 0.4429 - 657ms/epoch - 3ms/step\n",
            "Epoch 46/100\n",
            "188/188 - 1s - loss: 0.8862 - accuracy: 0.7091 - val_loss: 1.9889 - val_accuracy: 0.4324 - 671ms/epoch - 4ms/step\n",
            "Epoch 47/100\n",
            "188/188 - 1s - loss: 0.9352 - accuracy: 0.6989 - val_loss: 1.7595 - val_accuracy: 0.4685 - 682ms/epoch - 4ms/step\n",
            "Epoch 48/100\n",
            "188/188 - 1s - loss: 0.8803 - accuracy: 0.7051 - val_loss: 1.7676 - val_accuracy: 0.4880 - 665ms/epoch - 4ms/step\n",
            "Epoch 49/100\n",
            "188/188 - 1s - loss: 0.8660 - accuracy: 0.7240 - val_loss: 1.6939 - val_accuracy: 0.4850 - 666ms/epoch - 4ms/step\n",
            "Epoch 50/100\n",
            "188/188 - 1s - loss: 0.8716 - accuracy: 0.7126 - val_loss: 1.9305 - val_accuracy: 0.4535 - 667ms/epoch - 4ms/step\n",
            "Epoch 51/100\n",
            "188/188 - 1s - loss: 0.8553 - accuracy: 0.7288 - val_loss: 1.9136 - val_accuracy: 0.4399 - 663ms/epoch - 4ms/step\n",
            "Epoch 52/100\n",
            "188/188 - 1s - loss: 0.8537 - accuracy: 0.7282 - val_loss: 1.9145 - val_accuracy: 0.4655 - 675ms/epoch - 4ms/step\n",
            "Epoch 53/100\n",
            "188/188 - 1s - loss: 0.8904 - accuracy: 0.7173 - val_loss: 1.9241 - val_accuracy: 0.4474 - 660ms/epoch - 4ms/step\n",
            "Epoch 54/100\n",
            "188/188 - 1s - loss: 0.8309 - accuracy: 0.7322 - val_loss: 1.8181 - val_accuracy: 0.4640 - 658ms/epoch - 4ms/step\n",
            "Epoch 55/100\n",
            "188/188 - 1s - loss: 0.9081 - accuracy: 0.7069 - val_loss: 1.8016 - val_accuracy: 0.4880 - 664ms/epoch - 4ms/step\n",
            "Epoch 56/100\n",
            "188/188 - 1s - loss: 0.8834 - accuracy: 0.7129 - val_loss: 1.9012 - val_accuracy: 0.4384 - 725ms/epoch - 4ms/step\n",
            "Epoch 57/100\n",
            "188/188 - 1s - loss: 0.8820 - accuracy: 0.7173 - val_loss: 1.9561 - val_accuracy: 0.4505 - 750ms/epoch - 4ms/step\n",
            "Epoch 58/100\n",
            "188/188 - 1s - loss: 0.9044 - accuracy: 0.7086 - val_loss: 1.9500 - val_accuracy: 0.4204 - 722ms/epoch - 4ms/step\n",
            "Epoch 59/100\n",
            "188/188 - 1s - loss: 1.0152 - accuracy: 0.6725 - val_loss: 1.9140 - val_accuracy: 0.4369 - 678ms/epoch - 4ms/step\n",
            "Epoch 60/100\n",
            "188/188 - 1s - loss: 0.9450 - accuracy: 0.6876 - val_loss: 1.7336 - val_accuracy: 0.4835 - 669ms/epoch - 4ms/step\n",
            "Epoch 61/100\n",
            "188/188 - 1s - loss: 0.8720 - accuracy: 0.7166 - val_loss: 2.0466 - val_accuracy: 0.4264 - 668ms/epoch - 4ms/step\n",
            "Epoch 62/100\n",
            "188/188 - 1s - loss: 1.0922 - accuracy: 0.6546 - val_loss: 1.9951 - val_accuracy: 0.4489 - 670ms/epoch - 4ms/step\n",
            "Epoch 63/100\n",
            "188/188 - 1s - loss: 0.8995 - accuracy: 0.7111 - val_loss: 1.8397 - val_accuracy: 0.4685 - 663ms/epoch - 4ms/step\n",
            "Epoch 64/100\n",
            "188/188 - 1s - loss: 0.8727 - accuracy: 0.7170 - val_loss: 1.9185 - val_accuracy: 0.4565 - 669ms/epoch - 4ms/step\n",
            "Epoch 65/100\n",
            "188/188 - 1s - loss: 0.8510 - accuracy: 0.7233 - val_loss: 1.8605 - val_accuracy: 0.4429 - 664ms/epoch - 4ms/step\n",
            "Epoch 66/100\n",
            "188/188 - 1s - loss: 0.8353 - accuracy: 0.7275 - val_loss: 1.9149 - val_accuracy: 0.4730 - 666ms/epoch - 4ms/step\n",
            "Epoch 67/100\n",
            "188/188 - 1s - loss: 0.8753 - accuracy: 0.7136 - val_loss: 2.0365 - val_accuracy: 0.4399 - 663ms/epoch - 4ms/step\n",
            "Epoch 68/100\n",
            "188/188 - 1s - loss: 0.8477 - accuracy: 0.7251 - val_loss: 1.8371 - val_accuracy: 0.4444 - 670ms/epoch - 4ms/step\n",
            "Epoch 69/100\n",
            "188/188 - 1s - loss: 0.8297 - accuracy: 0.7333 - val_loss: 2.0514 - val_accuracy: 0.4429 - 664ms/epoch - 4ms/step\n",
            "Epoch 70/100\n",
            "188/188 - 1s - loss: 0.8342 - accuracy: 0.7285 - val_loss: 1.8023 - val_accuracy: 0.4850 - 665ms/epoch - 4ms/step\n",
            "Epoch 71/100\n",
            "188/188 - 1s - loss: 0.8636 - accuracy: 0.7295 - val_loss: 1.8029 - val_accuracy: 0.4865 - 661ms/epoch - 4ms/step\n",
            "Epoch 72/100\n",
            "188/188 - 1s - loss: 0.8881 - accuracy: 0.7141 - val_loss: 1.8651 - val_accuracy: 0.4730 - 681ms/epoch - 4ms/step\n",
            "Epoch 73/100\n",
            "188/188 - 1s - loss: 0.8675 - accuracy: 0.7218 - val_loss: 2.0161 - val_accuracy: 0.4414 - 666ms/epoch - 4ms/step\n",
            "Epoch 74/100\n",
            "188/188 - 1s - loss: 0.8238 - accuracy: 0.7373 - val_loss: 1.9824 - val_accuracy: 0.4444 - 662ms/epoch - 4ms/step\n",
            "Epoch 75/100\n",
            "188/188 - 1s - loss: 0.8650 - accuracy: 0.7173 - val_loss: 2.0297 - val_accuracy: 0.4384 - 659ms/epoch - 4ms/step\n",
            "Epoch 76/100\n",
            "188/188 - 1s - loss: 0.8480 - accuracy: 0.7205 - val_loss: 1.9612 - val_accuracy: 0.4550 - 655ms/epoch - 3ms/step\n",
            "Epoch 77/100\n",
            "188/188 - 1s - loss: 0.8288 - accuracy: 0.7392 - val_loss: 2.0280 - val_accuracy: 0.4745 - 675ms/epoch - 4ms/step\n",
            "Epoch 78/100\n",
            "188/188 - 1s - loss: 0.9334 - accuracy: 0.6931 - val_loss: 1.9558 - val_accuracy: 0.4640 - 669ms/epoch - 4ms/step\n",
            "Epoch 79/100\n",
            "188/188 - 1s - loss: 0.8337 - accuracy: 0.7345 - val_loss: 2.1366 - val_accuracy: 0.4354 - 666ms/epoch - 4ms/step\n",
            "Epoch 80/100\n",
            "188/188 - 1s - loss: 0.8534 - accuracy: 0.7266 - val_loss: 2.0863 - val_accuracy: 0.4429 - 664ms/epoch - 4ms/step\n",
            "Epoch 81/100\n",
            "188/188 - 1s - loss: 0.8262 - accuracy: 0.7327 - val_loss: 2.1099 - val_accuracy: 0.4595 - 664ms/epoch - 4ms/step\n",
            "Epoch 82/100\n",
            "188/188 - 1s - loss: 0.8920 - accuracy: 0.7151 - val_loss: 2.0597 - val_accuracy: 0.4429 - 674ms/epoch - 4ms/step\n",
            "Epoch 83/100\n",
            "188/188 - 1s - loss: 0.8353 - accuracy: 0.7417 - val_loss: 2.0738 - val_accuracy: 0.4700 - 672ms/epoch - 4ms/step\n",
            "Epoch 84/100\n",
            "188/188 - 1s - loss: 0.8543 - accuracy: 0.7283 - val_loss: 1.8787 - val_accuracy: 0.4760 - 665ms/epoch - 4ms/step\n",
            "Epoch 85/100\n",
            "188/188 - 1s - loss: 0.9370 - accuracy: 0.7071 - val_loss: 2.1418 - val_accuracy: 0.4384 - 668ms/epoch - 4ms/step\n",
            "Epoch 86/100\n",
            "188/188 - 1s - loss: 0.9169 - accuracy: 0.7041 - val_loss: 2.0069 - val_accuracy: 0.4249 - 667ms/epoch - 4ms/step\n",
            "Epoch 87/100\n",
            "188/188 - 1s - loss: 0.9070 - accuracy: 0.7078 - val_loss: 2.0088 - val_accuracy: 0.4595 - 666ms/epoch - 4ms/step\n",
            "Epoch 88/100\n",
            "188/188 - 1s - loss: 0.8601 - accuracy: 0.7282 - val_loss: 1.8729 - val_accuracy: 0.4685 - 660ms/epoch - 4ms/step\n",
            "Epoch 89/100\n",
            "188/188 - 1s - loss: 0.9277 - accuracy: 0.7073 - val_loss: 2.0980 - val_accuracy: 0.4009 - 658ms/epoch - 4ms/step\n",
            "Epoch 90/100\n",
            "188/188 - 1s - loss: 0.9107 - accuracy: 0.7079 - val_loss: 2.1984 - val_accuracy: 0.4054 - 664ms/epoch - 4ms/step\n",
            "Epoch 91/100\n",
            "188/188 - 1s - loss: 0.8635 - accuracy: 0.7288 - val_loss: 2.0655 - val_accuracy: 0.4324 - 673ms/epoch - 4ms/step\n",
            "Epoch 92/100\n",
            "188/188 - 1s - loss: 0.8428 - accuracy: 0.7372 - val_loss: 1.9971 - val_accuracy: 0.4535 - 691ms/epoch - 4ms/step\n",
            "Epoch 93/100\n",
            "188/188 - 1s - loss: 0.8650 - accuracy: 0.7191 - val_loss: 2.1009 - val_accuracy: 0.4324 - 663ms/epoch - 4ms/step\n",
            "Epoch 94/100\n",
            "188/188 - 1s - loss: 0.8369 - accuracy: 0.7285 - val_loss: 2.0976 - val_accuracy: 0.3994 - 664ms/epoch - 4ms/step\n",
            "Epoch 95/100\n",
            "188/188 - 1s - loss: 0.8163 - accuracy: 0.7429 - val_loss: 2.0100 - val_accuracy: 0.4565 - 675ms/epoch - 4ms/step\n",
            "Epoch 96/100\n",
            "188/188 - 1s - loss: 0.8559 - accuracy: 0.7340 - val_loss: 2.2593 - val_accuracy: 0.4429 - 682ms/epoch - 4ms/step\n",
            "Epoch 97/100\n",
            "188/188 - 1s - loss: 0.9337 - accuracy: 0.7173 - val_loss: 2.2353 - val_accuracy: 0.4249 - 673ms/epoch - 4ms/step\n",
            "Epoch 98/100\n",
            "188/188 - 1s - loss: 0.8615 - accuracy: 0.7248 - val_loss: 2.1848 - val_accuracy: 0.4474 - 679ms/epoch - 4ms/step\n",
            "Epoch 99/100\n",
            "188/188 - 1s - loss: 0.8231 - accuracy: 0.7313 - val_loss: 2.1283 - val_accuracy: 0.4279 - 661ms/epoch - 4ms/step\n",
            "Epoch 100/100\n",
            "188/188 - 1s - loss: 0.8291 - accuracy: 0.7298 - val_loss: 1.8600 - val_accuracy: 0.4535 - 664ms/epoch - 4ms/step\n",
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " reshape_6 (Reshape)         (None, 128, 40)           0         \n",
            "                                                                 \n",
            " conv1d_12 (Conv1D)          (None, 124, 12)           2412      \n",
            "                                                                 \n",
            " max_pooling1d_12 (MaxPoolin  (None, 62, 12)           0         \n",
            " g1D)                                                            \n",
            "                                                                 \n",
            " conv1d_13 (Conv1D)          (None, 58, 28)            1708      \n",
            "                                                                 \n",
            " max_pooling1d_13 (MaxPoolin  (None, 29, 28)           0         \n",
            " g1D)                                                            \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 29, 30)            870       \n",
            "                                                                 \n",
            " dropout_6 (Dropout)         (None, 29, 30)            0         \n",
            "                                                                 \n",
            " flatten_6 (Flatten)         (None, 870)               0         \n",
            "                                                                 \n",
            " y_pred (Dense)              (None, 10)                8710      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 13,700\n",
            "Trainable params: 13,700\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Result of fold:4\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 1.6375 - accuracy: 0.5417\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 40%|████      | 4/10 [04:50<07:05, 71.00s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "189/189 - 2s - loss: 2.1739 - accuracy: 0.2916 - val_loss: 1.7259 - val_accuracy: 0.4230 - 2s/epoch - 8ms/step\n",
            "Epoch 2/100\n",
            "189/189 - 1s - loss: 1.6443 - accuracy: 0.4160 - val_loss: 1.7005 - val_accuracy: 0.3662 - 667ms/epoch - 4ms/step\n",
            "Epoch 3/100\n",
            "189/189 - 1s - loss: 1.5306 - accuracy: 0.4687 - val_loss: 1.6521 - val_accuracy: 0.3722 - 667ms/epoch - 4ms/step\n",
            "Epoch 4/100\n",
            "189/189 - 1s - loss: 1.4413 - accuracy: 0.4994 - val_loss: 1.6752 - val_accuracy: 0.3707 - 655ms/epoch - 3ms/step\n",
            "Epoch 5/100\n",
            "189/189 - 1s - loss: 1.3633 - accuracy: 0.5380 - val_loss: 1.6183 - val_accuracy: 0.4096 - 659ms/epoch - 3ms/step\n",
            "Epoch 6/100\n",
            "189/189 - 1s - loss: 1.3506 - accuracy: 0.5499 - val_loss: 1.5396 - val_accuracy: 0.5007 - 671ms/epoch - 4ms/step\n",
            "Epoch 7/100\n",
            "189/189 - 1s - loss: 1.3051 - accuracy: 0.5652 - val_loss: 1.6741 - val_accuracy: 0.4439 - 656ms/epoch - 3ms/step\n",
            "Epoch 8/100\n",
            "189/189 - 1s - loss: 1.3234 - accuracy: 0.5537 - val_loss: 1.7335 - val_accuracy: 0.4350 - 667ms/epoch - 4ms/step\n",
            "Epoch 9/100\n",
            "189/189 - 1s - loss: 1.3425 - accuracy: 0.5546 - val_loss: 1.7258 - val_accuracy: 0.4230 - 666ms/epoch - 4ms/step\n",
            "Epoch 10/100\n",
            "189/189 - 1s - loss: 1.2988 - accuracy: 0.5615 - val_loss: 1.8089 - val_accuracy: 0.3991 - 667ms/epoch - 4ms/step\n",
            "Epoch 11/100\n",
            "189/189 - 1s - loss: 1.2287 - accuracy: 0.5938 - val_loss: 1.5741 - val_accuracy: 0.5277 - 672ms/epoch - 4ms/step\n",
            "Epoch 12/100\n",
            "189/189 - 1s - loss: 1.1897 - accuracy: 0.6022 - val_loss: 1.6522 - val_accuracy: 0.4350 - 669ms/epoch - 4ms/step\n",
            "Epoch 13/100\n",
            "189/189 - 1s - loss: 1.2638 - accuracy: 0.5841 - val_loss: 1.5780 - val_accuracy: 0.4425 - 662ms/epoch - 4ms/step\n",
            "Epoch 14/100\n",
            "189/189 - 1s - loss: 1.1742 - accuracy: 0.6087 - val_loss: 1.6872 - val_accuracy: 0.5351 - 665ms/epoch - 4ms/step\n",
            "Epoch 15/100\n",
            "189/189 - 1s - loss: 1.1236 - accuracy: 0.6336 - val_loss: 2.0848 - val_accuracy: 0.3408 - 668ms/epoch - 4ms/step\n",
            "Epoch 16/100\n",
            "189/189 - 1s - loss: 1.2088 - accuracy: 0.5949 - val_loss: 1.5922 - val_accuracy: 0.4993 - 659ms/epoch - 3ms/step\n",
            "Epoch 17/100\n",
            "189/189 - 1s - loss: 1.1658 - accuracy: 0.6157 - val_loss: 1.6745 - val_accuracy: 0.4410 - 658ms/epoch - 3ms/step\n",
            "Epoch 18/100\n",
            "189/189 - 1s - loss: 1.1101 - accuracy: 0.6283 - val_loss: 1.6650 - val_accuracy: 0.4559 - 660ms/epoch - 3ms/step\n",
            "Epoch 19/100\n",
            "189/189 - 1s - loss: 1.1215 - accuracy: 0.6230 - val_loss: 1.7683 - val_accuracy: 0.4365 - 671ms/epoch - 4ms/step\n",
            "Epoch 20/100\n",
            "189/189 - 1s - loss: 1.0825 - accuracy: 0.6446 - val_loss: 1.7114 - val_accuracy: 0.4469 - 662ms/epoch - 4ms/step\n",
            "Epoch 21/100\n",
            "189/189 - 1s - loss: 1.0273 - accuracy: 0.6673 - val_loss: 1.6701 - val_accuracy: 0.4559 - 671ms/epoch - 4ms/step\n",
            "Epoch 22/100\n",
            "189/189 - 1s - loss: 1.0528 - accuracy: 0.6633 - val_loss: 1.6221 - val_accuracy: 0.4948 - 663ms/epoch - 4ms/step\n",
            "Epoch 23/100\n",
            "189/189 - 1s - loss: 1.0407 - accuracy: 0.6645 - val_loss: 1.6953 - val_accuracy: 0.4664 - 664ms/epoch - 4ms/step\n",
            "Epoch 24/100\n",
            "189/189 - 1s - loss: 1.0104 - accuracy: 0.6687 - val_loss: 1.7386 - val_accuracy: 0.4828 - 659ms/epoch - 3ms/step\n",
            "Epoch 25/100\n",
            "189/189 - 1s - loss: 0.9759 - accuracy: 0.6721 - val_loss: 1.7996 - val_accuracy: 0.4768 - 656ms/epoch - 3ms/step\n",
            "Epoch 26/100\n",
            "189/189 - 1s - loss: 0.9767 - accuracy: 0.6841 - val_loss: 1.5888 - val_accuracy: 0.5067 - 660ms/epoch - 3ms/step\n",
            "Epoch 27/100\n",
            "189/189 - 1s - loss: 1.0251 - accuracy: 0.6718 - val_loss: 1.8587 - val_accuracy: 0.4454 - 656ms/epoch - 3ms/step\n",
            "Epoch 28/100\n",
            "189/189 - 1s - loss: 1.0435 - accuracy: 0.6607 - val_loss: 1.7874 - val_accuracy: 0.4768 - 657ms/epoch - 3ms/step\n",
            "Epoch 29/100\n",
            "189/189 - 1s - loss: 0.9901 - accuracy: 0.6816 - val_loss: 1.8467 - val_accuracy: 0.4574 - 669ms/epoch - 4ms/step\n",
            "Epoch 30/100\n",
            "189/189 - 1s - loss: 0.9349 - accuracy: 0.6911 - val_loss: 1.7583 - val_accuracy: 0.4933 - 646ms/epoch - 3ms/step\n",
            "Epoch 31/100\n",
            "189/189 - 1s - loss: 0.9196 - accuracy: 0.7040 - val_loss: 1.7561 - val_accuracy: 0.4903 - 660ms/epoch - 3ms/step\n",
            "Epoch 32/100\n",
            "189/189 - 1s - loss: 0.9097 - accuracy: 0.7017 - val_loss: 2.0333 - val_accuracy: 0.4275 - 653ms/epoch - 3ms/step\n",
            "Epoch 33/100\n",
            "189/189 - 1s - loss: 0.9715 - accuracy: 0.6848 - val_loss: 1.8125 - val_accuracy: 0.4679 - 657ms/epoch - 3ms/step\n",
            "Epoch 34/100\n",
            "189/189 - 1s - loss: 0.9945 - accuracy: 0.6710 - val_loss: 1.7608 - val_accuracy: 0.4963 - 671ms/epoch - 4ms/step\n",
            "Epoch 35/100\n",
            "189/189 - 1s - loss: 0.9571 - accuracy: 0.6809 - val_loss: 1.7242 - val_accuracy: 0.4843 - 678ms/epoch - 4ms/step\n",
            "Epoch 36/100\n",
            "189/189 - 1s - loss: 0.9965 - accuracy: 0.6712 - val_loss: 1.8071 - val_accuracy: 0.4604 - 656ms/epoch - 3ms/step\n",
            "Epoch 37/100\n",
            "189/189 - 1s - loss: 0.9299 - accuracy: 0.6991 - val_loss: 1.8364 - val_accuracy: 0.4918 - 656ms/epoch - 3ms/step\n",
            "Epoch 38/100\n",
            "189/189 - 1s - loss: 0.9206 - accuracy: 0.7014 - val_loss: 1.8903 - val_accuracy: 0.4335 - 659ms/epoch - 3ms/step\n",
            "Epoch 39/100\n",
            "189/189 - 1s - loss: 0.9270 - accuracy: 0.6999 - val_loss: 1.6972 - val_accuracy: 0.4768 - 662ms/epoch - 4ms/step\n",
            "Epoch 40/100\n",
            "189/189 - 1s - loss: 0.8964 - accuracy: 0.7030 - val_loss: 1.9062 - val_accuracy: 0.4529 - 657ms/epoch - 3ms/step\n",
            "Epoch 41/100\n",
            "189/189 - 1s - loss: 0.9365 - accuracy: 0.6992 - val_loss: 1.7735 - val_accuracy: 0.4574 - 666ms/epoch - 4ms/step\n",
            "Epoch 42/100\n",
            "189/189 - 1s - loss: 0.9211 - accuracy: 0.7007 - val_loss: 1.7665 - val_accuracy: 0.4723 - 667ms/epoch - 4ms/step\n",
            "Epoch 43/100\n",
            "189/189 - 1s - loss: 0.9108 - accuracy: 0.7080 - val_loss: 1.9437 - val_accuracy: 0.4694 - 655ms/epoch - 3ms/step\n",
            "Epoch 44/100\n",
            "189/189 - 1s - loss: 0.8935 - accuracy: 0.7084 - val_loss: 1.8104 - val_accuracy: 0.4395 - 666ms/epoch - 4ms/step\n",
            "Epoch 45/100\n",
            "189/189 - 1s - loss: 0.8887 - accuracy: 0.7128 - val_loss: 1.9080 - val_accuracy: 0.4634 - 659ms/epoch - 3ms/step\n",
            "Epoch 46/100\n",
            "189/189 - 1s - loss: 0.8668 - accuracy: 0.7115 - val_loss: 1.9455 - val_accuracy: 0.4634 - 660ms/epoch - 3ms/step\n",
            "Epoch 47/100\n",
            "189/189 - 1s - loss: 0.9009 - accuracy: 0.7122 - val_loss: 1.9124 - val_accuracy: 0.4768 - 655ms/epoch - 3ms/step\n",
            "Epoch 48/100\n",
            "189/189 - 1s - loss: 0.9154 - accuracy: 0.7057 - val_loss: 1.8426 - val_accuracy: 0.4813 - 660ms/epoch - 3ms/step\n",
            "Epoch 49/100\n",
            "189/189 - 1s - loss: 0.8669 - accuracy: 0.7183 - val_loss: 1.8529 - val_accuracy: 0.5396 - 656ms/epoch - 3ms/step\n",
            "Epoch 50/100\n",
            "189/189 - 1s - loss: 0.8920 - accuracy: 0.7168 - val_loss: 2.0233 - val_accuracy: 0.4395 - 650ms/epoch - 3ms/step\n",
            "Epoch 51/100\n",
            "189/189 - 1s - loss: 0.9338 - accuracy: 0.6956 - val_loss: 1.9415 - val_accuracy: 0.4604 - 670ms/epoch - 4ms/step\n",
            "Epoch 52/100\n",
            "189/189 - 1s - loss: 0.8899 - accuracy: 0.7250 - val_loss: 1.8007 - val_accuracy: 0.5052 - 696ms/epoch - 4ms/step\n",
            "Epoch 53/100\n",
            "189/189 - 1s - loss: 0.8657 - accuracy: 0.7188 - val_loss: 1.9508 - val_accuracy: 0.4439 - 657ms/epoch - 3ms/step\n",
            "Epoch 54/100\n",
            "189/189 - 1s - loss: 0.8393 - accuracy: 0.7245 - val_loss: 2.0982 - val_accuracy: 0.4544 - 660ms/epoch - 3ms/step\n",
            "Epoch 55/100\n",
            "189/189 - 1s - loss: 0.8795 - accuracy: 0.7175 - val_loss: 1.9888 - val_accuracy: 0.4335 - 655ms/epoch - 3ms/step\n",
            "Epoch 56/100\n",
            "189/189 - 1s - loss: 0.8505 - accuracy: 0.7263 - val_loss: 1.8963 - val_accuracy: 0.4544 - 668ms/epoch - 4ms/step\n",
            "Epoch 57/100\n",
            "189/189 - 1s - loss: 0.8297 - accuracy: 0.7288 - val_loss: 1.8827 - val_accuracy: 0.4888 - 675ms/epoch - 4ms/step\n",
            "Epoch 58/100\n",
            "189/189 - 1s - loss: 0.8459 - accuracy: 0.7270 - val_loss: 1.9249 - val_accuracy: 0.4978 - 670ms/epoch - 4ms/step\n",
            "Epoch 59/100\n",
            "189/189 - 1s - loss: 0.8495 - accuracy: 0.7221 - val_loss: 1.8224 - val_accuracy: 0.4888 - 665ms/epoch - 4ms/step\n",
            "Epoch 60/100\n",
            "189/189 - 1s - loss: 0.7957 - accuracy: 0.7386 - val_loss: 1.9020 - val_accuracy: 0.4738 - 661ms/epoch - 3ms/step\n",
            "Epoch 61/100\n",
            "189/189 - 1s - loss: 0.8182 - accuracy: 0.7429 - val_loss: 1.8647 - val_accuracy: 0.4768 - 658ms/epoch - 3ms/step\n",
            "Epoch 62/100\n",
            "189/189 - 1s - loss: 0.8098 - accuracy: 0.7392 - val_loss: 2.0296 - val_accuracy: 0.4933 - 658ms/epoch - 3ms/step\n",
            "Epoch 63/100\n",
            "189/189 - 1s - loss: 0.8497 - accuracy: 0.7231 - val_loss: 1.9916 - val_accuracy: 0.4753 - 651ms/epoch - 3ms/step\n",
            "Epoch 64/100\n",
            "189/189 - 1s - loss: 0.8294 - accuracy: 0.7281 - val_loss: 2.1890 - val_accuracy: 0.4694 - 657ms/epoch - 3ms/step\n",
            "Epoch 65/100\n",
            "189/189 - 1s - loss: 0.8461 - accuracy: 0.7140 - val_loss: 2.1824 - val_accuracy: 0.4873 - 658ms/epoch - 3ms/step\n",
            "Epoch 66/100\n",
            "189/189 - 1s - loss: 0.8343 - accuracy: 0.7271 - val_loss: 1.9726 - val_accuracy: 0.4858 - 672ms/epoch - 4ms/step\n",
            "Epoch 67/100\n",
            "189/189 - 1s - loss: 0.8060 - accuracy: 0.7324 - val_loss: 2.2305 - val_accuracy: 0.4649 - 665ms/epoch - 4ms/step\n",
            "Epoch 68/100\n",
            "189/189 - 1s - loss: 0.9929 - accuracy: 0.6805 - val_loss: 1.9810 - val_accuracy: 0.4454 - 662ms/epoch - 4ms/step\n",
            "Epoch 69/100\n",
            "189/189 - 1s - loss: 0.8153 - accuracy: 0.7353 - val_loss: 2.0581 - val_accuracy: 0.4529 - 662ms/epoch - 4ms/step\n",
            "Epoch 70/100\n",
            "189/189 - 1s - loss: 0.8174 - accuracy: 0.7339 - val_loss: 1.9955 - val_accuracy: 0.4559 - 664ms/epoch - 4ms/step\n",
            "Epoch 71/100\n",
            "189/189 - 1s - loss: 0.7969 - accuracy: 0.7387 - val_loss: 1.8339 - val_accuracy: 0.4768 - 666ms/epoch - 4ms/step\n",
            "Epoch 72/100\n",
            "189/189 - 1s - loss: 0.7766 - accuracy: 0.7522 - val_loss: 2.2127 - val_accuracy: 0.4529 - 662ms/epoch - 4ms/step\n",
            "Epoch 73/100\n",
            "189/189 - 1s - loss: 0.7827 - accuracy: 0.7446 - val_loss: 2.0731 - val_accuracy: 0.4574 - 655ms/epoch - 3ms/step\n",
            "Epoch 74/100\n",
            "189/189 - 1s - loss: 0.7844 - accuracy: 0.7422 - val_loss: 1.8210 - val_accuracy: 0.4993 - 664ms/epoch - 4ms/step\n",
            "Epoch 75/100\n",
            "189/189 - 1s - loss: 0.7770 - accuracy: 0.7490 - val_loss: 2.0653 - val_accuracy: 0.4350 - 666ms/epoch - 4ms/step\n",
            "Epoch 76/100\n",
            "189/189 - 1s - loss: 0.7991 - accuracy: 0.7366 - val_loss: 2.1192 - val_accuracy: 0.4723 - 657ms/epoch - 3ms/step\n",
            "Epoch 77/100\n",
            "189/189 - 1s - loss: 0.7936 - accuracy: 0.7427 - val_loss: 1.9393 - val_accuracy: 0.4649 - 656ms/epoch - 3ms/step\n",
            "Epoch 78/100\n",
            "189/189 - 1s - loss: 0.7679 - accuracy: 0.7500 - val_loss: 2.0528 - val_accuracy: 0.4469 - 662ms/epoch - 4ms/step\n",
            "Epoch 79/100\n",
            "189/189 - 1s - loss: 0.7503 - accuracy: 0.7530 - val_loss: 2.0080 - val_accuracy: 0.4753 - 658ms/epoch - 3ms/step\n",
            "Epoch 80/100\n",
            "189/189 - 1s - loss: 0.7906 - accuracy: 0.7396 - val_loss: 2.1910 - val_accuracy: 0.4305 - 665ms/epoch - 4ms/step\n",
            "Epoch 81/100\n",
            "189/189 - 1s - loss: 0.8102 - accuracy: 0.7459 - val_loss: 2.1918 - val_accuracy: 0.4574 - 673ms/epoch - 4ms/step\n",
            "Epoch 82/100\n",
            "189/189 - 1s - loss: 0.7848 - accuracy: 0.7519 - val_loss: 2.1048 - val_accuracy: 0.4529 - 654ms/epoch - 3ms/step\n",
            "Epoch 83/100\n",
            "189/189 - 1s - loss: 0.8194 - accuracy: 0.7341 - val_loss: 1.9234 - val_accuracy: 0.4738 - 656ms/epoch - 3ms/step\n",
            "Epoch 84/100\n",
            "189/189 - 1s - loss: 0.7952 - accuracy: 0.7464 - val_loss: 2.1051 - val_accuracy: 0.4604 - 660ms/epoch - 3ms/step\n",
            "Epoch 85/100\n",
            "189/189 - 1s - loss: 0.8571 - accuracy: 0.7285 - val_loss: 2.1752 - val_accuracy: 0.4350 - 659ms/epoch - 3ms/step\n",
            "Epoch 86/100\n",
            "189/189 - 1s - loss: 0.8456 - accuracy: 0.7273 - val_loss: 2.0836 - val_accuracy: 0.4484 - 661ms/epoch - 3ms/step\n",
            "Epoch 87/100\n",
            "189/189 - 1s - loss: 0.7852 - accuracy: 0.7494 - val_loss: 2.1681 - val_accuracy: 0.4410 - 667ms/epoch - 4ms/step\n",
            "Epoch 88/100\n",
            "189/189 - 1s - loss: 0.7852 - accuracy: 0.7474 - val_loss: 2.0088 - val_accuracy: 0.4709 - 660ms/epoch - 3ms/step\n",
            "Epoch 89/100\n",
            "189/189 - 1s - loss: 0.7712 - accuracy: 0.7504 - val_loss: 2.1062 - val_accuracy: 0.4380 - 656ms/epoch - 3ms/step\n",
            "Epoch 90/100\n",
            "189/189 - 1s - loss: 0.7963 - accuracy: 0.7497 - val_loss: 2.0989 - val_accuracy: 0.4141 - 663ms/epoch - 4ms/step\n",
            "Epoch 91/100\n",
            "189/189 - 1s - loss: 0.8200 - accuracy: 0.7392 - val_loss: 1.9859 - val_accuracy: 0.4798 - 654ms/epoch - 3ms/step\n",
            "Epoch 92/100\n",
            "189/189 - 1s - loss: 0.8889 - accuracy: 0.7150 - val_loss: 2.1543 - val_accuracy: 0.4141 - 660ms/epoch - 3ms/step\n",
            "Epoch 93/100\n",
            "189/189 - 1s - loss: 0.8420 - accuracy: 0.7329 - val_loss: 2.1135 - val_accuracy: 0.4529 - 674ms/epoch - 4ms/step\n",
            "Epoch 94/100\n",
            "189/189 - 1s - loss: 0.7995 - accuracy: 0.7477 - val_loss: 2.1667 - val_accuracy: 0.4664 - 675ms/epoch - 4ms/step\n",
            "Epoch 95/100\n",
            "189/189 - 1s - loss: 0.7728 - accuracy: 0.7451 - val_loss: 2.1474 - val_accuracy: 0.4634 - 680ms/epoch - 4ms/step\n",
            "Epoch 96/100\n",
            "189/189 - 1s - loss: 0.8197 - accuracy: 0.7366 - val_loss: 2.2406 - val_accuracy: 0.4574 - 691ms/epoch - 4ms/step\n",
            "Epoch 97/100\n",
            "189/189 - 1s - loss: 0.7857 - accuracy: 0.7530 - val_loss: 2.2064 - val_accuracy: 0.4604 - 676ms/epoch - 4ms/step\n",
            "Epoch 98/100\n",
            "189/189 - 1s - loss: 0.8064 - accuracy: 0.7411 - val_loss: 2.0660 - val_accuracy: 0.4738 - 682ms/epoch - 4ms/step\n",
            "Epoch 99/100\n",
            "189/189 - 1s - loss: 0.7697 - accuracy: 0.7572 - val_loss: 2.1808 - val_accuracy: 0.4529 - 694ms/epoch - 4ms/step\n",
            "Epoch 100/100\n",
            "189/189 - 1s - loss: 0.7804 - accuracy: 0.7485 - val_loss: 2.0778 - val_accuracy: 0.4439 - 677ms/epoch - 4ms/step\n",
            "Model: \"sequential_9\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " reshape_8 (Reshape)         (None, 128, 40)           0         \n",
            "                                                                 \n",
            " conv1d_16 (Conv1D)          (None, 124, 12)           2412      \n",
            "                                                                 \n",
            " max_pooling1d_16 (MaxPoolin  (None, 62, 12)           0         \n",
            " g1D)                                                            \n",
            "                                                                 \n",
            " conv1d_17 (Conv1D)          (None, 58, 28)            1708      \n",
            "                                                                 \n",
            " max_pooling1d_17 (MaxPoolin  (None, 29, 28)           0         \n",
            " g1D)                                                            \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 29, 30)            870       \n",
            "                                                                 \n",
            " dropout_8 (Dropout)         (None, 29, 30)            0         \n",
            "                                                                 \n",
            " flatten_8 (Flatten)         (None, 870)               0         \n",
            "                                                                 \n",
            " y_pred (Dense)              (None, 10)                8710      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 13,700\n",
            "Trainable params: 13,700\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Result of fold:5\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 2.3532 - accuracy: 0.4340\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 50%|█████     | 5/10 [05:59<05:50, 70.05s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "191/191 - 2s - loss: 2.2463 - accuracy: 0.2652 - val_loss: 1.8254 - val_accuracy: 0.3717 - 2s/epoch - 8ms/step\n",
            "Epoch 2/100\n",
            "191/191 - 1s - loss: 1.7485 - accuracy: 0.3694 - val_loss: 1.7148 - val_accuracy: 0.3820 - 680ms/epoch - 4ms/step\n",
            "Epoch 3/100\n",
            "191/191 - 1s - loss: 1.5850 - accuracy: 0.4327 - val_loss: 1.6025 - val_accuracy: 0.4779 - 684ms/epoch - 4ms/step\n",
            "Epoch 4/100\n",
            "191/191 - 1s - loss: 1.5685 - accuracy: 0.4577 - val_loss: 1.6860 - val_accuracy: 0.3953 - 683ms/epoch - 4ms/step\n",
            "Epoch 5/100\n",
            "191/191 - 1s - loss: 1.4575 - accuracy: 0.4831 - val_loss: 1.5785 - val_accuracy: 0.5044 - 695ms/epoch - 4ms/step\n",
            "Epoch 6/100\n",
            "191/191 - 1s - loss: 1.4525 - accuracy: 0.5021 - val_loss: 1.6319 - val_accuracy: 0.4587 - 685ms/epoch - 4ms/step\n",
            "Epoch 7/100\n",
            "191/191 - 1s - loss: 1.3841 - accuracy: 0.5251 - val_loss: 1.5711 - val_accuracy: 0.4720 - 669ms/epoch - 4ms/step\n",
            "Epoch 8/100\n",
            "191/191 - 1s - loss: 1.3409 - accuracy: 0.5404 - val_loss: 1.6305 - val_accuracy: 0.4543 - 671ms/epoch - 4ms/step\n",
            "Epoch 9/100\n",
            "191/191 - 1s - loss: 1.3152 - accuracy: 0.5517 - val_loss: 1.5439 - val_accuracy: 0.5265 - 667ms/epoch - 3ms/step\n",
            "Epoch 10/100\n",
            "191/191 - 1s - loss: 1.2385 - accuracy: 0.5971 - val_loss: 1.4352 - val_accuracy: 0.5487 - 672ms/epoch - 4ms/step\n",
            "Epoch 11/100\n",
            "191/191 - 1s - loss: 1.2382 - accuracy: 0.5916 - val_loss: 1.5164 - val_accuracy: 0.5516 - 672ms/epoch - 4ms/step\n",
            "Epoch 12/100\n",
            "191/191 - 1s - loss: 1.1836 - accuracy: 0.6167 - val_loss: 1.6073 - val_accuracy: 0.4867 - 664ms/epoch - 3ms/step\n",
            "Epoch 13/100\n",
            "191/191 - 1s - loss: 1.1513 - accuracy: 0.6223 - val_loss: 1.4995 - val_accuracy: 0.5059 - 683ms/epoch - 4ms/step\n",
            "Epoch 14/100\n",
            "191/191 - 1s - loss: 1.1043 - accuracy: 0.6380 - val_loss: 1.4437 - val_accuracy: 0.5324 - 662ms/epoch - 3ms/step\n",
            "Epoch 15/100\n",
            "191/191 - 1s - loss: 1.0960 - accuracy: 0.6387 - val_loss: 1.5307 - val_accuracy: 0.5221 - 682ms/epoch - 4ms/step\n",
            "Epoch 16/100\n",
            "191/191 - 1s - loss: 1.0822 - accuracy: 0.6492 - val_loss: 1.5150 - val_accuracy: 0.5206 - 666ms/epoch - 3ms/step\n",
            "Epoch 17/100\n",
            "191/191 - 1s - loss: 1.2109 - accuracy: 0.6058 - val_loss: 1.6376 - val_accuracy: 0.4764 - 666ms/epoch - 3ms/step\n",
            "Epoch 18/100\n",
            "191/191 - 1s - loss: 1.1453 - accuracy: 0.6260 - val_loss: 1.4897 - val_accuracy: 0.5162 - 668ms/epoch - 3ms/step\n",
            "Epoch 19/100\n",
            "191/191 - 1s - loss: 1.0702 - accuracy: 0.6441 - val_loss: 1.6580 - val_accuracy: 0.4985 - 664ms/epoch - 3ms/step\n",
            "Epoch 20/100\n",
            "191/191 - 1s - loss: 1.0479 - accuracy: 0.6544 - val_loss: 1.4446 - val_accuracy: 0.5398 - 670ms/epoch - 4ms/step\n",
            "Epoch 21/100\n",
            "191/191 - 1s - loss: 1.0653 - accuracy: 0.6516 - val_loss: 1.5117 - val_accuracy: 0.5118 - 666ms/epoch - 3ms/step\n",
            "Epoch 22/100\n",
            "191/191 - 1s - loss: 1.1394 - accuracy: 0.6214 - val_loss: 1.6723 - val_accuracy: 0.4823 - 675ms/epoch - 4ms/step\n",
            "Epoch 23/100\n",
            "191/191 - 1s - loss: 1.1153 - accuracy: 0.6277 - val_loss: 1.5345 - val_accuracy: 0.5147 - 686ms/epoch - 4ms/step\n",
            "Epoch 24/100\n",
            "191/191 - 1s - loss: 1.0879 - accuracy: 0.6388 - val_loss: 1.5923 - val_accuracy: 0.4941 - 675ms/epoch - 4ms/step\n",
            "Epoch 25/100\n",
            "191/191 - 1s - loss: 1.0327 - accuracy: 0.6644 - val_loss: 1.7181 - val_accuracy: 0.4617 - 682ms/epoch - 4ms/step\n",
            "Epoch 26/100\n",
            "191/191 - 1s - loss: 1.0293 - accuracy: 0.6611 - val_loss: 1.6701 - val_accuracy: 0.5103 - 671ms/epoch - 4ms/step\n",
            "Epoch 27/100\n",
            "191/191 - 1s - loss: 1.0235 - accuracy: 0.6615 - val_loss: 1.5583 - val_accuracy: 0.5133 - 665ms/epoch - 3ms/step\n",
            "Epoch 28/100\n",
            "191/191 - 1s - loss: 1.0042 - accuracy: 0.6703 - val_loss: 1.6715 - val_accuracy: 0.4971 - 668ms/epoch - 3ms/step\n",
            "Epoch 29/100\n",
            "191/191 - 1s - loss: 1.0123 - accuracy: 0.6753 - val_loss: 1.6093 - val_accuracy: 0.5177 - 663ms/epoch - 3ms/step\n",
            "Epoch 30/100\n",
            "191/191 - 1s - loss: 0.9928 - accuracy: 0.6790 - val_loss: 1.7478 - val_accuracy: 0.4838 - 667ms/epoch - 3ms/step\n",
            "Epoch 31/100\n",
            "191/191 - 1s - loss: 0.9588 - accuracy: 0.6835 - val_loss: 1.5637 - val_accuracy: 0.5074 - 673ms/epoch - 4ms/step\n",
            "Epoch 32/100\n",
            "191/191 - 1s - loss: 0.9794 - accuracy: 0.6810 - val_loss: 1.5868 - val_accuracy: 0.5206 - 663ms/epoch - 3ms/step\n",
            "Epoch 33/100\n",
            "191/191 - 1s - loss: 0.9199 - accuracy: 0.7040 - val_loss: 1.7602 - val_accuracy: 0.4882 - 682ms/epoch - 4ms/step\n",
            "Epoch 34/100\n",
            "191/191 - 1s - loss: 0.9554 - accuracy: 0.6941 - val_loss: 1.7337 - val_accuracy: 0.5177 - 668ms/epoch - 3ms/step\n",
            "Epoch 35/100\n",
            "191/191 - 1s - loss: 0.9118 - accuracy: 0.7117 - val_loss: 1.7505 - val_accuracy: 0.5118 - 664ms/epoch - 3ms/step\n",
            "Epoch 36/100\n",
            "191/191 - 1s - loss: 0.9176 - accuracy: 0.6977 - val_loss: 1.7297 - val_accuracy: 0.5133 - 666ms/epoch - 3ms/step\n",
            "Epoch 37/100\n",
            "191/191 - 1s - loss: 0.8856 - accuracy: 0.7176 - val_loss: 1.8145 - val_accuracy: 0.4720 - 664ms/epoch - 3ms/step\n",
            "Epoch 38/100\n",
            "191/191 - 1s - loss: 0.8884 - accuracy: 0.7132 - val_loss: 1.7372 - val_accuracy: 0.5015 - 686ms/epoch - 4ms/step\n",
            "Epoch 39/100\n",
            "191/191 - 1s - loss: 0.9491 - accuracy: 0.6862 - val_loss: 1.7473 - val_accuracy: 0.5015 - 681ms/epoch - 4ms/step\n",
            "Epoch 40/100\n",
            "191/191 - 1s - loss: 0.9305 - accuracy: 0.6982 - val_loss: 1.8620 - val_accuracy: 0.5147 - 669ms/epoch - 4ms/step\n",
            "Epoch 41/100\n",
            "191/191 - 1s - loss: 0.9319 - accuracy: 0.6977 - val_loss: 1.8038 - val_accuracy: 0.4749 - 660ms/epoch - 3ms/step\n",
            "Epoch 42/100\n",
            "191/191 - 1s - loss: 0.8771 - accuracy: 0.7158 - val_loss: 1.7351 - val_accuracy: 0.5324 - 671ms/epoch - 4ms/step\n",
            "Epoch 43/100\n",
            "191/191 - 1s - loss: 0.8727 - accuracy: 0.7235 - val_loss: 1.7531 - val_accuracy: 0.5177 - 678ms/epoch - 4ms/step\n",
            "Epoch 44/100\n",
            "191/191 - 1s - loss: 0.8905 - accuracy: 0.7132 - val_loss: 1.7761 - val_accuracy: 0.5147 - 671ms/epoch - 4ms/step\n",
            "Epoch 45/100\n",
            "191/191 - 1s - loss: 0.8838 - accuracy: 0.7217 - val_loss: 1.9672 - val_accuracy: 0.5029 - 673ms/epoch - 4ms/step\n",
            "Epoch 46/100\n",
            "191/191 - 1s - loss: 0.8756 - accuracy: 0.7251 - val_loss: 1.9112 - val_accuracy: 0.5015 - 707ms/epoch - 4ms/step\n",
            "Epoch 47/100\n",
            "191/191 - 1s - loss: 0.8296 - accuracy: 0.7376 - val_loss: 1.6669 - val_accuracy: 0.5088 - 675ms/epoch - 4ms/step\n",
            "Epoch 48/100\n",
            "191/191 - 1s - loss: 0.8781 - accuracy: 0.7118 - val_loss: 1.7050 - val_accuracy: 0.5236 - 678ms/epoch - 4ms/step\n",
            "Epoch 49/100\n",
            "191/191 - 1s - loss: 0.8903 - accuracy: 0.7110 - val_loss: 1.8204 - val_accuracy: 0.5133 - 719ms/epoch - 4ms/step\n",
            "Epoch 50/100\n",
            "191/191 - 1s - loss: 0.8602 - accuracy: 0.7263 - val_loss: 1.8218 - val_accuracy: 0.5147 - 755ms/epoch - 4ms/step\n",
            "Epoch 51/100\n",
            "191/191 - 1s - loss: 0.8913 - accuracy: 0.7115 - val_loss: 1.7093 - val_accuracy: 0.4912 - 749ms/epoch - 4ms/step\n",
            "Epoch 52/100\n",
            "191/191 - 1s - loss: 0.8691 - accuracy: 0.7219 - val_loss: 1.8294 - val_accuracy: 0.5428 - 679ms/epoch - 4ms/step\n",
            "Epoch 53/100\n",
            "191/191 - 1s - loss: 0.8797 - accuracy: 0.7283 - val_loss: 1.8371 - val_accuracy: 0.5177 - 673ms/epoch - 4ms/step\n",
            "Epoch 54/100\n",
            "191/191 - 1s - loss: 0.8678 - accuracy: 0.7219 - val_loss: 1.8093 - val_accuracy: 0.5147 - 672ms/epoch - 4ms/step\n",
            "Epoch 55/100\n",
            "191/191 - 1s - loss: 0.9061 - accuracy: 0.7118 - val_loss: 1.7849 - val_accuracy: 0.5339 - 678ms/epoch - 4ms/step\n",
            "Epoch 56/100\n",
            "191/191 - 1s - loss: 0.8437 - accuracy: 0.7265 - val_loss: 1.8633 - val_accuracy: 0.5015 - 678ms/epoch - 4ms/step\n",
            "Epoch 57/100\n",
            "191/191 - 1s - loss: 0.8330 - accuracy: 0.7355 - val_loss: 1.9846 - val_accuracy: 0.5029 - 667ms/epoch - 3ms/step\n",
            "Epoch 58/100\n",
            "191/191 - 1s - loss: 0.8282 - accuracy: 0.7384 - val_loss: 1.7332 - val_accuracy: 0.5428 - 674ms/epoch - 4ms/step\n",
            "Epoch 59/100\n",
            "191/191 - 1s - loss: 0.8547 - accuracy: 0.7283 - val_loss: 1.7625 - val_accuracy: 0.5221 - 669ms/epoch - 4ms/step\n",
            "Epoch 60/100\n",
            "191/191 - 1s - loss: 0.8279 - accuracy: 0.7378 - val_loss: 1.8577 - val_accuracy: 0.4971 - 670ms/epoch - 4ms/step\n",
            "Epoch 61/100\n",
            "191/191 - 1s - loss: 0.8170 - accuracy: 0.7399 - val_loss: 1.8008 - val_accuracy: 0.4676 - 676ms/epoch - 4ms/step\n",
            "Epoch 62/100\n",
            "191/191 - 1s - loss: 1.0434 - accuracy: 0.6621 - val_loss: 1.8972 - val_accuracy: 0.5059 - 665ms/epoch - 3ms/step\n",
            "Epoch 63/100\n",
            "191/191 - 1s - loss: 0.9191 - accuracy: 0.7046 - val_loss: 1.8016 - val_accuracy: 0.5103 - 662ms/epoch - 3ms/step\n",
            "Epoch 64/100\n",
            "191/191 - 1s - loss: 0.8501 - accuracy: 0.7307 - val_loss: 1.9028 - val_accuracy: 0.5059 - 686ms/epoch - 4ms/step\n",
            "Epoch 65/100\n",
            "191/191 - 1s - loss: 0.7898 - accuracy: 0.7476 - val_loss: 1.9296 - val_accuracy: 0.5029 - 688ms/epoch - 4ms/step\n",
            "Epoch 66/100\n",
            "191/191 - 1s - loss: 0.8105 - accuracy: 0.7463 - val_loss: 1.9510 - val_accuracy: 0.4853 - 688ms/epoch - 4ms/step\n",
            "Epoch 67/100\n",
            "191/191 - 1s - loss: 0.8247 - accuracy: 0.7347 - val_loss: 1.7563 - val_accuracy: 0.5147 - 675ms/epoch - 4ms/step\n",
            "Epoch 68/100\n",
            "191/191 - 1s - loss: 0.8112 - accuracy: 0.7330 - val_loss: 1.7794 - val_accuracy: 0.5531 - 704ms/epoch - 4ms/step\n",
            "Epoch 69/100\n",
            "191/191 - 1s - loss: 0.8034 - accuracy: 0.7465 - val_loss: 1.8655 - val_accuracy: 0.5206 - 674ms/epoch - 4ms/step\n",
            "Epoch 70/100\n",
            "191/191 - 1s - loss: 0.8097 - accuracy: 0.7488 - val_loss: 1.8146 - val_accuracy: 0.5074 - 688ms/epoch - 4ms/step\n",
            "Epoch 71/100\n",
            "191/191 - 1s - loss: 0.8165 - accuracy: 0.7435 - val_loss: 2.1111 - val_accuracy: 0.4676 - 683ms/epoch - 4ms/step\n",
            "Epoch 72/100\n",
            "191/191 - 1s - loss: 0.8215 - accuracy: 0.7401 - val_loss: 2.0636 - val_accuracy: 0.4572 - 687ms/epoch - 4ms/step\n",
            "Epoch 73/100\n",
            "191/191 - 1s - loss: 0.8111 - accuracy: 0.7379 - val_loss: 2.0552 - val_accuracy: 0.5295 - 669ms/epoch - 4ms/step\n",
            "Epoch 74/100\n",
            "191/191 - 1s - loss: 0.8059 - accuracy: 0.7442 - val_loss: 1.9812 - val_accuracy: 0.5029 - 679ms/epoch - 4ms/step\n",
            "Epoch 75/100\n",
            "191/191 - 1s - loss: 0.7927 - accuracy: 0.7427 - val_loss: 1.8016 - val_accuracy: 0.5147 - 665ms/epoch - 3ms/step\n",
            "Epoch 76/100\n",
            "191/191 - 1s - loss: 0.7881 - accuracy: 0.7504 - val_loss: 1.8583 - val_accuracy: 0.5118 - 677ms/epoch - 4ms/step\n",
            "Epoch 77/100\n",
            "191/191 - 1s - loss: 0.7833 - accuracy: 0.7491 - val_loss: 1.9570 - val_accuracy: 0.4926 - 676ms/epoch - 4ms/step\n",
            "Epoch 78/100\n",
            "191/191 - 1s - loss: 0.8462 - accuracy: 0.7376 - val_loss: 1.9083 - val_accuracy: 0.5310 - 664ms/epoch - 3ms/step\n",
            "Epoch 79/100\n",
            "191/191 - 1s - loss: 0.8327 - accuracy: 0.7383 - val_loss: 2.1158 - val_accuracy: 0.5192 - 666ms/epoch - 3ms/step\n",
            "Epoch 80/100\n",
            "191/191 - 1s - loss: 0.8192 - accuracy: 0.7437 - val_loss: 2.0171 - val_accuracy: 0.5133 - 665ms/epoch - 3ms/step\n",
            "Epoch 81/100\n",
            "191/191 - 1s - loss: 0.7862 - accuracy: 0.7509 - val_loss: 2.0523 - val_accuracy: 0.5192 - 664ms/epoch - 3ms/step\n",
            "Epoch 82/100\n",
            "191/191 - 1s - loss: 0.8320 - accuracy: 0.7373 - val_loss: 2.3417 - val_accuracy: 0.4410 - 676ms/epoch - 4ms/step\n",
            "Epoch 83/100\n",
            "191/191 - 1s - loss: 0.8432 - accuracy: 0.7373 - val_loss: 2.0455 - val_accuracy: 0.5192 - 670ms/epoch - 4ms/step\n",
            "Epoch 84/100\n",
            "191/191 - 1s - loss: 0.8214 - accuracy: 0.7373 - val_loss: 1.8858 - val_accuracy: 0.5133 - 680ms/epoch - 4ms/step\n",
            "Epoch 85/100\n",
            "191/191 - 1s - loss: 0.8158 - accuracy: 0.7455 - val_loss: 1.9220 - val_accuracy: 0.5324 - 672ms/epoch - 4ms/step\n",
            "Epoch 86/100\n",
            "191/191 - 1s - loss: 0.7698 - accuracy: 0.7589 - val_loss: 2.0488 - val_accuracy: 0.5221 - 672ms/epoch - 4ms/step\n",
            "Epoch 87/100\n",
            "191/191 - 1s - loss: 0.8044 - accuracy: 0.7447 - val_loss: 1.9557 - val_accuracy: 0.5546 - 667ms/epoch - 3ms/step\n",
            "Epoch 88/100\n",
            "191/191 - 1s - loss: 0.7787 - accuracy: 0.7527 - val_loss: 1.9416 - val_accuracy: 0.5206 - 671ms/epoch - 4ms/step\n",
            "Epoch 89/100\n",
            "191/191 - 1s - loss: 0.7819 - accuracy: 0.7491 - val_loss: 1.9387 - val_accuracy: 0.5029 - 678ms/epoch - 4ms/step\n",
            "Epoch 90/100\n",
            "191/191 - 1s - loss: 0.7564 - accuracy: 0.7558 - val_loss: 2.0490 - val_accuracy: 0.5000 - 664ms/epoch - 3ms/step\n",
            "Epoch 91/100\n",
            "191/191 - 1s - loss: 0.7891 - accuracy: 0.7498 - val_loss: 2.0060 - val_accuracy: 0.5251 - 673ms/epoch - 4ms/step\n",
            "Epoch 92/100\n",
            "191/191 - 1s - loss: 0.7903 - accuracy: 0.7509 - val_loss: 2.0425 - val_accuracy: 0.5354 - 672ms/epoch - 4ms/step\n",
            "Epoch 93/100\n",
            "191/191 - 1s - loss: 0.7810 - accuracy: 0.7742 - val_loss: 2.0613 - val_accuracy: 0.5103 - 670ms/epoch - 4ms/step\n",
            "Epoch 94/100\n",
            "191/191 - 1s - loss: 0.7704 - accuracy: 0.7621 - val_loss: 2.0432 - val_accuracy: 0.4971 - 662ms/epoch - 3ms/step\n",
            "Epoch 95/100\n",
            "191/191 - 1s - loss: 0.7677 - accuracy: 0.7581 - val_loss: 1.9061 - val_accuracy: 0.5516 - 671ms/epoch - 4ms/step\n",
            "Epoch 96/100\n",
            "191/191 - 1s - loss: 0.7536 - accuracy: 0.7583 - val_loss: 2.0190 - val_accuracy: 0.5162 - 667ms/epoch - 3ms/step\n",
            "Epoch 97/100\n",
            "191/191 - 1s - loss: 0.7463 - accuracy: 0.7601 - val_loss: 2.1249 - val_accuracy: 0.4823 - 684ms/epoch - 4ms/step\n",
            "Epoch 98/100\n",
            "191/191 - 1s - loss: 0.7907 - accuracy: 0.7506 - val_loss: 1.7649 - val_accuracy: 0.5619 - 685ms/epoch - 4ms/step\n",
            "Epoch 99/100\n",
            "191/191 - 1s - loss: 0.7781 - accuracy: 0.7491 - val_loss: 1.8551 - val_accuracy: 0.5428 - 679ms/epoch - 4ms/step\n",
            "Epoch 100/100\n",
            "191/191 - 1s - loss: 0.7638 - accuracy: 0.7535 - val_loss: 1.8743 - val_accuracy: 0.5280 - 681ms/epoch - 4ms/step\n",
            "Model: \"sequential_11\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " reshape_10 (Reshape)        (None, 128, 40)           0         \n",
            "                                                                 \n",
            " conv1d_20 (Conv1D)          (None, 124, 12)           2412      \n",
            "                                                                 \n",
            " max_pooling1d_20 (MaxPoolin  (None, 62, 12)           0         \n",
            " g1D)                                                            \n",
            "                                                                 \n",
            " conv1d_21 (Conv1D)          (None, 58, 28)            1708      \n",
            "                                                                 \n",
            " max_pooling1d_21 (MaxPoolin  (None, 29, 28)           0         \n",
            " g1D)                                                            \n",
            "                                                                 \n",
            " dense_10 (Dense)            (None, 29, 30)            870       \n",
            "                                                                 \n",
            " dropout_10 (Dropout)        (None, 29, 30)            0         \n",
            "                                                                 \n",
            " flatten_10 (Flatten)        (None, 870)               0         \n",
            "                                                                 \n",
            " y_pred (Dense)              (None, 10)                8710      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 13,700\n",
            "Trainable params: 13,700\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Result of fold:6\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 2.1919 - accuracy: 0.4618\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 60%|██████    | 6/10 [07:08<04:39, 69.91s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "190/190 - 2s - loss: 2.1107 - accuracy: 0.2784 - val_loss: 1.8667 - val_accuracy: 0.3378 - 2s/epoch - 8ms/step\n",
            "Epoch 2/100\n",
            "190/190 - 1s - loss: 1.7868 - accuracy: 0.3501 - val_loss: 1.7638 - val_accuracy: 0.3793 - 679ms/epoch - 4ms/step\n",
            "Epoch 3/100\n",
            "190/190 - 1s - loss: 1.6959 - accuracy: 0.3964 - val_loss: 1.6934 - val_accuracy: 0.3733 - 667ms/epoch - 4ms/step\n",
            "Epoch 4/100\n",
            "190/190 - 1s - loss: 1.5556 - accuracy: 0.4524 - val_loss: 1.5632 - val_accuracy: 0.4711 - 671ms/epoch - 4ms/step\n",
            "Epoch 5/100\n",
            "190/190 - 1s - loss: 1.5140 - accuracy: 0.4694 - val_loss: 1.6468 - val_accuracy: 0.4178 - 657ms/epoch - 3ms/step\n",
            "Epoch 6/100\n",
            "190/190 - 1s - loss: 1.4642 - accuracy: 0.4919 - val_loss: 1.6142 - val_accuracy: 0.4519 - 666ms/epoch - 4ms/step\n",
            "Epoch 7/100\n",
            "190/190 - 1s - loss: 1.4451 - accuracy: 0.5133 - val_loss: 1.6835 - val_accuracy: 0.4163 - 669ms/epoch - 4ms/step\n",
            "Epoch 8/100\n",
            "190/190 - 1s - loss: 1.3643 - accuracy: 0.5417 - val_loss: 1.6276 - val_accuracy: 0.4400 - 671ms/epoch - 4ms/step\n",
            "Epoch 9/100\n",
            "190/190 - 1s - loss: 1.3915 - accuracy: 0.5356 - val_loss: 1.8082 - val_accuracy: 0.3081 - 667ms/epoch - 4ms/step\n",
            "Epoch 10/100\n",
            "190/190 - 1s - loss: 1.3879 - accuracy: 0.5209 - val_loss: 1.6281 - val_accuracy: 0.4607 - 689ms/epoch - 4ms/step\n",
            "Epoch 11/100\n",
            "190/190 - 1s - loss: 1.3203 - accuracy: 0.5504 - val_loss: 1.6929 - val_accuracy: 0.4489 - 674ms/epoch - 4ms/step\n",
            "Epoch 12/100\n",
            "190/190 - 1s - loss: 1.2307 - accuracy: 0.5870 - val_loss: 1.7561 - val_accuracy: 0.4148 - 665ms/epoch - 4ms/step\n",
            "Epoch 13/100\n",
            "190/190 - 1s - loss: 1.2630 - accuracy: 0.5870 - val_loss: 1.6674 - val_accuracy: 0.4415 - 668ms/epoch - 4ms/step\n",
            "Epoch 14/100\n",
            "190/190 - 1s - loss: 1.2073 - accuracy: 0.5970 - val_loss: 1.7915 - val_accuracy: 0.4578 - 666ms/epoch - 4ms/step\n",
            "Epoch 15/100\n",
            "190/190 - 1s - loss: 1.1665 - accuracy: 0.6173 - val_loss: 1.7080 - val_accuracy: 0.4311 - 671ms/epoch - 4ms/step\n",
            "Epoch 16/100\n",
            "190/190 - 1s - loss: 1.2065 - accuracy: 0.6063 - val_loss: 1.7540 - val_accuracy: 0.4000 - 667ms/epoch - 4ms/step\n",
            "Epoch 17/100\n",
            "190/190 - 1s - loss: 1.1979 - accuracy: 0.6008 - val_loss: 1.7302 - val_accuracy: 0.4474 - 672ms/epoch - 4ms/step\n",
            "Epoch 18/100\n",
            "190/190 - 1s - loss: 1.1593 - accuracy: 0.6198 - val_loss: 1.6924 - val_accuracy: 0.4370 - 663ms/epoch - 3ms/step\n",
            "Epoch 19/100\n",
            "190/190 - 1s - loss: 1.1200 - accuracy: 0.6369 - val_loss: 1.8125 - val_accuracy: 0.4163 - 687ms/epoch - 4ms/step\n",
            "Epoch 20/100\n",
            "190/190 - 1s - loss: 1.0706 - accuracy: 0.6470 - val_loss: 1.7301 - val_accuracy: 0.4563 - 666ms/epoch - 4ms/step\n",
            "Epoch 21/100\n",
            "190/190 - 1s - loss: 1.0746 - accuracy: 0.6456 - val_loss: 1.7159 - val_accuracy: 0.4385 - 660ms/epoch - 3ms/step\n",
            "Epoch 22/100\n",
            "190/190 - 1s - loss: 1.0667 - accuracy: 0.6405 - val_loss: 1.8483 - val_accuracy: 0.4267 - 676ms/epoch - 4ms/step\n",
            "Epoch 23/100\n",
            "190/190 - 1s - loss: 1.0609 - accuracy: 0.6514 - val_loss: 1.8860 - val_accuracy: 0.4830 - 662ms/epoch - 3ms/step\n",
            "Epoch 24/100\n",
            "190/190 - 1s - loss: 1.0744 - accuracy: 0.6501 - val_loss: 1.7170 - val_accuracy: 0.4504 - 663ms/epoch - 3ms/step\n",
            "Epoch 25/100\n",
            "190/190 - 1s - loss: 1.0410 - accuracy: 0.6547 - val_loss: 1.6559 - val_accuracy: 0.4741 - 666ms/epoch - 4ms/step\n",
            "Epoch 26/100\n",
            "190/190 - 1s - loss: 1.0105 - accuracy: 0.6689 - val_loss: 1.8267 - val_accuracy: 0.4267 - 672ms/epoch - 4ms/step\n",
            "Epoch 27/100\n",
            "190/190 - 1s - loss: 1.0420 - accuracy: 0.6572 - val_loss: 1.8592 - val_accuracy: 0.3926 - 655ms/epoch - 3ms/step\n",
            "Epoch 28/100\n",
            "190/190 - 1s - loss: 1.0058 - accuracy: 0.6667 - val_loss: 1.7994 - val_accuracy: 0.4385 - 672ms/epoch - 4ms/step\n",
            "Epoch 29/100\n",
            "190/190 - 1s - loss: 1.0199 - accuracy: 0.6638 - val_loss: 1.7451 - val_accuracy: 0.4400 - 669ms/epoch - 4ms/step\n",
            "Epoch 30/100\n",
            "190/190 - 1s - loss: 0.9722 - accuracy: 0.6773 - val_loss: 1.7684 - val_accuracy: 0.4489 - 664ms/epoch - 3ms/step\n",
            "Epoch 31/100\n",
            "190/190 - 1s - loss: 1.0035 - accuracy: 0.6745 - val_loss: 2.1062 - val_accuracy: 0.3896 - 664ms/epoch - 3ms/step\n",
            "Epoch 32/100\n",
            "190/190 - 1s - loss: 0.9781 - accuracy: 0.6764 - val_loss: 1.8351 - val_accuracy: 0.4593 - 686ms/epoch - 4ms/step\n",
            "Epoch 33/100\n",
            "190/190 - 1s - loss: 1.0873 - accuracy: 0.6450 - val_loss: 1.8962 - val_accuracy: 0.4207 - 662ms/epoch - 3ms/step\n",
            "Epoch 34/100\n",
            "190/190 - 1s - loss: 1.0286 - accuracy: 0.6631 - val_loss: 1.8319 - val_accuracy: 0.4267 - 679ms/epoch - 4ms/step\n",
            "Epoch 35/100\n",
            "190/190 - 1s - loss: 0.9861 - accuracy: 0.6741 - val_loss: 1.7794 - val_accuracy: 0.4519 - 660ms/epoch - 3ms/step\n",
            "Epoch 36/100\n",
            "190/190 - 1s - loss: 0.9805 - accuracy: 0.6825 - val_loss: 1.9438 - val_accuracy: 0.4148 - 660ms/epoch - 3ms/step\n",
            "Epoch 37/100\n",
            "190/190 - 1s - loss: 0.9739 - accuracy: 0.6794 - val_loss: 1.9637 - val_accuracy: 0.4044 - 671ms/epoch - 4ms/step\n",
            "Epoch 38/100\n",
            "190/190 - 1s - loss: 0.9493 - accuracy: 0.6876 - val_loss: 2.0148 - val_accuracy: 0.3911 - 663ms/epoch - 3ms/step\n",
            "Epoch 39/100\n",
            "190/190 - 1s - loss: 0.9622 - accuracy: 0.6829 - val_loss: 1.9737 - val_accuracy: 0.4252 - 664ms/epoch - 3ms/step\n",
            "Epoch 40/100\n",
            "190/190 - 1s - loss: 0.9759 - accuracy: 0.6891 - val_loss: 1.9076 - val_accuracy: 0.4296 - 679ms/epoch - 4ms/step\n",
            "Epoch 41/100\n",
            "190/190 - 1s - loss: 0.9744 - accuracy: 0.6837 - val_loss: 1.8811 - val_accuracy: 0.4237 - 671ms/epoch - 4ms/step\n",
            "Epoch 42/100\n",
            "190/190 - 1s - loss: 0.9951 - accuracy: 0.6713 - val_loss: 2.0326 - val_accuracy: 0.3941 - 663ms/epoch - 3ms/step\n",
            "Epoch 43/100\n",
            "190/190 - 1s - loss: 1.0188 - accuracy: 0.6728 - val_loss: 2.0808 - val_accuracy: 0.4148 - 671ms/epoch - 4ms/step\n",
            "Epoch 44/100\n",
            "190/190 - 1s - loss: 0.9302 - accuracy: 0.6985 - val_loss: 2.0850 - val_accuracy: 0.4044 - 662ms/epoch - 3ms/step\n",
            "Epoch 45/100\n",
            "190/190 - 1s - loss: 0.9606 - accuracy: 0.6998 - val_loss: 1.8675 - val_accuracy: 0.4444 - 666ms/epoch - 4ms/step\n",
            "Epoch 46/100\n",
            "190/190 - 1s - loss: 0.9290 - accuracy: 0.6903 - val_loss: 1.9048 - val_accuracy: 0.4415 - 672ms/epoch - 4ms/step\n",
            "Epoch 47/100\n",
            "190/190 - 1s - loss: 0.9190 - accuracy: 0.6987 - val_loss: 1.9445 - val_accuracy: 0.4370 - 671ms/epoch - 4ms/step\n",
            "Epoch 48/100\n",
            "190/190 - 1s - loss: 0.8869 - accuracy: 0.7148 - val_loss: 1.9258 - val_accuracy: 0.4430 - 666ms/epoch - 4ms/step\n",
            "Epoch 49/100\n",
            "190/190 - 1s - loss: 0.8999 - accuracy: 0.7122 - val_loss: 2.0686 - val_accuracy: 0.4044 - 664ms/epoch - 3ms/step\n",
            "Epoch 50/100\n",
            "190/190 - 1s - loss: 0.8804 - accuracy: 0.7193 - val_loss: 1.9938 - val_accuracy: 0.4311 - 669ms/epoch - 4ms/step\n",
            "Epoch 51/100\n",
            "190/190 - 1s - loss: 0.8832 - accuracy: 0.7125 - val_loss: 2.1318 - val_accuracy: 0.4193 - 665ms/epoch - 4ms/step\n",
            "Epoch 52/100\n",
            "190/190 - 1s - loss: 0.8966 - accuracy: 0.7068 - val_loss: 2.0832 - val_accuracy: 0.4311 - 667ms/epoch - 4ms/step\n",
            "Epoch 53/100\n",
            "190/190 - 1s - loss: 0.8874 - accuracy: 0.7041 - val_loss: 2.0857 - val_accuracy: 0.4163 - 680ms/epoch - 4ms/step\n",
            "Epoch 54/100\n",
            "190/190 - 1s - loss: 0.8855 - accuracy: 0.7068 - val_loss: 2.1172 - val_accuracy: 0.4089 - 665ms/epoch - 4ms/step\n",
            "Epoch 55/100\n",
            "190/190 - 1s - loss: 0.9028 - accuracy: 0.6992 - val_loss: 2.0008 - val_accuracy: 0.4178 - 672ms/epoch - 4ms/step\n",
            "Epoch 56/100\n",
            "190/190 - 1s - loss: 0.8848 - accuracy: 0.7046 - val_loss: 1.9960 - val_accuracy: 0.4341 - 670ms/epoch - 4ms/step\n",
            "Epoch 57/100\n",
            "190/190 - 1s - loss: 0.8870 - accuracy: 0.7157 - val_loss: 2.0246 - val_accuracy: 0.4237 - 662ms/epoch - 3ms/step\n",
            "Epoch 58/100\n",
            "190/190 - 1s - loss: 0.8470 - accuracy: 0.7214 - val_loss: 2.0565 - val_accuracy: 0.4370 - 658ms/epoch - 3ms/step\n",
            "Epoch 59/100\n",
            "190/190 - 1s - loss: 0.8905 - accuracy: 0.7119 - val_loss: 1.9928 - val_accuracy: 0.4489 - 681ms/epoch - 4ms/step\n",
            "Epoch 60/100\n",
            "190/190 - 1s - loss: 0.9035 - accuracy: 0.7040 - val_loss: 2.0335 - val_accuracy: 0.4267 - 673ms/epoch - 4ms/step\n",
            "Epoch 61/100\n",
            "190/190 - 1s - loss: 0.8689 - accuracy: 0.7081 - val_loss: 1.9885 - val_accuracy: 0.4474 - 689ms/epoch - 4ms/step\n",
            "Epoch 62/100\n",
            "190/190 - 1s - loss: 0.8471 - accuracy: 0.7247 - val_loss: 2.0279 - val_accuracy: 0.4326 - 672ms/epoch - 4ms/step\n",
            "Epoch 63/100\n",
            "190/190 - 1s - loss: 0.9472 - accuracy: 0.6946 - val_loss: 1.8827 - val_accuracy: 0.4281 - 671ms/epoch - 4ms/step\n",
            "Epoch 64/100\n",
            "190/190 - 1s - loss: 0.8822 - accuracy: 0.7099 - val_loss: 1.9592 - val_accuracy: 0.4519 - 669ms/epoch - 4ms/step\n",
            "Epoch 65/100\n",
            "190/190 - 1s - loss: 0.8858 - accuracy: 0.7054 - val_loss: 2.1382 - val_accuracy: 0.4400 - 673ms/epoch - 4ms/step\n",
            "Epoch 66/100\n",
            "190/190 - 1s - loss: 0.8591 - accuracy: 0.7138 - val_loss: 2.0514 - val_accuracy: 0.4207 - 665ms/epoch - 4ms/step\n",
            "Epoch 67/100\n",
            "190/190 - 1s - loss: 0.8644 - accuracy: 0.7224 - val_loss: 2.0408 - val_accuracy: 0.4385 - 667ms/epoch - 4ms/step\n",
            "Epoch 68/100\n",
            "190/190 - 1s - loss: 0.8748 - accuracy: 0.7133 - val_loss: 2.1608 - val_accuracy: 0.4000 - 668ms/epoch - 4ms/step\n",
            "Epoch 69/100\n",
            "190/190 - 1s - loss: 0.8830 - accuracy: 0.7063 - val_loss: 2.0274 - val_accuracy: 0.4341 - 673ms/epoch - 4ms/step\n",
            "Epoch 70/100\n",
            "190/190 - 1s - loss: 0.8588 - accuracy: 0.7257 - val_loss: 2.1230 - val_accuracy: 0.4133 - 677ms/epoch - 4ms/step\n",
            "Epoch 71/100\n",
            "190/190 - 1s - loss: 0.8510 - accuracy: 0.7168 - val_loss: 2.0484 - val_accuracy: 0.4326 - 670ms/epoch - 4ms/step\n",
            "Epoch 72/100\n",
            "190/190 - 1s - loss: 0.8674 - accuracy: 0.7114 - val_loss: 1.9986 - val_accuracy: 0.4489 - 667ms/epoch - 4ms/step\n",
            "Epoch 73/100\n",
            "190/190 - 1s - loss: 0.8495 - accuracy: 0.7181 - val_loss: 2.0633 - val_accuracy: 0.4415 - 670ms/epoch - 4ms/step\n",
            "Epoch 74/100\n",
            "190/190 - 1s - loss: 0.9355 - accuracy: 0.6921 - val_loss: 2.0947 - val_accuracy: 0.4015 - 675ms/epoch - 4ms/step\n",
            "Epoch 75/100\n",
            "190/190 - 1s - loss: 1.3007 - accuracy: 0.5735 - val_loss: 2.1786 - val_accuracy: 0.3630 - 663ms/epoch - 3ms/step\n",
            "Epoch 76/100\n",
            "190/190 - 1s - loss: 1.1583 - accuracy: 0.6181 - val_loss: 2.2537 - val_accuracy: 0.3496 - 672ms/epoch - 4ms/step\n",
            "Epoch 77/100\n",
            "190/190 - 1s - loss: 1.0646 - accuracy: 0.6455 - val_loss: 2.0787 - val_accuracy: 0.3985 - 677ms/epoch - 4ms/step\n",
            "Epoch 78/100\n",
            "190/190 - 1s - loss: 1.0136 - accuracy: 0.6647 - val_loss: 1.8967 - val_accuracy: 0.4326 - 661ms/epoch - 3ms/step\n",
            "Epoch 79/100\n",
            "190/190 - 1s - loss: 0.9676 - accuracy: 0.6827 - val_loss: 2.1761 - val_accuracy: 0.4178 - 665ms/epoch - 3ms/step\n",
            "Epoch 80/100\n",
            "190/190 - 1s - loss: 0.9389 - accuracy: 0.6895 - val_loss: 2.0074 - val_accuracy: 0.4178 - 667ms/epoch - 4ms/step\n",
            "Epoch 81/100\n",
            "190/190 - 1s - loss: 0.9187 - accuracy: 0.6962 - val_loss: 2.0468 - val_accuracy: 0.4370 - 659ms/epoch - 3ms/step\n",
            "Epoch 82/100\n",
            "190/190 - 1s - loss: 0.8948 - accuracy: 0.7016 - val_loss: 2.0448 - val_accuracy: 0.4415 - 672ms/epoch - 4ms/step\n",
            "Epoch 83/100\n",
            "190/190 - 1s - loss: 0.8996 - accuracy: 0.7044 - val_loss: 2.2729 - val_accuracy: 0.4222 - 675ms/epoch - 4ms/step\n",
            "Epoch 84/100\n",
            "190/190 - 1s - loss: 0.8833 - accuracy: 0.7028 - val_loss: 2.0197 - val_accuracy: 0.4548 - 660ms/epoch - 3ms/step\n",
            "Epoch 85/100\n",
            "190/190 - 1s - loss: 0.8562 - accuracy: 0.7168 - val_loss: 2.0127 - val_accuracy: 0.4622 - 672ms/epoch - 4ms/step\n",
            "Epoch 86/100\n",
            "190/190 - 1s - loss: 0.8332 - accuracy: 0.7160 - val_loss: 2.0954 - val_accuracy: 0.4341 - 673ms/epoch - 4ms/step\n",
            "Epoch 87/100\n",
            "190/190 - 1s - loss: 0.8335 - accuracy: 0.7262 - val_loss: 1.9282 - val_accuracy: 0.4519 - 662ms/epoch - 3ms/step\n",
            "Epoch 88/100\n",
            "190/190 - 1s - loss: 0.8297 - accuracy: 0.7272 - val_loss: 1.9501 - val_accuracy: 0.4400 - 673ms/epoch - 4ms/step\n",
            "Epoch 89/100\n",
            "190/190 - 1s - loss: 0.8427 - accuracy: 0.7239 - val_loss: 1.9795 - val_accuracy: 0.4415 - 659ms/epoch - 3ms/step\n",
            "Epoch 90/100\n",
            "190/190 - 1s - loss: 0.9345 - accuracy: 0.6946 - val_loss: 2.1017 - val_accuracy: 0.4104 - 667ms/epoch - 4ms/step\n",
            "Epoch 91/100\n",
            "190/190 - 1s - loss: 0.9251 - accuracy: 0.6998 - val_loss: 2.1152 - val_accuracy: 0.4385 - 662ms/epoch - 3ms/step\n",
            "Epoch 92/100\n",
            "190/190 - 1s - loss: 0.8807 - accuracy: 0.7119 - val_loss: 2.2137 - val_accuracy: 0.4341 - 661ms/epoch - 3ms/step\n",
            "Epoch 93/100\n",
            "190/190 - 1s - loss: 0.8890 - accuracy: 0.7115 - val_loss: 2.1032 - val_accuracy: 0.4415 - 668ms/epoch - 4ms/step\n",
            "Epoch 94/100\n",
            "190/190 - 1s - loss: 0.8400 - accuracy: 0.7250 - val_loss: 2.2583 - val_accuracy: 0.4148 - 670ms/epoch - 4ms/step\n",
            "Epoch 95/100\n",
            "190/190 - 1s - loss: 0.8412 - accuracy: 0.7252 - val_loss: 2.1195 - val_accuracy: 0.4222 - 680ms/epoch - 4ms/step\n",
            "Epoch 96/100\n",
            "190/190 - 1s - loss: 0.8163 - accuracy: 0.7310 - val_loss: 2.1419 - val_accuracy: 0.4415 - 663ms/epoch - 3ms/step\n",
            "Epoch 97/100\n",
            "190/190 - 1s - loss: 0.8822 - accuracy: 0.7170 - val_loss: 2.2447 - val_accuracy: 0.4148 - 668ms/epoch - 4ms/step\n",
            "Epoch 98/100\n",
            "190/190 - 1s - loss: 0.8521 - accuracy: 0.7166 - val_loss: 2.0642 - val_accuracy: 0.4667 - 663ms/epoch - 3ms/step\n",
            "Epoch 99/100\n",
            "190/190 - 1s - loss: 0.8466 - accuracy: 0.7170 - val_loss: 2.1527 - val_accuracy: 0.4296 - 667ms/epoch - 4ms/step\n",
            "Epoch 100/100\n",
            "190/190 - 1s - loss: 0.7933 - accuracy: 0.7367 - val_loss: 2.2562 - val_accuracy: 0.4296 - 668ms/epoch - 4ms/step\n",
            "Model: \"sequential_13\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " reshape_12 (Reshape)        (None, 128, 40)           0         \n",
            "                                                                 \n",
            " conv1d_24 (Conv1D)          (None, 124, 12)           2412      \n",
            "                                                                 \n",
            " max_pooling1d_24 (MaxPoolin  (None, 62, 12)           0         \n",
            " g1D)                                                            \n",
            "                                                                 \n",
            " conv1d_25 (Conv1D)          (None, 58, 28)            1708      \n",
            "                                                                 \n",
            " max_pooling1d_25 (MaxPoolin  (None, 29, 28)           0         \n",
            " g1D)                                                            \n",
            "                                                                 \n",
            " dense_12 (Dense)            (None, 29, 30)            870       \n",
            "                                                                 \n",
            " dropout_12 (Dropout)        (None, 29, 30)            0         \n",
            "                                                                 \n",
            " flatten_12 (Flatten)        (None, 870)               0         \n",
            "                                                                 \n",
            " y_pred (Dense)              (None, 10)                8710      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 13,700\n",
            "Trainable params: 13,700\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Result of fold:7\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.6070 - accuracy: 0.5662\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 70%|███████   | 7/10 [08:17<03:28, 69.57s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "192/192 - 1s - loss: 2.3059 - accuracy: 0.2542 - val_loss: 1.8616 - val_accuracy: 0.3162 - 1s/epoch - 7ms/step\n",
            "Epoch 2/100\n",
            "192/192 - 1s - loss: 1.7662 - accuracy: 0.3719 - val_loss: 1.7324 - val_accuracy: 0.3574 - 666ms/epoch - 3ms/step\n",
            "Epoch 3/100\n",
            "192/192 - 1s - loss: 1.6541 - accuracy: 0.4066 - val_loss: 1.6683 - val_accuracy: 0.3485 - 694ms/epoch - 4ms/step\n",
            "Epoch 4/100\n",
            "192/192 - 1s - loss: 1.5887 - accuracy: 0.4230 - val_loss: 1.7645 - val_accuracy: 0.3044 - 676ms/epoch - 4ms/step\n",
            "Epoch 5/100\n",
            "192/192 - 1s - loss: 1.5193 - accuracy: 0.4516 - val_loss: 1.6344 - val_accuracy: 0.3926 - 673ms/epoch - 4ms/step\n",
            "Epoch 6/100\n",
            "192/192 - 1s - loss: 1.5058 - accuracy: 0.4702 - val_loss: 1.6384 - val_accuracy: 0.3412 - 681ms/epoch - 4ms/step\n",
            "Epoch 7/100\n",
            "192/192 - 1s - loss: 1.5144 - accuracy: 0.4639 - val_loss: 1.6296 - val_accuracy: 0.4162 - 662ms/epoch - 3ms/step\n",
            "Epoch 8/100\n",
            "192/192 - 1s - loss: 1.4706 - accuracy: 0.4738 - val_loss: 1.7883 - val_accuracy: 0.3750 - 681ms/epoch - 4ms/step\n",
            "Epoch 9/100\n",
            "192/192 - 1s - loss: 1.4643 - accuracy: 0.4944 - val_loss: 1.6327 - val_accuracy: 0.4426 - 675ms/epoch - 4ms/step\n",
            "Epoch 10/100\n",
            "192/192 - 1s - loss: 1.4490 - accuracy: 0.5041 - val_loss: 1.6791 - val_accuracy: 0.3779 - 672ms/epoch - 4ms/step\n",
            "Epoch 11/100\n",
            "192/192 - 1s - loss: 1.3776 - accuracy: 0.5211 - val_loss: 1.6177 - val_accuracy: 0.4309 - 675ms/epoch - 4ms/step\n",
            "Epoch 12/100\n",
            "192/192 - 1s - loss: 1.4229 - accuracy: 0.5039 - val_loss: 1.5671 - val_accuracy: 0.4588 - 678ms/epoch - 4ms/step\n",
            "Epoch 13/100\n",
            "192/192 - 1s - loss: 1.3177 - accuracy: 0.5345 - val_loss: 1.5549 - val_accuracy: 0.4956 - 680ms/epoch - 4ms/step\n",
            "Epoch 14/100\n",
            "192/192 - 1s - loss: 1.2763 - accuracy: 0.5684 - val_loss: 1.5755 - val_accuracy: 0.4691 - 682ms/epoch - 4ms/step\n",
            "Epoch 15/100\n",
            "192/192 - 1s - loss: 1.3075 - accuracy: 0.5604 - val_loss: 1.4735 - val_accuracy: 0.5294 - 675ms/epoch - 4ms/step\n",
            "Epoch 16/100\n",
            "192/192 - 1s - loss: 1.2326 - accuracy: 0.5810 - val_loss: 1.5301 - val_accuracy: 0.4662 - 677ms/epoch - 4ms/step\n",
            "Epoch 17/100\n",
            "192/192 - 1s - loss: 1.1896 - accuracy: 0.5947 - val_loss: 1.7481 - val_accuracy: 0.4309 - 684ms/epoch - 4ms/step\n",
            "Epoch 18/100\n",
            "192/192 - 1s - loss: 1.2608 - accuracy: 0.5646 - val_loss: 1.5029 - val_accuracy: 0.5059 - 665ms/epoch - 3ms/step\n",
            "Epoch 19/100\n",
            "192/192 - 1s - loss: 1.2488 - accuracy: 0.5702 - val_loss: 1.5628 - val_accuracy: 0.4897 - 691ms/epoch - 4ms/step\n",
            "Epoch 20/100\n",
            "192/192 - 1s - loss: 1.2695 - accuracy: 0.5675 - val_loss: 1.7402 - val_accuracy: 0.4000 - 677ms/epoch - 4ms/step\n",
            "Epoch 21/100\n",
            "192/192 - 1s - loss: 1.2116 - accuracy: 0.5927 - val_loss: 1.6609 - val_accuracy: 0.4868 - 674ms/epoch - 4ms/step\n",
            "Epoch 22/100\n",
            "192/192 - 1s - loss: 1.1791 - accuracy: 0.6106 - val_loss: 1.4808 - val_accuracy: 0.5103 - 675ms/epoch - 4ms/step\n",
            "Epoch 23/100\n",
            "192/192 - 1s - loss: 1.1457 - accuracy: 0.6133 - val_loss: 1.6263 - val_accuracy: 0.4441 - 687ms/epoch - 4ms/step\n",
            "Epoch 24/100\n",
            "192/192 - 1s - loss: 1.3318 - accuracy: 0.5636 - val_loss: 1.6911 - val_accuracy: 0.4250 - 680ms/epoch - 4ms/step\n",
            "Epoch 25/100\n",
            "192/192 - 1s - loss: 1.2319 - accuracy: 0.5873 - val_loss: 1.4968 - val_accuracy: 0.5176 - 681ms/epoch - 4ms/step\n",
            "Epoch 26/100\n",
            "192/192 - 1s - loss: 1.1418 - accuracy: 0.6174 - val_loss: 1.5320 - val_accuracy: 0.5044 - 677ms/epoch - 4ms/step\n",
            "Epoch 27/100\n",
            "192/192 - 1s - loss: 1.1216 - accuracy: 0.6312 - val_loss: 1.4592 - val_accuracy: 0.5426 - 668ms/epoch - 3ms/step\n",
            "Epoch 28/100\n",
            "192/192 - 1s - loss: 1.1155 - accuracy: 0.6250 - val_loss: 1.5537 - val_accuracy: 0.4985 - 683ms/epoch - 4ms/step\n",
            "Epoch 29/100\n",
            "192/192 - 1s - loss: 1.0551 - accuracy: 0.6420 - val_loss: 1.5248 - val_accuracy: 0.5044 - 676ms/epoch - 4ms/step\n",
            "Epoch 30/100\n",
            "192/192 - 1s - loss: 1.0547 - accuracy: 0.6523 - val_loss: 1.5252 - val_accuracy: 0.5147 - 685ms/epoch - 4ms/step\n",
            "Epoch 31/100\n",
            "192/192 - 1s - loss: 1.1166 - accuracy: 0.6220 - val_loss: 1.7498 - val_accuracy: 0.4529 - 683ms/epoch - 4ms/step\n",
            "Epoch 32/100\n",
            "192/192 - 1s - loss: 1.0616 - accuracy: 0.6426 - val_loss: 1.4862 - val_accuracy: 0.5044 - 671ms/epoch - 3ms/step\n",
            "Epoch 33/100\n",
            "192/192 - 1s - loss: 1.0800 - accuracy: 0.6367 - val_loss: 1.5720 - val_accuracy: 0.5176 - 677ms/epoch - 4ms/step\n",
            "Epoch 34/100\n",
            "192/192 - 1s - loss: 1.1086 - accuracy: 0.6318 - val_loss: 1.7076 - val_accuracy: 0.5029 - 673ms/epoch - 4ms/step\n",
            "Epoch 35/100\n",
            "192/192 - 1s - loss: 1.4138 - accuracy: 0.5116 - val_loss: 2.0218 - val_accuracy: 0.3471 - 679ms/epoch - 4ms/step\n",
            "Epoch 36/100\n",
            "192/192 - 1s - loss: 1.2812 - accuracy: 0.5687 - val_loss: 1.7440 - val_accuracy: 0.4324 - 666ms/epoch - 3ms/step\n",
            "Epoch 37/100\n",
            "192/192 - 1s - loss: 1.1854 - accuracy: 0.6066 - val_loss: 1.6826 - val_accuracy: 0.4632 - 687ms/epoch - 4ms/step\n",
            "Epoch 38/100\n",
            "192/192 - 1s - loss: 1.2066 - accuracy: 0.5908 - val_loss: 1.6229 - val_accuracy: 0.5412 - 687ms/epoch - 4ms/step\n",
            "Epoch 39/100\n",
            "192/192 - 1s - loss: 1.1093 - accuracy: 0.6318 - val_loss: 1.5544 - val_accuracy: 0.5015 - 676ms/epoch - 4ms/step\n",
            "Epoch 40/100\n",
            "192/192 - 1s - loss: 1.0557 - accuracy: 0.6488 - val_loss: 1.5955 - val_accuracy: 0.5324 - 682ms/epoch - 4ms/step\n",
            "Epoch 41/100\n",
            "192/192 - 1s - loss: 1.0188 - accuracy: 0.6636 - val_loss: 1.5128 - val_accuracy: 0.5221 - 711ms/epoch - 4ms/step\n",
            "Epoch 42/100\n",
            "192/192 - 1s - loss: 1.0406 - accuracy: 0.6585 - val_loss: 1.6338 - val_accuracy: 0.4809 - 733ms/epoch - 4ms/step\n",
            "Epoch 43/100\n",
            "192/192 - 1s - loss: 1.0034 - accuracy: 0.6711 - val_loss: 1.6533 - val_accuracy: 0.5176 - 759ms/epoch - 4ms/step\n",
            "Epoch 44/100\n",
            "192/192 - 1s - loss: 0.9622 - accuracy: 0.6869 - val_loss: 1.6598 - val_accuracy: 0.4765 - 700ms/epoch - 4ms/step\n",
            "Epoch 45/100\n",
            "192/192 - 1s - loss: 0.9673 - accuracy: 0.6801 - val_loss: 1.6732 - val_accuracy: 0.4897 - 688ms/epoch - 4ms/step\n",
            "Epoch 46/100\n",
            "192/192 - 1s - loss: 0.9637 - accuracy: 0.6807 - val_loss: 1.6416 - val_accuracy: 0.5147 - 697ms/epoch - 4ms/step\n",
            "Epoch 47/100\n",
            "192/192 - 1s - loss: 0.9314 - accuracy: 0.6948 - val_loss: 1.6403 - val_accuracy: 0.5206 - 704ms/epoch - 4ms/step\n",
            "Epoch 48/100\n",
            "192/192 - 1s - loss: 0.9435 - accuracy: 0.6914 - val_loss: 1.5894 - val_accuracy: 0.5118 - 675ms/epoch - 4ms/step\n",
            "Epoch 49/100\n",
            "192/192 - 1s - loss: 0.9439 - accuracy: 0.6876 - val_loss: 1.6627 - val_accuracy: 0.5279 - 676ms/epoch - 4ms/step\n",
            "Epoch 50/100\n",
            "192/192 - 1s - loss: 0.9316 - accuracy: 0.6928 - val_loss: 1.8554 - val_accuracy: 0.4824 - 691ms/epoch - 4ms/step\n",
            "Epoch 51/100\n",
            "192/192 - 1s - loss: 0.9253 - accuracy: 0.6973 - val_loss: 1.8613 - val_accuracy: 0.4868 - 680ms/epoch - 4ms/step\n",
            "Epoch 52/100\n",
            "192/192 - 1s - loss: 1.2089 - accuracy: 0.5906 - val_loss: 1.7730 - val_accuracy: 0.4676 - 674ms/epoch - 4ms/step\n",
            "Epoch 53/100\n",
            "192/192 - 1s - loss: 1.0309 - accuracy: 0.6600 - val_loss: 1.7397 - val_accuracy: 0.4603 - 684ms/epoch - 4ms/step\n",
            "Epoch 54/100\n",
            "192/192 - 1s - loss: 0.9945 - accuracy: 0.6639 - val_loss: 1.7296 - val_accuracy: 0.4956 - 667ms/epoch - 3ms/step\n",
            "Epoch 55/100\n",
            "192/192 - 1s - loss: 0.9326 - accuracy: 0.6922 - val_loss: 1.7126 - val_accuracy: 0.5206 - 668ms/epoch - 3ms/step\n",
            "Epoch 56/100\n",
            "192/192 - 1s - loss: 0.9181 - accuracy: 0.6959 - val_loss: 1.8535 - val_accuracy: 0.5015 - 676ms/epoch - 4ms/step\n",
            "Epoch 57/100\n",
            "192/192 - 1s - loss: 0.8940 - accuracy: 0.7048 - val_loss: 1.8622 - val_accuracy: 0.4529 - 665ms/epoch - 3ms/step\n",
            "Epoch 58/100\n",
            "192/192 - 1s - loss: 0.9394 - accuracy: 0.6892 - val_loss: 1.8305 - val_accuracy: 0.4441 - 666ms/epoch - 3ms/step\n",
            "Epoch 59/100\n",
            "192/192 - 1s - loss: 0.9209 - accuracy: 0.6963 - val_loss: 2.0021 - val_accuracy: 0.4382 - 679ms/epoch - 4ms/step\n",
            "Epoch 60/100\n",
            "192/192 - 1s - loss: 0.9125 - accuracy: 0.7018 - val_loss: 1.8603 - val_accuracy: 0.4529 - 677ms/epoch - 4ms/step\n",
            "Epoch 61/100\n",
            "192/192 - 1s - loss: 0.8776 - accuracy: 0.7097 - val_loss: 1.6844 - val_accuracy: 0.5029 - 670ms/epoch - 3ms/step\n",
            "Epoch 62/100\n",
            "192/192 - 1s - loss: 0.8718 - accuracy: 0.7131 - val_loss: 1.9142 - val_accuracy: 0.4838 - 677ms/epoch - 4ms/step\n",
            "Epoch 63/100\n",
            "192/192 - 1s - loss: 0.9376 - accuracy: 0.6987 - val_loss: 1.7316 - val_accuracy: 0.5382 - 690ms/epoch - 4ms/step\n",
            "Epoch 64/100\n",
            "192/192 - 1s - loss: 0.8976 - accuracy: 0.7049 - val_loss: 1.7794 - val_accuracy: 0.4985 - 671ms/epoch - 3ms/step\n",
            "Epoch 65/100\n",
            "192/192 - 1s - loss: 0.8635 - accuracy: 0.7170 - val_loss: 1.6794 - val_accuracy: 0.5074 - 680ms/epoch - 4ms/step\n",
            "Epoch 66/100\n",
            "192/192 - 1s - loss: 0.8639 - accuracy: 0.7172 - val_loss: 1.8619 - val_accuracy: 0.4838 - 669ms/epoch - 3ms/step\n",
            "Epoch 67/100\n",
            "192/192 - 1s - loss: 0.8559 - accuracy: 0.7102 - val_loss: 1.8790 - val_accuracy: 0.4897 - 668ms/epoch - 3ms/step\n",
            "Epoch 68/100\n",
            "192/192 - 1s - loss: 0.8728 - accuracy: 0.7156 - val_loss: 1.7819 - val_accuracy: 0.5426 - 694ms/epoch - 4ms/step\n",
            "Epoch 69/100\n",
            "192/192 - 1s - loss: 0.8682 - accuracy: 0.7161 - val_loss: 1.9200 - val_accuracy: 0.4868 - 685ms/epoch - 4ms/step\n",
            "Epoch 70/100\n",
            "192/192 - 1s - loss: 0.8782 - accuracy: 0.7100 - val_loss: 1.8685 - val_accuracy: 0.4853 - 673ms/epoch - 4ms/step\n",
            "Epoch 71/100\n",
            "192/192 - 1s - loss: 0.8360 - accuracy: 0.7287 - val_loss: 1.8723 - val_accuracy: 0.5147 - 679ms/epoch - 4ms/step\n",
            "Epoch 72/100\n",
            "192/192 - 1s - loss: 0.8281 - accuracy: 0.7283 - val_loss: 1.9493 - val_accuracy: 0.5176 - 681ms/epoch - 4ms/step\n",
            "Epoch 73/100\n",
            "192/192 - 1s - loss: 0.8643 - accuracy: 0.7295 - val_loss: 1.7166 - val_accuracy: 0.5559 - 683ms/epoch - 4ms/step\n",
            "Epoch 74/100\n",
            "192/192 - 1s - loss: 0.8313 - accuracy: 0.7259 - val_loss: 1.9276 - val_accuracy: 0.5250 - 676ms/epoch - 4ms/step\n",
            "Epoch 75/100\n",
            "192/192 - 1s - loss: 0.8053 - accuracy: 0.7334 - val_loss: 2.1137 - val_accuracy: 0.4765 - 673ms/epoch - 4ms/step\n",
            "Epoch 76/100\n",
            "192/192 - 1s - loss: 0.8223 - accuracy: 0.7337 - val_loss: 1.7946 - val_accuracy: 0.5147 - 679ms/epoch - 4ms/step\n",
            "Epoch 77/100\n",
            "192/192 - 1s - loss: 0.8427 - accuracy: 0.7269 - val_loss: 1.9635 - val_accuracy: 0.4809 - 675ms/epoch - 4ms/step\n",
            "Epoch 78/100\n",
            "192/192 - 1s - loss: 0.8109 - accuracy: 0.7332 - val_loss: 1.6478 - val_accuracy: 0.5515 - 676ms/epoch - 4ms/step\n",
            "Epoch 79/100\n",
            "192/192 - 1s - loss: 0.7936 - accuracy: 0.7414 - val_loss: 1.8891 - val_accuracy: 0.5368 - 669ms/epoch - 3ms/step\n",
            "Epoch 80/100\n",
            "192/192 - 1s - loss: 0.8514 - accuracy: 0.7184 - val_loss: 1.8264 - val_accuracy: 0.5324 - 671ms/epoch - 3ms/step\n",
            "Epoch 81/100\n",
            "192/192 - 1s - loss: 0.8080 - accuracy: 0.7380 - val_loss: 1.9092 - val_accuracy: 0.5324 - 683ms/epoch - 4ms/step\n",
            "Epoch 82/100\n",
            "192/192 - 1s - loss: 0.7852 - accuracy: 0.7434 - val_loss: 1.8871 - val_accuracy: 0.5426 - 670ms/epoch - 3ms/step\n",
            "Epoch 83/100\n",
            "192/192 - 1s - loss: 0.8481 - accuracy: 0.7180 - val_loss: 2.0898 - val_accuracy: 0.4721 - 679ms/epoch - 4ms/step\n",
            "Epoch 84/100\n",
            "192/192 - 1s - loss: 0.7950 - accuracy: 0.7462 - val_loss: 1.7307 - val_accuracy: 0.5265 - 673ms/epoch - 4ms/step\n",
            "Epoch 85/100\n",
            "192/192 - 1s - loss: 1.0128 - accuracy: 0.6711 - val_loss: 1.9669 - val_accuracy: 0.4706 - 677ms/epoch - 4ms/step\n",
            "Epoch 86/100\n",
            "192/192 - 1s - loss: 0.8403 - accuracy: 0.7252 - val_loss: 1.9471 - val_accuracy: 0.5059 - 670ms/epoch - 3ms/step\n",
            "Epoch 87/100\n",
            "192/192 - 1s - loss: 0.7968 - accuracy: 0.7412 - val_loss: 2.1328 - val_accuracy: 0.4912 - 680ms/epoch - 4ms/step\n",
            "Epoch 88/100\n",
            "192/192 - 1s - loss: 0.8065 - accuracy: 0.7380 - val_loss: 1.8865 - val_accuracy: 0.5191 - 673ms/epoch - 4ms/step\n",
            "Epoch 89/100\n",
            "192/192 - 1s - loss: 0.7786 - accuracy: 0.7452 - val_loss: 1.7969 - val_accuracy: 0.5544 - 671ms/epoch - 3ms/step\n",
            "Epoch 90/100\n",
            "192/192 - 1s - loss: 0.7879 - accuracy: 0.7409 - val_loss: 1.9684 - val_accuracy: 0.5059 - 677ms/epoch - 4ms/step\n",
            "Epoch 91/100\n",
            "192/192 - 1s - loss: 0.7753 - accuracy: 0.7435 - val_loss: 2.1271 - val_accuracy: 0.4824 - 675ms/epoch - 4ms/step\n",
            "Epoch 92/100\n",
            "192/192 - 1s - loss: 0.8486 - accuracy: 0.7218 - val_loss: 2.0331 - val_accuracy: 0.4824 - 692ms/epoch - 4ms/step\n",
            "Epoch 93/100\n",
            "192/192 - 1s - loss: 0.8020 - accuracy: 0.7355 - val_loss: 2.2053 - val_accuracy: 0.5221 - 676ms/epoch - 4ms/step\n",
            "Epoch 94/100\n",
            "192/192 - 1s - loss: 0.8059 - accuracy: 0.7368 - val_loss: 2.0084 - val_accuracy: 0.4397 - 671ms/epoch - 3ms/step\n",
            "Epoch 95/100\n",
            "192/192 - 1s - loss: 0.8066 - accuracy: 0.7404 - val_loss: 1.8329 - val_accuracy: 0.5235 - 674ms/epoch - 4ms/step\n",
            "Epoch 96/100\n",
            "192/192 - 1s - loss: 0.7838 - accuracy: 0.7434 - val_loss: 2.0148 - val_accuracy: 0.4912 - 681ms/epoch - 4ms/step\n",
            "Epoch 97/100\n",
            "192/192 - 1s - loss: 0.7831 - accuracy: 0.7470 - val_loss: 2.0930 - val_accuracy: 0.4529 - 672ms/epoch - 4ms/step\n",
            "Epoch 98/100\n",
            "192/192 - 1s - loss: 0.7773 - accuracy: 0.7470 - val_loss: 1.9919 - val_accuracy: 0.5074 - 695ms/epoch - 4ms/step\n",
            "Epoch 99/100\n",
            "192/192 - 1s - loss: 0.7797 - accuracy: 0.7462 - val_loss: 2.1929 - val_accuracy: 0.4603 - 675ms/epoch - 4ms/step\n",
            "Epoch 100/100\n",
            "192/192 - 1s - loss: 0.8005 - accuracy: 0.7388 - val_loss: 1.8260 - val_accuracy: 0.5162 - 680ms/epoch - 4ms/step\n",
            "Model: \"sequential_15\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " reshape_14 (Reshape)        (None, 128, 40)           0         \n",
            "                                                                 \n",
            " conv1d_28 (Conv1D)          (None, 124, 12)           2412      \n",
            "                                                                 \n",
            " max_pooling1d_28 (MaxPoolin  (None, 62, 12)           0         \n",
            " g1D)                                                            \n",
            "                                                                 \n",
            " conv1d_29 (Conv1D)          (None, 58, 28)            1708      \n",
            "                                                                 \n",
            " max_pooling1d_29 (MaxPoolin  (None, 29, 28)           0         \n",
            " g1D)                                                            \n",
            "                                                                 \n",
            " dense_14 (Dense)            (None, 29, 30)            870       \n",
            "                                                                 \n",
            " dropout_14 (Dropout)        (None, 29, 30)            0         \n",
            "                                                                 \n",
            " flatten_14 (Flatten)        (None, 870)               0         \n",
            "                                                                 \n",
            " y_pred (Dense)              (None, 10)                8710      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 13,700\n",
            "Trainable params: 13,700\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Result of fold:8\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 2.3859 - accuracy: 0.5219\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 80%|████████  | 8/10 [09:27<02:19, 69.65s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "191/191 - 1s - loss: 2.2439 - accuracy: 0.2953 - val_loss: 1.8571 - val_accuracy: 0.2437 - 1s/epoch - 8ms/step\n",
            "Epoch 2/100\n",
            "191/191 - 1s - loss: 1.6986 - accuracy: 0.3893 - val_loss: 1.7265 - val_accuracy: 0.3619 - 670ms/epoch - 4ms/step\n",
            "Epoch 3/100\n",
            "191/191 - 1s - loss: 1.5404 - accuracy: 0.4459 - val_loss: 1.7465 - val_accuracy: 0.4003 - 663ms/epoch - 3ms/step\n",
            "Epoch 4/100\n",
            "191/191 - 1s - loss: 1.4883 - accuracy: 0.4827 - val_loss: 1.5769 - val_accuracy: 0.4446 - 668ms/epoch - 3ms/step\n",
            "Epoch 5/100\n",
            "191/191 - 1s - loss: 1.4395 - accuracy: 0.5160 - val_loss: 1.6056 - val_accuracy: 0.4948 - 686ms/epoch - 4ms/step\n",
            "Epoch 6/100\n",
            "191/191 - 1s - loss: 1.4965 - accuracy: 0.4891 - val_loss: 1.6916 - val_accuracy: 0.4106 - 676ms/epoch - 4ms/step\n",
            "Epoch 7/100\n",
            "191/191 - 1s - loss: 1.4463 - accuracy: 0.4988 - val_loss: 1.8293 - val_accuracy: 0.3442 - 678ms/epoch - 4ms/step\n",
            "Epoch 8/100\n",
            "191/191 - 1s - loss: 1.3771 - accuracy: 0.5281 - val_loss: 1.6028 - val_accuracy: 0.4476 - 659ms/epoch - 3ms/step\n",
            "Epoch 9/100\n",
            "191/191 - 1s - loss: 1.3078 - accuracy: 0.5557 - val_loss: 1.8055 - val_accuracy: 0.4402 - 672ms/epoch - 4ms/step\n",
            "Epoch 10/100\n",
            "191/191 - 1s - loss: 1.3068 - accuracy: 0.5615 - val_loss: 1.7108 - val_accuracy: 0.4579 - 679ms/epoch - 4ms/step\n",
            "Epoch 11/100\n",
            "191/191 - 1s - loss: 1.2823 - accuracy: 0.5684 - val_loss: 1.6551 - val_accuracy: 0.4638 - 674ms/epoch - 4ms/step\n",
            "Epoch 12/100\n",
            "191/191 - 1s - loss: 1.2596 - accuracy: 0.5682 - val_loss: 1.6352 - val_accuracy: 0.4742 - 675ms/epoch - 4ms/step\n",
            "Epoch 13/100\n",
            "191/191 - 1s - loss: 1.2079 - accuracy: 0.5861 - val_loss: 1.6168 - val_accuracy: 0.4461 - 671ms/epoch - 4ms/step\n",
            "Epoch 14/100\n",
            "191/191 - 1s - loss: 1.1641 - accuracy: 0.6137 - val_loss: 1.8033 - val_accuracy: 0.4535 - 665ms/epoch - 3ms/step\n",
            "Epoch 15/100\n",
            "191/191 - 1s - loss: 1.2210 - accuracy: 0.5884 - val_loss: 1.5779 - val_accuracy: 0.4609 - 683ms/epoch - 4ms/step\n",
            "Epoch 16/100\n",
            "191/191 - 1s - loss: 1.1572 - accuracy: 0.6028 - val_loss: 1.5717 - val_accuracy: 0.5096 - 670ms/epoch - 4ms/step\n",
            "Epoch 17/100\n",
            "191/191 - 1s - loss: 1.1327 - accuracy: 0.6230 - val_loss: 1.7219 - val_accuracy: 0.4328 - 668ms/epoch - 3ms/step\n",
            "Epoch 18/100\n",
            "191/191 - 1s - loss: 1.1395 - accuracy: 0.6140 - val_loss: 1.7750 - val_accuracy: 0.4165 - 664ms/epoch - 3ms/step\n",
            "Epoch 19/100\n",
            "191/191 - 1s - loss: 1.1097 - accuracy: 0.6258 - val_loss: 1.6881 - val_accuracy: 0.4727 - 675ms/epoch - 4ms/step\n",
            "Epoch 20/100\n",
            "191/191 - 1s - loss: 1.0891 - accuracy: 0.6358 - val_loss: 1.6360 - val_accuracy: 0.4860 - 663ms/epoch - 3ms/step\n",
            "Epoch 21/100\n",
            "191/191 - 1s - loss: 1.0934 - accuracy: 0.6365 - val_loss: 1.6338 - val_accuracy: 0.4653 - 665ms/epoch - 3ms/step\n",
            "Epoch 22/100\n",
            "191/191 - 1s - loss: 1.0801 - accuracy: 0.6402 - val_loss: 1.8221 - val_accuracy: 0.4623 - 671ms/epoch - 4ms/step\n",
            "Epoch 23/100\n",
            "191/191 - 1s - loss: 1.0582 - accuracy: 0.6425 - val_loss: 1.5935 - val_accuracy: 0.5022 - 662ms/epoch - 3ms/step\n",
            "Epoch 24/100\n",
            "191/191 - 1s - loss: 1.0381 - accuracy: 0.6532 - val_loss: 1.5976 - val_accuracy: 0.4934 - 677ms/epoch - 4ms/step\n",
            "Epoch 25/100\n",
            "191/191 - 1s - loss: 1.0327 - accuracy: 0.6560 - val_loss: 1.6768 - val_accuracy: 0.4815 - 667ms/epoch - 3ms/step\n",
            "Epoch 26/100\n",
            "191/191 - 1s - loss: 1.0418 - accuracy: 0.6484 - val_loss: 1.6360 - val_accuracy: 0.4860 - 665ms/epoch - 3ms/step\n",
            "Epoch 27/100\n",
            "191/191 - 1s - loss: 1.0441 - accuracy: 0.6650 - val_loss: 1.6601 - val_accuracy: 0.4697 - 686ms/epoch - 4ms/step\n",
            "Epoch 28/100\n",
            "191/191 - 1s - loss: 1.0235 - accuracy: 0.6604 - val_loss: 1.7257 - val_accuracy: 0.4830 - 661ms/epoch - 3ms/step\n",
            "Epoch 29/100\n",
            "191/191 - 1s - loss: 1.0287 - accuracy: 0.6626 - val_loss: 1.6439 - val_accuracy: 0.4845 - 662ms/epoch - 3ms/step\n",
            "Epoch 30/100\n",
            "191/191 - 1s - loss: 1.0384 - accuracy: 0.6544 - val_loss: 1.7470 - val_accuracy: 0.4919 - 666ms/epoch - 3ms/step\n",
            "Epoch 31/100\n",
            "191/191 - 1s - loss: 1.0553 - accuracy: 0.6552 - val_loss: 1.7651 - val_accuracy: 0.4978 - 663ms/epoch - 3ms/step\n",
            "Epoch 32/100\n",
            "191/191 - 1s - loss: 1.0232 - accuracy: 0.6583 - val_loss: 1.6803 - val_accuracy: 0.4756 - 663ms/epoch - 3ms/step\n",
            "Epoch 33/100\n",
            "191/191 - 1s - loss: 0.9943 - accuracy: 0.6739 - val_loss: 1.7950 - val_accuracy: 0.4889 - 674ms/epoch - 4ms/step\n",
            "Epoch 34/100\n",
            "191/191 - 1s - loss: 0.9919 - accuracy: 0.6841 - val_loss: 1.8041 - val_accuracy: 0.4653 - 667ms/epoch - 3ms/step\n",
            "Epoch 35/100\n",
            "191/191 - 1s - loss: 0.9907 - accuracy: 0.6768 - val_loss: 1.7989 - val_accuracy: 0.4934 - 680ms/epoch - 4ms/step\n",
            "Epoch 36/100\n",
            "191/191 - 1s - loss: 0.9602 - accuracy: 0.6877 - val_loss: 1.7959 - val_accuracy: 0.4815 - 682ms/epoch - 4ms/step\n",
            "Epoch 37/100\n",
            "191/191 - 1s - loss: 1.1819 - accuracy: 0.6064 - val_loss: 1.6290 - val_accuracy: 0.4919 - 668ms/epoch - 3ms/step\n",
            "Epoch 38/100\n",
            "191/191 - 1s - loss: 1.0464 - accuracy: 0.6535 - val_loss: 1.6823 - val_accuracy: 0.4594 - 669ms/epoch - 4ms/step\n",
            "Epoch 39/100\n",
            "191/191 - 1s - loss: 0.9733 - accuracy: 0.6805 - val_loss: 1.6233 - val_accuracy: 0.5081 - 666ms/epoch - 3ms/step\n",
            "Epoch 40/100\n",
            "191/191 - 1s - loss: 0.9693 - accuracy: 0.6819 - val_loss: 1.6930 - val_accuracy: 0.4564 - 668ms/epoch - 3ms/step\n",
            "Epoch 41/100\n",
            "191/191 - 1s - loss: 0.9529 - accuracy: 0.6898 - val_loss: 1.7863 - val_accuracy: 0.4549 - 672ms/epoch - 4ms/step\n",
            "Epoch 42/100\n",
            "191/191 - 1s - loss: 0.9386 - accuracy: 0.6898 - val_loss: 1.7424 - val_accuracy: 0.4712 - 668ms/epoch - 3ms/step\n",
            "Epoch 43/100\n",
            "191/191 - 1s - loss: 0.9781 - accuracy: 0.6806 - val_loss: 1.6919 - val_accuracy: 0.4697 - 668ms/epoch - 3ms/step\n",
            "Epoch 44/100\n",
            "191/191 - 1s - loss: 0.9608 - accuracy: 0.6795 - val_loss: 1.7133 - val_accuracy: 0.4742 - 666ms/epoch - 3ms/step\n",
            "Epoch 45/100\n",
            "191/191 - 1s - loss: 0.9670 - accuracy: 0.6885 - val_loss: 1.8407 - val_accuracy: 0.4564 - 679ms/epoch - 4ms/step\n",
            "Epoch 46/100\n",
            "191/191 - 1s - loss: 0.9829 - accuracy: 0.6777 - val_loss: 1.8223 - val_accuracy: 0.4564 - 669ms/epoch - 4ms/step\n",
            "Epoch 47/100\n",
            "191/191 - 1s - loss: 0.9328 - accuracy: 0.6998 - val_loss: 1.9329 - val_accuracy: 0.4786 - 676ms/epoch - 4ms/step\n",
            "Epoch 48/100\n",
            "191/191 - 1s - loss: 0.9094 - accuracy: 0.6967 - val_loss: 1.7729 - val_accuracy: 0.4963 - 663ms/epoch - 3ms/step\n",
            "Epoch 49/100\n",
            "191/191 - 1s - loss: 0.8812 - accuracy: 0.7159 - val_loss: 1.7396 - val_accuracy: 0.4653 - 668ms/epoch - 3ms/step\n",
            "Epoch 50/100\n",
            "191/191 - 1s - loss: 0.8966 - accuracy: 0.7036 - val_loss: 1.9725 - val_accuracy: 0.4712 - 667ms/epoch - 3ms/step\n",
            "Epoch 51/100\n",
            "191/191 - 1s - loss: 0.9759 - accuracy: 0.6837 - val_loss: 1.7955 - val_accuracy: 0.4786 - 672ms/epoch - 4ms/step\n",
            "Epoch 52/100\n",
            "191/191 - 1s - loss: 0.9267 - accuracy: 0.6982 - val_loss: 1.7003 - val_accuracy: 0.4771 - 673ms/epoch - 4ms/step\n",
            "Epoch 53/100\n",
            "191/191 - 1s - loss: 0.9433 - accuracy: 0.6936 - val_loss: 1.8949 - val_accuracy: 0.4756 - 664ms/epoch - 3ms/step\n",
            "Epoch 54/100\n",
            "191/191 - 1s - loss: 0.8945 - accuracy: 0.7095 - val_loss: 1.7932 - val_accuracy: 0.4712 - 668ms/epoch - 3ms/step\n",
            "Epoch 55/100\n",
            "191/191 - 1s - loss: 0.8872 - accuracy: 0.7161 - val_loss: 1.8810 - val_accuracy: 0.4993 - 667ms/epoch - 3ms/step\n",
            "Epoch 56/100\n",
            "191/191 - 1s - loss: 0.9658 - accuracy: 0.6867 - val_loss: 2.0186 - val_accuracy: 0.4254 - 672ms/epoch - 4ms/step\n",
            "Epoch 57/100\n",
            "191/191 - 1s - loss: 0.9957 - accuracy: 0.6790 - val_loss: 1.8911 - val_accuracy: 0.4328 - 670ms/epoch - 4ms/step\n",
            "Epoch 58/100\n",
            "191/191 - 1s - loss: 1.2978 - accuracy: 0.5787 - val_loss: 1.8713 - val_accuracy: 0.4195 - 668ms/epoch - 3ms/step\n",
            "Epoch 59/100\n",
            "191/191 - 1s - loss: 1.1304 - accuracy: 0.6343 - val_loss: 1.7635 - val_accuracy: 0.4609 - 675ms/epoch - 4ms/step\n",
            "Epoch 60/100\n",
            "191/191 - 1s - loss: 1.0441 - accuracy: 0.6650 - val_loss: 1.8048 - val_accuracy: 0.4476 - 680ms/epoch - 4ms/step\n",
            "Epoch 61/100\n",
            "191/191 - 1s - loss: 1.0079 - accuracy: 0.6713 - val_loss: 1.8012 - val_accuracy: 0.4387 - 663ms/epoch - 3ms/step\n",
            "Epoch 62/100\n",
            "191/191 - 1s - loss: 1.0566 - accuracy: 0.6555 - val_loss: 1.7167 - val_accuracy: 0.4682 - 672ms/epoch - 4ms/step\n",
            "Epoch 63/100\n",
            "191/191 - 1s - loss: 1.0090 - accuracy: 0.6742 - val_loss: 1.7761 - val_accuracy: 0.4505 - 670ms/epoch - 4ms/step\n",
            "Epoch 64/100\n",
            "191/191 - 1s - loss: 0.9769 - accuracy: 0.6880 - val_loss: 1.8163 - val_accuracy: 0.4520 - 669ms/epoch - 4ms/step\n",
            "Epoch 65/100\n",
            "191/191 - 1s - loss: 0.9229 - accuracy: 0.7024 - val_loss: 1.8388 - val_accuracy: 0.4727 - 666ms/epoch - 3ms/step\n",
            "Epoch 66/100\n",
            "191/191 - 1s - loss: 0.9955 - accuracy: 0.6819 - val_loss: 1.8506 - val_accuracy: 0.4609 - 667ms/epoch - 3ms/step\n",
            "Epoch 67/100\n",
            "191/191 - 1s - loss: 0.9376 - accuracy: 0.7056 - val_loss: 1.7237 - val_accuracy: 0.4801 - 657ms/epoch - 3ms/step\n",
            "Epoch 68/100\n",
            "191/191 - 1s - loss: 0.9043 - accuracy: 0.7044 - val_loss: 1.8181 - val_accuracy: 0.5155 - 676ms/epoch - 4ms/step\n",
            "Epoch 69/100\n",
            "191/191 - 1s - loss: 0.9167 - accuracy: 0.7036 - val_loss: 1.9255 - val_accuracy: 0.4771 - 674ms/epoch - 4ms/step\n",
            "Epoch 70/100\n",
            "191/191 - 1s - loss: 0.9234 - accuracy: 0.7084 - val_loss: 1.8881 - val_accuracy: 0.4520 - 666ms/epoch - 3ms/step\n",
            "Epoch 71/100\n",
            "191/191 - 1s - loss: 0.9066 - accuracy: 0.7010 - val_loss: 1.8241 - val_accuracy: 0.4490 - 675ms/epoch - 4ms/step\n",
            "Epoch 72/100\n",
            "191/191 - 1s - loss: 0.8754 - accuracy: 0.7208 - val_loss: 1.8104 - val_accuracy: 0.4742 - 674ms/epoch - 4ms/step\n",
            "Epoch 73/100\n",
            "191/191 - 1s - loss: 0.9070 - accuracy: 0.7110 - val_loss: 1.7529 - val_accuracy: 0.4948 - 680ms/epoch - 4ms/step\n",
            "Epoch 74/100\n",
            "191/191 - 1s - loss: 0.8822 - accuracy: 0.7231 - val_loss: 1.8430 - val_accuracy: 0.4697 - 669ms/epoch - 4ms/step\n",
            "Epoch 75/100\n",
            "191/191 - 1s - loss: 0.8610 - accuracy: 0.7233 - val_loss: 1.7214 - val_accuracy: 0.4948 - 666ms/epoch - 3ms/step\n",
            "Epoch 76/100\n",
            "191/191 - 1s - loss: 0.8716 - accuracy: 0.7167 - val_loss: 1.7731 - val_accuracy: 0.4801 - 666ms/epoch - 3ms/step\n",
            "Epoch 77/100\n",
            "191/191 - 1s - loss: 0.9084 - accuracy: 0.7161 - val_loss: 1.8592 - val_accuracy: 0.4801 - 668ms/epoch - 3ms/step\n",
            "Epoch 78/100\n",
            "191/191 - 1s - loss: 0.8574 - accuracy: 0.7202 - val_loss: 1.8157 - val_accuracy: 0.4697 - 671ms/epoch - 4ms/step\n",
            "Epoch 79/100\n",
            "191/191 - 1s - loss: 0.8816 - accuracy: 0.7189 - val_loss: 1.7931 - val_accuracy: 0.4357 - 668ms/epoch - 3ms/step\n",
            "Epoch 80/100\n",
            "191/191 - 1s - loss: 0.9133 - accuracy: 0.7044 - val_loss: 2.0635 - val_accuracy: 0.4165 - 689ms/epoch - 4ms/step\n",
            "Epoch 81/100\n",
            "191/191 - 1s - loss: 0.8765 - accuracy: 0.7169 - val_loss: 1.7954 - val_accuracy: 0.4742 - 671ms/epoch - 4ms/step\n",
            "Epoch 82/100\n",
            "191/191 - 1s - loss: 0.8469 - accuracy: 0.7305 - val_loss: 1.6961 - val_accuracy: 0.4712 - 673ms/epoch - 4ms/step\n",
            "Epoch 83/100\n",
            "191/191 - 1s - loss: 0.8696 - accuracy: 0.7198 - val_loss: 1.8711 - val_accuracy: 0.4801 - 663ms/epoch - 3ms/step\n",
            "Epoch 84/100\n",
            "191/191 - 1s - loss: 0.8416 - accuracy: 0.7285 - val_loss: 1.9175 - val_accuracy: 0.4313 - 671ms/epoch - 4ms/step\n",
            "Epoch 85/100\n",
            "191/191 - 1s - loss: 0.8739 - accuracy: 0.7185 - val_loss: 1.9048 - val_accuracy: 0.4313 - 676ms/epoch - 4ms/step\n",
            "Epoch 86/100\n",
            "191/191 - 1s - loss: 0.8564 - accuracy: 0.7226 - val_loss: 1.7963 - val_accuracy: 0.4756 - 656ms/epoch - 3ms/step\n",
            "Epoch 87/100\n",
            "191/191 - 1s - loss: 0.8640 - accuracy: 0.7169 - val_loss: 1.8537 - val_accuracy: 0.4535 - 673ms/epoch - 4ms/step\n",
            "Epoch 88/100\n",
            "191/191 - 1s - loss: 0.8380 - accuracy: 0.7294 - val_loss: 1.9390 - val_accuracy: 0.4343 - 673ms/epoch - 4ms/step\n",
            "Epoch 89/100\n",
            "191/191 - 1s - loss: 0.7998 - accuracy: 0.7405 - val_loss: 1.9640 - val_accuracy: 0.4682 - 673ms/epoch - 4ms/step\n",
            "Epoch 90/100\n",
            "191/191 - 1s - loss: 0.8741 - accuracy: 0.7161 - val_loss: 1.9809 - val_accuracy: 0.4756 - 669ms/epoch - 4ms/step\n",
            "Epoch 91/100\n",
            "191/191 - 1s - loss: 0.8605 - accuracy: 0.7192 - val_loss: 1.7948 - val_accuracy: 0.4860 - 676ms/epoch - 4ms/step\n",
            "Epoch 92/100\n",
            "191/191 - 1s - loss: 0.8329 - accuracy: 0.7348 - val_loss: 2.0457 - val_accuracy: 0.4638 - 668ms/epoch - 3ms/step\n",
            "Epoch 93/100\n",
            "191/191 - 1s - loss: 0.8446 - accuracy: 0.7261 - val_loss: 1.7899 - val_accuracy: 0.4801 - 670ms/epoch - 4ms/step\n",
            "Epoch 94/100\n",
            "191/191 - 1s - loss: 0.8406 - accuracy: 0.7302 - val_loss: 1.7968 - val_accuracy: 0.4727 - 688ms/epoch - 4ms/step\n",
            "Epoch 95/100\n",
            "191/191 - 1s - loss: 0.8275 - accuracy: 0.7335 - val_loss: 1.7351 - val_accuracy: 0.5052 - 675ms/epoch - 4ms/step\n",
            "Epoch 96/100\n",
            "191/191 - 1s - loss: 0.8274 - accuracy: 0.7318 - val_loss: 1.9247 - val_accuracy: 0.4742 - 671ms/epoch - 4ms/step\n",
            "Epoch 97/100\n",
            "191/191 - 1s - loss: 0.8115 - accuracy: 0.7361 - val_loss: 1.9137 - val_accuracy: 0.4727 - 672ms/epoch - 4ms/step\n",
            "Epoch 98/100\n",
            "191/191 - 1s - loss: 0.8075 - accuracy: 0.7363 - val_loss: 1.8461 - val_accuracy: 0.4786 - 672ms/epoch - 4ms/step\n",
            "Epoch 99/100\n",
            "191/191 - 1s - loss: 0.8655 - accuracy: 0.7264 - val_loss: 1.9776 - val_accuracy: 0.4638 - 674ms/epoch - 4ms/step\n",
            "Epoch 100/100\n",
            "191/191 - 1s - loss: 0.9290 - accuracy: 0.7013 - val_loss: 1.8508 - val_accuracy: 0.4535 - 670ms/epoch - 4ms/step\n",
            "Model: \"sequential_17\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " reshape_16 (Reshape)        (None, 128, 40)           0         \n",
            "                                                                 \n",
            " conv1d_32 (Conv1D)          (None, 124, 12)           2412      \n",
            "                                                                 \n",
            " max_pooling1d_32 (MaxPoolin  (None, 62, 12)           0         \n",
            " g1D)                                                            \n",
            "                                                                 \n",
            " conv1d_33 (Conv1D)          (None, 58, 28)            1708      \n",
            "                                                                 \n",
            " max_pooling1d_33 (MaxPoolin  (None, 29, 28)           0         \n",
            " g1D)                                                            \n",
            "                                                                 \n",
            " dense_16 (Dense)            (None, 29, 30)            870       \n",
            "                                                                 \n",
            " dropout_16 (Dropout)        (None, 29, 30)            0         \n",
            "                                                                 \n",
            " flatten_16 (Flatten)        (None, 870)               0         \n",
            "                                                                 \n",
            " y_pred (Dense)              (None, 10)                8710      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 13,700\n",
            "Trainable params: 13,700\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Result of fold:9\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 1.8919 - accuracy: 0.4958\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 90%|█████████ | 9/10 [10:36<01:09, 69.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "191/191 - 1s - loss: 2.3488 - accuracy: 0.2276 - val_loss: 1.9005 - val_accuracy: 0.2777 - 1s/epoch - 8ms/step\n",
            "Epoch 2/100\n",
            "191/191 - 1s - loss: 1.7742 - accuracy: 0.3577 - val_loss: 1.6751 - val_accuracy: 0.4298 - 669ms/epoch - 4ms/step\n",
            "Epoch 3/100\n",
            "191/191 - 1s - loss: 1.7347 - accuracy: 0.3808 - val_loss: 1.7303 - val_accuracy: 0.3914 - 659ms/epoch - 3ms/step\n",
            "Epoch 4/100\n",
            "191/191 - 1s - loss: 1.6622 - accuracy: 0.3884 - val_loss: 1.6372 - val_accuracy: 0.4357 - 676ms/epoch - 4ms/step\n",
            "Epoch 5/100\n",
            "191/191 - 1s - loss: 1.6211 - accuracy: 0.4191 - val_loss: 1.6244 - val_accuracy: 0.4889 - 669ms/epoch - 4ms/step\n",
            "Epoch 6/100\n",
            "191/191 - 1s - loss: 1.5479 - accuracy: 0.4390 - val_loss: 1.6192 - val_accuracy: 0.4151 - 674ms/epoch - 4ms/step\n",
            "Epoch 7/100\n",
            "191/191 - 1s - loss: 1.5050 - accuracy: 0.4714 - val_loss: 1.4956 - val_accuracy: 0.5126 - 674ms/epoch - 4ms/step\n",
            "Epoch 8/100\n",
            "191/191 - 1s - loss: 1.4562 - accuracy: 0.4837 - val_loss: 1.5343 - val_accuracy: 0.4993 - 676ms/epoch - 4ms/step\n",
            "Epoch 9/100\n",
            "191/191 - 1s - loss: 1.4101 - accuracy: 0.5133 - val_loss: 1.5470 - val_accuracy: 0.5244 - 666ms/epoch - 3ms/step\n",
            "Epoch 10/100\n",
            "191/191 - 1s - loss: 1.3530 - accuracy: 0.5371 - val_loss: 1.4779 - val_accuracy: 0.5510 - 668ms/epoch - 3ms/step\n",
            "Epoch 11/100\n",
            "191/191 - 1s - loss: 1.3197 - accuracy: 0.5531 - val_loss: 1.5035 - val_accuracy: 0.5436 - 687ms/epoch - 4ms/step\n",
            "Epoch 12/100\n",
            "191/191 - 1s - loss: 1.2994 - accuracy: 0.5529 - val_loss: 1.4262 - val_accuracy: 0.5229 - 675ms/epoch - 4ms/step\n",
            "Epoch 13/100\n",
            "191/191 - 1s - loss: 1.2818 - accuracy: 0.5641 - val_loss: 1.4193 - val_accuracy: 0.5406 - 668ms/epoch - 3ms/step\n",
            "Epoch 14/100\n",
            "191/191 - 1s - loss: 1.2717 - accuracy: 0.5769 - val_loss: 1.4566 - val_accuracy: 0.4461 - 676ms/epoch - 4ms/step\n",
            "Epoch 15/100\n",
            "191/191 - 1s - loss: 1.2209 - accuracy: 0.5846 - val_loss: 1.4513 - val_accuracy: 0.4815 - 671ms/epoch - 4ms/step\n",
            "Epoch 16/100\n",
            "191/191 - 1s - loss: 1.1990 - accuracy: 0.5978 - val_loss: 1.3988 - val_accuracy: 0.4771 - 672ms/epoch - 4ms/step\n",
            "Epoch 17/100\n",
            "191/191 - 1s - loss: 1.1890 - accuracy: 0.5952 - val_loss: 1.4729 - val_accuracy: 0.5170 - 674ms/epoch - 4ms/step\n",
            "Epoch 18/100\n",
            "191/191 - 1s - loss: 1.1912 - accuracy: 0.5996 - val_loss: 1.4557 - val_accuracy: 0.5170 - 677ms/epoch - 4ms/step\n",
            "Epoch 19/100\n",
            "191/191 - 1s - loss: 1.1860 - accuracy: 0.6008 - val_loss: 1.4165 - val_accuracy: 0.5081 - 665ms/epoch - 3ms/step\n",
            "Epoch 20/100\n",
            "191/191 - 1s - loss: 1.1643 - accuracy: 0.6049 - val_loss: 1.3856 - val_accuracy: 0.5199 - 677ms/epoch - 4ms/step\n",
            "Epoch 21/100\n",
            "191/191 - 1s - loss: 1.1428 - accuracy: 0.6243 - val_loss: 1.4648 - val_accuracy: 0.4948 - 670ms/epoch - 4ms/step\n",
            "Epoch 22/100\n",
            "191/191 - 1s - loss: 1.1536 - accuracy: 0.6244 - val_loss: 1.4622 - val_accuracy: 0.4963 - 679ms/epoch - 4ms/step\n",
            "Epoch 23/100\n",
            "191/191 - 1s - loss: 1.1473 - accuracy: 0.6208 - val_loss: 1.5961 - val_accuracy: 0.4756 - 681ms/epoch - 4ms/step\n",
            "Epoch 24/100\n",
            "191/191 - 1s - loss: 1.1456 - accuracy: 0.6180 - val_loss: 1.4201 - val_accuracy: 0.4963 - 665ms/epoch - 3ms/step\n",
            "Epoch 25/100\n",
            "191/191 - 1s - loss: 1.1135 - accuracy: 0.6285 - val_loss: 1.5262 - val_accuracy: 0.5155 - 665ms/epoch - 3ms/step\n",
            "Epoch 26/100\n",
            "191/191 - 1s - loss: 1.1173 - accuracy: 0.6228 - val_loss: 1.4532 - val_accuracy: 0.5022 - 664ms/epoch - 3ms/step\n",
            "Epoch 27/100\n",
            "191/191 - 1s - loss: 1.0688 - accuracy: 0.6519 - val_loss: 1.4916 - val_accuracy: 0.5140 - 673ms/epoch - 4ms/step\n",
            "Epoch 28/100\n",
            "191/191 - 1s - loss: 1.0647 - accuracy: 0.6479 - val_loss: 1.4013 - val_accuracy: 0.4993 - 661ms/epoch - 3ms/step\n",
            "Epoch 29/100\n",
            "191/191 - 1s - loss: 1.0820 - accuracy: 0.6441 - val_loss: 1.5165 - val_accuracy: 0.4815 - 668ms/epoch - 3ms/step\n",
            "Epoch 30/100\n",
            "191/191 - 1s - loss: 1.0608 - accuracy: 0.6507 - val_loss: 1.4194 - val_accuracy: 0.4860 - 674ms/epoch - 4ms/step\n",
            "Epoch 31/100\n",
            "191/191 - 1s - loss: 1.0371 - accuracy: 0.6525 - val_loss: 1.4993 - val_accuracy: 0.5199 - 713ms/epoch - 4ms/step\n",
            "Epoch 32/100\n",
            "191/191 - 1s - loss: 1.0544 - accuracy: 0.6437 - val_loss: 1.4462 - val_accuracy: 0.5111 - 736ms/epoch - 4ms/step\n",
            "Epoch 33/100\n",
            "191/191 - 1s - loss: 1.0334 - accuracy: 0.6548 - val_loss: 1.4746 - val_accuracy: 0.5229 - 751ms/epoch - 4ms/step\n",
            "Epoch 34/100\n",
            "191/191 - 1s - loss: 1.0552 - accuracy: 0.6540 - val_loss: 1.3891 - val_accuracy: 0.5510 - 694ms/epoch - 4ms/step\n",
            "Epoch 35/100\n",
            "191/191 - 1s - loss: 1.0134 - accuracy: 0.6642 - val_loss: 1.3755 - val_accuracy: 0.5391 - 665ms/epoch - 3ms/step\n",
            "Epoch 36/100\n",
            "191/191 - 1s - loss: 1.0034 - accuracy: 0.6686 - val_loss: 1.5198 - val_accuracy: 0.5539 - 675ms/epoch - 4ms/step\n",
            "Epoch 37/100\n",
            "191/191 - 1s - loss: 1.0050 - accuracy: 0.6708 - val_loss: 1.4153 - val_accuracy: 0.5332 - 671ms/epoch - 4ms/step\n",
            "Epoch 38/100\n",
            "191/191 - 1s - loss: 1.0474 - accuracy: 0.6524 - val_loss: 1.5764 - val_accuracy: 0.5318 - 660ms/epoch - 3ms/step\n",
            "Epoch 39/100\n",
            "191/191 - 1s - loss: 0.9998 - accuracy: 0.6685 - val_loss: 1.5623 - val_accuracy: 0.5303 - 677ms/epoch - 4ms/step\n",
            "Epoch 40/100\n",
            "191/191 - 1s - loss: 1.0041 - accuracy: 0.6691 - val_loss: 1.4553 - val_accuracy: 0.5406 - 702ms/epoch - 4ms/step\n",
            "Epoch 41/100\n",
            "191/191 - 1s - loss: 1.0760 - accuracy: 0.6387 - val_loss: 1.5055 - val_accuracy: 0.5406 - 695ms/epoch - 4ms/step\n",
            "Epoch 42/100\n",
            "191/191 - 1s - loss: 0.9868 - accuracy: 0.6787 - val_loss: 1.6937 - val_accuracy: 0.5155 - 699ms/epoch - 4ms/step\n",
            "Epoch 43/100\n",
            "191/191 - 1s - loss: 1.0226 - accuracy: 0.6675 - val_loss: 1.4107 - val_accuracy: 0.5569 - 697ms/epoch - 4ms/step\n",
            "Epoch 44/100\n",
            "191/191 - 1s - loss: 0.9702 - accuracy: 0.6847 - val_loss: 1.4850 - val_accuracy: 0.5288 - 703ms/epoch - 4ms/step\n",
            "Epoch 45/100\n",
            "191/191 - 1s - loss: 0.9638 - accuracy: 0.6847 - val_loss: 1.4764 - val_accuracy: 0.5657 - 698ms/epoch - 4ms/step\n",
            "Epoch 46/100\n",
            "191/191 - 1s - loss: 0.9569 - accuracy: 0.6854 - val_loss: 1.5173 - val_accuracy: 0.5377 - 713ms/epoch - 4ms/step\n",
            "Epoch 47/100\n",
            "191/191 - 1s - loss: 0.9462 - accuracy: 0.6831 - val_loss: 1.5851 - val_accuracy: 0.5140 - 686ms/epoch - 4ms/step\n",
            "Epoch 48/100\n",
            "191/191 - 1s - loss: 0.9996 - accuracy: 0.6673 - val_loss: 1.6673 - val_accuracy: 0.5096 - 688ms/epoch - 4ms/step\n",
            "Epoch 49/100\n",
            "191/191 - 1s - loss: 1.0440 - accuracy: 0.6622 - val_loss: 1.6316 - val_accuracy: 0.5347 - 693ms/epoch - 4ms/step\n",
            "Epoch 50/100\n",
            "191/191 - 1s - loss: 0.9677 - accuracy: 0.6862 - val_loss: 1.5399 - val_accuracy: 0.5199 - 692ms/epoch - 4ms/step\n",
            "Epoch 51/100\n",
            "191/191 - 1s - loss: 0.9521 - accuracy: 0.6851 - val_loss: 1.5753 - val_accuracy: 0.5244 - 685ms/epoch - 4ms/step\n",
            "Epoch 52/100\n",
            "191/191 - 1s - loss: 0.9405 - accuracy: 0.6913 - val_loss: 1.6900 - val_accuracy: 0.5081 - 691ms/epoch - 4ms/step\n",
            "Epoch 53/100\n",
            "191/191 - 1s - loss: 1.0187 - accuracy: 0.6657 - val_loss: 1.5829 - val_accuracy: 0.5244 - 695ms/epoch - 4ms/step\n",
            "Epoch 54/100\n",
            "191/191 - 1s - loss: 0.9767 - accuracy: 0.6816 - val_loss: 1.6653 - val_accuracy: 0.5273 - 692ms/epoch - 4ms/step\n",
            "Epoch 55/100\n",
            "191/191 - 1s - loss: 0.9812 - accuracy: 0.6782 - val_loss: 1.7066 - val_accuracy: 0.5391 - 688ms/epoch - 4ms/step\n",
            "Epoch 56/100\n",
            "191/191 - 1s - loss: 0.9541 - accuracy: 0.6854 - val_loss: 1.5647 - val_accuracy: 0.5406 - 672ms/epoch - 4ms/step\n",
            "Epoch 57/100\n",
            "191/191 - 1s - loss: 0.9659 - accuracy: 0.6834 - val_loss: 1.6441 - val_accuracy: 0.5273 - 672ms/epoch - 4ms/step\n",
            "Epoch 58/100\n",
            "191/191 - 1s - loss: 0.9599 - accuracy: 0.6892 - val_loss: 1.5867 - val_accuracy: 0.5229 - 683ms/epoch - 4ms/step\n",
            "Epoch 59/100\n",
            "191/191 - 1s - loss: 0.9542 - accuracy: 0.6882 - val_loss: 1.6414 - val_accuracy: 0.5052 - 675ms/epoch - 4ms/step\n",
            "Epoch 60/100\n",
            "191/191 - 1s - loss: 0.9290 - accuracy: 0.6917 - val_loss: 1.7416 - val_accuracy: 0.5126 - 667ms/epoch - 3ms/step\n",
            "Epoch 61/100\n",
            "191/191 - 1s - loss: 0.9300 - accuracy: 0.6889 - val_loss: 1.8177 - val_accuracy: 0.5052 - 680ms/epoch - 4ms/step\n",
            "Epoch 62/100\n",
            "191/191 - 1s - loss: 0.9077 - accuracy: 0.7015 - val_loss: 1.6452 - val_accuracy: 0.5332 - 672ms/epoch - 4ms/step\n",
            "Epoch 63/100\n",
            "191/191 - 1s - loss: 0.9095 - accuracy: 0.7009 - val_loss: 1.6131 - val_accuracy: 0.5465 - 666ms/epoch - 3ms/step\n",
            "Epoch 64/100\n",
            "191/191 - 1s - loss: 0.9414 - accuracy: 0.6890 - val_loss: 1.6971 - val_accuracy: 0.5096 - 679ms/epoch - 4ms/step\n",
            "Epoch 65/100\n",
            "191/191 - 1s - loss: 0.9253 - accuracy: 0.6912 - val_loss: 1.6599 - val_accuracy: 0.5318 - 660ms/epoch - 3ms/step\n",
            "Epoch 66/100\n",
            "191/191 - 1s - loss: 0.8963 - accuracy: 0.7074 - val_loss: 1.7909 - val_accuracy: 0.5288 - 687ms/epoch - 4ms/step\n",
            "Epoch 67/100\n",
            "191/191 - 1s - loss: 0.9161 - accuracy: 0.6976 - val_loss: 1.7497 - val_accuracy: 0.5347 - 676ms/epoch - 4ms/step\n",
            "Epoch 68/100\n",
            "191/191 - 1s - loss: 1.0060 - accuracy: 0.6700 - val_loss: 1.7569 - val_accuracy: 0.5155 - 663ms/epoch - 3ms/step\n",
            "Epoch 69/100\n",
            "191/191 - 1s - loss: 0.9260 - accuracy: 0.6971 - val_loss: 1.6799 - val_accuracy: 0.5288 - 681ms/epoch - 4ms/step\n",
            "Epoch 70/100\n",
            "191/191 - 1s - loss: 0.9012 - accuracy: 0.7106 - val_loss: 1.7444 - val_accuracy: 0.5480 - 676ms/epoch - 4ms/step\n",
            "Epoch 71/100\n",
            "191/191 - 1s - loss: 0.9178 - accuracy: 0.7073 - val_loss: 1.6380 - val_accuracy: 0.5391 - 678ms/epoch - 4ms/step\n",
            "Epoch 72/100\n",
            "191/191 - 1s - loss: 0.9108 - accuracy: 0.6972 - val_loss: 1.7594 - val_accuracy: 0.5436 - 668ms/epoch - 3ms/step\n",
            "Epoch 73/100\n",
            "191/191 - 1s - loss: 1.3947 - accuracy: 0.5460 - val_loss: 1.9265 - val_accuracy: 0.4254 - 672ms/epoch - 4ms/step\n",
            "Epoch 74/100\n",
            "191/191 - 1s - loss: 2.1838 - accuracy: 0.5038 - val_loss: 2.0161 - val_accuracy: 0.3663 - 666ms/epoch - 3ms/step\n",
            "Epoch 75/100\n",
            "191/191 - 1s - loss: 1.3161 - accuracy: 0.5556 - val_loss: 1.8711 - val_accuracy: 0.4284 - 671ms/epoch - 4ms/step\n",
            "Epoch 76/100\n",
            "191/191 - 1s - loss: 1.2148 - accuracy: 0.5978 - val_loss: 1.8099 - val_accuracy: 0.4697 - 679ms/epoch - 4ms/step\n",
            "Epoch 77/100\n",
            "191/191 - 1s - loss: 1.1426 - accuracy: 0.6195 - val_loss: 1.8150 - val_accuracy: 0.4564 - 674ms/epoch - 4ms/step\n",
            "Epoch 78/100\n",
            "191/191 - 1s - loss: 1.1117 - accuracy: 0.6277 - val_loss: 1.8224 - val_accuracy: 0.4845 - 663ms/epoch - 3ms/step\n",
            "Epoch 79/100\n",
            "191/191 - 1s - loss: 1.0984 - accuracy: 0.6338 - val_loss: 1.9315 - val_accuracy: 0.4963 - 674ms/epoch - 4ms/step\n",
            "Epoch 80/100\n",
            "191/191 - 1s - loss: 1.0501 - accuracy: 0.6606 - val_loss: 1.8182 - val_accuracy: 0.4934 - 673ms/epoch - 4ms/step\n",
            "Epoch 81/100\n",
            "191/191 - 1s - loss: 1.0395 - accuracy: 0.6504 - val_loss: 1.8124 - val_accuracy: 0.4889 - 678ms/epoch - 4ms/step\n",
            "Epoch 82/100\n",
            "191/191 - 1s - loss: 1.1100 - accuracy: 0.6297 - val_loss: 1.8799 - val_accuracy: 0.5007 - 661ms/epoch - 3ms/step\n",
            "Epoch 83/100\n",
            "191/191 - 1s - loss: 1.0614 - accuracy: 0.6466 - val_loss: 1.7853 - val_accuracy: 0.5377 - 665ms/epoch - 3ms/step\n",
            "Epoch 84/100\n",
            "191/191 - 1s - loss: 1.0459 - accuracy: 0.6573 - val_loss: 1.8831 - val_accuracy: 0.5303 - 670ms/epoch - 4ms/step\n",
            "Epoch 85/100\n",
            "191/191 - 1s - loss: 1.0269 - accuracy: 0.6588 - val_loss: 2.0639 - val_accuracy: 0.4993 - 668ms/epoch - 3ms/step\n",
            "Epoch 86/100\n",
            "191/191 - 1s - loss: 1.0109 - accuracy: 0.6568 - val_loss: 1.9125 - val_accuracy: 0.5111 - 668ms/epoch - 3ms/step\n",
            "Epoch 87/100\n",
            "191/191 - 1s - loss: 1.0027 - accuracy: 0.6647 - val_loss: 1.8725 - val_accuracy: 0.4874 - 665ms/epoch - 3ms/step\n",
            "Epoch 88/100\n",
            "191/191 - 1s - loss: 1.0151 - accuracy: 0.6622 - val_loss: 1.9003 - val_accuracy: 0.5081 - 674ms/epoch - 4ms/step\n",
            "Epoch 89/100\n",
            "191/191 - 1s - loss: 0.9931 - accuracy: 0.6663 - val_loss: 1.8924 - val_accuracy: 0.5214 - 673ms/epoch - 4ms/step\n",
            "Epoch 90/100\n",
            "191/191 - 1s - loss: 0.9833 - accuracy: 0.6649 - val_loss: 1.8847 - val_accuracy: 0.5140 - 673ms/epoch - 4ms/step\n",
            "Epoch 91/100\n",
            "191/191 - 1s - loss: 0.9600 - accuracy: 0.6693 - val_loss: 2.0553 - val_accuracy: 0.5332 - 674ms/epoch - 4ms/step\n",
            "Epoch 92/100\n",
            "191/191 - 1s - loss: 0.9762 - accuracy: 0.6785 - val_loss: 2.0478 - val_accuracy: 0.5436 - 673ms/epoch - 4ms/step\n",
            "Epoch 93/100\n",
            "191/191 - 1s - loss: 0.9452 - accuracy: 0.6905 - val_loss: 1.8989 - val_accuracy: 0.5465 - 666ms/epoch - 3ms/step\n",
            "Epoch 94/100\n",
            "191/191 - 1s - loss: 0.9845 - accuracy: 0.6754 - val_loss: 1.9878 - val_accuracy: 0.5214 - 662ms/epoch - 3ms/step\n",
            "Epoch 95/100\n",
            "191/191 - 1s - loss: 0.9288 - accuracy: 0.6923 - val_loss: 1.9362 - val_accuracy: 0.5214 - 675ms/epoch - 4ms/step\n",
            "Epoch 96/100\n",
            "191/191 - 1s - loss: 0.9184 - accuracy: 0.6900 - val_loss: 2.0540 - val_accuracy: 0.5495 - 661ms/epoch - 3ms/step\n",
            "Epoch 97/100\n",
            "191/191 - 1s - loss: 0.9627 - accuracy: 0.6737 - val_loss: 2.0826 - val_accuracy: 0.5052 - 677ms/epoch - 4ms/step\n",
            "Epoch 98/100\n",
            "191/191 - 1s - loss: 0.8997 - accuracy: 0.6971 - val_loss: 1.9493 - val_accuracy: 0.5229 - 673ms/epoch - 4ms/step\n",
            "Epoch 99/100\n",
            "191/191 - 1s - loss: 0.9326 - accuracy: 0.6846 - val_loss: 1.8955 - val_accuracy: 0.5170 - 669ms/epoch - 4ms/step\n",
            "Epoch 100/100\n",
            "191/191 - 1s - loss: 0.9146 - accuracy: 0.6880 - val_loss: 2.0313 - val_accuracy: 0.5185 - 668ms/epoch - 3ms/step\n",
            "Model: \"sequential_19\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " reshape_18 (Reshape)        (None, 128, 40)           0         \n",
            "                                                                 \n",
            " conv1d_36 (Conv1D)          (None, 124, 12)           2412      \n",
            "                                                                 \n",
            " max_pooling1d_36 (MaxPoolin  (None, 62, 12)           0         \n",
            " g1D)                                                            \n",
            "                                                                 \n",
            " conv1d_37 (Conv1D)          (None, 58, 28)            1708      \n",
            "                                                                 \n",
            " max_pooling1d_37 (MaxPoolin  (None, 29, 28)           0         \n",
            " g1D)                                                            \n",
            "                                                                 \n",
            " dense_18 (Dense)            (None, 29, 30)            870       \n",
            "                                                                 \n",
            " dropout_18 (Dropout)        (None, 29, 30)            0         \n",
            "                                                                 \n",
            " flatten_18 (Flatten)        (None, 870)               0         \n",
            "                                                                 \n",
            " y_pred (Dense)              (None, 10)                8710      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 13,700\n",
            "Trainable params: 13,700\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Result of fold:10\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 2.1677 - accuracy: 0.3933\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [11:46<00:00, 70.61s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QcinAjM-3d0y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "You do not need to run them."
      ],
      "metadata": {
        "id": "6VTuBAiZ3ePo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import pandas as pd\n",
        "# import numpy as np\n",
        "\n",
        "# pd.plotting.register_matplotlib_converters()\n",
        "# import matplotlib.pyplot as plt\n",
        "# %matplotlib inline\n",
        "# import seaborn as sns\n",
        "\n",
        "# from sklearn.model_selection import train_test_split\n",
        "# from sklearn.metrics import classification_report\n",
        "# from sklearn.model_selection import GridSearchCV\n",
        "# from sklearn.preprocessing import MinMaxScaler\n",
        "# from tensorflow.keras.models import Sequential\n",
        "# from tensorflow.keras.layers import Conv2D, Flatten, Dense, MaxPool2D, Dropout\n",
        "# from tensorflow.keras.utils import to_categorical \n",
        "# import os,glob,skimage,librosa\n",
        "# import librosa.display\n",
        "\n",
        "# import warnings\n",
        "# warnings.filterwarnings(\"ignore\")  "
      ],
      "metadata": {
        "id": "izaNAb8-zRQ3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I2WlOelTzUJN",
        "outputId": "dfc192ea-8562-4879-d920-0aeca9b42815"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import sys, os, random\n",
        "# import tensorflow as tf\n",
        "# X = np.load('/content/drive/MyDrive/Thesis_Keras/Mel_conv1/data/datasetnpy/melspectro/x_train.npy')\n",
        "# Y = np.load('/content/drive/MyDrive/Thesis_Keras/Mel_conv1/data/datasetnpy/melspectro/y_train.npy')\n",
        "\n",
        "# x_train, x_val, Y_train, Y_val = train_test_split(X, Y, test_size=0.1, random_state=1)\n",
        "# input_length = x_train[0].shape[0]\n"
      ],
      "metadata": {
        "id": "6_mrZWgwd-hI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# x_test=np.load('/content/drive/MyDrive/Thesis_Keras/Mel_conv1/data/datasetnpy/melspectro/x_test.npy',allow_pickle=True)\n",
        "# Y_test = np.load('/content/drive/MyDrive/Thesis_Keras/Mel_conv1/data/datasetnpy/melspectro/y_test.npy')\n",
        "\n",
        "# # X_train = np.array([tf.image.resize(x, [60,41]) for x in x_train])\n",
        "# # X_test = np.array([tf.image.resize(x,[60,41]) for x in x_test])\n",
        "# # X_val = np.array([tf.image.resize(x,[60,41]) for x in x_val])\n",
        "\n",
        "# X_train = x_train\n",
        "# X_test = x_test\n",
        "# X_val = x_val\n",
        "# print(X_train.shape)\n",
        "# print(X_test.shape)\n",
        "# print(X_val.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L1BL9kEbMciI",
        "outputId": "409f44bc-0fbf-486d-ca85-282e8dc7b526"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(5383, 40, 128, 1)\n",
            "(1496, 40, 128, 1)\n",
            "(599, 40, 128, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import tensorflow as tf\n",
        "# from tensorflow.keras.models import Sequential\n",
        "# from tensorflow.keras.layers import Dense, InputLayer, Dropout, Conv1D, Convolution2D, Activation, Flatten, Reshape, MaxPooling1D, MaxPooling2D, BatchNormalization, TimeDistributed,LeakyReLU,SpatialDropout2D,GlobalAveragePooling2D\n",
        "# from tensorflow.keras.optimizers import Adam,SGD\n",
        "# from tensorflow.keras import regularizers\n",
        "# EPOCHS = 100\n",
        "# # this controls the batch size, or you can manipulate the tf.data.Dataset objects yourself\n",
        "# BATCH_SIZE = 32\n",
        "# input_length=len(X_train[0])\n",
        "# input_length1=len(X_train[0][1])\n",
        "# print(input_length)\n",
        "# print(input_length1)\n",
        "# callbacks = []"
      ],
      "metadata": {
        "id": "sUTn_42P_TGs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "75d5e2c8-73fe-4f92-f3c3-79598fd6f9fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "40\n",
            "128\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# def getModel():\n",
        "#     model = Sequential()\n",
        "#     model.add(Reshape((128,40), input_shape=(input_length,input_length1 )))\n",
        "#     model.add(Conv1D(12, kernel_size=5, activation='relu',kernel_regularizer=tf.keras.regularizers.L2(0.001)))\n",
        "#     #model.add(BatchNormalization())\n",
        "#     model.add(MaxPooling1D(pool_size=2, strides=2, padding='same'))\n",
        "#     model.add(Conv1D(28, kernel_size=5, activation='relu', padding='valid'))\n",
        "#     model.add(MaxPooling1D(pool_size=2, strides=2, padding='same'))\n",
        "#     model.add(Dense(30, activation='relu'))\n",
        "#     model.add(Dropout(0.5))\n",
        "\n",
        "#     model.add(Flatten())\n",
        "#     model.add(Dense(10, activation='softmax', name='y_pred'))\n",
        "\n",
        "#     return model"
      ],
      "metadata": {
        "id": "UN1Q-i4onwTV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# #opt = Adam(learning_rate=0.005, beta_1=0.9, beta_2=0.999)\n",
        "\n",
        "# opt = Adam(learning_rate=0.005, beta_1=0.9, beta_2=0.999)\n",
        "# optimizer=opt\n",
        "# model=getModel()\n",
        "\n",
        "# # train the neural network\n",
        "\n",
        "# model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
        "\n",
        "# model.fit(X_train,Y_train, batch_size=BATCH_SIZE, epochs=EPOCHS, validation_data=(X_val,Y_val), verbose=2, callbacks=callbacks)\n",
        "# print(model.summary())\n",
        "# # Use this flag to disable per-channel quantization for a model.\n",
        "# # This can reduce RAM usage for convolutional models, but may have\n",
        "# # an impact on accuracy.\n",
        "# disable_per_channel_quantization = False"
      ],
      "metadata": {
        "id": "cEAePPkfzllH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "73f76ac0-115e-4938-ff2b-bf1873518c04"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "169/169 - 1s - loss: 2.3215 - accuracy: 0.2330 - val_loss: 1.8309 - val_accuracy: 0.3038 - 1s/epoch - 8ms/step\n",
            "Epoch 2/100\n",
            "169/169 - 1s - loss: 1.7955 - accuracy: 0.3463 - val_loss: 1.7350 - val_accuracy: 0.3873 - 619ms/epoch - 4ms/step\n",
            "Epoch 3/100\n",
            "169/169 - 1s - loss: 1.7154 - accuracy: 0.3632 - val_loss: 1.6386 - val_accuracy: 0.4324 - 624ms/epoch - 4ms/step\n",
            "Epoch 4/100\n",
            "169/169 - 1s - loss: 1.6493 - accuracy: 0.4067 - val_loss: 1.5813 - val_accuracy: 0.4290 - 631ms/epoch - 4ms/step\n",
            "Epoch 5/100\n",
            "169/169 - 1s - loss: 1.5822 - accuracy: 0.4193 - val_loss: 1.5032 - val_accuracy: 0.4775 - 621ms/epoch - 4ms/step\n",
            "Epoch 6/100\n",
            "169/169 - 1s - loss: 1.5317 - accuracy: 0.4392 - val_loss: 1.4825 - val_accuracy: 0.5142 - 620ms/epoch - 4ms/step\n",
            "Epoch 7/100\n",
            "169/169 - 1s - loss: 1.5069 - accuracy: 0.4572 - val_loss: 1.4556 - val_accuracy: 0.4992 - 620ms/epoch - 4ms/step\n",
            "Epoch 8/100\n",
            "169/169 - 1s - loss: 1.5238 - accuracy: 0.4680 - val_loss: 1.4040 - val_accuracy: 0.5409 - 624ms/epoch - 4ms/step\n",
            "Epoch 9/100\n",
            "169/169 - 1s - loss: 1.4755 - accuracy: 0.4817 - val_loss: 1.3788 - val_accuracy: 0.5392 - 616ms/epoch - 4ms/step\n",
            "Epoch 10/100\n",
            "169/169 - 1s - loss: 1.4755 - accuracy: 0.5012 - val_loss: 1.3315 - val_accuracy: 0.5876 - 634ms/epoch - 4ms/step\n",
            "Epoch 11/100\n",
            "169/169 - 1s - loss: 1.4229 - accuracy: 0.5059 - val_loss: 1.4048 - val_accuracy: 0.5259 - 619ms/epoch - 4ms/step\n",
            "Epoch 12/100\n",
            "169/169 - 1s - loss: 1.4183 - accuracy: 0.5055 - val_loss: 1.3555 - val_accuracy: 0.5776 - 618ms/epoch - 4ms/step\n",
            "Epoch 13/100\n",
            "169/169 - 1s - loss: 1.3675 - accuracy: 0.5276 - val_loss: 1.2895 - val_accuracy: 0.6127 - 617ms/epoch - 4ms/step\n",
            "Epoch 14/100\n",
            "169/169 - 1s - loss: 1.3552 - accuracy: 0.5395 - val_loss: 1.2965 - val_accuracy: 0.5860 - 627ms/epoch - 4ms/step\n",
            "Epoch 15/100\n",
            "169/169 - 1s - loss: 1.3341 - accuracy: 0.5358 - val_loss: 1.2596 - val_accuracy: 0.5927 - 630ms/epoch - 4ms/step\n",
            "Epoch 16/100\n",
            "169/169 - 1s - loss: 1.2923 - accuracy: 0.5621 - val_loss: 1.2345 - val_accuracy: 0.6043 - 621ms/epoch - 4ms/step\n",
            "Epoch 17/100\n",
            "169/169 - 1s - loss: 1.2672 - accuracy: 0.5640 - val_loss: 1.2227 - val_accuracy: 0.6177 - 626ms/epoch - 4ms/step\n",
            "Epoch 18/100\n",
            "169/169 - 1s - loss: 1.2517 - accuracy: 0.5751 - val_loss: 1.1885 - val_accuracy: 0.6177 - 623ms/epoch - 4ms/step\n",
            "Epoch 19/100\n",
            "169/169 - 1s - loss: 1.2236 - accuracy: 0.5779 - val_loss: 1.1639 - val_accuracy: 0.5977 - 618ms/epoch - 4ms/step\n",
            "Epoch 20/100\n",
            "169/169 - 1s - loss: 1.2268 - accuracy: 0.5844 - val_loss: 1.1274 - val_accuracy: 0.6194 - 607ms/epoch - 4ms/step\n",
            "Epoch 21/100\n",
            "169/169 - 1s - loss: 1.2309 - accuracy: 0.5781 - val_loss: 1.1891 - val_accuracy: 0.6244 - 618ms/epoch - 4ms/step\n",
            "Epoch 22/100\n",
            "169/169 - 1s - loss: 1.2078 - accuracy: 0.5807 - val_loss: 1.1281 - val_accuracy: 0.6277 - 612ms/epoch - 4ms/step\n",
            "Epoch 23/100\n",
            "169/169 - 1s - loss: 1.1866 - accuracy: 0.6012 - val_loss: 1.1136 - val_accuracy: 0.6494 - 622ms/epoch - 4ms/step\n",
            "Epoch 24/100\n",
            "169/169 - 1s - loss: 1.2292 - accuracy: 0.5815 - val_loss: 1.2041 - val_accuracy: 0.6244 - 629ms/epoch - 4ms/step\n",
            "Epoch 25/100\n",
            "169/169 - 1s - loss: 1.1635 - accuracy: 0.6064 - val_loss: 1.1763 - val_accuracy: 0.6244 - 612ms/epoch - 4ms/step\n",
            "Epoch 26/100\n",
            "169/169 - 1s - loss: 1.1553 - accuracy: 0.6064 - val_loss: 1.1691 - val_accuracy: 0.6327 - 619ms/epoch - 4ms/step\n",
            "Epoch 27/100\n",
            "169/169 - 1s - loss: 1.1690 - accuracy: 0.6064 - val_loss: 1.0753 - val_accuracy: 0.6461 - 619ms/epoch - 4ms/step\n",
            "Epoch 28/100\n",
            "169/169 - 1s - loss: 1.1298 - accuracy: 0.6205 - val_loss: 1.2079 - val_accuracy: 0.5977 - 621ms/epoch - 4ms/step\n",
            "Epoch 29/100\n",
            "169/169 - 1s - loss: 1.1208 - accuracy: 0.6192 - val_loss: 1.0837 - val_accuracy: 0.6411 - 626ms/epoch - 4ms/step\n",
            "Epoch 30/100\n",
            "169/169 - 1s - loss: 1.1404 - accuracy: 0.6123 - val_loss: 1.0724 - val_accuracy: 0.6761 - 618ms/epoch - 4ms/step\n",
            "Epoch 31/100\n",
            "169/169 - 1s - loss: 1.1239 - accuracy: 0.6273 - val_loss: 1.1095 - val_accuracy: 0.6511 - 611ms/epoch - 4ms/step\n",
            "Epoch 32/100\n",
            "169/169 - 1s - loss: 1.1379 - accuracy: 0.6142 - val_loss: 1.1400 - val_accuracy: 0.6411 - 622ms/epoch - 4ms/step\n",
            "Epoch 33/100\n",
            "169/169 - 1s - loss: 1.1208 - accuracy: 0.6292 - val_loss: 1.1482 - val_accuracy: 0.6444 - 630ms/epoch - 4ms/step\n",
            "Epoch 34/100\n",
            "169/169 - 1s - loss: 1.1240 - accuracy: 0.6272 - val_loss: 1.1143 - val_accuracy: 0.6544 - 610ms/epoch - 4ms/step\n",
            "Epoch 35/100\n",
            "169/169 - 1s - loss: 1.1270 - accuracy: 0.6221 - val_loss: 1.1494 - val_accuracy: 0.6611 - 614ms/epoch - 4ms/step\n",
            "Epoch 36/100\n",
            "169/169 - 1s - loss: 1.0917 - accuracy: 0.6379 - val_loss: 1.1231 - val_accuracy: 0.6745 - 624ms/epoch - 4ms/step\n",
            "Epoch 37/100\n",
            "169/169 - 1s - loss: 1.1141 - accuracy: 0.6303 - val_loss: 1.0598 - val_accuracy: 0.6761 - 615ms/epoch - 4ms/step\n",
            "Epoch 38/100\n",
            "169/169 - 1s - loss: 1.0618 - accuracy: 0.6491 - val_loss: 1.0613 - val_accuracy: 0.6644 - 623ms/epoch - 4ms/step\n",
            "Epoch 39/100\n",
            "169/169 - 1s - loss: 1.0956 - accuracy: 0.6413 - val_loss: 1.0912 - val_accuracy: 0.6561 - 618ms/epoch - 4ms/step\n",
            "Epoch 40/100\n",
            "169/169 - 1s - loss: 1.0897 - accuracy: 0.6370 - val_loss: 1.0565 - val_accuracy: 0.6628 - 617ms/epoch - 4ms/step\n",
            "Epoch 41/100\n",
            "169/169 - 1s - loss: 1.0774 - accuracy: 0.6392 - val_loss: 1.0459 - val_accuracy: 0.6511 - 628ms/epoch - 4ms/step\n",
            "Epoch 42/100\n",
            "169/169 - 1s - loss: 1.0691 - accuracy: 0.6372 - val_loss: 1.0508 - val_accuracy: 0.6644 - 628ms/epoch - 4ms/step\n",
            "Epoch 43/100\n",
            "169/169 - 1s - loss: 1.0339 - accuracy: 0.6584 - val_loss: 1.0415 - val_accuracy: 0.6544 - 615ms/epoch - 4ms/step\n",
            "Epoch 44/100\n",
            "169/169 - 1s - loss: 1.0516 - accuracy: 0.6496 - val_loss: 1.0312 - val_accuracy: 0.6895 - 631ms/epoch - 4ms/step\n",
            "Epoch 45/100\n",
            "169/169 - 1s - loss: 1.0358 - accuracy: 0.6550 - val_loss: 1.1436 - val_accuracy: 0.6528 - 615ms/epoch - 4ms/step\n",
            "Epoch 46/100\n",
            "169/169 - 1s - loss: 1.0466 - accuracy: 0.6485 - val_loss: 1.0153 - val_accuracy: 0.6778 - 614ms/epoch - 4ms/step\n",
            "Epoch 47/100\n",
            "169/169 - 1s - loss: 1.0338 - accuracy: 0.6508 - val_loss: 1.0079 - val_accuracy: 0.6878 - 618ms/epoch - 4ms/step\n",
            "Epoch 48/100\n",
            "169/169 - 1s - loss: 1.0263 - accuracy: 0.6565 - val_loss: 1.0531 - val_accuracy: 0.6761 - 612ms/epoch - 4ms/step\n",
            "Epoch 49/100\n",
            "169/169 - 1s - loss: 0.9954 - accuracy: 0.6717 - val_loss: 1.0683 - val_accuracy: 0.6678 - 624ms/epoch - 4ms/step\n",
            "Epoch 50/100\n",
            "169/169 - 1s - loss: 1.0075 - accuracy: 0.6617 - val_loss: 1.0926 - val_accuracy: 0.6528 - 623ms/epoch - 4ms/step\n",
            "Epoch 51/100\n",
            "169/169 - 1s - loss: 1.0031 - accuracy: 0.6675 - val_loss: 1.0428 - val_accuracy: 0.6561 - 615ms/epoch - 4ms/step\n",
            "Epoch 52/100\n",
            "169/169 - 1s - loss: 1.0000 - accuracy: 0.6753 - val_loss: 0.9783 - val_accuracy: 0.7045 - 617ms/epoch - 4ms/step\n",
            "Epoch 53/100\n",
            "169/169 - 1s - loss: 0.9721 - accuracy: 0.6756 - val_loss: 1.0175 - val_accuracy: 0.6795 - 614ms/epoch - 4ms/step\n",
            "Epoch 54/100\n",
            "169/169 - 1s - loss: 1.0030 - accuracy: 0.6667 - val_loss: 1.0566 - val_accuracy: 0.6761 - 619ms/epoch - 4ms/step\n",
            "Epoch 55/100\n",
            "169/169 - 1s - loss: 0.9723 - accuracy: 0.6818 - val_loss: 1.0467 - val_accuracy: 0.6845 - 617ms/epoch - 4ms/step\n",
            "Epoch 56/100\n",
            "169/169 - 1s - loss: 1.0136 - accuracy: 0.6656 - val_loss: 1.0113 - val_accuracy: 0.6845 - 630ms/epoch - 4ms/step\n",
            "Epoch 57/100\n",
            "169/169 - 1s - loss: 0.9748 - accuracy: 0.6814 - val_loss: 1.0352 - val_accuracy: 0.6978 - 621ms/epoch - 4ms/step\n",
            "Epoch 58/100\n",
            "169/169 - 1s - loss: 0.9416 - accuracy: 0.6927 - val_loss: 0.9741 - val_accuracy: 0.7028 - 618ms/epoch - 4ms/step\n",
            "Epoch 59/100\n",
            "169/169 - 1s - loss: 0.9878 - accuracy: 0.6820 - val_loss: 0.9935 - val_accuracy: 0.6945 - 615ms/epoch - 4ms/step\n",
            "Epoch 60/100\n",
            "169/169 - 1s - loss: 0.9617 - accuracy: 0.6833 - val_loss: 0.9993 - val_accuracy: 0.6978 - 626ms/epoch - 4ms/step\n",
            "Epoch 61/100\n",
            "169/169 - 1s - loss: 0.9574 - accuracy: 0.6842 - val_loss: 1.0260 - val_accuracy: 0.6594 - 618ms/epoch - 4ms/step\n",
            "Epoch 62/100\n",
            "169/169 - 1s - loss: 0.9917 - accuracy: 0.6786 - val_loss: 0.9904 - val_accuracy: 0.6978 - 620ms/epoch - 4ms/step\n",
            "Epoch 63/100\n",
            "169/169 - 1s - loss: 0.9286 - accuracy: 0.6894 - val_loss: 0.9857 - val_accuracy: 0.6962 - 640ms/epoch - 4ms/step\n",
            "Epoch 64/100\n",
            "169/169 - 1s - loss: 0.9544 - accuracy: 0.6899 - val_loss: 1.0254 - val_accuracy: 0.6745 - 638ms/epoch - 4ms/step\n",
            "Epoch 65/100\n",
            "169/169 - 1s - loss: 1.0402 - accuracy: 0.6578 - val_loss: 1.0107 - val_accuracy: 0.6811 - 617ms/epoch - 4ms/step\n",
            "Epoch 66/100\n",
            "169/169 - 1s - loss: 0.9780 - accuracy: 0.6771 - val_loss: 1.0382 - val_accuracy: 0.6661 - 604ms/epoch - 4ms/step\n",
            "Epoch 67/100\n",
            "169/169 - 1s - loss: 0.9595 - accuracy: 0.6831 - val_loss: 1.0259 - val_accuracy: 0.6945 - 617ms/epoch - 4ms/step\n",
            "Epoch 68/100\n",
            "169/169 - 1s - loss: 0.9546 - accuracy: 0.6831 - val_loss: 1.0021 - val_accuracy: 0.6895 - 631ms/epoch - 4ms/step\n",
            "Epoch 69/100\n",
            "169/169 - 1s - loss: 0.9721 - accuracy: 0.6745 - val_loss: 0.9999 - val_accuracy: 0.6828 - 624ms/epoch - 4ms/step\n",
            "Epoch 70/100\n",
            "169/169 - 1s - loss: 0.9729 - accuracy: 0.6805 - val_loss: 0.9892 - val_accuracy: 0.6761 - 654ms/epoch - 4ms/step\n",
            "Epoch 71/100\n",
            "169/169 - 1s - loss: 0.9234 - accuracy: 0.6983 - val_loss: 1.0268 - val_accuracy: 0.6928 - 683ms/epoch - 4ms/step\n",
            "Epoch 72/100\n",
            "169/169 - 1s - loss: 0.9133 - accuracy: 0.6979 - val_loss: 0.9761 - val_accuracy: 0.6945 - 683ms/epoch - 4ms/step\n",
            "Epoch 73/100\n",
            "169/169 - 1s - loss: 0.9277 - accuracy: 0.6950 - val_loss: 1.0580 - val_accuracy: 0.6644 - 666ms/epoch - 4ms/step\n",
            "Epoch 74/100\n",
            "169/169 - 1s - loss: 0.9215 - accuracy: 0.7056 - val_loss: 1.0060 - val_accuracy: 0.6828 - 633ms/epoch - 4ms/step\n",
            "Epoch 75/100\n",
            "169/169 - 1s - loss: 0.9327 - accuracy: 0.6970 - val_loss: 1.1002 - val_accuracy: 0.6561 - 618ms/epoch - 4ms/step\n",
            "Epoch 76/100\n",
            "169/169 - 1s - loss: 1.0227 - accuracy: 0.6654 - val_loss: 1.0451 - val_accuracy: 0.6661 - 621ms/epoch - 4ms/step\n",
            "Epoch 77/100\n",
            "169/169 - 1s - loss: 0.9798 - accuracy: 0.6736 - val_loss: 1.0245 - val_accuracy: 0.6828 - 638ms/epoch - 4ms/step\n",
            "Epoch 78/100\n",
            "169/169 - 1s - loss: 0.9099 - accuracy: 0.7007 - val_loss: 1.0077 - val_accuracy: 0.6962 - 611ms/epoch - 4ms/step\n",
            "Epoch 79/100\n",
            "169/169 - 1s - loss: 0.9150 - accuracy: 0.6981 - val_loss: 0.9962 - val_accuracy: 0.7045 - 618ms/epoch - 4ms/step\n",
            "Epoch 80/100\n",
            "169/169 - 1s - loss: 0.9201 - accuracy: 0.7020 - val_loss: 1.0230 - val_accuracy: 0.6845 - 609ms/epoch - 4ms/step\n",
            "Epoch 81/100\n",
            "169/169 - 1s - loss: 0.9395 - accuracy: 0.6961 - val_loss: 0.9950 - val_accuracy: 0.7028 - 630ms/epoch - 4ms/step\n",
            "Epoch 82/100\n",
            "169/169 - 1s - loss: 0.9505 - accuracy: 0.6890 - val_loss: 1.0048 - val_accuracy: 0.6912 - 624ms/epoch - 4ms/step\n",
            "Epoch 83/100\n",
            "169/169 - 1s - loss: 0.8953 - accuracy: 0.6970 - val_loss: 1.0303 - val_accuracy: 0.6895 - 619ms/epoch - 4ms/step\n",
            "Epoch 84/100\n",
            "169/169 - 1s - loss: 0.9206 - accuracy: 0.6989 - val_loss: 1.0275 - val_accuracy: 0.6962 - 621ms/epoch - 4ms/step\n",
            "Epoch 85/100\n",
            "169/169 - 1s - loss: 0.9000 - accuracy: 0.7072 - val_loss: 1.0126 - val_accuracy: 0.6962 - 610ms/epoch - 4ms/step\n",
            "Epoch 86/100\n",
            "169/169 - 1s - loss: 0.8950 - accuracy: 0.7044 - val_loss: 0.9646 - val_accuracy: 0.6995 - 624ms/epoch - 4ms/step\n",
            "Epoch 87/100\n",
            "169/169 - 1s - loss: 0.8942 - accuracy: 0.7050 - val_loss: 1.0295 - val_accuracy: 0.6861 - 633ms/epoch - 4ms/step\n",
            "Epoch 88/100\n",
            "169/169 - 1s - loss: 0.9022 - accuracy: 0.7063 - val_loss: 0.9723 - val_accuracy: 0.7162 - 624ms/epoch - 4ms/step\n",
            "Epoch 89/100\n",
            "169/169 - 1s - loss: 0.9714 - accuracy: 0.6818 - val_loss: 1.0254 - val_accuracy: 0.7012 - 626ms/epoch - 4ms/step\n",
            "Epoch 90/100\n",
            "169/169 - 1s - loss: 0.8890 - accuracy: 0.7109 - val_loss: 0.9947 - val_accuracy: 0.7012 - 623ms/epoch - 4ms/step\n",
            "Epoch 91/100\n",
            "169/169 - 1s - loss: 0.8969 - accuracy: 0.7063 - val_loss: 0.9638 - val_accuracy: 0.7162 - 613ms/epoch - 4ms/step\n",
            "Epoch 92/100\n",
            "169/169 - 1s - loss: 0.8526 - accuracy: 0.7217 - val_loss: 0.9933 - val_accuracy: 0.6778 - 616ms/epoch - 4ms/step\n",
            "Epoch 93/100\n",
            "169/169 - 1s - loss: 0.9614 - accuracy: 0.6963 - val_loss: 1.2297 - val_accuracy: 0.7012 - 615ms/epoch - 4ms/step\n",
            "Epoch 94/100\n",
            "169/169 - 1s - loss: 0.9591 - accuracy: 0.6875 - val_loss: 0.9680 - val_accuracy: 0.7028 - 617ms/epoch - 4ms/step\n",
            "Epoch 95/100\n",
            "169/169 - 1s - loss: 0.9067 - accuracy: 0.6998 - val_loss: 0.9974 - val_accuracy: 0.6995 - 621ms/epoch - 4ms/step\n",
            "Epoch 96/100\n",
            "169/169 - 1s - loss: 0.9020 - accuracy: 0.7015 - val_loss: 0.9855 - val_accuracy: 0.7028 - 615ms/epoch - 4ms/step\n",
            "Epoch 97/100\n",
            "169/169 - 1s - loss: 0.8726 - accuracy: 0.7124 - val_loss: 0.9399 - val_accuracy: 0.7212 - 627ms/epoch - 4ms/step\n",
            "Epoch 98/100\n",
            "169/169 - 1s - loss: 0.9055 - accuracy: 0.7026 - val_loss: 1.0067 - val_accuracy: 0.7045 - 607ms/epoch - 4ms/step\n",
            "Epoch 99/100\n",
            "169/169 - 1s - loss: 0.8654 - accuracy: 0.7134 - val_loss: 0.9785 - val_accuracy: 0.6995 - 606ms/epoch - 4ms/step\n",
            "Epoch 100/100\n",
            "169/169 - 1s - loss: 0.8792 - accuracy: 0.7141 - val_loss: 0.9957 - val_accuracy: 0.7062 - 620ms/epoch - 4ms/step\n",
            "Model: \"sequential_23\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " reshape_13 (Reshape)        (None, 128, 40)           0         \n",
            "                                                                 \n",
            " conv1d_24 (Conv1D)          (None, 124, 12)           2412      \n",
            "                                                                 \n",
            " max_pooling1d_22 (MaxPoolin  (None, 62, 12)           0         \n",
            " g1D)                                                            \n",
            "                                                                 \n",
            " conv1d_25 (Conv1D)          (None, 58, 28)            1708      \n",
            "                                                                 \n",
            " max_pooling1d_23 (MaxPoolin  (None, 29, 28)           0         \n",
            " g1D)                                                            \n",
            "                                                                 \n",
            " dense_10 (Dense)            (None, 29, 30)            870       \n",
            "                                                                 \n",
            " dropout_10 (Dropout)        (None, 29, 30)            0         \n",
            "                                                                 \n",
            " flatten_6 (Flatten)         (None, 870)               0         \n",
            "                                                                 \n",
            " y_pred (Dense)              (None, 10)                8710      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 13,700\n",
            "Trainable params: 13,700\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # Save the model to disk\n",
        "# model.save('/content/drive/MyDrive/Thesis_Keras/SBCNN/data/saved_models/spectro')"
      ],
      "metadata": {
        "id": "Z8jHfvnOnw1G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# score = model.evaluate(\n",
        "#         x=X_test,\n",
        "#         y=Y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ujLL2n-o-bu8",
        "outputId": "6ad56aa8-3868-4349-8660-1e6714b31e75"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "47/47 [==============================] - 0s 3ms/step - loss: 0.9766 - accuracy: 0.7166\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vLAkLFThlOBF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# mfccs = extract_feature(examplePath)\n",
        "# plt.figure(figsize=(20,5))\n",
        "# librosa.display.specshow(mfccs, sr=22050, x_axis='time', cmap='viridis')\n",
        "# plt.colorbar()\n",
        "# plt.show()\n",
        "# print (mfccs.var(axis=1))\n",
        "# print (mfccs.mean(axis=1))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 721
        },
        "id": "yferRfxW1ZSz",
        "outputId": "e3b635d3-efd0-4f6f-e1d8-50199ca4326e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_data.py:236: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
            "  \"Numerical issues were encountered \"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_data.py:255: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
            "  \"Numerical issues were encountered \"\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1440x360 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1.0000001  1.0000001  1.         1.         1.0000001  1.0000001\n",
            " 1.         0.99999994 1.0000001  1.         0.9999998  1.\n",
            " 1.         0.99999994 1.         1.         0.99999994 1.\n",
            " 1.         1.0000001  1.0000001  0.99999994 0.99999994 1.\n",
            " 1.0000001  1.0000001  1.0000001  1.0000001  1.         1.0000001\n",
            " 1.0000001  1.         1.         0.9999998  0.99999994 0.9999998\n",
            " 1.         1.         1.         0.99999994]\n",
            "[-1.1025136e-08  0.0000000e+00  6.8907102e-09  2.7562841e-09\n",
            "  0.0000000e+00  2.2050273e-08  5.5125682e-09  1.1025136e-08\n",
            " -4.1344261e-09  5.5125682e-09 -1.3781420e-09  0.0000000e+00\n",
            " -1.1025136e-08  1.1025136e-08 -1.1025136e-08 -2.2050273e-08\n",
            " -5.5125682e-09 -2.7562841e-09  1.1025136e-08  1.1025136e-08\n",
            "  0.0000000e+00 -5.5125682e-09 -5.5125682e-09  0.0000000e+00\n",
            " -1.1025136e-08 -1.1025136e-08  0.0000000e+00 -2.2050273e-08\n",
            "  0.0000000e+00  0.0000000e+00  0.0000000e+00 -5.5125682e-09\n",
            " -4.1344261e-09  1.1025136e-08 -5.5125682e-09 -5.5125682e-09\n",
            "  7.5797812e-09 -8.2688523e-09  0.0000000e+00  0.0000000e+00]\n"
          ]
        }
      ]
    }
  ]
}