{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Prepare data for ten-fold again and again.\n"
      ],
      "metadata": {
        "id": "qDNO81YEzH_S"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "o2Y8HmBnIgpu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import librosa\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "import keras\n",
        "from scipy import signal\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tqdm import tqdm\n",
        "from tqdm._tqdm import trange\n",
        "from keras.utils import np_utils\n",
        "\n",
        "def readFromCsv(csvpth):\n",
        "    # 生成数据列表\n",
        "    # 读取wav文件函数\n",
        "    #data = pd.read_csv('metadata/UrbanSound8K.csv')\n",
        "    data = pd.read_csv(csvpth)\n",
        "    valid_data = data[['slice_file_name', 'fold', 'classID', 'class']][data['end'] - data['start'] >= 2]\n",
        "    valid_data['path'] = 'fold' + valid_data['fold'].astype('str') + '/' + valid_data['slice_file_name'].astype(\n",
        "        'str')\n",
        "    return valid_data\n",
        "\n",
        "\n",
        "def splitData(current):\n",
        "  \n",
        "  D1=[]\n",
        "  D2=[]\n",
        "  csvPth = '/content/drive/MyDrive/Thesis_Keras/UrbanSound8K/metadata/UrbanSound8K.csv'\n",
        "  #df=pd.read_csv(csvPth)\n",
        "  #valid_data=readFromCsv(csvPth)\n",
        "  i=1\n",
        "\n",
        "  for row in tqdm(current.itertuples(),total=current.shape[0]):\n",
        "        #print(row.path)\n",
        "        #print(row.classID)\n",
        "        #print(f\"{i} out of {len(current)}\")\n",
        "        y1, sr1 = librosa.load(\"/content/drive/MyDrive/Thesis_Keras/UrbanSound8K/audio/\" + row.path,sr=22050,duration=0.95)\n",
        "\n",
        "        #print(y1.shape)\n",
        "        if y1.shape != (20948,):\n",
        "          continue\n",
        "\n",
        "        \n",
        "        mels = librosa.feature.melspectrogram(y1, sr=sr1,\n",
        "                         n_mels=60,\n",
        "                         n_fft=1024,\n",
        "                         hop_length=512,\n",
        "                         )\n",
        "        logmelspec = librosa.power_to_db(mels)\n",
        "\n",
        "        i+=1\n",
        "\n",
        "        #print(logmelspec.shape)\n",
        "        D1.append((mels, row.classID))\n",
        "        D2.append((logmelspec, row.classID))\n",
        "\n",
        "  dataset1 = D1\n",
        "  dataset2=D2\n",
        "  X_mel,y=zip(*dataset1)\n",
        "  X_log,_=zip(*dataset2)\n",
        "  #print(\"type of X is:\",type(X))\n",
        "  y=np.array(y).astype(np.int64)\n",
        "  y = np.array(np_utils.to_categorical(y, 10))\n",
        "\n",
        "  return  X_mel,X_log,y\n",
        "\n",
        "\n",
        "def save_npy(nparr,modelName,featureName,subDataset,fold):\n",
        "    import os\n",
        "    dirs = \"drive/MyDrive/Thesis_Keras/TenFoldDataset/datasetnpy\"+'/'+modelName+'/'+featureName+'/'+fold\n",
        "    \n",
        "    #Create a directory to place the dataset npy files.\n",
        "    if not os.path.exists(dirs):\n",
        "        os.makedirs(dirs)\n",
        "        print(f\"Created directory:{dirs}\")\n",
        "    \n",
        "    subDataset+='.npy'\n",
        "    print(subDataset)\n",
        "    subsetPth=os.path.join(dirs,subDataset)\n",
        "    #with open(subsetPth, 'w') as f:\n",
        "    np.save(subsetPth, nparr)\n",
        "    print(f\"save {subDataset} done\")\n",
        "    print(f\"Path:{subsetPth}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-dy27qHqzHUl",
        "outputId": "e9fcba3c-4ca4-4a1f-f715-cb93f223e343"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:10: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
            "Please use `tqdm.std.*` instead of `tqdm._tqdm.*`\n",
            "  # Remove the CWD from sys.path while we load stuff.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def Ten_fold():\n",
        "    csvPth = '/content/drive/MyDrive/Thesis_Keras/UrbanSound8K/metadata/UrbanSound8K.csv'\n",
        "    #df=pd.read_csv(csvPth)\n",
        "    valid_data=readFromCsv(csvPth)\n",
        "    #valid_data = df[['slice_file_name', 'fold', 'classID', 'class']][df['end'] - df['start']]\n",
        "    # valid_data['path'] = 'fold' + valid_data['fold'].astype('str') + '/' + valid_data['slice_file_name'].astype(\n",
        "    #     'str')\n",
        "    for i in range(10):#Folder : \"fold1\" to \"fold10\"\n",
        "        print(f\"fold:{i+1} out of 10\")\n",
        "        current=valid_data[valid_data['fold'] == i+1]\n",
        "        X_mel,X_log,y = splitData(current)\n",
        "        print(\"Dataset split done!\")\n",
        "        print(\"Saving subsets to .npy files!\")\n",
        "        \n",
        "        save_npy(X_mel, 'PiczakCNN', 'mel', 'X',f\"fold{i+1}\")\n",
        "        save_npy(X_log, 'PiczakCNN', 'log', 'X',f\"fold{i+1}\")\n",
        "        save_npy(y, 'PiczakCNN', 'mel', 'y',f\"fold{i+1}\")\n",
        "        save_npy(y, 'PiczakCNN', 'log', 'y',f\"fold{i+1}\")"
      ],
      "metadata": {
        "id": "WmIKyJlvzLeC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Ten_fold()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XQ43yel1z3PG",
        "outputId": "fad6411c-c701-40bf-aa76-daabb21a3853"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold:1 out of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 779/779 [03:04<00:00,  4.22it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset split done!\n",
            "Saving subsets to .npy files!\n",
            "Created directory:drive/MyDrive/Thesis_Keras/TenFoldDataset/datasetnpy/PiczakCNN/mel/fold1\n",
            "X.npy\n",
            "save X.npy done\n",
            "Path:drive/MyDrive/Thesis_Keras/TenFoldDataset/datasetnpy/PiczakCNN/mel/fold1/X.npy\n",
            "Created directory:drive/MyDrive/Thesis_Keras/TenFoldDataset/datasetnpy/PiczakCNN/log/fold1\n",
            "X.npy\n",
            "save X.npy done\n",
            "Path:drive/MyDrive/Thesis_Keras/TenFoldDataset/datasetnpy/PiczakCNN/log/fold1/X.npy\n",
            "y.npy\n",
            "save y.npy done\n",
            "Path:drive/MyDrive/Thesis_Keras/TenFoldDataset/datasetnpy/PiczakCNN/mel/fold1/y.npy\n",
            "y.npy\n",
            "save y.npy done\n",
            "Path:drive/MyDrive/Thesis_Keras/TenFoldDataset/datasetnpy/PiczakCNN/log/fold1/y.npy\n",
            "fold:2 out of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 776/776 [05:41<00:00,  2.27it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset split done!\n",
            "Saving subsets to .npy files!\n",
            "Created directory:drive/MyDrive/Thesis_Keras/TenFoldDataset/datasetnpy/PiczakCNN/mel/fold2\n",
            "X.npy\n",
            "save X.npy done\n",
            "Path:drive/MyDrive/Thesis_Keras/TenFoldDataset/datasetnpy/PiczakCNN/mel/fold2/X.npy\n",
            "Created directory:drive/MyDrive/Thesis_Keras/TenFoldDataset/datasetnpy/PiczakCNN/log/fold2\n",
            "X.npy\n",
            "save X.npy done\n",
            "Path:drive/MyDrive/Thesis_Keras/TenFoldDataset/datasetnpy/PiczakCNN/log/fold2/X.npy\n",
            "y.npy\n",
            "save y.npy done\n",
            "Path:drive/MyDrive/Thesis_Keras/TenFoldDataset/datasetnpy/PiczakCNN/mel/fold2/y.npy\n",
            "y.npy\n",
            "save y.npy done\n",
            "Path:drive/MyDrive/Thesis_Keras/TenFoldDataset/datasetnpy/PiczakCNN/log/fold2/y.npy\n",
            "fold:3 out of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 838/838 [05:56<00:00,  2.35it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset split done!\n",
            "Saving subsets to .npy files!\n",
            "Created directory:drive/MyDrive/Thesis_Keras/TenFoldDataset/datasetnpy/PiczakCNN/mel/fold3\n",
            "X.npy\n",
            "save X.npy done\n",
            "Path:drive/MyDrive/Thesis_Keras/TenFoldDataset/datasetnpy/PiczakCNN/mel/fold3/X.npy\n",
            "Created directory:drive/MyDrive/Thesis_Keras/TenFoldDataset/datasetnpy/PiczakCNN/log/fold3\n",
            "X.npy\n",
            "save X.npy done\n",
            "Path:drive/MyDrive/Thesis_Keras/TenFoldDataset/datasetnpy/PiczakCNN/log/fold3/X.npy\n",
            "y.npy\n",
            "save y.npy done\n",
            "Path:drive/MyDrive/Thesis_Keras/TenFoldDataset/datasetnpy/PiczakCNN/mel/fold3/y.npy\n",
            "y.npy\n",
            "save y.npy done\n",
            "Path:drive/MyDrive/Thesis_Keras/TenFoldDataset/datasetnpy/PiczakCNN/log/fold3/y.npy\n",
            "fold:4 out of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 872/872 [06:17<00:00,  2.31it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset split done!\n",
            "Saving subsets to .npy files!\n",
            "Created directory:drive/MyDrive/Thesis_Keras/TenFoldDataset/datasetnpy/PiczakCNN/mel/fold4\n",
            "X.npy\n",
            "save X.npy done\n",
            "Path:drive/MyDrive/Thesis_Keras/TenFoldDataset/datasetnpy/PiczakCNN/mel/fold4/X.npy\n",
            "Created directory:drive/MyDrive/Thesis_Keras/TenFoldDataset/datasetnpy/PiczakCNN/log/fold4\n",
            "X.npy\n",
            "save X.npy done\n",
            "Path:drive/MyDrive/Thesis_Keras/TenFoldDataset/datasetnpy/PiczakCNN/log/fold4/X.npy\n",
            "y.npy\n",
            "save y.npy done\n",
            "Path:drive/MyDrive/Thesis_Keras/TenFoldDataset/datasetnpy/PiczakCNN/mel/fold4/y.npy\n",
            "y.npy\n",
            "save y.npy done\n",
            "Path:drive/MyDrive/Thesis_Keras/TenFoldDataset/datasetnpy/PiczakCNN/log/fold4/y.npy\n",
            "fold:5 out of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 809/809 [06:23<00:00,  2.11it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset split done!\n",
            "Saving subsets to .npy files!\n",
            "Created directory:drive/MyDrive/Thesis_Keras/TenFoldDataset/datasetnpy/PiczakCNN/mel/fold5\n",
            "X.npy\n",
            "save X.npy done\n",
            "Path:drive/MyDrive/Thesis_Keras/TenFoldDataset/datasetnpy/PiczakCNN/mel/fold5/X.npy\n",
            "Created directory:drive/MyDrive/Thesis_Keras/TenFoldDataset/datasetnpy/PiczakCNN/log/fold5\n",
            "X.npy\n",
            "save X.npy done\n",
            "Path:drive/MyDrive/Thesis_Keras/TenFoldDataset/datasetnpy/PiczakCNN/log/fold5/X.npy\n",
            "y.npy\n",
            "save y.npy done\n",
            "Path:drive/MyDrive/Thesis_Keras/TenFoldDataset/datasetnpy/PiczakCNN/mel/fold5/y.npy\n",
            "y.npy\n",
            "save y.npy done\n",
            "Path:drive/MyDrive/Thesis_Keras/TenFoldDataset/datasetnpy/PiczakCNN/log/fold5/y.npy\n",
            "fold:6 out of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 720/720 [05:25<00:00,  2.21it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset split done!\n",
            "Saving subsets to .npy files!\n",
            "Created directory:drive/MyDrive/Thesis_Keras/TenFoldDataset/datasetnpy/PiczakCNN/mel/fold6\n",
            "X.npy\n",
            "save X.npy done\n",
            "Path:drive/MyDrive/Thesis_Keras/TenFoldDataset/datasetnpy/PiczakCNN/mel/fold6/X.npy\n",
            "Created directory:drive/MyDrive/Thesis_Keras/TenFoldDataset/datasetnpy/PiczakCNN/log/fold6\n",
            "X.npy\n",
            "save X.npy done\n",
            "Path:drive/MyDrive/Thesis_Keras/TenFoldDataset/datasetnpy/PiczakCNN/log/fold6/X.npy\n",
            "y.npy\n",
            "save y.npy done\n",
            "Path:drive/MyDrive/Thesis_Keras/TenFoldDataset/datasetnpy/PiczakCNN/mel/fold6/y.npy\n",
            "y.npy\n",
            "save y.npy done\n",
            "Path:drive/MyDrive/Thesis_Keras/TenFoldDataset/datasetnpy/PiczakCNN/log/fold6/y.npy\n",
            "fold:7 out of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 759/759 [05:36<00:00,  2.25it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset split done!\n",
            "Saving subsets to .npy files!\n",
            "Created directory:drive/MyDrive/Thesis_Keras/TenFoldDataset/datasetnpy/PiczakCNN/mel/fold7\n",
            "X.npy\n",
            "save X.npy done\n",
            "Path:drive/MyDrive/Thesis_Keras/TenFoldDataset/datasetnpy/PiczakCNN/mel/fold7/X.npy\n",
            "Created directory:drive/MyDrive/Thesis_Keras/TenFoldDataset/datasetnpy/PiczakCNN/log/fold7\n",
            "X.npy\n",
            "save X.npy done\n",
            "Path:drive/MyDrive/Thesis_Keras/TenFoldDataset/datasetnpy/PiczakCNN/log/fold7/X.npy\n",
            "y.npy\n",
            "save y.npy done\n",
            "Path:drive/MyDrive/Thesis_Keras/TenFoldDataset/datasetnpy/PiczakCNN/mel/fold7/y.npy\n",
            "y.npy\n",
            "save y.npy done\n",
            "Path:drive/MyDrive/Thesis_Keras/TenFoldDataset/datasetnpy/PiczakCNN/log/fold7/y.npy\n",
            "fold:8 out of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 713/713 [05:28<00:00,  2.17it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset split done!\n",
            "Saving subsets to .npy files!\n",
            "Created directory:drive/MyDrive/Thesis_Keras/TenFoldDataset/datasetnpy/PiczakCNN/mel/fold8\n",
            "X.npy\n",
            "save X.npy done\n",
            "Path:drive/MyDrive/Thesis_Keras/TenFoldDataset/datasetnpy/PiczakCNN/mel/fold8/X.npy\n",
            "Created directory:drive/MyDrive/Thesis_Keras/TenFoldDataset/datasetnpy/PiczakCNN/log/fold8\n",
            "X.npy\n",
            "save X.npy done\n",
            "Path:drive/MyDrive/Thesis_Keras/TenFoldDataset/datasetnpy/PiczakCNN/log/fold8/X.npy\n",
            "y.npy\n",
            "save y.npy done\n",
            "Path:drive/MyDrive/Thesis_Keras/TenFoldDataset/datasetnpy/PiczakCNN/mel/fold8/y.npy\n",
            "y.npy\n",
            "save y.npy done\n",
            "Path:drive/MyDrive/Thesis_Keras/TenFoldDataset/datasetnpy/PiczakCNN/log/fold8/y.npy\n",
            "fold:9 out of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 735/735 [05:21<00:00,  2.29it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset split done!\n",
            "Saving subsets to .npy files!\n",
            "Created directory:drive/MyDrive/Thesis_Keras/TenFoldDataset/datasetnpy/PiczakCNN/mel/fold9\n",
            "X.npy\n",
            "save X.npy done\n",
            "Path:drive/MyDrive/Thesis_Keras/TenFoldDataset/datasetnpy/PiczakCNN/mel/fold9/X.npy\n",
            "Created directory:drive/MyDrive/Thesis_Keras/TenFoldDataset/datasetnpy/PiczakCNN/log/fold9\n",
            "X.npy\n",
            "save X.npy done\n",
            "Path:drive/MyDrive/Thesis_Keras/TenFoldDataset/datasetnpy/PiczakCNN/log/fold9/X.npy\n",
            "y.npy\n",
            "save y.npy done\n",
            "Path:drive/MyDrive/Thesis_Keras/TenFoldDataset/datasetnpy/PiczakCNN/mel/fold9/y.npy\n",
            "y.npy\n",
            "save y.npy done\n",
            "Path:drive/MyDrive/Thesis_Keras/TenFoldDataset/datasetnpy/PiczakCNN/log/fold9/y.npy\n",
            "fold:10 out of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 749/749 [05:32<00:00,  2.25it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset split done!\n",
            "Saving subsets to .npy files!\n",
            "Created directory:drive/MyDrive/Thesis_Keras/TenFoldDataset/datasetnpy/PiczakCNN/mel/fold10\n",
            "X.npy\n",
            "save X.npy done\n",
            "Path:drive/MyDrive/Thesis_Keras/TenFoldDataset/datasetnpy/PiczakCNN/mel/fold10/X.npy\n",
            "Created directory:drive/MyDrive/Thesis_Keras/TenFoldDataset/datasetnpy/PiczakCNN/log/fold10\n",
            "X.npy\n",
            "save X.npy done\n",
            "Path:drive/MyDrive/Thesis_Keras/TenFoldDataset/datasetnpy/PiczakCNN/log/fold10/X.npy\n",
            "y.npy\n",
            "save y.npy done\n",
            "Path:drive/MyDrive/Thesis_Keras/TenFoldDataset/datasetnpy/PiczakCNN/mel/fold10/y.npy\n",
            "y.npy\n",
            "save y.npy done\n",
            "Path:drive/MyDrive/Thesis_Keras/TenFoldDataset/datasetnpy/PiczakCNN/log/fold10/y.npy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "10-fold validation"
      ],
      "metadata": {
        "id": "4RSooQ56JPgp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "def generate_loader(i_val):\n",
        "    train_X = []\n",
        "    train_y=[]\n",
        "    X_test=[]\n",
        "    y_test=[]\n",
        "\n",
        "    for i in range(10):\n",
        "        if i + 1 == i_val:\n",
        "            X_test = np.load(\n",
        "                \"drive/MyDrive/Thesis_Keras/TenFoldDataset/datasetnpy/PiczakCNN/mel/\"+f\"fold{i + 1}\"+\"/X.npy\"\n",
        "                )\n",
        "            y_test=np.load(\n",
        "                \"drive/MyDrive/Thesis_Keras/TenFoldDataset/datasetnpy/PiczakCNN/mel/\"+f\"fold{i + 1}\"+\"/y.npy\"\n",
        "            )\n",
        "        else:\n",
        "            X_train = np.load(\n",
        "                \"drive/MyDrive/Thesis_Keras/TenFoldDataset/datasetnpy/PiczakCNN/mel/\"+f\"fold{i + 1}\"+\"/X.npy\"\n",
        "            )\n",
        "            y_train = np.load(\n",
        "                \"drive/MyDrive/Thesis_Keras/TenFoldDataset/datasetnpy/PiczakCNN/mel/\"+f\"fold{i + 1}\"+\"/y.npy\"\n",
        "            )\n",
        "\n",
        "            for item in X_train:\n",
        "                train_X.append(item)\n",
        "            for item in y_train:\n",
        "                train_y.append(item)\n",
        "\n",
        "    return np.array(train_X),np.array(train_y),np.array(X_test),np.array(y_test)"
      ],
      "metadata": {
        "id": "zzrlKIu0JRzW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, InputLayer, Dropout, Conv1D, Conv2D, Flatten, Reshape, MaxPooling1D, MaxPooling2D, BatchNormalization, TimeDistributed,AveragePooling1D,AveragePooling2D\n",
        "from tensorflow.keras.optimizers import Adam,SGD\n",
        "\n",
        "def build_model(bands=60, frames=41, channels=1, n_labels=10,\n",
        "                fc=5000, dropout=0.5):\n",
        "\n",
        "    \"\"\"\n",
        "    Implements the short-segment CNN from\n",
        "    ENVIRONMENTAL SOUND CLASSIFICATION WITH CONVOLUTIONAL NEURAL NETWORKS\n",
        "    Karol J. Piczak, 2015.\n",
        "    https://karol.piczak.com/papers/Piczak2015-ESC-ConvNet.pdf\n",
        "    \"\"\"\n",
        "\n",
        "    from keras.models import Sequential\n",
        "    from keras.layers import Dense, Dropout, Activation, Flatten\n",
        "    from keras.layers import Convolution2D, MaxPooling2D\n",
        "    from keras.regularizers import l2\n",
        "\n",
        "    input_shape = (bands, frames, channels)\n",
        "\n",
        "    model = Sequential([\n",
        "        \n",
        "        Convolution2D(80, (bands-3,6), strides=(1,1), input_shape=input_shape, activation='relu'),\n",
        "        MaxPooling2D((4,3), strides=(1,3)),\n",
        "        BatchNormalization(),\n",
        "        Convolution2D(80, (1,3), activation='relu'),\n",
        "        MaxPooling2D((1,3), strides=(1,3)),\n",
        "        Flatten(),\n",
        "        Dense(fc, activation='relu'),\n",
        "        Dropout(dropout),\n",
        "        Dense(fc, activation='relu'),\n",
        "        Dropout(dropout),\n",
        "        Dense(n_labels, activation='softmax'),\n",
        "    ])\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "def train_model(model,X_train,Y_train,X_test,Y_test,foldNum):\n",
        "  EPOCHS = 300\n",
        "  # this controls the batch size, or you can manipulate the tf.data.Dataset objects yourself\n",
        "  BATCH_SIZE = 512\n",
        "  callbacks = []\n",
        "  # model architecture\n",
        "  \n",
        "  # this controls the learning rate\n",
        "  opt =Adam(learning_rate=0.005, beta_1=0.9, beta_2=0.999)\n",
        "  #SGD(lr=0.01, decay=0.001, momentum=0.1, nesterov=True) \n",
        "  #callbacks.append(BatchLoggerCallback(BATCH_SIZE, train_sample_count, epochs=EPOCHS))\n",
        "\n",
        "  # train the neural network\n",
        "  model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
        "\n",
        "  model.fit(X_train,Y_train, batch_size=BATCH_SIZE, epochs=EPOCHS, verbose=2,validation_split=0.1,shuffle=True)\n",
        "  print(model.summary())\n",
        "  # Use this flag to disable per-channel quantization for a model.\n",
        "  # This can reduce RAM usage for convolutional models, but may have\n",
        "  # an impact on accuracy.\n",
        "  disable_per_channel_quantization = False\n",
        "  print(\"Result of fold:\"+f\"{foldNum}\")\n",
        "  score = model.evaluate(\n",
        "        x=X_test,\n",
        "        y=Y_test)"
      ],
      "metadata": {
        "id": "TfXjyYEyKGLk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in tqdm(range(10)):\n",
        "  #from tensorflow.compat.v1.keras import backend as K\n",
        "  import tensorflow as tf\n",
        "\n",
        "  import os\n",
        "  # os.environ[\"TF_FORCE_GPU_ALLOW_GROWTH\"] = \"true\"\n",
        "  # config = tf.compat.v1.ConfigProto()#对session进行参数配置\n",
        "  # config.allow_soft_placement=True #如果你指定的设备不存在，允许TF自动分配设备\n",
        "  # config.gpu_options.per_process_gpu_memory_fraction=0.7#分配百分之七十的显存给程序使用，避免内存溢出，可以自己调整\n",
        "  # config.gpu_options.allow_growth = True#按需分配显存，这个比较重要\n",
        "        \n",
        "  # sess = tf.compat.v1.Session(config=config)\n",
        "  # #tf.compat.v1.keras.backend.set_session(sess)\n",
        "  # #K.set_session(sess)\n",
        "  X_mel_train,y_train,X_mel_test,y_test = generate_loader(i+1)\n",
        "  #X_log_train,_,X_log_test,_ = generate_loader(i+1,0)\n",
        "  print(X_mel_train.shape)\n",
        "  #print(\"inputdata\",(X_train[1]))\n",
        "  #print(\"rows\",len(X_train[1]))\n",
        "  #print(\"cols\",len(X_train[1][1]))\n",
        "  #print(y_train[1])\n",
        "  X_train=np.array([X_mel_train,X_log_train])\n",
        "  X_test=np.array([X_log_train,X_log_test])\n",
        "\n",
        "  input_len=len(X_mel_train[1])\n",
        "\n",
        "  model = build_model(bands=len(X_mel_train[114]), frames=len(X_mel_train[514][1]), channels=1, n_labels=10,\n",
        "                fc=5000, dropout=0.5)\n",
        "  if not i==0:\n",
        "    model = build_model(bands=len(X_mel_train[114]), frames=len(X_mel_train[514][1]), channels=1, n_labels=10,\n",
        "                fc=5000, dropout=0.5)\n",
        "  \n",
        "  train_model(model,X_mel_train,y_train,X_mel_test,y_test,i+1)\n",
        "  model.save(\"/content/drive/MyDrive/Thesis_Keras/\"+\"model/saved/Piczak\"+f\"fold{i+1}\"+\".h5\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z5vgabE-KNX3",
        "outputId": "e6e1063c-f002-49ef-d949-2c589a8d80bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/10 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:22: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:23: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(6903, 60, 41)\n",
            "Epoch 1/300\n",
            "13/13 - 1s - loss: 5.4868 - accuracy: 0.1484 - val_loss: 2.2254 - val_accuracy: 0.1838 - 1s/epoch - 78ms/step\n",
            "Epoch 2/300\n",
            "13/13 - 0s - loss: 2.1704 - accuracy: 0.2009 - val_loss: 2.1133 - val_accuracy: 0.1737 - 297ms/epoch - 23ms/step\n",
            "Epoch 3/300\n",
            "13/13 - 0s - loss: 2.0832 - accuracy: 0.2254 - val_loss: 2.0639 - val_accuracy: 0.1766 - 299ms/epoch - 23ms/step\n",
            "Epoch 4/300\n",
            "13/13 - 0s - loss: 2.0238 - accuracy: 0.2558 - val_loss: 2.1108 - val_accuracy: 0.1896 - 296ms/epoch - 23ms/step\n",
            "Epoch 5/300\n",
            "13/13 - 0s - loss: 2.0150 - accuracy: 0.2452 - val_loss: 1.9859 - val_accuracy: 0.2330 - 295ms/epoch - 23ms/step\n",
            "Epoch 6/300\n",
            "13/13 - 0s - loss: 1.9111 - accuracy: 0.2973 - val_loss: 2.0377 - val_accuracy: 0.2200 - 294ms/epoch - 23ms/step\n",
            "Epoch 7/300\n",
            "13/13 - 0s - loss: 1.9148 - accuracy: 0.2960 - val_loss: 1.9549 - val_accuracy: 0.2923 - 296ms/epoch - 23ms/step\n",
            "Epoch 8/300\n",
            "13/13 - 0s - loss: 1.8344 - accuracy: 0.3281 - val_loss: 1.8922 - val_accuracy: 0.3213 - 298ms/epoch - 23ms/step\n",
            "Epoch 9/300\n",
            "13/13 - 0s - loss: 1.8008 - accuracy: 0.3387 - val_loss: 1.8725 - val_accuracy: 0.2460 - 296ms/epoch - 23ms/step\n",
            "Epoch 10/300\n",
            "13/13 - 0s - loss: 1.8088 - accuracy: 0.3492 - val_loss: 1.9915 - val_accuracy: 0.3140 - 298ms/epoch - 23ms/step\n",
            "Epoch 11/300\n",
            "13/13 - 0s - loss: 1.7378 - accuracy: 0.3690 - val_loss: 2.0006 - val_accuracy: 0.3314 - 299ms/epoch - 23ms/step\n",
            "Epoch 12/300\n",
            "13/13 - 0s - loss: 1.6804 - accuracy: 0.3986 - val_loss: 1.9640 - val_accuracy: 0.2619 - 300ms/epoch - 23ms/step\n",
            "Epoch 13/300\n",
            "13/13 - 0s - loss: 1.7344 - accuracy: 0.3759 - val_loss: 1.9418 - val_accuracy: 0.3300 - 296ms/epoch - 23ms/step\n",
            "Epoch 14/300\n",
            "13/13 - 0s - loss: 1.6848 - accuracy: 0.3936 - val_loss: 2.0206 - val_accuracy: 0.3126 - 297ms/epoch - 23ms/step\n",
            "Epoch 15/300\n",
            "13/13 - 0s - loss: 1.6878 - accuracy: 0.3926 - val_loss: 1.8675 - val_accuracy: 0.3603 - 296ms/epoch - 23ms/step\n",
            "Epoch 16/300\n",
            "13/13 - 0s - loss: 1.6002 - accuracy: 0.4354 - val_loss: 2.0739 - val_accuracy: 0.3184 - 297ms/epoch - 23ms/step\n",
            "Epoch 17/300\n",
            "13/13 - 0s - loss: 1.5957 - accuracy: 0.4271 - val_loss: 1.7661 - val_accuracy: 0.3676 - 299ms/epoch - 23ms/step\n",
            "Epoch 18/300\n",
            "13/13 - 0s - loss: 1.5779 - accuracy: 0.4245 - val_loss: 1.8117 - val_accuracy: 0.4298 - 297ms/epoch - 23ms/step\n",
            "Epoch 19/300\n",
            "13/13 - 0s - loss: 1.5001 - accuracy: 0.4647 - val_loss: 1.8187 - val_accuracy: 0.3835 - 298ms/epoch - 23ms/step\n",
            "Epoch 20/300\n",
            "13/13 - 0s - loss: 1.4631 - accuracy: 0.4755 - val_loss: 1.7437 - val_accuracy: 0.3661 - 296ms/epoch - 23ms/step\n",
            "Epoch 21/300\n",
            "13/13 - 0s - loss: 1.5326 - accuracy: 0.4400 - val_loss: 1.8736 - val_accuracy: 0.4211 - 296ms/epoch - 23ms/step\n",
            "Epoch 22/300\n",
            "13/13 - 0s - loss: 1.4576 - accuracy: 0.4862 - val_loss: 1.8866 - val_accuracy: 0.3603 - 290ms/epoch - 22ms/step\n",
            "Epoch 23/300\n",
            "13/13 - 0s - loss: 1.5311 - accuracy: 0.4604 - val_loss: 1.8818 - val_accuracy: 0.4211 - 297ms/epoch - 23ms/step\n",
            "Epoch 24/300\n",
            "13/13 - 0s - loss: 1.4987 - accuracy: 0.4676 - val_loss: 1.9749 - val_accuracy: 0.3661 - 294ms/epoch - 23ms/step\n",
            "Epoch 25/300\n",
            "13/13 - 0s - loss: 1.4616 - accuracy: 0.4923 - val_loss: 1.9298 - val_accuracy: 0.3690 - 301ms/epoch - 23ms/step\n",
            "Epoch 26/300\n",
            "13/13 - 0s - loss: 1.5372 - accuracy: 0.4551 - val_loss: 1.9483 - val_accuracy: 0.4240 - 298ms/epoch - 23ms/step\n",
            "Epoch 27/300\n",
            "13/13 - 0s - loss: 1.4584 - accuracy: 0.4863 - val_loss: 1.9457 - val_accuracy: 0.3444 - 302ms/epoch - 23ms/step\n",
            "Epoch 28/300\n",
            "13/13 - 0s - loss: 1.4190 - accuracy: 0.4973 - val_loss: 1.8779 - val_accuracy: 0.4486 - 293ms/epoch - 23ms/step\n",
            "Epoch 29/300\n",
            "13/13 - 0s - loss: 1.3891 - accuracy: 0.5114 - val_loss: 1.8044 - val_accuracy: 0.4081 - 294ms/epoch - 23ms/step\n",
            "Epoch 30/300\n",
            "13/13 - 0s - loss: 1.3829 - accuracy: 0.5089 - val_loss: 1.9246 - val_accuracy: 0.3994 - 299ms/epoch - 23ms/step\n",
            "Epoch 31/300\n",
            "13/13 - 0s - loss: 1.3327 - accuracy: 0.5328 - val_loss: 1.7067 - val_accuracy: 0.4153 - 305ms/epoch - 23ms/step\n",
            "Epoch 32/300\n",
            "13/13 - 0s - loss: 1.3175 - accuracy: 0.5319 - val_loss: 1.7839 - val_accuracy: 0.4559 - 294ms/epoch - 23ms/step\n",
            "Epoch 33/300\n",
            "13/13 - 0s - loss: 1.2447 - accuracy: 0.5629 - val_loss: 1.9176 - val_accuracy: 0.4385 - 299ms/epoch - 23ms/step\n",
            "Epoch 34/300\n",
            "13/13 - 0s - loss: 1.2292 - accuracy: 0.5647 - val_loss: 1.7547 - val_accuracy: 0.4182 - 297ms/epoch - 23ms/step\n",
            "Epoch 35/300\n",
            "13/13 - 0s - loss: 1.3447 - accuracy: 0.5277 - val_loss: 1.8389 - val_accuracy: 0.4718 - 296ms/epoch - 23ms/step\n",
            "Epoch 36/300\n",
            "13/13 - 0s - loss: 1.3121 - accuracy: 0.5372 - val_loss: 1.7524 - val_accuracy: 0.4790 - 289ms/epoch - 22ms/step\n",
            "Epoch 37/300\n",
            "13/13 - 0s - loss: 1.3190 - accuracy: 0.5457 - val_loss: 1.6817 - val_accuracy: 0.5051 - 295ms/epoch - 23ms/step\n",
            "Epoch 38/300\n",
            "13/13 - 0s - loss: 1.3080 - accuracy: 0.5427 - val_loss: 1.8286 - val_accuracy: 0.4747 - 295ms/epoch - 23ms/step\n",
            "Epoch 39/300\n",
            "13/13 - 0s - loss: 1.3145 - accuracy: 0.5478 - val_loss: 1.7600 - val_accuracy: 0.4284 - 297ms/epoch - 23ms/step\n",
            "Epoch 40/300\n",
            "13/13 - 0s - loss: 1.3988 - accuracy: 0.5448 - val_loss: 1.7226 - val_accuracy: 0.4457 - 297ms/epoch - 23ms/step\n",
            "Epoch 41/300\n",
            "13/13 - 0s - loss: 1.3299 - accuracy: 0.5555 - val_loss: 1.7643 - val_accuracy: 0.4240 - 300ms/epoch - 23ms/step\n",
            "Epoch 42/300\n",
            "13/13 - 0s - loss: 1.2354 - accuracy: 0.5647 - val_loss: 1.7145 - val_accuracy: 0.4515 - 299ms/epoch - 23ms/step\n",
            "Epoch 43/300\n",
            "13/13 - 0s - loss: 1.2409 - accuracy: 0.5671 - val_loss: 1.9651 - val_accuracy: 0.4834 - 297ms/epoch - 23ms/step\n",
            "Epoch 44/300\n",
            "13/13 - 0s - loss: 1.3076 - accuracy: 0.5518 - val_loss: 1.8080 - val_accuracy: 0.4457 - 294ms/epoch - 23ms/step\n",
            "Epoch 45/300\n",
            "13/13 - 0s - loss: 1.2683 - accuracy: 0.5663 - val_loss: 1.7958 - val_accuracy: 0.4602 - 295ms/epoch - 23ms/step\n",
            "Epoch 46/300\n",
            "13/13 - 0s - loss: 1.2671 - accuracy: 0.5657 - val_loss: 1.8096 - val_accuracy: 0.3835 - 294ms/epoch - 23ms/step\n",
            "Epoch 47/300\n",
            "13/13 - 0s - loss: 1.2709 - accuracy: 0.5557 - val_loss: 1.7824 - val_accuracy: 0.4313 - 298ms/epoch - 23ms/step\n",
            "Epoch 48/300\n",
            "13/13 - 0s - loss: 1.2659 - accuracy: 0.5615 - val_loss: 2.0517 - val_accuracy: 0.3401 - 302ms/epoch - 23ms/step\n",
            "Epoch 49/300\n",
            "13/13 - 0s - loss: 1.2949 - accuracy: 0.5382 - val_loss: 1.8808 - val_accuracy: 0.3951 - 295ms/epoch - 23ms/step\n",
            "Epoch 50/300\n",
            "13/13 - 0s - loss: 1.3147 - accuracy: 0.5475 - val_loss: 1.7310 - val_accuracy: 0.4805 - 302ms/epoch - 23ms/step\n",
            "Epoch 51/300\n",
            "13/13 - 0s - loss: 1.2108 - accuracy: 0.5815 - val_loss: 1.7950 - val_accuracy: 0.4399 - 296ms/epoch - 23ms/step\n",
            "Epoch 52/300\n",
            "13/13 - 0s - loss: 1.2100 - accuracy: 0.5834 - val_loss: 1.8253 - val_accuracy: 0.4313 - 289ms/epoch - 22ms/step\n",
            "Epoch 53/300\n",
            "13/13 - 0s - loss: 1.3909 - accuracy: 0.5277 - val_loss: 1.8445 - val_accuracy: 0.4023 - 296ms/epoch - 23ms/step\n",
            "Epoch 54/300\n",
            "13/13 - 0s - loss: 1.3309 - accuracy: 0.5428 - val_loss: 1.9247 - val_accuracy: 0.4284 - 291ms/epoch - 22ms/step\n",
            "Epoch 55/300\n",
            "13/13 - 0s - loss: 1.3063 - accuracy: 0.5534 - val_loss: 2.0154 - val_accuracy: 0.4414 - 298ms/epoch - 23ms/step\n",
            "Epoch 56/300\n",
            "13/13 - 0s - loss: 1.2315 - accuracy: 0.5676 - val_loss: 1.9167 - val_accuracy: 0.4559 - 296ms/epoch - 23ms/step\n",
            "Epoch 57/300\n",
            "13/13 - 0s - loss: 1.2388 - accuracy: 0.5736 - val_loss: 1.8248 - val_accuracy: 0.4602 - 298ms/epoch - 23ms/step\n",
            "Epoch 58/300\n",
            "13/13 - 0s - loss: 1.2764 - accuracy: 0.5560 - val_loss: 1.7773 - val_accuracy: 0.4689 - 298ms/epoch - 23ms/step\n",
            "Epoch 59/300\n",
            "13/13 - 0s - loss: 1.3348 - accuracy: 0.5481 - val_loss: 1.9917 - val_accuracy: 0.4327 - 294ms/epoch - 23ms/step\n",
            "Epoch 60/300\n",
            "13/13 - 0s - loss: 1.3168 - accuracy: 0.5422 - val_loss: 1.8944 - val_accuracy: 0.4501 - 293ms/epoch - 23ms/step\n",
            "Epoch 61/300\n",
            "13/13 - 0s - loss: 1.3486 - accuracy: 0.5449 - val_loss: 1.7242 - val_accuracy: 0.4602 - 297ms/epoch - 23ms/step\n",
            "Epoch 62/300\n",
            "13/13 - 0s - loss: 1.3640 - accuracy: 0.5344 - val_loss: 1.8250 - val_accuracy: 0.4298 - 296ms/epoch - 23ms/step\n",
            "Epoch 63/300\n",
            "13/13 - 0s - loss: 1.2552 - accuracy: 0.5676 - val_loss: 1.7065 - val_accuracy: 0.4197 - 294ms/epoch - 23ms/step\n",
            "Epoch 64/300\n",
            "13/13 - 0s - loss: 1.1946 - accuracy: 0.5890 - val_loss: 1.8127 - val_accuracy: 0.5036 - 294ms/epoch - 23ms/step\n",
            "Epoch 65/300\n",
            "13/13 - 0s - loss: 1.1738 - accuracy: 0.5934 - val_loss: 1.6885 - val_accuracy: 0.4501 - 294ms/epoch - 23ms/step\n",
            "Epoch 66/300\n",
            "13/13 - 0s - loss: 1.1576 - accuracy: 0.6069 - val_loss: 1.9177 - val_accuracy: 0.4428 - 294ms/epoch - 23ms/step\n",
            "Epoch 67/300\n",
            "13/13 - 0s - loss: 1.1869 - accuracy: 0.5908 - val_loss: 1.7656 - val_accuracy: 0.4573 - 292ms/epoch - 22ms/step\n",
            "Epoch 68/300\n",
            "13/13 - 0s - loss: 1.2401 - accuracy: 0.5887 - val_loss: 1.9052 - val_accuracy: 0.4703 - 295ms/epoch - 23ms/step\n",
            "Epoch 69/300\n",
            "13/13 - 0s - loss: 1.4448 - accuracy: 0.5892 - val_loss: 1.8003 - val_accuracy: 0.4124 - 294ms/epoch - 23ms/step\n",
            "Epoch 70/300\n",
            "13/13 - 0s - loss: 1.2809 - accuracy: 0.5871 - val_loss: 1.8360 - val_accuracy: 0.4486 - 291ms/epoch - 22ms/step\n",
            "Epoch 71/300\n",
            "13/13 - 0s - loss: 1.3384 - accuracy: 0.5382 - val_loss: 1.9214 - val_accuracy: 0.3922 - 301ms/epoch - 23ms/step\n",
            "Epoch 72/300\n",
            "13/13 - 0s - loss: 1.3142 - accuracy: 0.5563 - val_loss: 1.7578 - val_accuracy: 0.4443 - 293ms/epoch - 23ms/step\n",
            "Epoch 73/300\n",
            "13/13 - 0s - loss: 1.2432 - accuracy: 0.5821 - val_loss: 1.9066 - val_accuracy: 0.3705 - 295ms/epoch - 23ms/step\n",
            "Epoch 74/300\n",
            "13/13 - 0s - loss: 1.1666 - accuracy: 0.5940 - val_loss: 1.8011 - val_accuracy: 0.4530 - 297ms/epoch - 23ms/step\n",
            "Epoch 75/300\n",
            "13/13 - 0s - loss: 1.1761 - accuracy: 0.5961 - val_loss: 1.9509 - val_accuracy: 0.4110 - 298ms/epoch - 23ms/step\n",
            "Epoch 76/300\n",
            "13/13 - 0s - loss: 1.1677 - accuracy: 0.6005 - val_loss: 1.8089 - val_accuracy: 0.4703 - 298ms/epoch - 23ms/step\n",
            "Epoch 77/300\n",
            "13/13 - 0s - loss: 1.1348 - accuracy: 0.6051 - val_loss: 1.7962 - val_accuracy: 0.4457 - 294ms/epoch - 23ms/step\n",
            "Epoch 78/300\n",
            "13/13 - 0s - loss: 1.1394 - accuracy: 0.6040 - val_loss: 1.6865 - val_accuracy: 0.4327 - 294ms/epoch - 23ms/step\n",
            "Epoch 79/300\n",
            "13/13 - 0s - loss: 1.1074 - accuracy: 0.6185 - val_loss: 1.7693 - val_accuracy: 0.4631 - 297ms/epoch - 23ms/step\n",
            "Epoch 80/300\n",
            "13/13 - 0s - loss: 1.1382 - accuracy: 0.6135 - val_loss: 1.7486 - val_accuracy: 0.4645 - 297ms/epoch - 23ms/step\n",
            "Epoch 81/300\n",
            "13/13 - 0s - loss: 1.1612 - accuracy: 0.5972 - val_loss: 1.8372 - val_accuracy: 0.4530 - 293ms/epoch - 23ms/step\n",
            "Epoch 82/300\n",
            "13/13 - 0s - loss: 1.1224 - accuracy: 0.6206 - val_loss: 1.7016 - val_accuracy: 0.4790 - 293ms/epoch - 23ms/step\n",
            "Epoch 83/300\n",
            "13/13 - 0s - loss: 1.1162 - accuracy: 0.6153 - val_loss: 1.9262 - val_accuracy: 0.4703 - 301ms/epoch - 23ms/step\n",
            "Epoch 84/300\n",
            "13/13 - 0s - loss: 1.1436 - accuracy: 0.6054 - val_loss: 1.9439 - val_accuracy: 0.4443 - 301ms/epoch - 23ms/step\n",
            "Epoch 85/300\n",
            "13/13 - 0s - loss: 1.1337 - accuracy: 0.5992 - val_loss: 1.8077 - val_accuracy: 0.4660 - 308ms/epoch - 24ms/step\n",
            "Epoch 86/300\n",
            "13/13 - 0s - loss: 1.1019 - accuracy: 0.6310 - val_loss: 1.8687 - val_accuracy: 0.4588 - 311ms/epoch - 24ms/step\n",
            "Epoch 87/300\n",
            "13/13 - 0s - loss: 1.0706 - accuracy: 0.6317 - val_loss: 1.8301 - val_accuracy: 0.4790 - 309ms/epoch - 24ms/step\n",
            "Epoch 88/300\n",
            "13/13 - 0s - loss: 1.1147 - accuracy: 0.6198 - val_loss: 2.0030 - val_accuracy: 0.4342 - 298ms/epoch - 23ms/step\n",
            "Epoch 89/300\n",
            "13/13 - 0s - loss: 1.1132 - accuracy: 0.6294 - val_loss: 1.8022 - val_accuracy: 0.4443 - 298ms/epoch - 23ms/step\n",
            "Epoch 90/300\n",
            "13/13 - 0s - loss: 1.0973 - accuracy: 0.6275 - val_loss: 2.0514 - val_accuracy: 0.4588 - 294ms/epoch - 23ms/step\n",
            "Epoch 91/300\n",
            "13/13 - 0s - loss: 1.1285 - accuracy: 0.6159 - val_loss: 1.7579 - val_accuracy: 0.4385 - 293ms/epoch - 23ms/step\n",
            "Epoch 92/300\n",
            "13/13 - 0s - loss: 1.1058 - accuracy: 0.6288 - val_loss: 1.7592 - val_accuracy: 0.4588 - 295ms/epoch - 23ms/step\n",
            "Epoch 93/300\n",
            "13/13 - 0s - loss: 1.1249 - accuracy: 0.6243 - val_loss: 1.7915 - val_accuracy: 0.4935 - 292ms/epoch - 22ms/step\n",
            "Epoch 94/300\n",
            "13/13 - 0s - loss: 1.2922 - accuracy: 0.5683 - val_loss: 1.8223 - val_accuracy: 0.4399 - 298ms/epoch - 23ms/step\n",
            "Epoch 95/300\n",
            "13/13 - 0s - loss: 1.2106 - accuracy: 0.5897 - val_loss: 1.9474 - val_accuracy: 0.4501 - 296ms/epoch - 23ms/step\n",
            "Epoch 96/300\n",
            "13/13 - 0s - loss: 1.1392 - accuracy: 0.6116 - val_loss: 1.9783 - val_accuracy: 0.4689 - 291ms/epoch - 22ms/step\n",
            "Epoch 97/300\n",
            "13/13 - 0s - loss: 1.1608 - accuracy: 0.6190 - val_loss: 1.7134 - val_accuracy: 0.4877 - 296ms/epoch - 23ms/step\n",
            "Epoch 98/300\n",
            "13/13 - 0s - loss: 1.1210 - accuracy: 0.6315 - val_loss: 1.6765 - val_accuracy: 0.4732 - 299ms/epoch - 23ms/step\n",
            "Epoch 99/300\n",
            "13/13 - 0s - loss: 1.0514 - accuracy: 0.6410 - val_loss: 1.7347 - val_accuracy: 0.4747 - 297ms/epoch - 23ms/step\n",
            "Epoch 100/300\n",
            "13/13 - 0s - loss: 1.0560 - accuracy: 0.6454 - val_loss: 1.7695 - val_accuracy: 0.4732 - 292ms/epoch - 22ms/step\n",
            "Epoch 101/300\n",
            "13/13 - 0s - loss: 1.0274 - accuracy: 0.6449 - val_loss: 2.0814 - val_accuracy: 0.4689 - 298ms/epoch - 23ms/step\n",
            "Epoch 102/300\n",
            "13/13 - 0s - loss: 1.2688 - accuracy: 0.6458 - val_loss: 1.7572 - val_accuracy: 0.4761 - 301ms/epoch - 23ms/step\n",
            "Epoch 103/300\n",
            "13/13 - 0s - loss: 1.1045 - accuracy: 0.6355 - val_loss: 1.8468 - val_accuracy: 0.4530 - 301ms/epoch - 23ms/step\n",
            "Epoch 104/300\n",
            "13/13 - 0s - loss: 1.2216 - accuracy: 0.6114 - val_loss: 1.8951 - val_accuracy: 0.4255 - 296ms/epoch - 23ms/step\n",
            "Epoch 105/300\n",
            "13/13 - 0s - loss: 1.1485 - accuracy: 0.6120 - val_loss: 1.8225 - val_accuracy: 0.4573 - 294ms/epoch - 23ms/step\n",
            "Epoch 106/300\n",
            "13/13 - 0s - loss: 1.0610 - accuracy: 0.6322 - val_loss: 1.7781 - val_accuracy: 0.4834 - 297ms/epoch - 23ms/step\n",
            "Epoch 107/300\n",
            "13/13 - 0s - loss: 1.0743 - accuracy: 0.6264 - val_loss: 1.6726 - val_accuracy: 0.4848 - 297ms/epoch - 23ms/step\n",
            "Epoch 108/300\n",
            "13/13 - 0s - loss: 1.1115 - accuracy: 0.6153 - val_loss: 1.8236 - val_accuracy: 0.4732 - 296ms/epoch - 23ms/step\n",
            "Epoch 109/300\n",
            "13/13 - 0s - loss: 1.0694 - accuracy: 0.6325 - val_loss: 1.7959 - val_accuracy: 0.4848 - 292ms/epoch - 22ms/step\n",
            "Epoch 110/300\n",
            "13/13 - 0s - loss: 1.0829 - accuracy: 0.6286 - val_loss: 2.2592 - val_accuracy: 0.4385 - 297ms/epoch - 23ms/step\n",
            "Epoch 111/300\n",
            "13/13 - 0s - loss: 1.0675 - accuracy: 0.6457 - val_loss: 1.8900 - val_accuracy: 0.4920 - 296ms/epoch - 23ms/step\n",
            "Epoch 112/300\n",
            "13/13 - 0s - loss: 1.1221 - accuracy: 0.6336 - val_loss: 2.0476 - val_accuracy: 0.5195 - 293ms/epoch - 23ms/step\n",
            "Epoch 113/300\n",
            "13/13 - 0s - loss: 1.1110 - accuracy: 0.6223 - val_loss: 1.7857 - val_accuracy: 0.4935 - 294ms/epoch - 23ms/step\n",
            "Epoch 114/300\n",
            "13/13 - 0s - loss: 1.0123 - accuracy: 0.6515 - val_loss: 1.9457 - val_accuracy: 0.4819 - 299ms/epoch - 23ms/step\n",
            "Epoch 115/300\n",
            "13/13 - 0s - loss: 1.0836 - accuracy: 0.6491 - val_loss: 1.7917 - val_accuracy: 0.4848 - 298ms/epoch - 23ms/step\n",
            "Epoch 116/300\n",
            "13/13 - 0s - loss: 1.1479 - accuracy: 0.6127 - val_loss: 1.4725 - val_accuracy: 0.5311 - 295ms/epoch - 23ms/step\n",
            "Epoch 117/300\n",
            "13/13 - 0s - loss: 1.1259 - accuracy: 0.6183 - val_loss: 1.5884 - val_accuracy: 0.5137 - 295ms/epoch - 23ms/step\n",
            "Epoch 118/300\n",
            "13/13 - 0s - loss: 1.0846 - accuracy: 0.6328 - val_loss: 1.4707 - val_accuracy: 0.5036 - 292ms/epoch - 22ms/step\n",
            "Epoch 119/300\n",
            "13/13 - 0s - loss: 1.0714 - accuracy: 0.6330 - val_loss: 1.5614 - val_accuracy: 0.5051 - 290ms/epoch - 22ms/step\n",
            "Epoch 120/300\n",
            "13/13 - 0s - loss: 1.0798 - accuracy: 0.6328 - val_loss: 1.7202 - val_accuracy: 0.5051 - 296ms/epoch - 23ms/step\n",
            "Epoch 121/300\n",
            "13/13 - 0s - loss: 1.1377 - accuracy: 0.6198 - val_loss: 1.9261 - val_accuracy: 0.4428 - 295ms/epoch - 23ms/step\n",
            "Epoch 122/300\n",
            "13/13 - 0s - loss: 1.1513 - accuracy: 0.6252 - val_loss: 1.9388 - val_accuracy: 0.3951 - 291ms/epoch - 22ms/step\n",
            "Epoch 123/300\n",
            "13/13 - 0s - loss: 1.0725 - accuracy: 0.6325 - val_loss: 1.9361 - val_accuracy: 0.4009 - 294ms/epoch - 23ms/step\n",
            "Epoch 124/300\n",
            "13/13 - 0s - loss: 1.0838 - accuracy: 0.6256 - val_loss: 1.7642 - val_accuracy: 0.4501 - 297ms/epoch - 23ms/step\n",
            "Epoch 125/300\n",
            "13/13 - 0s - loss: 1.1033 - accuracy: 0.6252 - val_loss: 1.6210 - val_accuracy: 0.4891 - 292ms/epoch - 22ms/step\n",
            "Epoch 126/300\n",
            "13/13 - 0s - loss: 1.0513 - accuracy: 0.6389 - val_loss: 1.8222 - val_accuracy: 0.5137 - 294ms/epoch - 23ms/step\n",
            "Epoch 127/300\n",
            "13/13 - 0s - loss: 1.0667 - accuracy: 0.6479 - val_loss: 1.7207 - val_accuracy: 0.5195 - 296ms/epoch - 23ms/step\n",
            "Epoch 128/300\n",
            "13/13 - 0s - loss: 1.0569 - accuracy: 0.6394 - val_loss: 1.8550 - val_accuracy: 0.5195 - 296ms/epoch - 23ms/step\n",
            "Epoch 129/300\n",
            "13/13 - 0s - loss: 1.1216 - accuracy: 0.6328 - val_loss: 1.9924 - val_accuracy: 0.4067 - 294ms/epoch - 23ms/step\n",
            "Epoch 130/300\n",
            "13/13 - 0s - loss: 1.0975 - accuracy: 0.6420 - val_loss: 1.9358 - val_accuracy: 0.4399 - 295ms/epoch - 23ms/step\n",
            "Epoch 131/300\n",
            "13/13 - 0s - loss: 1.0792 - accuracy: 0.6421 - val_loss: 1.7510 - val_accuracy: 0.4689 - 297ms/epoch - 23ms/step\n",
            "Epoch 132/300\n",
            "13/13 - 0s - loss: 1.0535 - accuracy: 0.6513 - val_loss: 1.8960 - val_accuracy: 0.4891 - 292ms/epoch - 22ms/step\n",
            "Epoch 133/300\n",
            "13/13 - 0s - loss: 1.2579 - accuracy: 0.6066 - val_loss: 2.0804 - val_accuracy: 0.4385 - 295ms/epoch - 23ms/step\n",
            "Epoch 134/300\n",
            "13/13 - 0s - loss: 1.1455 - accuracy: 0.6108 - val_loss: 1.9044 - val_accuracy: 0.4327 - 289ms/epoch - 22ms/step\n",
            "Epoch 135/300\n",
            "13/13 - 0s - loss: 1.3034 - accuracy: 0.5732 - val_loss: 1.9905 - val_accuracy: 0.4284 - 301ms/epoch - 23ms/step\n",
            "Epoch 136/300\n",
            "13/13 - 0s - loss: 1.3907 - accuracy: 0.5536 - val_loss: 2.3137 - val_accuracy: 0.4255 - 295ms/epoch - 23ms/step\n",
            "Epoch 137/300\n",
            "13/13 - 0s - loss: 1.2648 - accuracy: 0.5800 - val_loss: 1.8011 - val_accuracy: 0.4602 - 293ms/epoch - 23ms/step\n",
            "Epoch 138/300\n",
            "13/13 - 0s - loss: 1.3478 - accuracy: 0.5901 - val_loss: 2.0264 - val_accuracy: 0.4573 - 292ms/epoch - 22ms/step\n",
            "Epoch 139/300\n",
            "13/13 - 0s - loss: 1.2581 - accuracy: 0.5773 - val_loss: 1.5713 - val_accuracy: 0.5181 - 296ms/epoch - 23ms/step\n",
            "Epoch 140/300\n",
            "13/13 - 0s - loss: 1.2006 - accuracy: 0.5974 - val_loss: 1.6079 - val_accuracy: 0.4501 - 291ms/epoch - 22ms/step\n",
            "Epoch 141/300\n",
            "13/13 - 0s - loss: 1.1137 - accuracy: 0.6252 - val_loss: 1.6528 - val_accuracy: 0.4703 - 298ms/epoch - 23ms/step\n",
            "Epoch 142/300\n",
            "13/13 - 0s - loss: 1.0948 - accuracy: 0.6278 - val_loss: 1.6546 - val_accuracy: 0.5036 - 289ms/epoch - 22ms/step\n",
            "Epoch 143/300\n",
            "13/13 - 0s - loss: 1.0609 - accuracy: 0.6454 - val_loss: 1.6126 - val_accuracy: 0.5065 - 300ms/epoch - 23ms/step\n",
            "Epoch 144/300\n",
            "13/13 - 0s - loss: 1.0627 - accuracy: 0.6367 - val_loss: 1.7941 - val_accuracy: 0.4631 - 298ms/epoch - 23ms/step\n",
            "Epoch 145/300\n",
            "13/13 - 0s - loss: 1.1134 - accuracy: 0.6283 - val_loss: 1.6449 - val_accuracy: 0.4761 - 293ms/epoch - 23ms/step\n",
            "Epoch 146/300\n",
            "13/13 - 0s - loss: 1.0866 - accuracy: 0.6520 - val_loss: 1.6967 - val_accuracy: 0.5166 - 294ms/epoch - 23ms/step\n",
            "Epoch 147/300\n",
            "13/13 - 0s - loss: 1.0520 - accuracy: 0.6380 - val_loss: 1.8398 - val_accuracy: 0.4732 - 293ms/epoch - 23ms/step\n",
            "Epoch 148/300\n",
            "13/13 - 0s - loss: 1.0683 - accuracy: 0.6510 - val_loss: 1.6462 - val_accuracy: 0.5398 - 291ms/epoch - 22ms/step\n",
            "Epoch 149/300\n",
            "13/13 - 0s - loss: 1.0827 - accuracy: 0.6418 - val_loss: 1.6699 - val_accuracy: 0.4993 - 298ms/epoch - 23ms/step\n",
            "Epoch 150/300\n",
            "13/13 - 0s - loss: 1.1088 - accuracy: 0.6249 - val_loss: 1.6711 - val_accuracy: 0.4486 - 293ms/epoch - 23ms/step\n",
            "Epoch 151/300\n",
            "13/13 - 0s - loss: 1.0873 - accuracy: 0.6397 - val_loss: 1.7404 - val_accuracy: 0.4891 - 295ms/epoch - 23ms/step\n",
            "Epoch 152/300\n",
            "13/13 - 0s - loss: 1.0419 - accuracy: 0.6383 - val_loss: 1.7591 - val_accuracy: 0.4920 - 292ms/epoch - 22ms/step\n",
            "Epoch 153/300\n",
            "13/13 - 0s - loss: 1.0229 - accuracy: 0.6550 - val_loss: 1.6255 - val_accuracy: 0.5137 - 293ms/epoch - 23ms/step\n",
            "Epoch 154/300\n",
            "13/13 - 0s - loss: 1.0144 - accuracy: 0.6563 - val_loss: 1.7584 - val_accuracy: 0.4660 - 295ms/epoch - 23ms/step\n",
            "Epoch 155/300\n",
            "13/13 - 0s - loss: 1.0300 - accuracy: 0.6529 - val_loss: 1.8524 - val_accuracy: 0.4573 - 295ms/epoch - 23ms/step\n",
            "Epoch 156/300\n",
            "13/13 - 0s - loss: 1.0475 - accuracy: 0.6425 - val_loss: 1.6709 - val_accuracy: 0.4616 - 293ms/epoch - 23ms/step\n",
            "Epoch 157/300\n",
            "13/13 - 0s - loss: 1.0990 - accuracy: 0.6359 - val_loss: 1.9157 - val_accuracy: 0.4255 - 296ms/epoch - 23ms/step\n",
            "Epoch 158/300\n",
            "13/13 - 0s - loss: 1.1986 - accuracy: 0.5947 - val_loss: 1.7464 - val_accuracy: 0.4428 - 295ms/epoch - 23ms/step\n",
            "Epoch 159/300\n",
            "13/13 - 0s - loss: 1.1241 - accuracy: 0.6080 - val_loss: 1.9645 - val_accuracy: 0.4298 - 298ms/epoch - 23ms/step\n",
            "Epoch 160/300\n",
            "13/13 - 0s - loss: 1.1495 - accuracy: 0.6045 - val_loss: 2.2055 - val_accuracy: 0.4573 - 296ms/epoch - 23ms/step\n",
            "Epoch 161/300\n",
            "13/13 - 0s - loss: 1.1155 - accuracy: 0.6154 - val_loss: 2.3872 - val_accuracy: 0.4544 - 295ms/epoch - 23ms/step\n",
            "Epoch 162/300\n",
            "13/13 - 0s - loss: 1.1746 - accuracy: 0.6045 - val_loss: 1.7140 - val_accuracy: 0.4877 - 294ms/epoch - 23ms/step\n",
            "Epoch 163/300\n",
            "13/13 - 0s - loss: 1.1635 - accuracy: 0.6169 - val_loss: 1.8794 - val_accuracy: 0.4790 - 298ms/epoch - 23ms/step\n",
            "Epoch 164/300\n",
            "13/13 - 0s - loss: 1.0866 - accuracy: 0.6269 - val_loss: 1.8912 - val_accuracy: 0.4732 - 290ms/epoch - 22ms/step\n",
            "Epoch 165/300\n",
            "13/13 - 0s - loss: 1.0667 - accuracy: 0.6306 - val_loss: 1.8746 - val_accuracy: 0.4834 - 295ms/epoch - 23ms/step\n",
            "Epoch 166/300\n",
            "13/13 - 0s - loss: 1.0158 - accuracy: 0.6566 - val_loss: 1.9996 - val_accuracy: 0.4848 - 293ms/epoch - 23ms/step\n",
            "Epoch 167/300\n",
            "13/13 - 0s - loss: 1.0559 - accuracy: 0.6515 - val_loss: 1.6959 - val_accuracy: 0.5311 - 292ms/epoch - 22ms/step\n",
            "Epoch 168/300\n",
            "13/13 - 0s - loss: 1.0557 - accuracy: 0.6513 - val_loss: 1.5998 - val_accuracy: 0.5152 - 296ms/epoch - 23ms/step\n",
            "Epoch 169/300\n",
            "13/13 - 0s - loss: 1.0425 - accuracy: 0.6491 - val_loss: 1.7209 - val_accuracy: 0.4891 - 293ms/epoch - 23ms/step\n",
            "Epoch 170/300\n",
            "13/13 - 0s - loss: 1.0409 - accuracy: 0.6475 - val_loss: 1.6317 - val_accuracy: 0.4805 - 296ms/epoch - 23ms/step\n",
            "Epoch 171/300\n",
            "13/13 - 0s - loss: 1.0477 - accuracy: 0.6574 - val_loss: 2.0774 - val_accuracy: 0.4573 - 305ms/epoch - 23ms/step\n",
            "Epoch 172/300\n",
            "13/13 - 0s - loss: 1.1909 - accuracy: 0.5966 - val_loss: 1.7736 - val_accuracy: 0.4631 - 292ms/epoch - 22ms/step\n",
            "Epoch 173/300\n",
            "13/13 - 0s - loss: 1.0986 - accuracy: 0.6217 - val_loss: 1.7859 - val_accuracy: 0.4848 - 291ms/epoch - 22ms/step\n",
            "Epoch 174/300\n",
            "13/13 - 0s - loss: 1.0064 - accuracy: 0.6573 - val_loss: 1.8017 - val_accuracy: 0.4920 - 292ms/epoch - 22ms/step\n",
            "Epoch 175/300\n",
            "13/13 - 0s - loss: 1.0368 - accuracy: 0.6547 - val_loss: 1.9501 - val_accuracy: 0.4530 - 304ms/epoch - 23ms/step\n",
            "Epoch 176/300\n",
            "13/13 - 0s - loss: 0.9987 - accuracy: 0.6602 - val_loss: 1.9003 - val_accuracy: 0.4993 - 300ms/epoch - 23ms/step\n",
            "Epoch 177/300\n",
            "13/13 - 0s - loss: 0.9340 - accuracy: 0.6764 - val_loss: 1.7578 - val_accuracy: 0.5123 - 298ms/epoch - 23ms/step\n",
            "Epoch 178/300\n",
            "13/13 - 0s - loss: 0.9174 - accuracy: 0.6834 - val_loss: 1.8954 - val_accuracy: 0.5123 - 297ms/epoch - 23ms/step\n",
            "Epoch 179/300\n",
            "13/13 - 0s - loss: 0.8987 - accuracy: 0.6858 - val_loss: 1.8741 - val_accuracy: 0.5051 - 295ms/epoch - 23ms/step\n",
            "Epoch 180/300\n",
            "13/13 - 0s - loss: 0.9121 - accuracy: 0.6832 - val_loss: 1.9128 - val_accuracy: 0.5007 - 298ms/epoch - 23ms/step\n",
            "Epoch 181/300\n",
            "13/13 - 0s - loss: 0.9249 - accuracy: 0.6787 - val_loss: 1.8939 - val_accuracy: 0.5065 - 299ms/epoch - 23ms/step\n",
            "Epoch 182/300\n",
            "13/13 - 0s - loss: 0.9516 - accuracy: 0.6714 - val_loss: 1.9330 - val_accuracy: 0.4935 - 292ms/epoch - 22ms/step\n",
            "Epoch 183/300\n",
            "13/13 - 0s - loss: 0.9115 - accuracy: 0.6798 - val_loss: 2.0533 - val_accuracy: 0.4573 - 291ms/epoch - 22ms/step\n",
            "Epoch 184/300\n",
            "13/13 - 0s - loss: 0.9720 - accuracy: 0.6771 - val_loss: 1.9976 - val_accuracy: 0.4906 - 301ms/epoch - 23ms/step\n",
            "Epoch 185/300\n",
            "13/13 - 0s - loss: 0.9732 - accuracy: 0.6769 - val_loss: 2.0335 - val_accuracy: 0.4747 - 294ms/epoch - 23ms/step\n",
            "Epoch 186/300\n",
            "13/13 - 0s - loss: 0.9375 - accuracy: 0.6766 - val_loss: 1.9725 - val_accuracy: 0.5036 - 294ms/epoch - 23ms/step\n",
            "Epoch 187/300\n",
            "13/13 - 0s - loss: 0.9720 - accuracy: 0.6681 - val_loss: 1.9243 - val_accuracy: 0.4559 - 297ms/epoch - 23ms/step\n",
            "Epoch 188/300\n",
            "13/13 - 0s - loss: 0.9378 - accuracy: 0.6803 - val_loss: 1.8330 - val_accuracy: 0.4761 - 294ms/epoch - 23ms/step\n",
            "Epoch 189/300\n",
            "13/13 - 0s - loss: 0.9565 - accuracy: 0.6788 - val_loss: 1.9600 - val_accuracy: 0.5109 - 299ms/epoch - 23ms/step\n",
            "Epoch 190/300\n",
            "13/13 - 0s - loss: 0.9944 - accuracy: 0.6748 - val_loss: 1.8698 - val_accuracy: 0.4573 - 295ms/epoch - 23ms/step\n",
            "Epoch 191/300\n",
            "13/13 - 0s - loss: 1.1097 - accuracy: 0.6392 - val_loss: 1.8110 - val_accuracy: 0.4732 - 296ms/epoch - 23ms/step\n",
            "Epoch 192/300\n",
            "13/13 - 0s - loss: 1.0616 - accuracy: 0.6378 - val_loss: 2.0345 - val_accuracy: 0.4747 - 293ms/epoch - 23ms/step\n",
            "Epoch 193/300\n",
            "13/13 - 0s - loss: 1.0187 - accuracy: 0.6502 - val_loss: 2.0192 - val_accuracy: 0.4747 - 296ms/epoch - 23ms/step\n",
            "Epoch 194/300\n",
            "13/13 - 0s - loss: 1.0690 - accuracy: 0.6347 - val_loss: 1.8091 - val_accuracy: 0.4891 - 295ms/epoch - 23ms/step\n",
            "Epoch 195/300\n",
            "13/13 - 0s - loss: 1.1782 - accuracy: 0.6265 - val_loss: 1.6842 - val_accuracy: 0.4515 - 292ms/epoch - 22ms/step\n",
            "Epoch 196/300\n",
            "13/13 - 0s - loss: 1.1627 - accuracy: 0.6291 - val_loss: 1.9318 - val_accuracy: 0.4211 - 295ms/epoch - 23ms/step\n",
            "Epoch 197/300\n",
            "13/13 - 0s - loss: 1.1335 - accuracy: 0.6172 - val_loss: 1.8656 - val_accuracy: 0.4703 - 296ms/epoch - 23ms/step\n",
            "Epoch 198/300\n",
            "13/13 - 0s - loss: 1.5277 - accuracy: 0.5881 - val_loss: 1.7664 - val_accuracy: 0.3994 - 296ms/epoch - 23ms/step\n",
            "Epoch 199/300\n",
            "13/13 - 0s - loss: 1.4945 - accuracy: 0.5571 - val_loss: 1.7576 - val_accuracy: 0.4313 - 301ms/epoch - 23ms/step\n",
            "Epoch 200/300\n",
            "13/13 - 0s - loss: 1.3790 - accuracy: 0.5240 - val_loss: 1.8517 - val_accuracy: 0.4515 - 292ms/epoch - 22ms/step\n",
            "Epoch 201/300\n",
            "13/13 - 0s - loss: 1.3290 - accuracy: 0.5270 - val_loss: 2.0697 - val_accuracy: 0.4052 - 296ms/epoch - 23ms/step\n",
            "Epoch 202/300\n",
            "13/13 - 0s - loss: 1.3375 - accuracy: 0.5407 - val_loss: 1.9357 - val_accuracy: 0.3806 - 297ms/epoch - 23ms/step\n",
            "Epoch 203/300\n",
            "13/13 - 0s - loss: 1.2963 - accuracy: 0.5328 - val_loss: 1.7943 - val_accuracy: 0.3748 - 295ms/epoch - 23ms/step\n",
            "Epoch 204/300\n",
            "13/13 - 0s - loss: 1.2344 - accuracy: 0.5675 - val_loss: 1.9047 - val_accuracy: 0.3849 - 289ms/epoch - 22ms/step\n",
            "Epoch 205/300\n",
            "13/13 - 0s - loss: 1.2418 - accuracy: 0.5654 - val_loss: 1.9939 - val_accuracy: 0.3994 - 296ms/epoch - 23ms/step\n",
            "Epoch 206/300\n",
            "13/13 - 0s - loss: 1.2873 - accuracy: 0.5578 - val_loss: 1.9693 - val_accuracy: 0.4342 - 294ms/epoch - 23ms/step\n",
            "Epoch 207/300\n",
            "13/13 - 0s - loss: 1.2426 - accuracy: 0.5703 - val_loss: 1.9730 - val_accuracy: 0.3748 - 294ms/epoch - 23ms/step\n",
            "Epoch 208/300\n",
            "13/13 - 0s - loss: 1.1806 - accuracy: 0.5760 - val_loss: 1.9240 - val_accuracy: 0.4182 - 297ms/epoch - 23ms/step\n",
            "Epoch 209/300\n",
            "13/13 - 0s - loss: 1.1986 - accuracy: 0.5826 - val_loss: 1.7837 - val_accuracy: 0.4370 - 295ms/epoch - 23ms/step\n",
            "Epoch 210/300\n",
            "13/13 - 0s - loss: 1.1943 - accuracy: 0.5671 - val_loss: 1.6692 - val_accuracy: 0.4197 - 302ms/epoch - 23ms/step\n",
            "Epoch 211/300\n",
            "13/13 - 0s - loss: 1.1675 - accuracy: 0.5852 - val_loss: 1.6890 - val_accuracy: 0.4255 - 301ms/epoch - 23ms/step\n",
            "Epoch 212/300\n",
            "13/13 - 0s - loss: 1.1735 - accuracy: 0.5742 - val_loss: 1.7241 - val_accuracy: 0.4573 - 293ms/epoch - 23ms/step\n",
            "Epoch 213/300\n",
            "13/13 - 0s - loss: 1.1810 - accuracy: 0.5940 - val_loss: 1.8047 - val_accuracy: 0.4428 - 297ms/epoch - 23ms/step\n",
            "Epoch 214/300\n",
            "13/13 - 0s - loss: 1.2064 - accuracy: 0.5864 - val_loss: 1.7866 - val_accuracy: 0.4877 - 298ms/epoch - 23ms/step\n",
            "Epoch 215/300\n",
            "13/13 - 0s - loss: 1.1297 - accuracy: 0.5945 - val_loss: 1.7770 - val_accuracy: 0.4616 - 294ms/epoch - 23ms/step\n",
            "Epoch 216/300\n",
            "13/13 - 0s - loss: 1.1725 - accuracy: 0.5966 - val_loss: 1.7041 - val_accuracy: 0.4602 - 293ms/epoch - 23ms/step\n",
            "Epoch 217/300\n",
            "13/13 - 0s - loss: 1.1666 - accuracy: 0.5942 - val_loss: 1.6122 - val_accuracy: 0.4703 - 299ms/epoch - 23ms/step\n",
            "Epoch 218/300\n",
            "13/13 - 0s - loss: 1.1945 - accuracy: 0.5855 - val_loss: 1.8647 - val_accuracy: 0.4081 - 294ms/epoch - 23ms/step\n",
            "Epoch 219/300\n",
            "13/13 - 0s - loss: 1.1686 - accuracy: 0.6050 - val_loss: 1.8704 - val_accuracy: 0.4501 - 297ms/epoch - 23ms/step\n",
            "Epoch 220/300\n",
            "13/13 - 0s - loss: 1.1371 - accuracy: 0.6017 - val_loss: 1.7083 - val_accuracy: 0.4761 - 302ms/epoch - 23ms/step\n",
            "Epoch 221/300\n",
            "13/13 - 0s - loss: 1.1085 - accuracy: 0.6006 - val_loss: 1.8379 - val_accuracy: 0.4834 - 295ms/epoch - 23ms/step\n",
            "Epoch 222/300\n",
            "13/13 - 0s - loss: 1.1834 - accuracy: 0.5982 - val_loss: 1.8735 - val_accuracy: 0.4834 - 295ms/epoch - 23ms/step\n",
            "Epoch 223/300\n",
            "13/13 - 0s - loss: 1.1054 - accuracy: 0.6053 - val_loss: 1.9325 - val_accuracy: 0.4414 - 292ms/epoch - 22ms/step\n",
            "Epoch 224/300\n",
            "13/13 - 0s - loss: 1.2539 - accuracy: 0.6043 - val_loss: 1.8816 - val_accuracy: 0.4645 - 296ms/epoch - 23ms/step\n",
            "Epoch 225/300\n",
            "13/13 - 0s - loss: 1.2013 - accuracy: 0.5763 - val_loss: 1.8993 - val_accuracy: 0.4645 - 295ms/epoch - 23ms/step\n",
            "Epoch 226/300\n",
            "13/13 - 0s - loss: 1.2025 - accuracy: 0.5898 - val_loss: 1.7833 - val_accuracy: 0.4544 - 294ms/epoch - 23ms/step\n",
            "Epoch 227/300\n",
            "13/13 - 0s - loss: 1.1186 - accuracy: 0.6029 - val_loss: 1.8057 - val_accuracy: 0.4414 - 293ms/epoch - 23ms/step\n",
            "Epoch 228/300\n",
            "13/13 - 0s - loss: 1.0892 - accuracy: 0.6112 - val_loss: 1.9128 - val_accuracy: 0.4370 - 292ms/epoch - 22ms/step\n",
            "Epoch 229/300\n",
            "13/13 - 0s - loss: 1.1181 - accuracy: 0.5972 - val_loss: 1.6543 - val_accuracy: 0.4515 - 289ms/epoch - 22ms/step\n",
            "Epoch 230/300\n",
            "13/13 - 0s - loss: 1.1044 - accuracy: 0.5918 - val_loss: 1.9198 - val_accuracy: 0.4472 - 294ms/epoch - 23ms/step\n",
            "Epoch 231/300\n",
            "13/13 - 0s - loss: 1.1100 - accuracy: 0.6058 - val_loss: 1.9823 - val_accuracy: 0.4197 - 299ms/epoch - 23ms/step\n",
            "Epoch 232/300\n",
            "13/13 - 0s - loss: 1.2031 - accuracy: 0.5852 - val_loss: 1.8809 - val_accuracy: 0.4399 - 293ms/epoch - 23ms/step\n",
            "Epoch 233/300\n",
            "13/13 - 0s - loss: 1.1859 - accuracy: 0.5906 - val_loss: 1.7267 - val_accuracy: 0.4009 - 295ms/epoch - 23ms/step\n",
            "Epoch 234/300\n",
            "13/13 - 0s - loss: 1.2355 - accuracy: 0.6067 - val_loss: 1.7112 - val_accuracy: 0.4544 - 299ms/epoch - 23ms/step\n",
            "Epoch 235/300\n",
            "13/13 - 0s - loss: 1.1605 - accuracy: 0.6030 - val_loss: 1.9220 - val_accuracy: 0.4168 - 293ms/epoch - 23ms/step\n",
            "Epoch 236/300\n",
            "13/13 - 0s - loss: 1.1174 - accuracy: 0.6095 - val_loss: 1.9273 - val_accuracy: 0.4240 - 297ms/epoch - 23ms/step\n",
            "Epoch 237/300\n",
            "13/13 - 0s - loss: 1.0922 - accuracy: 0.6222 - val_loss: 1.8282 - val_accuracy: 0.4602 - 297ms/epoch - 23ms/step\n",
            "Epoch 238/300\n",
            "13/13 - 0s - loss: 1.0510 - accuracy: 0.6310 - val_loss: 1.7633 - val_accuracy: 0.4602 - 291ms/epoch - 22ms/step\n",
            "Epoch 239/300\n",
            "13/13 - 0s - loss: 1.0958 - accuracy: 0.6231 - val_loss: 1.8900 - val_accuracy: 0.4544 - 303ms/epoch - 23ms/step\n",
            "Epoch 240/300\n",
            "13/13 - 0s - loss: 1.0289 - accuracy: 0.6336 - val_loss: 1.8280 - val_accuracy: 0.4313 - 292ms/epoch - 22ms/step\n",
            "Epoch 241/300\n",
            "13/13 - 0s - loss: 1.0238 - accuracy: 0.6418 - val_loss: 1.8345 - val_accuracy: 0.4313 - 292ms/epoch - 22ms/step\n",
            "Epoch 242/300\n",
            "13/13 - 0s - loss: 1.0758 - accuracy: 0.6391 - val_loss: 1.7186 - val_accuracy: 0.4414 - 291ms/epoch - 22ms/step\n",
            "Epoch 243/300\n",
            "13/13 - 0s - loss: 0.9902 - accuracy: 0.6478 - val_loss: 1.7290 - val_accuracy: 0.4399 - 297ms/epoch - 23ms/step\n",
            "Epoch 244/300\n",
            "13/13 - 0s - loss: 0.9553 - accuracy: 0.6568 - val_loss: 1.9405 - val_accuracy: 0.4645 - 294ms/epoch - 23ms/step\n",
            "Epoch 245/300\n",
            "13/13 - 0s - loss: 0.9608 - accuracy: 0.6644 - val_loss: 1.8653 - val_accuracy: 0.4428 - 295ms/epoch - 23ms/step\n",
            "Epoch 246/300\n",
            "13/13 - 0s - loss: 0.9857 - accuracy: 0.6531 - val_loss: 1.8732 - val_accuracy: 0.4081 - 293ms/epoch - 23ms/step\n",
            "Epoch 247/300\n",
            "13/13 - 0s - loss: 1.0114 - accuracy: 0.6484 - val_loss: 1.7478 - val_accuracy: 0.4703 - 292ms/epoch - 22ms/step\n",
            "Epoch 248/300\n",
            "13/13 - 0s - loss: 1.0280 - accuracy: 0.6521 - val_loss: 1.7643 - val_accuracy: 0.4544 - 296ms/epoch - 23ms/step\n",
            "Epoch 249/300\n",
            "13/13 - 0s - loss: 1.2615 - accuracy: 0.6217 - val_loss: 1.6647 - val_accuracy: 0.4776 - 291ms/epoch - 22ms/step\n",
            "Epoch 250/300\n",
            "13/13 - 0s - loss: 1.0995 - accuracy: 0.6273 - val_loss: 2.1538 - val_accuracy: 0.4689 - 295ms/epoch - 23ms/step\n",
            "Epoch 251/300\n",
            "13/13 - 0s - loss: 1.2221 - accuracy: 0.6093 - val_loss: 1.8362 - val_accuracy: 0.4501 - 293ms/epoch - 23ms/step\n",
            "Epoch 252/300\n",
            "13/13 - 0s - loss: 1.1358 - accuracy: 0.6141 - val_loss: 1.7377 - val_accuracy: 0.4486 - 302ms/epoch - 23ms/step\n",
            "Epoch 253/300\n",
            "13/13 - 0s - loss: 1.0719 - accuracy: 0.6331 - val_loss: 1.7085 - val_accuracy: 0.4414 - 295ms/epoch - 23ms/step\n",
            "Epoch 254/300\n",
            "13/13 - 0s - loss: 1.1359 - accuracy: 0.5897 - val_loss: 1.9238 - val_accuracy: 0.4486 - 295ms/epoch - 23ms/step\n",
            "Epoch 255/300\n",
            "13/13 - 0s - loss: 1.1206 - accuracy: 0.6130 - val_loss: 1.6564 - val_accuracy: 0.4588 - 296ms/epoch - 23ms/step\n",
            "Epoch 256/300\n",
            "13/13 - 0s - loss: 1.2388 - accuracy: 0.5874 - val_loss: 1.6983 - val_accuracy: 0.4602 - 292ms/epoch - 22ms/step\n",
            "Epoch 257/300\n",
            "13/13 - 0s - loss: 1.1687 - accuracy: 0.5966 - val_loss: 1.7171 - val_accuracy: 0.4327 - 295ms/epoch - 23ms/step\n",
            "Epoch 258/300\n",
            "13/13 - 0s - loss: 1.1364 - accuracy: 0.6165 - val_loss: 1.8457 - val_accuracy: 0.4081 - 295ms/epoch - 23ms/step\n",
            "Epoch 259/300\n",
            "13/13 - 0s - loss: 1.1057 - accuracy: 0.6354 - val_loss: 1.8019 - val_accuracy: 0.4414 - 293ms/epoch - 23ms/step\n",
            "Epoch 260/300\n",
            "13/13 - 0s - loss: 1.0894 - accuracy: 0.6251 - val_loss: 1.8779 - val_accuracy: 0.4457 - 296ms/epoch - 23ms/step\n",
            "Epoch 261/300\n",
            "13/13 - 0s - loss: 1.0987 - accuracy: 0.6323 - val_loss: 1.8291 - val_accuracy: 0.4182 - 292ms/epoch - 22ms/step\n",
            "Epoch 262/300\n",
            "13/13 - 0s - loss: 1.0704 - accuracy: 0.6299 - val_loss: 1.8041 - val_accuracy: 0.4385 - 294ms/epoch - 23ms/step\n",
            "Epoch 263/300\n",
            "13/13 - 0s - loss: 1.0587 - accuracy: 0.6429 - val_loss: 1.8931 - val_accuracy: 0.4342 - 294ms/epoch - 23ms/step\n",
            "Epoch 264/300\n",
            "13/13 - 0s - loss: 1.0042 - accuracy: 0.6452 - val_loss: 1.9114 - val_accuracy: 0.4515 - 299ms/epoch - 23ms/step\n",
            "Epoch 265/300\n",
            "13/13 - 0s - loss: 0.9857 - accuracy: 0.6636 - val_loss: 1.8755 - val_accuracy: 0.4356 - 290ms/epoch - 22ms/step\n",
            "Epoch 266/300\n",
            "13/13 - 0s - loss: 0.9773 - accuracy: 0.6581 - val_loss: 2.0796 - val_accuracy: 0.4588 - 290ms/epoch - 22ms/step\n",
            "Epoch 267/300\n",
            "13/13 - 0s - loss: 1.0054 - accuracy: 0.6619 - val_loss: 2.4714 - val_accuracy: 0.4877 - 292ms/epoch - 22ms/step\n",
            "Epoch 268/300\n",
            "13/13 - 0s - loss: 1.0652 - accuracy: 0.6471 - val_loss: 1.8466 - val_accuracy: 0.4356 - 298ms/epoch - 23ms/step\n",
            "Epoch 269/300\n",
            "13/13 - 0s - loss: 1.0828 - accuracy: 0.6238 - val_loss: 2.0047 - val_accuracy: 0.4356 - 294ms/epoch - 23ms/step\n",
            "Epoch 270/300\n",
            "13/13 - 0s - loss: 1.0149 - accuracy: 0.6494 - val_loss: 2.0924 - val_accuracy: 0.4616 - 295ms/epoch - 23ms/step\n",
            "Epoch 271/300\n",
            "13/13 - 0s - loss: 1.0225 - accuracy: 0.6531 - val_loss: 1.8761 - val_accuracy: 0.4559 - 296ms/epoch - 23ms/step\n",
            "Epoch 272/300\n",
            "13/13 - 0s - loss: 1.0855 - accuracy: 0.6467 - val_loss: 1.9834 - val_accuracy: 0.4645 - 296ms/epoch - 23ms/step\n",
            "Epoch 273/300\n",
            "13/13 - 0s - loss: 1.0775 - accuracy: 0.6397 - val_loss: 1.7644 - val_accuracy: 0.4703 - 293ms/epoch - 23ms/step\n",
            "Epoch 274/300\n",
            "13/13 - 0s - loss: 1.0955 - accuracy: 0.6214 - val_loss: 1.8565 - val_accuracy: 0.4414 - 293ms/epoch - 23ms/step\n",
            "Epoch 275/300\n",
            "13/13 - 0s - loss: 1.0145 - accuracy: 0.6412 - val_loss: 1.7213 - val_accuracy: 0.4732 - 292ms/epoch - 22ms/step\n",
            "Epoch 276/300\n",
            "13/13 - 0s - loss: 1.0298 - accuracy: 0.6561 - val_loss: 1.6825 - val_accuracy: 0.4805 - 296ms/epoch - 23ms/step\n",
            "Epoch 277/300\n",
            "13/13 - 0s - loss: 0.9585 - accuracy: 0.6761 - val_loss: 1.9157 - val_accuracy: 0.4935 - 291ms/epoch - 22ms/step\n",
            "Epoch 278/300\n",
            "13/13 - 0s - loss: 0.9776 - accuracy: 0.6647 - val_loss: 2.2806 - val_accuracy: 0.4949 - 298ms/epoch - 23ms/step\n",
            "Epoch 279/300\n",
            "13/13 - 0s - loss: 1.0635 - accuracy: 0.6528 - val_loss: 1.8946 - val_accuracy: 0.4935 - 292ms/epoch - 22ms/step\n",
            "Epoch 280/300\n",
            "13/13 - 0s - loss: 1.0070 - accuracy: 0.6463 - val_loss: 1.9431 - val_accuracy: 0.4486 - 296ms/epoch - 23ms/step\n",
            "Epoch 281/300\n",
            "13/13 - 0s - loss: 1.1042 - accuracy: 0.6227 - val_loss: 1.9655 - val_accuracy: 0.4631 - 294ms/epoch - 23ms/step\n",
            "Epoch 282/300\n",
            "13/13 - 0s - loss: 1.0376 - accuracy: 0.6420 - val_loss: 1.9579 - val_accuracy: 0.4573 - 290ms/epoch - 22ms/step\n",
            "Epoch 283/300\n",
            "13/13 - 0s - loss: 1.0125 - accuracy: 0.6442 - val_loss: 1.9792 - val_accuracy: 0.4313 - 296ms/epoch - 23ms/step\n",
            "Epoch 284/300\n",
            "13/13 - 0s - loss: 0.9842 - accuracy: 0.6682 - val_loss: 1.9877 - val_accuracy: 0.4848 - 294ms/epoch - 23ms/step\n",
            "Epoch 285/300\n",
            "13/13 - 0s - loss: 0.9949 - accuracy: 0.6537 - val_loss: 2.1196 - val_accuracy: 0.4848 - 289ms/epoch - 22ms/step\n",
            "Epoch 286/300\n",
            "13/13 - 0s - loss: 1.0073 - accuracy: 0.6711 - val_loss: 2.0519 - val_accuracy: 0.5051 - 295ms/epoch - 23ms/step\n",
            "Epoch 287/300\n",
            "13/13 - 0s - loss: 1.0486 - accuracy: 0.6465 - val_loss: 2.3602 - val_accuracy: 0.3792 - 293ms/epoch - 23ms/step\n",
            "Epoch 288/300\n",
            "13/13 - 0s - loss: 1.0090 - accuracy: 0.6594 - val_loss: 1.8993 - val_accuracy: 0.4935 - 297ms/epoch - 23ms/step\n",
            "Epoch 289/300\n",
            "13/13 - 0s - loss: 0.9382 - accuracy: 0.6759 - val_loss: 2.0530 - val_accuracy: 0.4732 - 294ms/epoch - 23ms/step\n",
            "Epoch 290/300\n",
            "13/13 - 0s - loss: 0.9255 - accuracy: 0.6854 - val_loss: 2.1033 - val_accuracy: 0.4747 - 293ms/epoch - 23ms/step\n",
            "Epoch 291/300\n",
            "13/13 - 0s - loss: 0.9312 - accuracy: 0.6861 - val_loss: 2.2477 - val_accuracy: 0.5065 - 298ms/epoch - 23ms/step\n",
            "Epoch 292/300\n",
            "13/13 - 0s - loss: 1.0175 - accuracy: 0.6550 - val_loss: 2.0483 - val_accuracy: 0.4631 - 298ms/epoch - 23ms/step\n",
            "Epoch 293/300\n",
            "13/13 - 0s - loss: 0.9779 - accuracy: 0.6621 - val_loss: 1.9414 - val_accuracy: 0.4790 - 292ms/epoch - 22ms/step\n",
            "Epoch 294/300\n",
            "13/13 - 0s - loss: 0.9321 - accuracy: 0.6875 - val_loss: 1.8667 - val_accuracy: 0.4935 - 295ms/epoch - 23ms/step\n",
            "Epoch 295/300\n",
            "13/13 - 0s - loss: 0.9360 - accuracy: 0.6809 - val_loss: 1.9456 - val_accuracy: 0.4776 - 295ms/epoch - 23ms/step\n",
            "Epoch 296/300\n",
            "13/13 - 0s - loss: 0.9038 - accuracy: 0.6896 - val_loss: 1.9257 - val_accuracy: 0.5398 - 295ms/epoch - 23ms/step\n",
            "Epoch 297/300\n",
            "13/13 - 0s - loss: 0.9186 - accuracy: 0.6834 - val_loss: 1.9095 - val_accuracy: 0.4689 - 293ms/epoch - 23ms/step\n",
            "Epoch 298/300\n",
            "13/13 - 0s - loss: 0.8695 - accuracy: 0.6980 - val_loss: 1.9120 - val_accuracy: 0.5109 - 297ms/epoch - 23ms/step\n",
            "Epoch 299/300\n",
            "13/13 - 0s - loss: 0.9141 - accuracy: 0.6969 - val_loss: 1.8936 - val_accuracy: 0.4703 - 291ms/epoch - 22ms/step\n",
            "Epoch 300/300\n",
            "13/13 - 0s - loss: 1.0338 - accuracy: 0.6698 - val_loss: 2.0999 - val_accuracy: 0.4993 - 291ms/epoch - 22ms/step\n",
            "Model: \"sequential_87\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_174 (Conv2D)         (None, 4, 36, 80)         27440     \n",
            "                                                                 \n",
            " max_pooling2d_174 (MaxPooli  (None, 1, 12, 80)        0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_87 (Bat  (None, 1, 12, 80)        320       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv2d_175 (Conv2D)         (None, 1, 10, 80)         19280     \n",
            "                                                                 \n",
            " max_pooling2d_175 (MaxPooli  (None, 1, 3, 80)         0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " flatten_87 (Flatten)        (None, 240)               0         \n",
            "                                                                 \n",
            " dense_261 (Dense)           (None, 5000)              1205000   \n",
            "                                                                 \n",
            " dropout_174 (Dropout)       (None, 5000)              0         \n",
            "                                                                 \n",
            " dense_262 (Dense)           (None, 5000)              25005000  \n",
            "                                                                 \n",
            " dropout_175 (Dropout)       (None, 5000)              0         \n",
            "                                                                 \n",
            " dense_263 (Dense)           (None, 10)                50010     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 26,307,050\n",
            "Trainable params: 26,306,890\n",
            "Non-trainable params: 160\n",
            "_________________________________________________________________\n",
            "None\n",
            "Result of fold:1\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 4.4873 - accuracy: 0.3979\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 10%|█         | 1/10 [01:33<14:00, 93.39s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(6900, 60, 41)\n",
            "Epoch 1/300\n",
            "13/13 - 1s - loss: 4.8789 - accuracy: 0.1597 - val_loss: 2.1826 - val_accuracy: 0.1826 - 1s/epoch - 82ms/step\n",
            "Epoch 2/300\n",
            "13/13 - 0s - loss: 2.0640 - accuracy: 0.2465 - val_loss: 2.0131 - val_accuracy: 0.2652 - 295ms/epoch - 23ms/step\n",
            "Epoch 3/300\n",
            "13/13 - 0s - loss: 1.9833 - accuracy: 0.2789 - val_loss: 1.9925 - val_accuracy: 0.2304 - 290ms/epoch - 22ms/step\n",
            "Epoch 4/300\n",
            "13/13 - 0s - loss: 1.9073 - accuracy: 0.3068 - val_loss: 1.8757 - val_accuracy: 0.3000 - 298ms/epoch - 23ms/step\n",
            "Epoch 5/300\n",
            "13/13 - 0s - loss: 1.8359 - accuracy: 0.3179 - val_loss: 1.8516 - val_accuracy: 0.2899 - 299ms/epoch - 23ms/step\n",
            "Epoch 6/300\n",
            "13/13 - 0s - loss: 1.7759 - accuracy: 0.3422 - val_loss: 1.8045 - val_accuracy: 0.3043 - 295ms/epoch - 23ms/step\n",
            "Epoch 7/300\n",
            "13/13 - 0s - loss: 1.8374 - accuracy: 0.3272 - val_loss: 1.8036 - val_accuracy: 0.3594 - 302ms/epoch - 23ms/step\n",
            "Epoch 8/300\n",
            "13/13 - 0s - loss: 1.7240 - accuracy: 0.3705 - val_loss: 1.7876 - val_accuracy: 0.3043 - 297ms/epoch - 23ms/step\n",
            "Epoch 9/300\n",
            "13/13 - 0s - loss: 1.7237 - accuracy: 0.3852 - val_loss: 1.9611 - val_accuracy: 0.2565 - 291ms/epoch - 22ms/step\n",
            "Epoch 10/300\n",
            "13/13 - 0s - loss: 1.7201 - accuracy: 0.3884 - val_loss: 1.8741 - val_accuracy: 0.3188 - 291ms/epoch - 22ms/step\n",
            "Epoch 11/300\n",
            "13/13 - 0s - loss: 1.6371 - accuracy: 0.4055 - val_loss: 1.7377 - val_accuracy: 0.3826 - 295ms/epoch - 23ms/step\n",
            "Epoch 12/300\n",
            "13/13 - 0s - loss: 1.5747 - accuracy: 0.4404 - val_loss: 1.8094 - val_accuracy: 0.3087 - 297ms/epoch - 23ms/step\n",
            "Epoch 13/300\n",
            "13/13 - 0s - loss: 1.6234 - accuracy: 0.4196 - val_loss: 1.8547 - val_accuracy: 0.3406 - 297ms/epoch - 23ms/step\n",
            "Epoch 14/300\n",
            "13/13 - 0s - loss: 1.5493 - accuracy: 0.4567 - val_loss: 1.7559 - val_accuracy: 0.3754 - 295ms/epoch - 23ms/step\n",
            "Epoch 15/300\n",
            "13/13 - 0s - loss: 1.5327 - accuracy: 0.4481 - val_loss: 1.9004 - val_accuracy: 0.3580 - 296ms/epoch - 23ms/step\n",
            "Epoch 16/300\n",
            "13/13 - 0s - loss: 1.4758 - accuracy: 0.4742 - val_loss: 1.7557 - val_accuracy: 0.3580 - 289ms/epoch - 22ms/step\n",
            "Epoch 17/300\n",
            "13/13 - 0s - loss: 1.4304 - accuracy: 0.4984 - val_loss: 1.8180 - val_accuracy: 0.3449 - 292ms/epoch - 22ms/step\n",
            "Epoch 18/300\n",
            "13/13 - 0s - loss: 1.4810 - accuracy: 0.4797 - val_loss: 1.7013 - val_accuracy: 0.3667 - 295ms/epoch - 23ms/step\n",
            "Epoch 19/300\n",
            "13/13 - 0s - loss: 1.4866 - accuracy: 0.4776 - val_loss: 1.6646 - val_accuracy: 0.3986 - 294ms/epoch - 23ms/step\n",
            "Epoch 20/300\n",
            "13/13 - 0s - loss: 1.4757 - accuracy: 0.4741 - val_loss: 1.7575 - val_accuracy: 0.4058 - 298ms/epoch - 23ms/step\n",
            "Epoch 21/300\n",
            "13/13 - 0s - loss: 1.4871 - accuracy: 0.4754 - val_loss: 1.6672 - val_accuracy: 0.4406 - 297ms/epoch - 23ms/step\n",
            "Epoch 22/300\n",
            "13/13 - 0s - loss: 1.4847 - accuracy: 0.4784 - val_loss: 1.6868 - val_accuracy: 0.3884 - 305ms/epoch - 23ms/step\n",
            "Epoch 23/300\n",
            "13/13 - 0s - loss: 1.4291 - accuracy: 0.4894 - val_loss: 1.6679 - val_accuracy: 0.4101 - 300ms/epoch - 23ms/step\n",
            "Epoch 24/300\n",
            "13/13 - 0s - loss: 1.3651 - accuracy: 0.5158 - val_loss: 1.6112 - val_accuracy: 0.3884 - 293ms/epoch - 23ms/step\n",
            "Epoch 25/300\n",
            "13/13 - 0s - loss: 1.3396 - accuracy: 0.5206 - val_loss: 1.5714 - val_accuracy: 0.4942 - 292ms/epoch - 22ms/step\n",
            "Epoch 26/300\n",
            "13/13 - 0s - loss: 1.3170 - accuracy: 0.5303 - val_loss: 1.5554 - val_accuracy: 0.4986 - 300ms/epoch - 23ms/step\n",
            "Epoch 27/300\n",
            "13/13 - 0s - loss: 1.2951 - accuracy: 0.5456 - val_loss: 1.6320 - val_accuracy: 0.4971 - 297ms/epoch - 23ms/step\n",
            "Epoch 28/300\n",
            "13/13 - 0s - loss: 1.2902 - accuracy: 0.5478 - val_loss: 1.5814 - val_accuracy: 0.4826 - 297ms/epoch - 23ms/step\n",
            "Epoch 29/300\n",
            "13/13 - 0s - loss: 1.2701 - accuracy: 0.5596 - val_loss: 1.6703 - val_accuracy: 0.4522 - 303ms/epoch - 23ms/step\n",
            "Epoch 30/300\n",
            "13/13 - 0s - loss: 1.3419 - accuracy: 0.5356 - val_loss: 1.6460 - val_accuracy: 0.4841 - 298ms/epoch - 23ms/step\n",
            "Epoch 31/300\n",
            "13/13 - 0s - loss: 1.3064 - accuracy: 0.5441 - val_loss: 1.7378 - val_accuracy: 0.4855 - 303ms/epoch - 23ms/step\n",
            "Epoch 32/300\n",
            "13/13 - 0s - loss: 1.2588 - accuracy: 0.5597 - val_loss: 1.6148 - val_accuracy: 0.4884 - 302ms/epoch - 23ms/step\n",
            "Epoch 33/300\n",
            "13/13 - 0s - loss: 1.3332 - accuracy: 0.5469 - val_loss: 1.4989 - val_accuracy: 0.4928 - 307ms/epoch - 24ms/step\n",
            "Epoch 34/300\n",
            "13/13 - 0s - loss: 1.2783 - accuracy: 0.5604 - val_loss: 1.6798 - val_accuracy: 0.4841 - 300ms/epoch - 23ms/step\n",
            "Epoch 35/300\n",
            "13/13 - 0s - loss: 1.1837 - accuracy: 0.5900 - val_loss: 1.5350 - val_accuracy: 0.5246 - 307ms/epoch - 24ms/step\n",
            "Epoch 36/300\n",
            "13/13 - 0s - loss: 1.2572 - accuracy: 0.5519 - val_loss: 1.7496 - val_accuracy: 0.4899 - 302ms/epoch - 23ms/step\n",
            "Epoch 37/300\n",
            "13/13 - 0s - loss: 1.2975 - accuracy: 0.5691 - val_loss: 1.8648 - val_accuracy: 0.4348 - 305ms/epoch - 23ms/step\n",
            "Epoch 38/300\n",
            "13/13 - 0s - loss: 1.3006 - accuracy: 0.5585 - val_loss: 1.6336 - val_accuracy: 0.4928 - 299ms/epoch - 23ms/step\n",
            "Epoch 39/300\n",
            "13/13 - 0s - loss: 1.2417 - accuracy: 0.5725 - val_loss: 1.6397 - val_accuracy: 0.4333 - 296ms/epoch - 23ms/step\n",
            "Epoch 40/300\n",
            "13/13 - 0s - loss: 1.2521 - accuracy: 0.5681 - val_loss: 1.5396 - val_accuracy: 0.5087 - 295ms/epoch - 23ms/step\n",
            "Epoch 41/300\n",
            "13/13 - 0s - loss: 1.2117 - accuracy: 0.5829 - val_loss: 1.7174 - val_accuracy: 0.4942 - 299ms/epoch - 23ms/step\n",
            "Epoch 42/300\n",
            "13/13 - 0s - loss: 1.1877 - accuracy: 0.5821 - val_loss: 1.7200 - val_accuracy: 0.4667 - 298ms/epoch - 23ms/step\n",
            "Epoch 43/300\n",
            "13/13 - 0s - loss: 1.1526 - accuracy: 0.5921 - val_loss: 1.8392 - val_accuracy: 0.4174 - 291ms/epoch - 22ms/step\n",
            "Epoch 44/300\n",
            "13/13 - 0s - loss: 1.1908 - accuracy: 0.5900 - val_loss: 1.7641 - val_accuracy: 0.4188 - 293ms/epoch - 23ms/step\n",
            "Epoch 45/300\n",
            "13/13 - 0s - loss: 1.1544 - accuracy: 0.5881 - val_loss: 1.7332 - val_accuracy: 0.4783 - 299ms/epoch - 23ms/step\n",
            "Epoch 46/300\n",
            "13/13 - 0s - loss: 1.1847 - accuracy: 0.5973 - val_loss: 1.5668 - val_accuracy: 0.5043 - 301ms/epoch - 23ms/step\n",
            "Epoch 47/300\n",
            "13/13 - 0s - loss: 1.1708 - accuracy: 0.5977 - val_loss: 1.7308 - val_accuracy: 0.4275 - 299ms/epoch - 23ms/step\n",
            "Epoch 48/300\n",
            "13/13 - 0s - loss: 1.1314 - accuracy: 0.6103 - val_loss: 1.6502 - val_accuracy: 0.5000 - 297ms/epoch - 23ms/step\n",
            "Epoch 49/300\n",
            "13/13 - 0s - loss: 1.2494 - accuracy: 0.5688 - val_loss: 1.6134 - val_accuracy: 0.4449 - 296ms/epoch - 23ms/step\n",
            "Epoch 50/300\n",
            "13/13 - 0s - loss: 1.2260 - accuracy: 0.5734 - val_loss: 1.6740 - val_accuracy: 0.4609 - 297ms/epoch - 23ms/step\n",
            "Epoch 51/300\n",
            "13/13 - 0s - loss: 1.2185 - accuracy: 0.5849 - val_loss: 1.7964 - val_accuracy: 0.4391 - 295ms/epoch - 23ms/step\n",
            "Epoch 52/300\n",
            "13/13 - 0s - loss: 1.2538 - accuracy: 0.5681 - val_loss: 1.6200 - val_accuracy: 0.5043 - 297ms/epoch - 23ms/step\n",
            "Epoch 53/300\n",
            "13/13 - 0s - loss: 1.1350 - accuracy: 0.5932 - val_loss: 1.6497 - val_accuracy: 0.4913 - 292ms/epoch - 22ms/step\n",
            "Epoch 54/300\n",
            "13/13 - 0s - loss: 1.1788 - accuracy: 0.5924 - val_loss: 1.7201 - val_accuracy: 0.4449 - 297ms/epoch - 23ms/step\n",
            "Epoch 55/300\n",
            "13/13 - 0s - loss: 1.1539 - accuracy: 0.6011 - val_loss: 1.6872 - val_accuracy: 0.4681 - 289ms/epoch - 22ms/step\n",
            "Epoch 56/300\n",
            "13/13 - 0s - loss: 1.1688 - accuracy: 0.6011 - val_loss: 1.7743 - val_accuracy: 0.4957 - 294ms/epoch - 23ms/step\n",
            "Epoch 57/300\n",
            "13/13 - 0s - loss: 1.1149 - accuracy: 0.6166 - val_loss: 1.8401 - val_accuracy: 0.5174 - 299ms/epoch - 23ms/step\n",
            "Epoch 58/300\n",
            "13/13 - 0s - loss: 1.2408 - accuracy: 0.5820 - val_loss: 2.0437 - val_accuracy: 0.4159 - 297ms/epoch - 23ms/step\n",
            "Epoch 59/300\n",
            "13/13 - 0s - loss: 1.2914 - accuracy: 0.5839 - val_loss: 1.9800 - val_accuracy: 0.4580 - 299ms/epoch - 23ms/step\n",
            "Epoch 60/300\n",
            "13/13 - 0s - loss: 1.1769 - accuracy: 0.6026 - val_loss: 1.9216 - val_accuracy: 0.4058 - 292ms/epoch - 22ms/step\n",
            "Epoch 61/300\n",
            "13/13 - 0s - loss: 1.1162 - accuracy: 0.6047 - val_loss: 1.8006 - val_accuracy: 0.4493 - 299ms/epoch - 23ms/step\n",
            "Epoch 62/300\n",
            "13/13 - 0s - loss: 1.1066 - accuracy: 0.6093 - val_loss: 1.8663 - val_accuracy: 0.4522 - 295ms/epoch - 23ms/step\n",
            "Epoch 63/300\n",
            "13/13 - 0s - loss: 1.1193 - accuracy: 0.6272 - val_loss: 1.6276 - val_accuracy: 0.4812 - 293ms/epoch - 23ms/step\n",
            "Epoch 64/300\n",
            "13/13 - 0s - loss: 1.0995 - accuracy: 0.6190 - val_loss: 1.6132 - val_accuracy: 0.4652 - 301ms/epoch - 23ms/step\n",
            "Epoch 65/300\n",
            "13/13 - 0s - loss: 1.1331 - accuracy: 0.6052 - val_loss: 1.7155 - val_accuracy: 0.4449 - 299ms/epoch - 23ms/step\n",
            "Epoch 66/300\n",
            "13/13 - 0s - loss: 1.1290 - accuracy: 0.6050 - val_loss: 2.0337 - val_accuracy: 0.4333 - 296ms/epoch - 23ms/step\n",
            "Epoch 67/300\n",
            "13/13 - 0s - loss: 1.1629 - accuracy: 0.5974 - val_loss: 1.5758 - val_accuracy: 0.4812 - 295ms/epoch - 23ms/step\n",
            "Epoch 68/300\n",
            "13/13 - 0s - loss: 1.1735 - accuracy: 0.5997 - val_loss: 1.7885 - val_accuracy: 0.4667 - 292ms/epoch - 22ms/step\n",
            "Epoch 69/300\n",
            "13/13 - 0s - loss: 1.2183 - accuracy: 0.5960 - val_loss: 1.7110 - val_accuracy: 0.4420 - 293ms/epoch - 23ms/step\n",
            "Epoch 70/300\n",
            "13/13 - 0s - loss: 1.1407 - accuracy: 0.6177 - val_loss: 2.0174 - val_accuracy: 0.5029 - 294ms/epoch - 23ms/step\n",
            "Epoch 71/300\n",
            "13/13 - 0s - loss: 1.1720 - accuracy: 0.6127 - val_loss: 1.5857 - val_accuracy: 0.5391 - 298ms/epoch - 23ms/step\n",
            "Epoch 72/300\n",
            "13/13 - 0s - loss: 1.0797 - accuracy: 0.6332 - val_loss: 1.7785 - val_accuracy: 0.4681 - 299ms/epoch - 23ms/step\n",
            "Epoch 73/300\n",
            "13/13 - 0s - loss: 1.1646 - accuracy: 0.6079 - val_loss: 1.7897 - val_accuracy: 0.4667 - 298ms/epoch - 23ms/step\n",
            "Epoch 74/300\n",
            "13/13 - 0s - loss: 1.1313 - accuracy: 0.6159 - val_loss: 1.7060 - val_accuracy: 0.4942 - 296ms/epoch - 23ms/step\n",
            "Epoch 75/300\n",
            "13/13 - 0s - loss: 1.1706 - accuracy: 0.6209 - val_loss: 1.7100 - val_accuracy: 0.4333 - 294ms/epoch - 23ms/step\n",
            "Epoch 76/300\n",
            "13/13 - 0s - loss: 1.1303 - accuracy: 0.6058 - val_loss: 1.8322 - val_accuracy: 0.4812 - 301ms/epoch - 23ms/step\n",
            "Epoch 77/300\n",
            "13/13 - 0s - loss: 1.1227 - accuracy: 0.6240 - val_loss: 1.6437 - val_accuracy: 0.4174 - 300ms/epoch - 23ms/step\n",
            "Epoch 78/300\n",
            "13/13 - 0s - loss: 1.0547 - accuracy: 0.6317 - val_loss: 1.6358 - val_accuracy: 0.4942 - 292ms/epoch - 22ms/step\n",
            "Epoch 79/300\n",
            "13/13 - 0s - loss: 1.0407 - accuracy: 0.6259 - val_loss: 1.9992 - val_accuracy: 0.4420 - 301ms/epoch - 23ms/step\n",
            "Epoch 80/300\n",
            "13/13 - 0s - loss: 1.2213 - accuracy: 0.5913 - val_loss: 1.8785 - val_accuracy: 0.3826 - 294ms/epoch - 23ms/step\n",
            "Epoch 81/300\n",
            "13/13 - 0s - loss: 1.1640 - accuracy: 0.5986 - val_loss: 1.6159 - val_accuracy: 0.4420 - 300ms/epoch - 23ms/step\n",
            "Epoch 82/300\n",
            "13/13 - 0s - loss: 1.1154 - accuracy: 0.6113 - val_loss: 1.5711 - val_accuracy: 0.4681 - 291ms/epoch - 22ms/step\n",
            "Epoch 83/300\n",
            "13/13 - 0s - loss: 1.0995 - accuracy: 0.6280 - val_loss: 1.5755 - val_accuracy: 0.5232 - 296ms/epoch - 23ms/step\n",
            "Epoch 84/300\n",
            "13/13 - 0s - loss: 1.0998 - accuracy: 0.6243 - val_loss: 2.1829 - val_accuracy: 0.4304 - 293ms/epoch - 23ms/step\n",
            "Epoch 85/300\n",
            "13/13 - 0s - loss: 1.2150 - accuracy: 0.5977 - val_loss: 1.9881 - val_accuracy: 0.4217 - 296ms/epoch - 23ms/step\n",
            "Epoch 86/300\n",
            "13/13 - 0s - loss: 1.1944 - accuracy: 0.6006 - val_loss: 1.9605 - val_accuracy: 0.4594 - 293ms/epoch - 23ms/step\n",
            "Epoch 87/300\n",
            "13/13 - 0s - loss: 1.2099 - accuracy: 0.6055 - val_loss: 1.7387 - val_accuracy: 0.4493 - 300ms/epoch - 23ms/step\n",
            "Epoch 88/300\n",
            "13/13 - 0s - loss: 1.1656 - accuracy: 0.6035 - val_loss: 1.6679 - val_accuracy: 0.4246 - 302ms/epoch - 23ms/step\n",
            "Epoch 89/300\n",
            "13/13 - 0s - loss: 1.0822 - accuracy: 0.6167 - val_loss: 1.7650 - val_accuracy: 0.4797 - 294ms/epoch - 23ms/step\n",
            "Epoch 90/300\n",
            "13/13 - 0s - loss: 1.1108 - accuracy: 0.6224 - val_loss: 1.8644 - val_accuracy: 0.3957 - 291ms/epoch - 22ms/step\n",
            "Epoch 91/300\n",
            "13/13 - 0s - loss: 1.2113 - accuracy: 0.6037 - val_loss: 1.7695 - val_accuracy: 0.4841 - 294ms/epoch - 23ms/step\n",
            "Epoch 92/300\n",
            "13/13 - 0s - loss: 1.1773 - accuracy: 0.6126 - val_loss: 1.7525 - val_accuracy: 0.4957 - 293ms/epoch - 23ms/step\n",
            "Epoch 93/300\n",
            "13/13 - 0s - loss: 1.2154 - accuracy: 0.6100 - val_loss: 1.8032 - val_accuracy: 0.4638 - 290ms/epoch - 22ms/step\n",
            "Epoch 94/300\n",
            "13/13 - 0s - loss: 1.2265 - accuracy: 0.5950 - val_loss: 1.9451 - val_accuracy: 0.4870 - 298ms/epoch - 23ms/step\n",
            "Epoch 95/300\n",
            "13/13 - 0s - loss: 1.1451 - accuracy: 0.6092 - val_loss: 1.8120 - val_accuracy: 0.4812 - 296ms/epoch - 23ms/step\n",
            "Epoch 96/300\n",
            "13/13 - 0s - loss: 1.1140 - accuracy: 0.6121 - val_loss: 1.6894 - val_accuracy: 0.4710 - 291ms/epoch - 22ms/step\n",
            "Epoch 97/300\n",
            "13/13 - 0s - loss: 1.0802 - accuracy: 0.6253 - val_loss: 1.6459 - val_accuracy: 0.5493 - 295ms/epoch - 23ms/step\n",
            "Epoch 98/300\n",
            "13/13 - 0s - loss: 1.0368 - accuracy: 0.6306 - val_loss: 1.9160 - val_accuracy: 0.4638 - 293ms/epoch - 23ms/step\n",
            "Epoch 99/300\n",
            "13/13 - 0s - loss: 1.0083 - accuracy: 0.6390 - val_loss: 1.9639 - val_accuracy: 0.5101 - 298ms/epoch - 23ms/step\n",
            "Epoch 100/300\n",
            "13/13 - 0s - loss: 1.1199 - accuracy: 0.6126 - val_loss: 1.9835 - val_accuracy: 0.3957 - 293ms/epoch - 23ms/step\n",
            "Epoch 101/300\n",
            "13/13 - 0s - loss: 1.0256 - accuracy: 0.6325 - val_loss: 1.7955 - val_accuracy: 0.4899 - 295ms/epoch - 23ms/step\n",
            "Epoch 102/300\n",
            "13/13 - 0s - loss: 1.0146 - accuracy: 0.6473 - val_loss: 1.7219 - val_accuracy: 0.4870 - 302ms/epoch - 23ms/step\n",
            "Epoch 103/300\n",
            "13/13 - 0s - loss: 1.0243 - accuracy: 0.6396 - val_loss: 1.7514 - val_accuracy: 0.4623 - 302ms/epoch - 23ms/step\n",
            "Epoch 104/300\n",
            "13/13 - 0s - loss: 1.0285 - accuracy: 0.6362 - val_loss: 1.7651 - val_accuracy: 0.4391 - 300ms/epoch - 23ms/step\n",
            "Epoch 105/300\n",
            "13/13 - 0s - loss: 1.0557 - accuracy: 0.6267 - val_loss: 1.8034 - val_accuracy: 0.4812 - 297ms/epoch - 23ms/step\n",
            "Epoch 106/300\n",
            "13/13 - 0s - loss: 1.1657 - accuracy: 0.6233 - val_loss: 1.6525 - val_accuracy: 0.5101 - 298ms/epoch - 23ms/step\n",
            "Epoch 107/300\n",
            "13/13 - 0s - loss: 1.1717 - accuracy: 0.6251 - val_loss: 1.7206 - val_accuracy: 0.4261 - 297ms/epoch - 23ms/step\n",
            "Epoch 108/300\n",
            "13/13 - 0s - loss: 1.1036 - accuracy: 0.6353 - val_loss: 1.7528 - val_accuracy: 0.4435 - 302ms/epoch - 23ms/step\n",
            "Epoch 109/300\n",
            "13/13 - 0s - loss: 1.0711 - accuracy: 0.6346 - val_loss: 2.0071 - val_accuracy: 0.4870 - 312ms/epoch - 24ms/step\n",
            "Epoch 110/300\n",
            "13/13 - 0s - loss: 1.1946 - accuracy: 0.6116 - val_loss: 1.8379 - val_accuracy: 0.4681 - 310ms/epoch - 24ms/step\n",
            "Epoch 111/300\n",
            "13/13 - 0s - loss: 1.1748 - accuracy: 0.6121 - val_loss: 1.5902 - val_accuracy: 0.5275 - 305ms/epoch - 23ms/step\n",
            "Epoch 112/300\n",
            "13/13 - 0s - loss: 1.1672 - accuracy: 0.6158 - val_loss: 1.6670 - val_accuracy: 0.5116 - 302ms/epoch - 23ms/step\n",
            "Epoch 113/300\n",
            "13/13 - 0s - loss: 1.1132 - accuracy: 0.6150 - val_loss: 1.6541 - val_accuracy: 0.4826 - 305ms/epoch - 23ms/step\n",
            "Epoch 114/300\n",
            "13/13 - 0s - loss: 1.1682 - accuracy: 0.6118 - val_loss: 1.5751 - val_accuracy: 0.5391 - 300ms/epoch - 23ms/step\n",
            "Epoch 115/300\n",
            "13/13 - 0s - loss: 1.2054 - accuracy: 0.5973 - val_loss: 1.6726 - val_accuracy: 0.4406 - 310ms/epoch - 24ms/step\n",
            "Epoch 116/300\n",
            "13/13 - 0s - loss: 1.1113 - accuracy: 0.6143 - val_loss: 1.7137 - val_accuracy: 0.5348 - 299ms/epoch - 23ms/step\n",
            "Epoch 117/300\n",
            "13/13 - 0s - loss: 1.0361 - accuracy: 0.6452 - val_loss: 1.7953 - val_accuracy: 0.4957 - 299ms/epoch - 23ms/step\n",
            "Epoch 118/300\n",
            "13/13 - 0s - loss: 1.0114 - accuracy: 0.6501 - val_loss: 1.8213 - val_accuracy: 0.4739 - 299ms/epoch - 23ms/step\n",
            "Epoch 119/300\n",
            "13/13 - 0s - loss: 1.2781 - accuracy: 0.5976 - val_loss: 1.7212 - val_accuracy: 0.4826 - 301ms/epoch - 23ms/step\n",
            "Epoch 120/300\n",
            "13/13 - 0s - loss: 1.1560 - accuracy: 0.5894 - val_loss: 1.8520 - val_accuracy: 0.4870 - 308ms/epoch - 24ms/step\n",
            "Epoch 121/300\n",
            "13/13 - 0s - loss: 1.0631 - accuracy: 0.6246 - val_loss: 1.7086 - val_accuracy: 0.5145 - 303ms/epoch - 23ms/step\n",
            "Epoch 122/300\n",
            "13/13 - 0s - loss: 1.0365 - accuracy: 0.6280 - val_loss: 1.6996 - val_accuracy: 0.4841 - 297ms/epoch - 23ms/step\n",
            "Epoch 123/300\n",
            "13/13 - 0s - loss: 0.9864 - accuracy: 0.6557 - val_loss: 1.9578 - val_accuracy: 0.5000 - 294ms/epoch - 23ms/step\n",
            "Epoch 124/300\n",
            "13/13 - 0s - loss: 0.9760 - accuracy: 0.6491 - val_loss: 1.9630 - val_accuracy: 0.5174 - 300ms/epoch - 23ms/step\n",
            "Epoch 125/300\n",
            "13/13 - 0s - loss: 1.0048 - accuracy: 0.6475 - val_loss: 1.9315 - val_accuracy: 0.5159 - 303ms/epoch - 23ms/step\n",
            "Epoch 126/300\n",
            "13/13 - 0s - loss: 0.9933 - accuracy: 0.6520 - val_loss: 2.0822 - val_accuracy: 0.5159 - 297ms/epoch - 23ms/step\n",
            "Epoch 127/300\n",
            "13/13 - 0s - loss: 1.0509 - accuracy: 0.6385 - val_loss: 2.2144 - val_accuracy: 0.4667 - 295ms/epoch - 23ms/step\n",
            "Epoch 128/300\n",
            "13/13 - 0s - loss: 1.0623 - accuracy: 0.6361 - val_loss: 1.9425 - val_accuracy: 0.5203 - 296ms/epoch - 23ms/step\n",
            "Epoch 129/300\n",
            "13/13 - 0s - loss: 1.0070 - accuracy: 0.6520 - val_loss: 1.9996 - val_accuracy: 0.5377 - 301ms/epoch - 23ms/step\n",
            "Epoch 130/300\n",
            "13/13 - 0s - loss: 0.9945 - accuracy: 0.6488 - val_loss: 1.9794 - val_accuracy: 0.5000 - 297ms/epoch - 23ms/step\n",
            "Epoch 131/300\n",
            "13/13 - 0s - loss: 0.9972 - accuracy: 0.6554 - val_loss: 2.1115 - val_accuracy: 0.4725 - 293ms/epoch - 23ms/step\n",
            "Epoch 132/300\n",
            "13/13 - 0s - loss: 1.0242 - accuracy: 0.6403 - val_loss: 1.9753 - val_accuracy: 0.5464 - 299ms/epoch - 23ms/step\n",
            "Epoch 133/300\n",
            "13/13 - 0s - loss: 0.9498 - accuracy: 0.6639 - val_loss: 2.0288 - val_accuracy: 0.4551 - 294ms/epoch - 23ms/step\n",
            "Epoch 134/300\n",
            "13/13 - 0s - loss: 0.9850 - accuracy: 0.6531 - val_loss: 2.0501 - val_accuracy: 0.4565 - 296ms/epoch - 23ms/step\n",
            "Epoch 135/300\n",
            "13/13 - 0s - loss: 0.9806 - accuracy: 0.6509 - val_loss: 2.0144 - val_accuracy: 0.4768 - 297ms/epoch - 23ms/step\n",
            "Epoch 136/300\n",
            "13/13 - 0s - loss: 0.9629 - accuracy: 0.6607 - val_loss: 1.8697 - val_accuracy: 0.5275 - 295ms/epoch - 23ms/step\n",
            "Epoch 137/300\n",
            "13/13 - 0s - loss: 0.9870 - accuracy: 0.6568 - val_loss: 2.0567 - val_accuracy: 0.4783 - 298ms/epoch - 23ms/step\n",
            "Epoch 138/300\n",
            "13/13 - 0s - loss: 0.9635 - accuracy: 0.6655 - val_loss: 2.1005 - val_accuracy: 0.4478 - 297ms/epoch - 23ms/step\n",
            "Epoch 139/300\n",
            "13/13 - 0s - loss: 0.9279 - accuracy: 0.6755 - val_loss: 1.9349 - val_accuracy: 0.4971 - 297ms/epoch - 23ms/step\n",
            "Epoch 140/300\n",
            "13/13 - 0s - loss: 0.9778 - accuracy: 0.6659 - val_loss: 1.7910 - val_accuracy: 0.4580 - 294ms/epoch - 23ms/step\n",
            "Epoch 141/300\n",
            "13/13 - 0s - loss: 0.9657 - accuracy: 0.6649 - val_loss: 1.9469 - val_accuracy: 0.4348 - 291ms/epoch - 22ms/step\n",
            "Epoch 142/300\n",
            "13/13 - 0s - loss: 0.9921 - accuracy: 0.6506 - val_loss: 1.7363 - val_accuracy: 0.5014 - 293ms/epoch - 23ms/step\n",
            "Epoch 143/300\n",
            "13/13 - 0s - loss: 0.9630 - accuracy: 0.6651 - val_loss: 1.9446 - val_accuracy: 0.4565 - 294ms/epoch - 23ms/step\n",
            "Epoch 144/300\n",
            "13/13 - 0s - loss: 1.0356 - accuracy: 0.6488 - val_loss: 1.8177 - val_accuracy: 0.5348 - 289ms/epoch - 22ms/step\n",
            "Epoch 145/300\n",
            "13/13 - 0s - loss: 1.0969 - accuracy: 0.6254 - val_loss: 1.8170 - val_accuracy: 0.4928 - 296ms/epoch - 23ms/step\n",
            "Epoch 146/300\n",
            "13/13 - 0s - loss: 1.1074 - accuracy: 0.6519 - val_loss: 1.7725 - val_accuracy: 0.5014 - 298ms/epoch - 23ms/step\n",
            "Epoch 147/300\n",
            "13/13 - 0s - loss: 1.0800 - accuracy: 0.6528 - val_loss: 1.9887 - val_accuracy: 0.4261 - 298ms/epoch - 23ms/step\n",
            "Epoch 148/300\n",
            "13/13 - 0s - loss: 1.0613 - accuracy: 0.6393 - val_loss: 1.7449 - val_accuracy: 0.4507 - 291ms/epoch - 22ms/step\n",
            "Epoch 149/300\n",
            "13/13 - 0s - loss: 0.9920 - accuracy: 0.6567 - val_loss: 1.8366 - val_accuracy: 0.5116 - 294ms/epoch - 23ms/step\n",
            "Epoch 150/300\n",
            "13/13 - 0s - loss: 0.9717 - accuracy: 0.6622 - val_loss: 1.6585 - val_accuracy: 0.5217 - 303ms/epoch - 23ms/step\n",
            "Epoch 151/300\n",
            "13/13 - 0s - loss: 0.9345 - accuracy: 0.6768 - val_loss: 1.7651 - val_accuracy: 0.5058 - 291ms/epoch - 22ms/step\n",
            "Epoch 152/300\n",
            "13/13 - 0s - loss: 0.9673 - accuracy: 0.6713 - val_loss: 1.9261 - val_accuracy: 0.5101 - 296ms/epoch - 23ms/step\n",
            "Epoch 153/300\n",
            "13/13 - 0s - loss: 0.9302 - accuracy: 0.6713 - val_loss: 1.9483 - val_accuracy: 0.5101 - 297ms/epoch - 23ms/step\n",
            "Epoch 154/300\n",
            "13/13 - 0s - loss: 0.9619 - accuracy: 0.6662 - val_loss: 2.1112 - val_accuracy: 0.4609 - 296ms/epoch - 23ms/step\n",
            "Epoch 155/300\n",
            "13/13 - 0s - loss: 1.0198 - accuracy: 0.6496 - val_loss: 2.2825 - val_accuracy: 0.4609 - 292ms/epoch - 22ms/step\n",
            "Epoch 156/300\n",
            "13/13 - 0s - loss: 1.0082 - accuracy: 0.6507 - val_loss: 2.1582 - val_accuracy: 0.4768 - 299ms/epoch - 23ms/step\n",
            "Epoch 157/300\n",
            "13/13 - 0s - loss: 1.1950 - accuracy: 0.6166 - val_loss: 1.7667 - val_accuracy: 0.5348 - 293ms/epoch - 23ms/step\n",
            "Epoch 158/300\n",
            "13/13 - 0s - loss: 1.1287 - accuracy: 0.6116 - val_loss: 1.7089 - val_accuracy: 0.4870 - 296ms/epoch - 23ms/step\n",
            "Epoch 159/300\n",
            "13/13 - 0s - loss: 0.9965 - accuracy: 0.6382 - val_loss: 1.8251 - val_accuracy: 0.5072 - 298ms/epoch - 23ms/step\n",
            "Epoch 160/300\n",
            "13/13 - 0s - loss: 0.9683 - accuracy: 0.6556 - val_loss: 1.8774 - val_accuracy: 0.5101 - 295ms/epoch - 23ms/step\n",
            "Epoch 161/300\n",
            "13/13 - 0s - loss: 0.9494 - accuracy: 0.6657 - val_loss: 1.7947 - val_accuracy: 0.4754 - 291ms/epoch - 22ms/step\n",
            "Epoch 162/300\n",
            "13/13 - 0s - loss: 0.9637 - accuracy: 0.6605 - val_loss: 1.7733 - val_accuracy: 0.5087 - 291ms/epoch - 22ms/step\n",
            "Epoch 163/300\n",
            "13/13 - 0s - loss: 0.9374 - accuracy: 0.6622 - val_loss: 1.8258 - val_accuracy: 0.5478 - 295ms/epoch - 23ms/step\n",
            "Epoch 164/300\n",
            "13/13 - 0s - loss: 0.9426 - accuracy: 0.6636 - val_loss: 2.1212 - val_accuracy: 0.5101 - 301ms/epoch - 23ms/step\n",
            "Epoch 165/300\n",
            "13/13 - 0s - loss: 0.9345 - accuracy: 0.6601 - val_loss: 2.3728 - val_accuracy: 0.4638 - 293ms/epoch - 23ms/step\n",
            "Epoch 166/300\n",
            "13/13 - 0s - loss: 0.8619 - accuracy: 0.6884 - val_loss: 2.3889 - val_accuracy: 0.4971 - 293ms/epoch - 23ms/step\n",
            "Epoch 167/300\n",
            "13/13 - 0s - loss: 0.8624 - accuracy: 0.6834 - val_loss: 2.2129 - val_accuracy: 0.5319 - 295ms/epoch - 23ms/step\n",
            "Epoch 168/300\n",
            "13/13 - 0s - loss: 0.8502 - accuracy: 0.6992 - val_loss: 2.1372 - val_accuracy: 0.5043 - 291ms/epoch - 22ms/step\n",
            "Epoch 169/300\n",
            "13/13 - 0s - loss: 1.0063 - accuracy: 0.6478 - val_loss: 2.2365 - val_accuracy: 0.4406 - 293ms/epoch - 23ms/step\n",
            "Epoch 170/300\n",
            "13/13 - 0s - loss: 0.9903 - accuracy: 0.6588 - val_loss: 2.1537 - val_accuracy: 0.4754 - 295ms/epoch - 23ms/step\n",
            "Epoch 171/300\n",
            "13/13 - 0s - loss: 1.0116 - accuracy: 0.6541 - val_loss: 1.9481 - val_accuracy: 0.5435 - 293ms/epoch - 23ms/step\n",
            "Epoch 172/300\n",
            "13/13 - 0s - loss: 0.9309 - accuracy: 0.6710 - val_loss: 2.0634 - val_accuracy: 0.5072 - 300ms/epoch - 23ms/step\n",
            "Epoch 173/300\n",
            "13/13 - 0s - loss: 0.9570 - accuracy: 0.6665 - val_loss: 2.0966 - val_accuracy: 0.5014 - 293ms/epoch - 23ms/step\n",
            "Epoch 174/300\n",
            "13/13 - 0s - loss: 0.9958 - accuracy: 0.6630 - val_loss: 1.9573 - val_accuracy: 0.5725 - 297ms/epoch - 23ms/step\n",
            "Epoch 175/300\n",
            "13/13 - 0s - loss: 0.8819 - accuracy: 0.6828 - val_loss: 1.8875 - val_accuracy: 0.5406 - 295ms/epoch - 23ms/step\n",
            "Epoch 176/300\n",
            "13/13 - 0s - loss: 0.8834 - accuracy: 0.6876 - val_loss: 2.1506 - val_accuracy: 0.4870 - 300ms/epoch - 23ms/step\n",
            "Epoch 177/300\n",
            "13/13 - 0s - loss: 0.9371 - accuracy: 0.6768 - val_loss: 2.0089 - val_accuracy: 0.4739 - 297ms/epoch - 23ms/step\n",
            "Epoch 178/300\n",
            "13/13 - 0s - loss: 0.9377 - accuracy: 0.6738 - val_loss: 2.1140 - val_accuracy: 0.5174 - 294ms/epoch - 23ms/step\n",
            "Epoch 179/300\n",
            "13/13 - 0s - loss: 0.9248 - accuracy: 0.6739 - val_loss: 2.4425 - val_accuracy: 0.4928 - 296ms/epoch - 23ms/step\n",
            "Epoch 180/300\n",
            "13/13 - 0s - loss: 0.8803 - accuracy: 0.6826 - val_loss: 2.3468 - val_accuracy: 0.5420 - 297ms/epoch - 23ms/step\n",
            "Epoch 181/300\n",
            "13/13 - 0s - loss: 0.8475 - accuracy: 0.6973 - val_loss: 2.4668 - val_accuracy: 0.5159 - 300ms/epoch - 23ms/step\n",
            "Epoch 182/300\n",
            "13/13 - 0s - loss: 0.8437 - accuracy: 0.6899 - val_loss: 2.4529 - val_accuracy: 0.5536 - 299ms/epoch - 23ms/step\n",
            "Epoch 183/300\n",
            "13/13 - 0s - loss: 0.8349 - accuracy: 0.6928 - val_loss: 2.4962 - val_accuracy: 0.5159 - 292ms/epoch - 22ms/step\n",
            "Epoch 184/300\n",
            "13/13 - 0s - loss: 0.8190 - accuracy: 0.7068 - val_loss: 2.3496 - val_accuracy: 0.5261 - 296ms/epoch - 23ms/step\n",
            "Epoch 185/300\n",
            "13/13 - 0s - loss: 0.8506 - accuracy: 0.7032 - val_loss: 2.1572 - val_accuracy: 0.4986 - 291ms/epoch - 22ms/step\n",
            "Epoch 186/300\n",
            "13/13 - 0s - loss: 0.8274 - accuracy: 0.7000 - val_loss: 2.0990 - val_accuracy: 0.5406 - 299ms/epoch - 23ms/step\n",
            "Epoch 187/300\n",
            "13/13 - 0s - loss: 0.9037 - accuracy: 0.6950 - val_loss: 2.1076 - val_accuracy: 0.5333 - 295ms/epoch - 23ms/step\n",
            "Epoch 188/300\n",
            "13/13 - 0s - loss: 0.9814 - accuracy: 0.6651 - val_loss: 2.2873 - val_accuracy: 0.4971 - 298ms/epoch - 23ms/step\n",
            "Epoch 189/300\n",
            "13/13 - 0s - loss: 0.9936 - accuracy: 0.6647 - val_loss: 2.2422 - val_accuracy: 0.4812 - 299ms/epoch - 23ms/step\n",
            "Epoch 190/300\n",
            "13/13 - 0s - loss: 1.0764 - accuracy: 0.6406 - val_loss: 2.1170 - val_accuracy: 0.4638 - 299ms/epoch - 23ms/step\n",
            "Epoch 191/300\n",
            "13/13 - 0s - loss: 1.2183 - accuracy: 0.6232 - val_loss: 2.2362 - val_accuracy: 0.4725 - 297ms/epoch - 23ms/step\n",
            "Epoch 192/300\n",
            "13/13 - 0s - loss: 1.0504 - accuracy: 0.6473 - val_loss: 1.9663 - val_accuracy: 0.4841 - 300ms/epoch - 23ms/step\n",
            "Epoch 193/300\n",
            "13/13 - 0s - loss: 1.0357 - accuracy: 0.6359 - val_loss: 2.4636 - val_accuracy: 0.4551 - 302ms/epoch - 23ms/step\n",
            "Epoch 194/300\n",
            "13/13 - 0s - loss: 1.1138 - accuracy: 0.6314 - val_loss: 2.0722 - val_accuracy: 0.4826 - 297ms/epoch - 23ms/step\n",
            "Epoch 195/300\n",
            "13/13 - 0s - loss: 1.0342 - accuracy: 0.6454 - val_loss: 1.7069 - val_accuracy: 0.5290 - 302ms/epoch - 23ms/step\n",
            "Epoch 196/300\n",
            "13/13 - 0s - loss: 0.9849 - accuracy: 0.6541 - val_loss: 1.8271 - val_accuracy: 0.4957 - 296ms/epoch - 23ms/step\n",
            "Epoch 197/300\n",
            "13/13 - 0s - loss: 0.9554 - accuracy: 0.6702 - val_loss: 1.9980 - val_accuracy: 0.4594 - 293ms/epoch - 23ms/step\n",
            "Epoch 198/300\n",
            "13/13 - 0s - loss: 1.0038 - accuracy: 0.6448 - val_loss: 1.9904 - val_accuracy: 0.4928 - 294ms/epoch - 23ms/step\n",
            "Epoch 199/300\n",
            "13/13 - 0s - loss: 0.9973 - accuracy: 0.6663 - val_loss: 1.9669 - val_accuracy: 0.5145 - 294ms/epoch - 23ms/step\n",
            "Epoch 200/300\n",
            "13/13 - 0s - loss: 1.0128 - accuracy: 0.6705 - val_loss: 2.3783 - val_accuracy: 0.4928 - 300ms/epoch - 23ms/step\n",
            "Epoch 201/300\n",
            "13/13 - 0s - loss: 0.9908 - accuracy: 0.6744 - val_loss: 2.2623 - val_accuracy: 0.4609 - 299ms/epoch - 23ms/step\n",
            "Epoch 202/300\n",
            "13/13 - 0s - loss: 0.9625 - accuracy: 0.6620 - val_loss: 2.3315 - val_accuracy: 0.4652 - 292ms/epoch - 22ms/step\n",
            "Epoch 203/300\n",
            "13/13 - 0s - loss: 1.0191 - accuracy: 0.6667 - val_loss: 2.0456 - val_accuracy: 0.4478 - 294ms/epoch - 23ms/step\n",
            "Epoch 204/300\n",
            "13/13 - 0s - loss: 0.9898 - accuracy: 0.6551 - val_loss: 1.8350 - val_accuracy: 0.5014 - 299ms/epoch - 23ms/step\n",
            "Epoch 205/300\n",
            "13/13 - 0s - loss: 0.9143 - accuracy: 0.6810 - val_loss: 1.9808 - val_accuracy: 0.5203 - 298ms/epoch - 23ms/step\n",
            "Epoch 206/300\n",
            "13/13 - 0s - loss: 1.0414 - accuracy: 0.6378 - val_loss: 2.0698 - val_accuracy: 0.4681 - 296ms/epoch - 23ms/step\n",
            "Epoch 207/300\n",
            "13/13 - 0s - loss: 0.9472 - accuracy: 0.6709 - val_loss: 2.1748 - val_accuracy: 0.5058 - 295ms/epoch - 23ms/step\n",
            "Epoch 208/300\n",
            "13/13 - 0s - loss: 0.8598 - accuracy: 0.6928 - val_loss: 2.0891 - val_accuracy: 0.5159 - 299ms/epoch - 23ms/step\n",
            "Epoch 209/300\n",
            "13/13 - 0s - loss: 0.9570 - accuracy: 0.6758 - val_loss: 1.9813 - val_accuracy: 0.4725 - 295ms/epoch - 23ms/step\n",
            "Epoch 210/300\n",
            "13/13 - 0s - loss: 1.0710 - accuracy: 0.6383 - val_loss: 1.9374 - val_accuracy: 0.4536 - 296ms/epoch - 23ms/step\n",
            "Epoch 211/300\n",
            "13/13 - 0s - loss: 1.0519 - accuracy: 0.6361 - val_loss: 2.1872 - val_accuracy: 0.4087 - 298ms/epoch - 23ms/step\n",
            "Epoch 212/300\n",
            "13/13 - 0s - loss: 1.0678 - accuracy: 0.6651 - val_loss: 2.1968 - val_accuracy: 0.4449 - 295ms/epoch - 23ms/step\n",
            "Epoch 213/300\n",
            "13/13 - 0s - loss: 0.9264 - accuracy: 0.6841 - val_loss: 2.0118 - val_accuracy: 0.5000 - 291ms/epoch - 22ms/step\n",
            "Epoch 214/300\n",
            "13/13 - 0s - loss: 1.0428 - accuracy: 0.6478 - val_loss: 2.0024 - val_accuracy: 0.4855 - 289ms/epoch - 22ms/step\n",
            "Epoch 215/300\n",
            "13/13 - 0s - loss: 0.9675 - accuracy: 0.6602 - val_loss: 2.2400 - val_accuracy: 0.4362 - 296ms/epoch - 23ms/step\n",
            "Epoch 216/300\n",
            "13/13 - 0s - loss: 0.9716 - accuracy: 0.6733 - val_loss: 1.8928 - val_accuracy: 0.5232 - 296ms/epoch - 23ms/step\n",
            "Epoch 217/300\n",
            "13/13 - 0s - loss: 0.9745 - accuracy: 0.6530 - val_loss: 2.4212 - val_accuracy: 0.4797 - 295ms/epoch - 23ms/step\n",
            "Epoch 218/300\n",
            "13/13 - 0s - loss: 1.0498 - accuracy: 0.6477 - val_loss: 2.2622 - val_accuracy: 0.4391 - 296ms/epoch - 23ms/step\n",
            "Epoch 219/300\n",
            "13/13 - 0s - loss: 0.9833 - accuracy: 0.6581 - val_loss: 2.1381 - val_accuracy: 0.4942 - 294ms/epoch - 23ms/step\n",
            "Epoch 220/300\n",
            "13/13 - 0s - loss: 0.9560 - accuracy: 0.6654 - val_loss: 2.0058 - val_accuracy: 0.5420 - 294ms/epoch - 23ms/step\n",
            "Epoch 221/300\n",
            "13/13 - 0s - loss: 0.8894 - accuracy: 0.6865 - val_loss: 2.0189 - val_accuracy: 0.5043 - 297ms/epoch - 23ms/step\n",
            "Epoch 222/300\n",
            "13/13 - 0s - loss: 0.8620 - accuracy: 0.6986 - val_loss: 1.9549 - val_accuracy: 0.5000 - 300ms/epoch - 23ms/step\n",
            "Epoch 223/300\n",
            "13/13 - 0s - loss: 0.8810 - accuracy: 0.6884 - val_loss: 2.0725 - val_accuracy: 0.5261 - 291ms/epoch - 22ms/step\n",
            "Epoch 224/300\n",
            "13/13 - 0s - loss: 0.9298 - accuracy: 0.6758 - val_loss: 1.7633 - val_accuracy: 0.4971 - 292ms/epoch - 22ms/step\n",
            "Epoch 225/300\n",
            "13/13 - 0s - loss: 0.8987 - accuracy: 0.6818 - val_loss: 1.8563 - val_accuracy: 0.4899 - 293ms/epoch - 23ms/step\n",
            "Epoch 226/300\n",
            "13/13 - 0s - loss: 0.9148 - accuracy: 0.6794 - val_loss: 1.7780 - val_accuracy: 0.4754 - 298ms/epoch - 23ms/step\n",
            "Epoch 227/300\n",
            "13/13 - 0s - loss: 0.8836 - accuracy: 0.6794 - val_loss: 1.8000 - val_accuracy: 0.5464 - 293ms/epoch - 23ms/step\n",
            "Epoch 228/300\n",
            "13/13 - 0s - loss: 0.8694 - accuracy: 0.6976 - val_loss: 1.8133 - val_accuracy: 0.5058 - 298ms/epoch - 23ms/step\n",
            "Epoch 229/300\n",
            "13/13 - 0s - loss: 0.8102 - accuracy: 0.7047 - val_loss: 1.7882 - val_accuracy: 0.5449 - 297ms/epoch - 23ms/step\n",
            "Epoch 230/300\n",
            "13/13 - 0s - loss: 0.8466 - accuracy: 0.6989 - val_loss: 2.0360 - val_accuracy: 0.5145 - 302ms/epoch - 23ms/step\n",
            "Epoch 231/300\n",
            "13/13 - 0s - loss: 0.8670 - accuracy: 0.6952 - val_loss: 2.1378 - val_accuracy: 0.4928 - 300ms/epoch - 23ms/step\n",
            "Epoch 232/300\n",
            "13/13 - 0s - loss: 0.9757 - accuracy: 0.6736 - val_loss: 2.1321 - val_accuracy: 0.5232 - 298ms/epoch - 23ms/step\n",
            "Epoch 233/300\n",
            "13/13 - 0s - loss: 0.9786 - accuracy: 0.6913 - val_loss: 1.9447 - val_accuracy: 0.5304 - 298ms/epoch - 23ms/step\n",
            "Epoch 234/300\n",
            "13/13 - 0s - loss: 0.9020 - accuracy: 0.6952 - val_loss: 1.9089 - val_accuracy: 0.5435 - 300ms/epoch - 23ms/step\n",
            "Epoch 235/300\n",
            "13/13 - 0s - loss: 0.8361 - accuracy: 0.7093 - val_loss: 1.9337 - val_accuracy: 0.5101 - 296ms/epoch - 23ms/step\n",
            "Epoch 236/300\n",
            "13/13 - 0s - loss: 0.8853 - accuracy: 0.6918 - val_loss: 2.1402 - val_accuracy: 0.4507 - 297ms/epoch - 23ms/step\n",
            "Epoch 237/300\n",
            "13/13 - 0s - loss: 0.8840 - accuracy: 0.6923 - val_loss: 1.8730 - val_accuracy: 0.5159 - 296ms/epoch - 23ms/step\n",
            "Epoch 238/300\n",
            "13/13 - 0s - loss: 0.8529 - accuracy: 0.7135 - val_loss: 2.0912 - val_accuracy: 0.4623 - 297ms/epoch - 23ms/step\n",
            "Epoch 239/300\n",
            "13/13 - 0s - loss: 0.8193 - accuracy: 0.7095 - val_loss: 2.0257 - val_accuracy: 0.5087 - 302ms/epoch - 23ms/step\n",
            "Epoch 240/300\n",
            "13/13 - 0s - loss: 0.8482 - accuracy: 0.7132 - val_loss: 2.2102 - val_accuracy: 0.4870 - 295ms/epoch - 23ms/step\n",
            "Epoch 241/300\n",
            "13/13 - 0s - loss: 0.8446 - accuracy: 0.7008 - val_loss: 2.3780 - val_accuracy: 0.5130 - 292ms/epoch - 22ms/step\n",
            "Epoch 242/300\n",
            "13/13 - 0s - loss: 0.8340 - accuracy: 0.7122 - val_loss: 2.2582 - val_accuracy: 0.5232 - 297ms/epoch - 23ms/step\n",
            "Epoch 243/300\n",
            "13/13 - 0s - loss: 0.9123 - accuracy: 0.6945 - val_loss: 1.9279 - val_accuracy: 0.5319 - 293ms/epoch - 23ms/step\n",
            "Epoch 244/300\n",
            "13/13 - 0s - loss: 0.8976 - accuracy: 0.6871 - val_loss: 1.9662 - val_accuracy: 0.5362 - 295ms/epoch - 23ms/step\n",
            "Epoch 245/300\n",
            "13/13 - 0s - loss: 0.8765 - accuracy: 0.6884 - val_loss: 2.2204 - val_accuracy: 0.4855 - 301ms/epoch - 23ms/step\n",
            "Epoch 246/300\n",
            "13/13 - 0s - loss: 0.9224 - accuracy: 0.6849 - val_loss: 2.2695 - val_accuracy: 0.4507 - 300ms/epoch - 23ms/step\n",
            "Epoch 247/300\n",
            "13/13 - 0s - loss: 0.9803 - accuracy: 0.6713 - val_loss: 1.8890 - val_accuracy: 0.4971 - 301ms/epoch - 23ms/step\n",
            "Epoch 248/300\n",
            "13/13 - 0s - loss: 1.1623 - accuracy: 0.6190 - val_loss: 2.7219 - val_accuracy: 0.4449 - 289ms/epoch - 22ms/step\n",
            "Epoch 249/300\n",
            "13/13 - 0s - loss: 1.0979 - accuracy: 0.6277 - val_loss: 2.4609 - val_accuracy: 0.3826 - 294ms/epoch - 23ms/step\n",
            "Epoch 250/300\n",
            "13/13 - 0s - loss: 1.0984 - accuracy: 0.6243 - val_loss: 2.1520 - val_accuracy: 0.4594 - 295ms/epoch - 23ms/step\n",
            "Epoch 251/300\n",
            "13/13 - 0s - loss: 1.0783 - accuracy: 0.6517 - val_loss: 1.9882 - val_accuracy: 0.4362 - 295ms/epoch - 23ms/step\n",
            "Epoch 252/300\n",
            "13/13 - 0s - loss: 1.0680 - accuracy: 0.6320 - val_loss: 2.1426 - val_accuracy: 0.4449 - 299ms/epoch - 23ms/step\n",
            "Epoch 253/300\n",
            "13/13 - 0s - loss: 0.9950 - accuracy: 0.6570 - val_loss: 2.1423 - val_accuracy: 0.4957 - 294ms/epoch - 23ms/step\n",
            "Epoch 254/300\n",
            "13/13 - 0s - loss: 1.0275 - accuracy: 0.6539 - val_loss: 1.7622 - val_accuracy: 0.4870 - 299ms/epoch - 23ms/step\n",
            "Epoch 255/300\n",
            "13/13 - 0s - loss: 0.9486 - accuracy: 0.6721 - val_loss: 1.7160 - val_accuracy: 0.4768 - 296ms/epoch - 23ms/step\n",
            "Epoch 256/300\n",
            "13/13 - 0s - loss: 0.9547 - accuracy: 0.6733 - val_loss: 1.6367 - val_accuracy: 0.5580 - 295ms/epoch - 23ms/step\n",
            "Epoch 257/300\n",
            "13/13 - 0s - loss: 0.8453 - accuracy: 0.7048 - val_loss: 1.7453 - val_accuracy: 0.5362 - 288ms/epoch - 22ms/step\n",
            "Epoch 258/300\n",
            "13/13 - 0s - loss: 0.8616 - accuracy: 0.6852 - val_loss: 1.7053 - val_accuracy: 0.5188 - 288ms/epoch - 22ms/step\n",
            "Epoch 259/300\n",
            "13/13 - 0s - loss: 0.8328 - accuracy: 0.6971 - val_loss: 1.7949 - val_accuracy: 0.5188 - 300ms/epoch - 23ms/step\n",
            "Epoch 260/300\n",
            "13/13 - 0s - loss: 0.8701 - accuracy: 0.6948 - val_loss: 1.7515 - val_accuracy: 0.4957 - 293ms/epoch - 23ms/step\n",
            "Epoch 261/300\n",
            "13/13 - 0s - loss: 0.9337 - accuracy: 0.6895 - val_loss: 1.6318 - val_accuracy: 0.5623 - 294ms/epoch - 23ms/step\n",
            "Epoch 262/300\n",
            "13/13 - 0s - loss: 0.9233 - accuracy: 0.6752 - val_loss: 1.6026 - val_accuracy: 0.4971 - 292ms/epoch - 22ms/step\n",
            "Epoch 263/300\n",
            "13/13 - 0s - loss: 0.8899 - accuracy: 0.6910 - val_loss: 1.7526 - val_accuracy: 0.5217 - 298ms/epoch - 23ms/step\n",
            "Epoch 264/300\n",
            "13/13 - 0s - loss: 0.8438 - accuracy: 0.6911 - val_loss: 1.7390 - val_accuracy: 0.5188 - 296ms/epoch - 23ms/step\n",
            "Epoch 265/300\n",
            "13/13 - 0s - loss: 0.8640 - accuracy: 0.7052 - val_loss: 1.7564 - val_accuracy: 0.4971 - 292ms/epoch - 22ms/step\n",
            "Epoch 266/300\n",
            "13/13 - 0s - loss: 0.8196 - accuracy: 0.7056 - val_loss: 1.8439 - val_accuracy: 0.5217 - 302ms/epoch - 23ms/step\n",
            "Epoch 267/300\n",
            "13/13 - 0s - loss: 0.7543 - accuracy: 0.7267 - val_loss: 1.7305 - val_accuracy: 0.5072 - 294ms/epoch - 23ms/step\n",
            "Epoch 268/300\n",
            "13/13 - 0s - loss: 0.7665 - accuracy: 0.7132 - val_loss: 1.9170 - val_accuracy: 0.4710 - 296ms/epoch - 23ms/step\n",
            "Epoch 269/300\n",
            "13/13 - 0s - loss: 0.8083 - accuracy: 0.7018 - val_loss: 1.8569 - val_accuracy: 0.4928 - 289ms/epoch - 22ms/step\n",
            "Epoch 270/300\n",
            "13/13 - 0s - loss: 0.8579 - accuracy: 0.6957 - val_loss: 2.1437 - val_accuracy: 0.4826 - 298ms/epoch - 23ms/step\n",
            "Epoch 271/300\n",
            "13/13 - 0s - loss: 0.8395 - accuracy: 0.7047 - val_loss: 1.9640 - val_accuracy: 0.4754 - 296ms/epoch - 23ms/step\n",
            "Epoch 272/300\n",
            "13/13 - 0s - loss: 1.0151 - accuracy: 0.6684 - val_loss: 1.8506 - val_accuracy: 0.4623 - 298ms/epoch - 23ms/step\n",
            "Epoch 273/300\n",
            "13/13 - 0s - loss: 1.2353 - accuracy: 0.6267 - val_loss: 2.2756 - val_accuracy: 0.3623 - 295ms/epoch - 23ms/step\n",
            "Epoch 274/300\n",
            "13/13 - 0s - loss: 1.1845 - accuracy: 0.6176 - val_loss: 2.2438 - val_accuracy: 0.3870 - 294ms/epoch - 23ms/step\n",
            "Epoch 275/300\n",
            "13/13 - 0s - loss: 1.1557 - accuracy: 0.6235 - val_loss: 1.8077 - val_accuracy: 0.4826 - 296ms/epoch - 23ms/step\n",
            "Epoch 276/300\n",
            "13/13 - 0s - loss: 1.0734 - accuracy: 0.6266 - val_loss: 2.0605 - val_accuracy: 0.4739 - 297ms/epoch - 23ms/step\n",
            "Epoch 277/300\n",
            "13/13 - 0s - loss: 1.0160 - accuracy: 0.6404 - val_loss: 2.2240 - val_accuracy: 0.4449 - 302ms/epoch - 23ms/step\n",
            "Epoch 278/300\n",
            "13/13 - 0s - loss: 1.0101 - accuracy: 0.6668 - val_loss: 1.9816 - val_accuracy: 0.4406 - 293ms/epoch - 23ms/step\n",
            "Epoch 279/300\n",
            "13/13 - 0s - loss: 0.9557 - accuracy: 0.6678 - val_loss: 1.9422 - val_accuracy: 0.4116 - 291ms/epoch - 22ms/step\n",
            "Epoch 280/300\n",
            "13/13 - 0s - loss: 0.9062 - accuracy: 0.6818 - val_loss: 1.8768 - val_accuracy: 0.4913 - 297ms/epoch - 23ms/step\n",
            "Epoch 281/300\n",
            "13/13 - 0s - loss: 0.9352 - accuracy: 0.6668 - val_loss: 2.0827 - val_accuracy: 0.4406 - 297ms/epoch - 23ms/step\n",
            "Epoch 282/300\n",
            "13/13 - 0s - loss: 0.8900 - accuracy: 0.6829 - val_loss: 2.1486 - val_accuracy: 0.4116 - 294ms/epoch - 23ms/step\n",
            "Epoch 283/300\n",
            "13/13 - 0s - loss: 0.8424 - accuracy: 0.6932 - val_loss: 2.1105 - val_accuracy: 0.4261 - 297ms/epoch - 23ms/step\n",
            "Epoch 284/300\n",
            "13/13 - 0s - loss: 0.8094 - accuracy: 0.7147 - val_loss: 1.9629 - val_accuracy: 0.5232 - 297ms/epoch - 23ms/step\n",
            "Epoch 285/300\n",
            "13/13 - 0s - loss: 0.8082 - accuracy: 0.7155 - val_loss: 1.9275 - val_accuracy: 0.4783 - 298ms/epoch - 23ms/step\n",
            "Epoch 286/300\n",
            "13/13 - 0s - loss: 0.8231 - accuracy: 0.7087 - val_loss: 1.8379 - val_accuracy: 0.4913 - 290ms/epoch - 22ms/step\n",
            "Epoch 287/300\n",
            "13/13 - 0s - loss: 0.8426 - accuracy: 0.7116 - val_loss: 1.8668 - val_accuracy: 0.4768 - 292ms/epoch - 22ms/step\n",
            "Epoch 288/300\n",
            "13/13 - 0s - loss: 0.8134 - accuracy: 0.7111 - val_loss: 1.8480 - val_accuracy: 0.5275 - 298ms/epoch - 23ms/step\n",
            "Epoch 289/300\n",
            "13/13 - 0s - loss: 0.8779 - accuracy: 0.7050 - val_loss: 2.0125 - val_accuracy: 0.4725 - 298ms/epoch - 23ms/step\n",
            "Epoch 290/300\n",
            "13/13 - 0s - loss: 0.9590 - accuracy: 0.6678 - val_loss: 2.0280 - val_accuracy: 0.5029 - 291ms/epoch - 22ms/step\n",
            "Epoch 291/300\n",
            "13/13 - 0s - loss: 0.9703 - accuracy: 0.6754 - val_loss: 2.2304 - val_accuracy: 0.4348 - 297ms/epoch - 23ms/step\n",
            "Epoch 292/300\n",
            "13/13 - 0s - loss: 0.9054 - accuracy: 0.6850 - val_loss: 2.1067 - val_accuracy: 0.4551 - 297ms/epoch - 23ms/step\n",
            "Epoch 293/300\n",
            "13/13 - 0s - loss: 0.8458 - accuracy: 0.7021 - val_loss: 2.0534 - val_accuracy: 0.5014 - 294ms/epoch - 23ms/step\n",
            "Epoch 294/300\n",
            "13/13 - 0s - loss: 0.8115 - accuracy: 0.7190 - val_loss: 1.9741 - val_accuracy: 0.4783 - 299ms/epoch - 23ms/step\n",
            "Epoch 295/300\n",
            "13/13 - 0s - loss: 0.8623 - accuracy: 0.7042 - val_loss: 1.9512 - val_accuracy: 0.5188 - 299ms/epoch - 23ms/step\n",
            "Epoch 296/300\n",
            "13/13 - 0s - loss: 0.8101 - accuracy: 0.7047 - val_loss: 2.2338 - val_accuracy: 0.5043 - 298ms/epoch - 23ms/step\n",
            "Epoch 297/300\n",
            "13/13 - 0s - loss: 0.8014 - accuracy: 0.7138 - val_loss: 2.2171 - val_accuracy: 0.4841 - 295ms/epoch - 23ms/step\n",
            "Epoch 298/300\n",
            "13/13 - 0s - loss: 0.8193 - accuracy: 0.7108 - val_loss: 2.1918 - val_accuracy: 0.4681 - 291ms/epoch - 22ms/step\n",
            "Epoch 299/300\n",
            "13/13 - 0s - loss: 0.8074 - accuracy: 0.7148 - val_loss: 1.9735 - val_accuracy: 0.5377 - 293ms/epoch - 23ms/step\n",
            "Epoch 300/300\n",
            "13/13 - 0s - loss: 0.8698 - accuracy: 0.6957 - val_loss: 2.2330 - val_accuracy: 0.4899 - 291ms/epoch - 22ms/step\n",
            "Model: \"sequential_89\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_178 (Conv2D)         (None, 4, 36, 80)         27440     \n",
            "                                                                 \n",
            " max_pooling2d_178 (MaxPooli  (None, 1, 12, 80)        0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_89 (Bat  (None, 1, 12, 80)        320       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv2d_179 (Conv2D)         (None, 1, 10, 80)         19280     \n",
            "                                                                 \n",
            " max_pooling2d_179 (MaxPooli  (None, 1, 3, 80)         0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " flatten_89 (Flatten)        (None, 240)               0         \n",
            "                                                                 \n",
            " dense_267 (Dense)           (None, 5000)              1205000   \n",
            "                                                                 \n",
            " dropout_178 (Dropout)       (None, 5000)              0         \n",
            "                                                                 \n",
            " dense_268 (Dense)           (None, 5000)              25005000  \n",
            "                                                                 \n",
            " dropout_179 (Dropout)       (None, 5000)              0         \n",
            "                                                                 \n",
            " dense_269 (Dense)           (None, 10)                50010     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 26,307,050\n",
            "Trainable params: 26,306,890\n",
            "Non-trainable params: 160\n",
            "_________________________________________________________________\n",
            "None\n",
            "Result of fold:2\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 2.8457 - accuracy: 0.4054\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 20%|██        | 2/10 [03:07<12:28, 93.59s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(6852, 60, 41)\n",
            "Epoch 1/300\n",
            "13/13 - 1s - loss: 4.8288 - accuracy: 0.1356 - val_loss: 2.2982 - val_accuracy: 0.1414 - 1s/epoch - 110ms/step\n",
            "Epoch 2/300\n",
            "13/13 - 0s - loss: 2.1737 - accuracy: 0.1855 - val_loss: 2.3769 - val_accuracy: 0.1501 - 300ms/epoch - 23ms/step\n",
            "Epoch 3/300\n",
            "13/13 - 0s - loss: 2.0996 - accuracy: 0.2160 - val_loss: 2.1682 - val_accuracy: 0.1778 - 295ms/epoch - 23ms/step\n",
            "Epoch 4/300\n",
            "13/13 - 0s - loss: 2.0671 - accuracy: 0.2277 - val_loss: 2.1571 - val_accuracy: 0.1837 - 291ms/epoch - 22ms/step\n",
            "Epoch 5/300\n",
            "13/13 - 0s - loss: 2.0248 - accuracy: 0.2588 - val_loss: 2.0013 - val_accuracy: 0.2128 - 293ms/epoch - 23ms/step\n",
            "Epoch 6/300\n",
            "13/13 - 0s - loss: 1.9604 - accuracy: 0.2867 - val_loss: 1.9484 - val_accuracy: 0.2507 - 294ms/epoch - 23ms/step\n",
            "Epoch 7/300\n",
            "13/13 - 0s - loss: 1.9241 - accuracy: 0.2898 - val_loss: 2.0798 - val_accuracy: 0.2041 - 291ms/epoch - 22ms/step\n",
            "Epoch 8/300\n",
            "13/13 - 0s - loss: 1.8894 - accuracy: 0.3051 - val_loss: 1.9748 - val_accuracy: 0.3601 - 289ms/epoch - 22ms/step\n",
            "Epoch 9/300\n",
            "13/13 - 0s - loss: 1.8638 - accuracy: 0.3179 - val_loss: 2.0347 - val_accuracy: 0.3426 - 301ms/epoch - 23ms/step\n",
            "Epoch 10/300\n",
            "13/13 - 0s - loss: 1.8431 - accuracy: 0.3284 - val_loss: 1.8494 - val_accuracy: 0.3382 - 295ms/epoch - 23ms/step\n",
            "Epoch 11/300\n",
            "13/13 - 0s - loss: 1.7602 - accuracy: 0.3570 - val_loss: 1.8432 - val_accuracy: 0.2901 - 295ms/epoch - 23ms/step\n",
            "Epoch 12/300\n",
            "13/13 - 0s - loss: 1.7385 - accuracy: 0.3617 - val_loss: 2.1606 - val_accuracy: 0.2391 - 291ms/epoch - 22ms/step\n",
            "Epoch 13/300\n",
            "13/13 - 0s - loss: 1.7402 - accuracy: 0.3709 - val_loss: 2.1185 - val_accuracy: 0.2420 - 301ms/epoch - 23ms/step\n",
            "Epoch 14/300\n",
            "13/13 - 0s - loss: 1.7246 - accuracy: 0.3717 - val_loss: 2.1123 - val_accuracy: 0.3688 - 298ms/epoch - 23ms/step\n",
            "Epoch 15/300\n",
            "13/13 - 0s - loss: 1.6957 - accuracy: 0.3975 - val_loss: 1.9917 - val_accuracy: 0.3469 - 293ms/epoch - 23ms/step\n",
            "Epoch 16/300\n",
            "13/13 - 0s - loss: 1.7347 - accuracy: 0.3793 - val_loss: 1.8887 - val_accuracy: 0.3615 - 296ms/epoch - 23ms/step\n",
            "Epoch 17/300\n",
            "13/13 - 0s - loss: 1.6494 - accuracy: 0.4061 - val_loss: 2.0598 - val_accuracy: 0.2536 - 292ms/epoch - 22ms/step\n",
            "Epoch 18/300\n",
            "13/13 - 0s - loss: 1.7759 - accuracy: 0.3557 - val_loss: 1.9671 - val_accuracy: 0.3790 - 295ms/epoch - 23ms/step\n",
            "Epoch 19/300\n",
            "13/13 - 0s - loss: 1.6976 - accuracy: 0.3933 - val_loss: 2.0302 - val_accuracy: 0.3659 - 292ms/epoch - 22ms/step\n",
            "Epoch 20/300\n",
            "13/13 - 0s - loss: 1.7536 - accuracy: 0.3626 - val_loss: 1.9324 - val_accuracy: 0.3353 - 293ms/epoch - 23ms/step\n",
            "Epoch 21/300\n",
            "13/13 - 0s - loss: 1.6678 - accuracy: 0.3941 - val_loss: 1.9204 - val_accuracy: 0.3192 - 303ms/epoch - 23ms/step\n",
            "Epoch 22/300\n",
            "13/13 - 0s - loss: 1.6745 - accuracy: 0.3915 - val_loss: 1.7948 - val_accuracy: 0.4329 - 295ms/epoch - 23ms/step\n",
            "Epoch 23/300\n",
            "13/13 - 0s - loss: 1.6175 - accuracy: 0.4089 - val_loss: 1.9841 - val_accuracy: 0.3892 - 295ms/epoch - 23ms/step\n",
            "Epoch 24/300\n",
            "13/13 - 0s - loss: 1.5756 - accuracy: 0.4380 - val_loss: 1.9124 - val_accuracy: 0.4577 - 298ms/epoch - 23ms/step\n",
            "Epoch 25/300\n",
            "13/13 - 0s - loss: 1.6012 - accuracy: 0.4132 - val_loss: 1.8439 - val_accuracy: 0.4315 - 300ms/epoch - 23ms/step\n",
            "Epoch 26/300\n",
            "13/13 - 0s - loss: 1.6389 - accuracy: 0.4207 - val_loss: 1.7471 - val_accuracy: 0.3732 - 296ms/epoch - 23ms/step\n",
            "Epoch 27/300\n",
            "13/13 - 0s - loss: 1.5644 - accuracy: 0.4262 - val_loss: 1.7331 - val_accuracy: 0.4227 - 291ms/epoch - 22ms/step\n",
            "Epoch 28/300\n",
            "13/13 - 0s - loss: 1.5586 - accuracy: 0.4350 - val_loss: 2.0564 - val_accuracy: 0.3834 - 307ms/epoch - 24ms/step\n",
            "Epoch 29/300\n",
            "13/13 - 0s - loss: 1.6587 - accuracy: 0.4108 - val_loss: 1.8333 - val_accuracy: 0.3163 - 293ms/epoch - 23ms/step\n",
            "Epoch 30/300\n",
            "13/13 - 0s - loss: 1.6482 - accuracy: 0.3930 - val_loss: 1.8246 - val_accuracy: 0.3834 - 295ms/epoch - 23ms/step\n",
            "Epoch 31/300\n",
            "13/13 - 0s - loss: 1.6718 - accuracy: 0.3787 - val_loss: 1.8136 - val_accuracy: 0.3688 - 292ms/epoch - 22ms/step\n",
            "Epoch 32/300\n",
            "13/13 - 0s - loss: 1.6968 - accuracy: 0.3936 - val_loss: 1.9173 - val_accuracy: 0.3732 - 305ms/epoch - 23ms/step\n",
            "Epoch 33/300\n",
            "13/13 - 0s - loss: 1.6626 - accuracy: 0.4118 - val_loss: 1.8284 - val_accuracy: 0.3790 - 308ms/epoch - 24ms/step\n",
            "Epoch 34/300\n",
            "13/13 - 0s - loss: 1.6689 - accuracy: 0.4079 - val_loss: 1.9312 - val_accuracy: 0.3353 - 303ms/epoch - 23ms/step\n",
            "Epoch 35/300\n",
            "13/13 - 0s - loss: 1.6481 - accuracy: 0.3886 - val_loss: 1.8143 - val_accuracy: 0.3586 - 313ms/epoch - 24ms/step\n",
            "Epoch 36/300\n",
            "13/13 - 0s - loss: 1.5928 - accuracy: 0.4163 - val_loss: 1.9054 - val_accuracy: 0.3513 - 315ms/epoch - 24ms/step\n",
            "Epoch 37/300\n",
            "13/13 - 0s - loss: 1.5889 - accuracy: 0.4213 - val_loss: 1.7234 - val_accuracy: 0.3921 - 317ms/epoch - 24ms/step\n",
            "Epoch 38/300\n",
            "13/13 - 0s - loss: 1.5803 - accuracy: 0.4270 - val_loss: 1.7919 - val_accuracy: 0.4242 - 304ms/epoch - 23ms/step\n",
            "Epoch 39/300\n",
            "13/13 - 0s - loss: 1.5734 - accuracy: 0.4320 - val_loss: 1.6986 - val_accuracy: 0.4636 - 324ms/epoch - 25ms/step\n",
            "Epoch 40/300\n",
            "13/13 - 0s - loss: 1.5838 - accuracy: 0.4200 - val_loss: 1.7323 - val_accuracy: 0.4752 - 318ms/epoch - 24ms/step\n",
            "Epoch 41/300\n",
            "13/13 - 0s - loss: 1.6121 - accuracy: 0.4150 - val_loss: 1.9101 - val_accuracy: 0.4373 - 304ms/epoch - 23ms/step\n",
            "Epoch 42/300\n",
            "13/13 - 0s - loss: 1.6078 - accuracy: 0.4329 - val_loss: 1.7870 - val_accuracy: 0.4169 - 302ms/epoch - 23ms/step\n",
            "Epoch 43/300\n",
            "13/13 - 0s - loss: 1.7385 - accuracy: 0.3988 - val_loss: 1.8640 - val_accuracy: 0.3892 - 306ms/epoch - 24ms/step\n",
            "Epoch 44/300\n",
            "13/13 - 0s - loss: 1.6260 - accuracy: 0.4030 - val_loss: 1.8106 - val_accuracy: 0.3673 - 299ms/epoch - 23ms/step\n",
            "Epoch 45/300\n",
            "13/13 - 0s - loss: 1.6144 - accuracy: 0.4038 - val_loss: 1.7112 - val_accuracy: 0.4140 - 300ms/epoch - 23ms/step\n",
            "Epoch 46/300\n",
            "13/13 - 0s - loss: 1.6183 - accuracy: 0.4226 - val_loss: 1.7828 - val_accuracy: 0.4344 - 296ms/epoch - 23ms/step\n",
            "Epoch 47/300\n",
            "13/13 - 0s - loss: 1.6028 - accuracy: 0.4145 - val_loss: 1.8182 - val_accuracy: 0.4286 - 295ms/epoch - 23ms/step\n",
            "Epoch 48/300\n",
            "13/13 - 0s - loss: 1.6241 - accuracy: 0.4157 - val_loss: 1.8633 - val_accuracy: 0.4213 - 289ms/epoch - 22ms/step\n",
            "Epoch 49/300\n",
            "13/13 - 0s - loss: 1.5542 - accuracy: 0.4342 - val_loss: 2.0267 - val_accuracy: 0.3630 - 296ms/epoch - 23ms/step\n",
            "Epoch 50/300\n",
            "13/13 - 0s - loss: 1.6069 - accuracy: 0.4239 - val_loss: 1.8158 - val_accuracy: 0.4198 - 303ms/epoch - 23ms/step\n",
            "Epoch 51/300\n",
            "13/13 - 0s - loss: 1.6093 - accuracy: 0.4303 - val_loss: 1.7423 - val_accuracy: 0.4344 - 299ms/epoch - 23ms/step\n",
            "Epoch 52/300\n",
            "13/13 - 0s - loss: 1.5739 - accuracy: 0.4372 - val_loss: 1.8944 - val_accuracy: 0.4140 - 301ms/epoch - 23ms/step\n",
            "Epoch 53/300\n",
            "13/13 - 0s - loss: 1.5544 - accuracy: 0.4410 - val_loss: 1.9554 - val_accuracy: 0.4213 - 296ms/epoch - 23ms/step\n",
            "Epoch 54/300\n",
            "13/13 - 0s - loss: 1.5843 - accuracy: 0.4197 - val_loss: 1.9282 - val_accuracy: 0.4242 - 295ms/epoch - 23ms/step\n",
            "Epoch 55/300\n",
            "13/13 - 0s - loss: 1.5320 - accuracy: 0.4408 - val_loss: 2.0778 - val_accuracy: 0.3659 - 294ms/epoch - 23ms/step\n",
            "Epoch 56/300\n",
            "13/13 - 0s - loss: 1.5823 - accuracy: 0.4239 - val_loss: 1.9329 - val_accuracy: 0.3324 - 295ms/epoch - 23ms/step\n",
            "Epoch 57/300\n",
            "13/13 - 0s - loss: 1.5054 - accuracy: 0.4575 - val_loss: 1.8167 - val_accuracy: 0.4694 - 300ms/epoch - 23ms/step\n",
            "Epoch 58/300\n",
            "13/13 - 0s - loss: 1.4876 - accuracy: 0.4659 - val_loss: 1.7614 - val_accuracy: 0.4577 - 292ms/epoch - 22ms/step\n",
            "Epoch 59/300\n",
            "13/13 - 0s - loss: 1.5403 - accuracy: 0.4549 - val_loss: 1.7082 - val_accuracy: 0.4781 - 292ms/epoch - 22ms/step\n",
            "Epoch 60/300\n",
            "13/13 - 0s - loss: 1.4784 - accuracy: 0.4596 - val_loss: 1.7894 - val_accuracy: 0.4461 - 295ms/epoch - 23ms/step\n",
            "Epoch 61/300\n",
            "13/13 - 0s - loss: 1.4641 - accuracy: 0.4771 - val_loss: 1.8678 - val_accuracy: 0.4956 - 300ms/epoch - 23ms/step\n",
            "Epoch 62/300\n",
            "13/13 - 0s - loss: 1.4904 - accuracy: 0.4661 - val_loss: 1.7913 - val_accuracy: 0.4534 - 298ms/epoch - 23ms/step\n",
            "Epoch 63/300\n",
            "13/13 - 0s - loss: 1.4638 - accuracy: 0.4708 - val_loss: 2.2197 - val_accuracy: 0.4067 - 301ms/epoch - 23ms/step\n",
            "Epoch 64/300\n",
            "13/13 - 0s - loss: 1.4322 - accuracy: 0.4784 - val_loss: 2.0906 - val_accuracy: 0.3921 - 290ms/epoch - 22ms/step\n",
            "Epoch 65/300\n",
            "13/13 - 0s - loss: 1.5318 - accuracy: 0.4899 - val_loss: 2.0249 - val_accuracy: 0.4052 - 299ms/epoch - 23ms/step\n",
            "Epoch 66/300\n",
            "13/13 - 0s - loss: 1.4588 - accuracy: 0.4822 - val_loss: 1.8792 - val_accuracy: 0.4271 - 299ms/epoch - 23ms/step\n",
            "Epoch 67/300\n",
            "13/13 - 0s - loss: 1.5200 - accuracy: 0.4512 - val_loss: 1.9155 - val_accuracy: 0.3149 - 295ms/epoch - 23ms/step\n",
            "Epoch 68/300\n",
            "13/13 - 0s - loss: 1.5395 - accuracy: 0.4372 - val_loss: 1.8068 - val_accuracy: 0.3907 - 294ms/epoch - 23ms/step\n",
            "Epoch 69/300\n",
            "13/13 - 0s - loss: 1.5290 - accuracy: 0.4632 - val_loss: 1.6906 - val_accuracy: 0.4504 - 293ms/epoch - 23ms/step\n",
            "Epoch 70/300\n",
            "13/13 - 0s - loss: 1.5815 - accuracy: 0.4210 - val_loss: 1.7882 - val_accuracy: 0.4286 - 297ms/epoch - 23ms/step\n",
            "Epoch 71/300\n",
            "13/13 - 0s - loss: 1.5467 - accuracy: 0.4380 - val_loss: 1.7119 - val_accuracy: 0.4373 - 294ms/epoch - 23ms/step\n",
            "Epoch 72/300\n",
            "13/13 - 0s - loss: 1.5605 - accuracy: 0.4324 - val_loss: 1.7660 - val_accuracy: 0.4461 - 294ms/epoch - 23ms/step\n",
            "Epoch 73/300\n",
            "13/13 - 0s - loss: 1.5410 - accuracy: 0.4517 - val_loss: 1.6429 - val_accuracy: 0.4650 - 294ms/epoch - 23ms/step\n",
            "Epoch 74/300\n",
            "13/13 - 0s - loss: 1.4790 - accuracy: 0.4711 - val_loss: 1.7667 - val_accuracy: 0.4315 - 290ms/epoch - 22ms/step\n",
            "Epoch 75/300\n",
            "13/13 - 0s - loss: 1.4981 - accuracy: 0.4658 - val_loss: 1.6614 - val_accuracy: 0.4592 - 296ms/epoch - 23ms/step\n",
            "Epoch 76/300\n",
            "13/13 - 0s - loss: 1.4557 - accuracy: 0.4734 - val_loss: 1.6413 - val_accuracy: 0.4767 - 294ms/epoch - 23ms/step\n",
            "Epoch 77/300\n",
            "13/13 - 0s - loss: 1.4444 - accuracy: 0.4851 - val_loss: 1.7587 - val_accuracy: 0.4810 - 292ms/epoch - 22ms/step\n",
            "Epoch 78/300\n",
            "13/13 - 0s - loss: 1.5819 - accuracy: 0.4535 - val_loss: 1.6153 - val_accuracy: 0.5073 - 291ms/epoch - 22ms/step\n",
            "Epoch 79/300\n",
            "13/13 - 0s - loss: 1.5272 - accuracy: 0.4708 - val_loss: 1.8053 - val_accuracy: 0.4213 - 289ms/epoch - 22ms/step\n",
            "Epoch 80/300\n",
            "13/13 - 0s - loss: 1.4943 - accuracy: 0.4637 - val_loss: 1.7723 - val_accuracy: 0.4534 - 289ms/epoch - 22ms/step\n",
            "Epoch 81/300\n",
            "13/13 - 0s - loss: 1.4865 - accuracy: 0.4861 - val_loss: 1.8629 - val_accuracy: 0.4271 - 292ms/epoch - 22ms/step\n",
            "Epoch 82/300\n",
            "13/13 - 0s - loss: 1.4676 - accuracy: 0.4762 - val_loss: 1.6671 - val_accuracy: 0.4665 - 300ms/epoch - 23ms/step\n",
            "Epoch 83/300\n",
            "13/13 - 0s - loss: 1.5679 - accuracy: 0.4436 - val_loss: 1.7193 - val_accuracy: 0.4257 - 298ms/epoch - 23ms/step\n",
            "Epoch 84/300\n",
            "13/13 - 0s - loss: 1.4800 - accuracy: 0.4689 - val_loss: 1.8135 - val_accuracy: 0.5102 - 290ms/epoch - 22ms/step\n",
            "Epoch 85/300\n",
            "13/13 - 0s - loss: 1.4466 - accuracy: 0.4992 - val_loss: 1.5865 - val_accuracy: 0.4781 - 287ms/epoch - 22ms/step\n",
            "Epoch 86/300\n",
            "13/13 - 0s - loss: 1.3968 - accuracy: 0.5112 - val_loss: 1.5848 - val_accuracy: 0.4752 - 292ms/epoch - 22ms/step\n",
            "Epoch 87/300\n",
            "13/13 - 0s - loss: 1.4470 - accuracy: 0.4895 - val_loss: 1.9580 - val_accuracy: 0.3980 - 296ms/epoch - 23ms/step\n",
            "Epoch 88/300\n",
            "13/13 - 0s - loss: 1.4722 - accuracy: 0.4724 - val_loss: 1.6315 - val_accuracy: 0.4388 - 291ms/epoch - 22ms/step\n",
            "Epoch 89/300\n",
            "13/13 - 0s - loss: 1.5311 - accuracy: 0.4405 - val_loss: 1.7266 - val_accuracy: 0.4446 - 287ms/epoch - 22ms/step\n",
            "Epoch 90/300\n",
            "13/13 - 0s - loss: 1.5326 - accuracy: 0.4330 - val_loss: 1.7267 - val_accuracy: 0.4431 - 291ms/epoch - 22ms/step\n",
            "Epoch 91/300\n",
            "13/13 - 0s - loss: 1.5710 - accuracy: 0.4356 - val_loss: 1.7432 - val_accuracy: 0.4125 - 294ms/epoch - 23ms/step\n",
            "Epoch 92/300\n",
            "13/13 - 0s - loss: 1.4707 - accuracy: 0.4606 - val_loss: 1.7278 - val_accuracy: 0.4694 - 293ms/epoch - 23ms/step\n",
            "Epoch 93/300\n",
            "13/13 - 0s - loss: 1.5000 - accuracy: 0.4484 - val_loss: 1.7851 - val_accuracy: 0.3455 - 291ms/epoch - 22ms/step\n",
            "Epoch 94/300\n",
            "13/13 - 0s - loss: 1.5156 - accuracy: 0.4337 - val_loss: 1.7796 - val_accuracy: 0.3542 - 296ms/epoch - 23ms/step\n",
            "Epoch 95/300\n",
            "13/13 - 0s - loss: 1.5110 - accuracy: 0.4458 - val_loss: 1.6808 - val_accuracy: 0.4344 - 294ms/epoch - 23ms/step\n",
            "Epoch 96/300\n",
            "13/13 - 0s - loss: 1.4430 - accuracy: 0.4620 - val_loss: 1.6566 - val_accuracy: 0.4883 - 298ms/epoch - 23ms/step\n",
            "Epoch 97/300\n",
            "13/13 - 0s - loss: 1.4232 - accuracy: 0.4818 - val_loss: 1.6509 - val_accuracy: 0.4417 - 290ms/epoch - 22ms/step\n",
            "Epoch 98/300\n",
            "13/13 - 0s - loss: 1.4912 - accuracy: 0.4468 - val_loss: 1.6712 - val_accuracy: 0.4402 - 290ms/epoch - 22ms/step\n",
            "Epoch 99/300\n",
            "13/13 - 0s - loss: 1.5348 - accuracy: 0.4601 - val_loss: 1.7093 - val_accuracy: 0.4854 - 296ms/epoch - 23ms/step\n",
            "Epoch 100/300\n",
            "13/13 - 0s - loss: 1.4746 - accuracy: 0.4517 - val_loss: 1.6157 - val_accuracy: 0.4300 - 293ms/epoch - 23ms/step\n",
            "Epoch 101/300\n",
            "13/13 - 0s - loss: 1.4651 - accuracy: 0.4486 - val_loss: 1.7645 - val_accuracy: 0.4096 - 294ms/epoch - 23ms/step\n",
            "Epoch 102/300\n",
            "13/13 - 0s - loss: 1.5389 - accuracy: 0.4358 - val_loss: 1.8355 - val_accuracy: 0.3717 - 292ms/epoch - 22ms/step\n",
            "Epoch 103/300\n",
            "13/13 - 0s - loss: 1.4775 - accuracy: 0.4689 - val_loss: 1.6962 - val_accuracy: 0.4431 - 291ms/epoch - 22ms/step\n",
            "Epoch 104/300\n",
            "13/13 - 0s - loss: 1.3953 - accuracy: 0.4781 - val_loss: 1.6456 - val_accuracy: 0.4665 - 291ms/epoch - 22ms/step\n",
            "Epoch 105/300\n",
            "13/13 - 0s - loss: 1.3942 - accuracy: 0.4865 - val_loss: 1.6836 - val_accuracy: 0.4825 - 294ms/epoch - 23ms/step\n",
            "Epoch 106/300\n",
            "13/13 - 0s - loss: 1.3800 - accuracy: 0.4906 - val_loss: 1.6850 - val_accuracy: 0.4548 - 294ms/epoch - 23ms/step\n",
            "Epoch 107/300\n",
            "13/13 - 0s - loss: 1.3949 - accuracy: 0.4886 - val_loss: 1.6561 - val_accuracy: 0.4723 - 296ms/epoch - 23ms/step\n",
            "Epoch 108/300\n",
            "13/13 - 0s - loss: 1.4642 - accuracy: 0.4719 - val_loss: 1.8283 - val_accuracy: 0.4723 - 297ms/epoch - 23ms/step\n",
            "Epoch 109/300\n",
            "13/13 - 0s - loss: 1.3829 - accuracy: 0.4899 - val_loss: 1.6022 - val_accuracy: 0.5044 - 289ms/epoch - 22ms/step\n",
            "Epoch 110/300\n",
            "13/13 - 0s - loss: 1.3935 - accuracy: 0.4846 - val_loss: 1.7597 - val_accuracy: 0.4810 - 296ms/epoch - 23ms/step\n",
            "Epoch 111/300\n",
            "13/13 - 0s - loss: 1.5245 - accuracy: 0.4442 - val_loss: 1.9690 - val_accuracy: 0.4504 - 294ms/epoch - 23ms/step\n",
            "Epoch 112/300\n",
            "13/13 - 0s - loss: 1.4504 - accuracy: 0.4604 - val_loss: 2.0662 - val_accuracy: 0.4592 - 291ms/epoch - 22ms/step\n",
            "Epoch 113/300\n",
            "13/13 - 0s - loss: 1.3662 - accuracy: 0.5037 - val_loss: 1.7511 - val_accuracy: 0.4577 - 291ms/epoch - 22ms/step\n",
            "Epoch 114/300\n",
            "13/13 - 0s - loss: 1.3603 - accuracy: 0.5209 - val_loss: 1.7605 - val_accuracy: 0.4956 - 293ms/epoch - 23ms/step\n",
            "Epoch 115/300\n",
            "13/13 - 0s - loss: 1.4496 - accuracy: 0.4909 - val_loss: 1.7615 - val_accuracy: 0.4606 - 298ms/epoch - 23ms/step\n",
            "Epoch 116/300\n",
            "13/13 - 0s - loss: 1.5692 - accuracy: 0.4500 - val_loss: 1.8584 - val_accuracy: 0.3703 - 296ms/epoch - 23ms/step\n",
            "Epoch 117/300\n",
            "13/13 - 0s - loss: 1.6576 - accuracy: 0.3980 - val_loss: 1.7751 - val_accuracy: 0.3717 - 289ms/epoch - 22ms/step\n",
            "Epoch 118/300\n",
            "13/13 - 0s - loss: 1.6713 - accuracy: 0.4103 - val_loss: 1.8952 - val_accuracy: 0.3950 - 292ms/epoch - 22ms/step\n",
            "Epoch 119/300\n",
            "13/13 - 0s - loss: 1.5791 - accuracy: 0.4285 - val_loss: 1.7093 - val_accuracy: 0.3936 - 298ms/epoch - 23ms/step\n",
            "Epoch 120/300\n",
            "13/13 - 0s - loss: 1.5838 - accuracy: 0.4385 - val_loss: 1.7507 - val_accuracy: 0.4125 - 299ms/epoch - 23ms/step\n",
            "Epoch 121/300\n",
            "13/13 - 0s - loss: 1.5784 - accuracy: 0.4204 - val_loss: 1.7090 - val_accuracy: 0.4242 - 297ms/epoch - 23ms/step\n",
            "Epoch 122/300\n",
            "13/13 - 0s - loss: 1.5861 - accuracy: 0.4351 - val_loss: 1.8559 - val_accuracy: 0.3878 - 287ms/epoch - 22ms/step\n",
            "Epoch 123/300\n",
            "13/13 - 0s - loss: 1.5255 - accuracy: 0.4272 - val_loss: 1.8930 - val_accuracy: 0.4052 - 293ms/epoch - 23ms/step\n",
            "Epoch 124/300\n",
            "13/13 - 0s - loss: 1.5465 - accuracy: 0.4445 - val_loss: 1.9408 - val_accuracy: 0.4067 - 300ms/epoch - 23ms/step\n",
            "Epoch 125/300\n",
            "13/13 - 0s - loss: 1.5096 - accuracy: 0.4525 - val_loss: 1.7233 - val_accuracy: 0.4548 - 293ms/epoch - 23ms/step\n",
            "Epoch 126/300\n",
            "13/13 - 0s - loss: 1.4875 - accuracy: 0.4447 - val_loss: 1.7008 - val_accuracy: 0.4286 - 292ms/epoch - 22ms/step\n",
            "Epoch 127/300\n",
            "13/13 - 0s - loss: 1.4772 - accuracy: 0.4538 - val_loss: 1.7485 - val_accuracy: 0.4082 - 295ms/epoch - 23ms/step\n",
            "Epoch 128/300\n",
            "13/13 - 0s - loss: 1.4835 - accuracy: 0.4489 - val_loss: 1.8221 - val_accuracy: 0.3965 - 291ms/epoch - 22ms/step\n",
            "Epoch 129/300\n",
            "13/13 - 0s - loss: 1.4425 - accuracy: 0.4778 - val_loss: 1.7365 - val_accuracy: 0.4417 - 290ms/epoch - 22ms/step\n",
            "Epoch 130/300\n",
            "13/13 - 0s - loss: 1.4337 - accuracy: 0.4878 - val_loss: 1.8899 - val_accuracy: 0.3921 - 295ms/epoch - 23ms/step\n",
            "Epoch 131/300\n",
            "13/13 - 0s - loss: 1.9351 - accuracy: 0.4398 - val_loss: 1.7227 - val_accuracy: 0.4504 - 289ms/epoch - 22ms/step\n",
            "Epoch 132/300\n",
            "13/13 - 0s - loss: 1.5684 - accuracy: 0.4471 - val_loss: 1.7823 - val_accuracy: 0.4752 - 292ms/epoch - 22ms/step\n",
            "Epoch 133/300\n",
            "13/13 - 0s - loss: 1.5845 - accuracy: 0.4573 - val_loss: 1.8041 - val_accuracy: 0.4373 - 295ms/epoch - 23ms/step\n",
            "Epoch 134/300\n",
            "13/13 - 0s - loss: 1.5089 - accuracy: 0.4458 - val_loss: 1.7605 - val_accuracy: 0.4431 - 293ms/epoch - 23ms/step\n",
            "Epoch 135/300\n",
            "13/13 - 0s - loss: 1.5368 - accuracy: 0.4476 - val_loss: 1.7899 - val_accuracy: 0.3878 - 290ms/epoch - 22ms/step\n",
            "Epoch 136/300\n",
            "13/13 - 0s - loss: 1.4911 - accuracy: 0.4465 - val_loss: 1.7642 - val_accuracy: 0.4373 - 293ms/epoch - 23ms/step\n",
            "Epoch 137/300\n",
            "13/13 - 0s - loss: 1.4565 - accuracy: 0.4650 - val_loss: 1.7814 - val_accuracy: 0.4548 - 290ms/epoch - 22ms/step\n",
            "Epoch 138/300\n",
            "13/13 - 0s - loss: 1.4594 - accuracy: 0.4659 - val_loss: 1.8077 - val_accuracy: 0.4767 - 292ms/epoch - 22ms/step\n",
            "Epoch 139/300\n",
            "13/13 - 0s - loss: 1.5641 - accuracy: 0.4246 - val_loss: 1.8729 - val_accuracy: 0.3950 - 290ms/epoch - 22ms/step\n",
            "Epoch 140/300\n",
            "13/13 - 0s - loss: 1.5143 - accuracy: 0.4439 - val_loss: 1.8120 - val_accuracy: 0.4140 - 290ms/epoch - 22ms/step\n",
            "Epoch 141/300\n",
            "13/13 - 0s - loss: 1.6126 - accuracy: 0.4217 - val_loss: 1.7529 - val_accuracy: 0.4271 - 294ms/epoch - 23ms/step\n",
            "Epoch 142/300\n",
            "13/13 - 0s - loss: 1.5921 - accuracy: 0.4176 - val_loss: 2.0019 - val_accuracy: 0.3673 - 293ms/epoch - 23ms/step\n",
            "Epoch 143/300\n",
            "13/13 - 0s - loss: 1.5997 - accuracy: 0.4123 - val_loss: 1.9200 - val_accuracy: 0.3280 - 290ms/epoch - 22ms/step\n",
            "Epoch 144/300\n",
            "13/13 - 0s - loss: 1.6662 - accuracy: 0.4014 - val_loss: 1.7698 - val_accuracy: 0.4431 - 292ms/epoch - 22ms/step\n",
            "Epoch 145/300\n",
            "13/13 - 0s - loss: 1.5939 - accuracy: 0.4082 - val_loss: 1.8613 - val_accuracy: 0.3673 - 293ms/epoch - 23ms/step\n",
            "Epoch 146/300\n",
            "13/13 - 0s - loss: 1.6308 - accuracy: 0.4502 - val_loss: 1.9353 - val_accuracy: 0.3309 - 290ms/epoch - 22ms/step\n",
            "Epoch 147/300\n",
            "13/13 - 0s - loss: 1.6083 - accuracy: 0.4100 - val_loss: 1.8187 - val_accuracy: 0.4184 - 287ms/epoch - 22ms/step\n",
            "Epoch 148/300\n",
            "13/13 - 0s - loss: 1.5513 - accuracy: 0.4256 - val_loss: 1.8754 - val_accuracy: 0.3528 - 292ms/epoch - 22ms/step\n",
            "Epoch 149/300\n",
            "13/13 - 0s - loss: 1.5207 - accuracy: 0.4413 - val_loss: 1.7113 - val_accuracy: 0.4096 - 294ms/epoch - 23ms/step\n",
            "Epoch 150/300\n",
            "13/13 - 0s - loss: 1.5290 - accuracy: 0.4358 - val_loss: 1.6689 - val_accuracy: 0.4534 - 289ms/epoch - 22ms/step\n",
            "Epoch 151/300\n",
            "13/13 - 0s - loss: 1.5557 - accuracy: 0.4129 - val_loss: 1.7943 - val_accuracy: 0.3455 - 291ms/epoch - 22ms/step\n",
            "Epoch 152/300\n",
            "13/13 - 0s - loss: 1.5712 - accuracy: 0.4239 - val_loss: 1.6352 - val_accuracy: 0.4548 - 287ms/epoch - 22ms/step\n",
            "Epoch 153/300\n",
            "13/13 - 0s - loss: 1.6785 - accuracy: 0.3722 - val_loss: 1.9721 - val_accuracy: 0.3717 - 288ms/epoch - 22ms/step\n",
            "Epoch 154/300\n",
            "13/13 - 0s - loss: 1.6011 - accuracy: 0.4243 - val_loss: 1.7868 - val_accuracy: 0.3601 - 290ms/epoch - 22ms/step\n",
            "Epoch 155/300\n",
            "13/13 - 0s - loss: 1.5969 - accuracy: 0.4184 - val_loss: 1.7751 - val_accuracy: 0.4461 - 291ms/epoch - 22ms/step\n",
            "Epoch 156/300\n",
            "13/13 - 0s - loss: 1.5251 - accuracy: 0.4295 - val_loss: 1.8225 - val_accuracy: 0.4155 - 290ms/epoch - 22ms/step\n",
            "Epoch 157/300\n",
            "13/13 - 0s - loss: 1.5885 - accuracy: 0.4247 - val_loss: 1.8851 - val_accuracy: 0.4198 - 293ms/epoch - 23ms/step\n",
            "Epoch 158/300\n",
            "13/13 - 0s - loss: 1.4550 - accuracy: 0.4620 - val_loss: 1.7179 - val_accuracy: 0.4796 - 293ms/epoch - 23ms/step\n",
            "Epoch 159/300\n",
            "13/13 - 0s - loss: 1.6067 - accuracy: 0.4275 - val_loss: 2.1500 - val_accuracy: 0.2930 - 297ms/epoch - 23ms/step\n",
            "Epoch 160/300\n",
            "13/13 - 0s - loss: 1.8383 - accuracy: 0.3484 - val_loss: 1.8022 - val_accuracy: 0.3950 - 297ms/epoch - 23ms/step\n",
            "Epoch 161/300\n",
            "13/13 - 0s - loss: 1.6312 - accuracy: 0.4119 - val_loss: 1.8025 - val_accuracy: 0.4096 - 293ms/epoch - 23ms/step\n",
            "Epoch 162/300\n",
            "13/13 - 0s - loss: 1.5799 - accuracy: 0.4262 - val_loss: 2.0053 - val_accuracy: 0.3105 - 292ms/epoch - 22ms/step\n",
            "Epoch 163/300\n",
            "13/13 - 0s - loss: 1.5297 - accuracy: 0.4379 - val_loss: 1.8752 - val_accuracy: 0.3907 - 290ms/epoch - 22ms/step\n",
            "Epoch 164/300\n",
            "13/13 - 0s - loss: 1.4719 - accuracy: 0.4577 - val_loss: 1.7676 - val_accuracy: 0.4125 - 294ms/epoch - 23ms/step\n",
            "Epoch 165/300\n",
            "13/13 - 0s - loss: 1.5437 - accuracy: 0.4351 - val_loss: 1.8310 - val_accuracy: 0.3921 - 290ms/epoch - 22ms/step\n",
            "Epoch 166/300\n",
            "13/13 - 0s - loss: 1.5542 - accuracy: 0.4295 - val_loss: 1.8425 - val_accuracy: 0.3717 - 289ms/epoch - 22ms/step\n",
            "Epoch 167/300\n",
            "13/13 - 0s - loss: 1.6004 - accuracy: 0.4329 - val_loss: 1.8200 - val_accuracy: 0.3586 - 293ms/epoch - 23ms/step\n",
            "Epoch 168/300\n",
            "13/13 - 0s - loss: 1.6615 - accuracy: 0.4127 - val_loss: 1.9507 - val_accuracy: 0.3703 - 288ms/epoch - 22ms/step\n",
            "Epoch 169/300\n",
            "13/13 - 0s - loss: 1.6273 - accuracy: 0.4170 - val_loss: 2.0610 - val_accuracy: 0.3251 - 292ms/epoch - 22ms/step\n",
            "Epoch 170/300\n",
            "13/13 - 0s - loss: 1.6403 - accuracy: 0.4132 - val_loss: 1.8370 - val_accuracy: 0.3673 - 290ms/epoch - 22ms/step\n",
            "Epoch 171/300\n",
            "13/13 - 0s - loss: 1.5706 - accuracy: 0.4257 - val_loss: 1.8040 - val_accuracy: 0.4140 - 295ms/epoch - 23ms/step\n",
            "Epoch 172/300\n",
            "13/13 - 0s - loss: 1.5488 - accuracy: 0.4314 - val_loss: 1.7720 - val_accuracy: 0.3950 - 292ms/epoch - 22ms/step\n",
            "Epoch 173/300\n",
            "13/13 - 0s - loss: 1.6546 - accuracy: 0.4003 - val_loss: 1.9439 - val_accuracy: 0.3382 - 298ms/epoch - 23ms/step\n",
            "Epoch 174/300\n",
            "13/13 - 0s - loss: 1.5944 - accuracy: 0.4158 - val_loss: 1.7592 - val_accuracy: 0.4155 - 295ms/epoch - 23ms/step\n",
            "Epoch 175/300\n",
            "13/13 - 0s - loss: 1.5881 - accuracy: 0.4178 - val_loss: 1.8441 - val_accuracy: 0.3790 - 295ms/epoch - 23ms/step\n",
            "Epoch 176/300\n",
            "13/13 - 0s - loss: 1.5607 - accuracy: 0.4350 - val_loss: 1.9732 - val_accuracy: 0.3499 - 287ms/epoch - 22ms/step\n",
            "Epoch 177/300\n",
            "13/13 - 0s - loss: 1.6662 - accuracy: 0.3853 - val_loss: 2.0002 - val_accuracy: 0.3499 - 292ms/epoch - 22ms/step\n",
            "Epoch 178/300\n",
            "13/13 - 0s - loss: 1.6358 - accuracy: 0.3931 - val_loss: 2.0058 - val_accuracy: 0.3878 - 294ms/epoch - 23ms/step\n",
            "Epoch 179/300\n",
            "13/13 - 0s - loss: 1.5696 - accuracy: 0.4132 - val_loss: 1.9779 - val_accuracy: 0.4052 - 291ms/epoch - 22ms/step\n",
            "Epoch 180/300\n",
            "13/13 - 0s - loss: 1.6725 - accuracy: 0.3918 - val_loss: 1.8115 - val_accuracy: 0.3673 - 287ms/epoch - 22ms/step\n",
            "Epoch 181/300\n",
            "13/13 - 0s - loss: 1.6260 - accuracy: 0.4231 - val_loss: 1.9090 - val_accuracy: 0.3892 - 291ms/epoch - 22ms/step\n",
            "Epoch 182/300\n",
            "13/13 - 0s - loss: 1.6818 - accuracy: 0.4022 - val_loss: 2.2350 - val_accuracy: 0.3513 - 298ms/epoch - 23ms/step\n",
            "Epoch 183/300\n",
            "13/13 - 0s - loss: 1.5880 - accuracy: 0.4149 - val_loss: 1.7591 - val_accuracy: 0.4184 - 298ms/epoch - 23ms/step\n",
            "Epoch 184/300\n",
            "13/13 - 0s - loss: 1.5419 - accuracy: 0.4363 - val_loss: 1.7399 - val_accuracy: 0.4242 - 296ms/epoch - 23ms/step\n",
            "Epoch 185/300\n",
            "13/13 - 0s - loss: 1.5273 - accuracy: 0.4337 - val_loss: 1.8010 - val_accuracy: 0.3994 - 294ms/epoch - 23ms/step\n",
            "Epoch 186/300\n",
            "13/13 - 0s - loss: 1.5246 - accuracy: 0.4366 - val_loss: 1.7460 - val_accuracy: 0.4475 - 291ms/epoch - 22ms/step\n",
            "Epoch 187/300\n",
            "13/13 - 0s - loss: 1.5399 - accuracy: 0.4251 - val_loss: 1.7841 - val_accuracy: 0.3717 - 289ms/epoch - 22ms/step\n",
            "Epoch 188/300\n",
            "13/13 - 0s - loss: 1.5300 - accuracy: 0.4205 - val_loss: 1.8108 - val_accuracy: 0.3659 - 296ms/epoch - 23ms/step\n",
            "Epoch 189/300\n",
            "13/13 - 0s - loss: 1.5804 - accuracy: 0.4168 - val_loss: 2.6837 - val_accuracy: 0.3965 - 292ms/epoch - 22ms/step\n",
            "Epoch 190/300\n",
            "13/13 - 0s - loss: 1.8569 - accuracy: 0.4020 - val_loss: 1.8798 - val_accuracy: 0.3703 - 294ms/epoch - 23ms/step\n",
            "Epoch 191/300\n",
            "13/13 - 0s - loss: 1.5778 - accuracy: 0.4204 - val_loss: 1.8350 - val_accuracy: 0.4111 - 293ms/epoch - 23ms/step\n",
            "Epoch 192/300\n",
            "13/13 - 0s - loss: 1.4956 - accuracy: 0.4488 - val_loss: 1.7538 - val_accuracy: 0.3921 - 297ms/epoch - 23ms/step\n",
            "Epoch 193/300\n",
            "13/13 - 0s - loss: 1.5933 - accuracy: 0.4218 - val_loss: 1.8852 - val_accuracy: 0.3382 - 296ms/epoch - 23ms/step\n",
            "Epoch 194/300\n",
            "13/13 - 0s - loss: 1.5771 - accuracy: 0.4299 - val_loss: 2.0514 - val_accuracy: 0.2886 - 300ms/epoch - 23ms/step\n",
            "Epoch 195/300\n",
            "13/13 - 0s - loss: 1.5587 - accuracy: 0.4364 - val_loss: 1.7796 - val_accuracy: 0.4592 - 292ms/epoch - 22ms/step\n",
            "Epoch 196/300\n",
            "13/13 - 0s - loss: 1.8587 - accuracy: 0.3667 - val_loss: 1.7524 - val_accuracy: 0.3601 - 293ms/epoch - 23ms/step\n",
            "Epoch 197/300\n",
            "13/13 - 0s - loss: 1.6778 - accuracy: 0.3952 - val_loss: 1.7648 - val_accuracy: 0.3469 - 289ms/epoch - 22ms/step\n",
            "Epoch 198/300\n",
            "13/13 - 0s - loss: 1.5686 - accuracy: 0.4286 - val_loss: 1.8878 - val_accuracy: 0.3571 - 291ms/epoch - 22ms/step\n",
            "Epoch 199/300\n",
            "13/13 - 0s - loss: 1.5894 - accuracy: 0.4345 - val_loss: 1.7854 - val_accuracy: 0.3994 - 293ms/epoch - 23ms/step\n",
            "Epoch 200/300\n",
            "13/13 - 0s - loss: 1.5083 - accuracy: 0.4358 - val_loss: 1.7504 - val_accuracy: 0.3921 - 291ms/epoch - 22ms/step\n",
            "Epoch 201/300\n",
            "13/13 - 0s - loss: 1.4868 - accuracy: 0.4560 - val_loss: 1.7451 - val_accuracy: 0.4009 - 287ms/epoch - 22ms/step\n",
            "Epoch 202/300\n",
            "13/13 - 0s - loss: 1.4750 - accuracy: 0.4497 - val_loss: 1.8262 - val_accuracy: 0.3980 - 293ms/epoch - 23ms/step\n",
            "Epoch 203/300\n",
            "13/13 - 0s - loss: 1.4828 - accuracy: 0.4405 - val_loss: 1.8342 - val_accuracy: 0.3426 - 297ms/epoch - 23ms/step\n",
            "Epoch 204/300\n",
            "13/13 - 0s - loss: 1.5235 - accuracy: 0.4286 - val_loss: 1.7565 - val_accuracy: 0.3673 - 294ms/epoch - 23ms/step\n",
            "Epoch 205/300\n",
            "13/13 - 0s - loss: 1.5150 - accuracy: 0.4405 - val_loss: 1.7332 - val_accuracy: 0.3994 - 288ms/epoch - 22ms/step\n",
            "Epoch 206/300\n",
            "13/13 - 0s - loss: 1.4513 - accuracy: 0.4539 - val_loss: 1.7428 - val_accuracy: 0.3965 - 292ms/epoch - 22ms/step\n",
            "Epoch 207/300\n",
            "13/13 - 0s - loss: 1.4416 - accuracy: 0.4564 - val_loss: 1.9682 - val_accuracy: 0.3426 - 291ms/epoch - 22ms/step\n",
            "Epoch 208/300\n",
            "13/13 - 0s - loss: 1.4354 - accuracy: 0.4601 - val_loss: 1.6923 - val_accuracy: 0.4198 - 289ms/epoch - 22ms/step\n",
            "Epoch 209/300\n",
            "13/13 - 0s - loss: 1.4085 - accuracy: 0.4640 - val_loss: 1.7282 - val_accuracy: 0.4198 - 297ms/epoch - 23ms/step\n",
            "Epoch 210/300\n",
            "13/13 - 0s - loss: 1.4632 - accuracy: 0.4692 - val_loss: 1.7010 - val_accuracy: 0.4854 - 290ms/epoch - 22ms/step\n",
            "Epoch 211/300\n",
            "13/13 - 0s - loss: 1.5230 - accuracy: 0.4306 - val_loss: 1.9720 - val_accuracy: 0.3863 - 292ms/epoch - 22ms/step\n",
            "Epoch 212/300\n",
            "13/13 - 0s - loss: 1.4949 - accuracy: 0.4452 - val_loss: 1.7941 - val_accuracy: 0.3761 - 291ms/epoch - 22ms/step\n",
            "Epoch 213/300\n",
            "13/13 - 0s - loss: 1.4772 - accuracy: 0.4585 - val_loss: 1.9104 - val_accuracy: 0.4271 - 292ms/epoch - 22ms/step\n",
            "Epoch 214/300\n",
            "13/13 - 0s - loss: 1.4405 - accuracy: 0.4666 - val_loss: 1.9286 - val_accuracy: 0.3761 - 294ms/epoch - 23ms/step\n",
            "Epoch 215/300\n",
            "13/13 - 0s - loss: 1.4796 - accuracy: 0.4562 - val_loss: 1.8814 - val_accuracy: 0.4169 - 287ms/epoch - 22ms/step\n",
            "Epoch 216/300\n",
            "13/13 - 0s - loss: 1.4823 - accuracy: 0.4672 - val_loss: 1.7900 - val_accuracy: 0.4169 - 295ms/epoch - 23ms/step\n",
            "Epoch 217/300\n",
            "13/13 - 0s - loss: 1.4676 - accuracy: 0.4502 - val_loss: 1.8183 - val_accuracy: 0.3338 - 288ms/epoch - 22ms/step\n",
            "Epoch 218/300\n",
            "13/13 - 0s - loss: 1.4497 - accuracy: 0.4611 - val_loss: 1.7855 - val_accuracy: 0.3673 - 291ms/epoch - 22ms/step\n",
            "Epoch 219/300\n",
            "13/13 - 0s - loss: 1.4646 - accuracy: 0.4619 - val_loss: 1.8437 - val_accuracy: 0.3746 - 294ms/epoch - 23ms/step\n",
            "Epoch 220/300\n",
            "13/13 - 0s - loss: 1.4561 - accuracy: 0.4608 - val_loss: 1.7730 - val_accuracy: 0.3630 - 292ms/epoch - 22ms/step\n",
            "Epoch 221/300\n",
            "13/13 - 0s - loss: 1.4200 - accuracy: 0.4596 - val_loss: 1.7301 - val_accuracy: 0.4344 - 295ms/epoch - 23ms/step\n",
            "Epoch 222/300\n",
            "13/13 - 0s - loss: 1.4529 - accuracy: 0.4736 - val_loss: 1.6748 - val_accuracy: 0.4344 - 291ms/epoch - 22ms/step\n",
            "Epoch 223/300\n",
            "13/13 - 0s - loss: 1.4141 - accuracy: 0.4861 - val_loss: 1.6693 - val_accuracy: 0.4636 - 293ms/epoch - 23ms/step\n",
            "Epoch 224/300\n",
            "13/13 - 0s - loss: 1.4563 - accuracy: 0.4695 - val_loss: 1.8958 - val_accuracy: 0.3790 - 293ms/epoch - 23ms/step\n",
            "Epoch 225/300\n",
            "13/13 - 0s - loss: 1.6135 - accuracy: 0.4298 - val_loss: 1.9529 - val_accuracy: 0.3426 - 292ms/epoch - 22ms/step\n",
            "Epoch 226/300\n",
            "13/13 - 0s - loss: 1.7491 - accuracy: 0.3808 - val_loss: 1.8782 - val_accuracy: 0.3557 - 290ms/epoch - 22ms/step\n",
            "Epoch 227/300\n",
            "13/13 - 0s - loss: 1.7005 - accuracy: 0.3748 - val_loss: 1.8259 - val_accuracy: 0.3834 - 295ms/epoch - 23ms/step\n",
            "Epoch 228/300\n",
            "13/13 - 0s - loss: 1.6842 - accuracy: 0.3803 - val_loss: 1.8086 - val_accuracy: 0.3586 - 293ms/epoch - 23ms/step\n",
            "Epoch 229/300\n",
            "13/13 - 0s - loss: 1.6362 - accuracy: 0.4059 - val_loss: 1.9303 - val_accuracy: 0.3659 - 297ms/epoch - 23ms/step\n",
            "Epoch 230/300\n",
            "13/13 - 0s - loss: 1.7424 - accuracy: 0.3613 - val_loss: 1.9337 - val_accuracy: 0.3397 - 293ms/epoch - 23ms/step\n",
            "Epoch 231/300\n",
            "13/13 - 0s - loss: 1.7107 - accuracy: 0.3542 - val_loss: 1.8802 - val_accuracy: 0.3003 - 291ms/epoch - 22ms/step\n",
            "Epoch 232/300\n",
            "13/13 - 0s - loss: 1.6394 - accuracy: 0.3896 - val_loss: 1.7481 - val_accuracy: 0.4023 - 290ms/epoch - 22ms/step\n",
            "Epoch 233/300\n",
            "13/13 - 0s - loss: 1.6073 - accuracy: 0.4184 - val_loss: 2.4597 - val_accuracy: 0.3790 - 297ms/epoch - 23ms/step\n",
            "Epoch 234/300\n",
            "13/13 - 0s - loss: 1.7506 - accuracy: 0.3991 - val_loss: 1.6981 - val_accuracy: 0.4315 - 293ms/epoch - 23ms/step\n",
            "Epoch 235/300\n",
            "13/13 - 0s - loss: 1.5985 - accuracy: 0.4139 - val_loss: 1.7471 - val_accuracy: 0.4023 - 291ms/epoch - 22ms/step\n",
            "Epoch 236/300\n",
            "13/13 - 0s - loss: 1.5471 - accuracy: 0.4296 - val_loss: 1.7231 - val_accuracy: 0.4767 - 288ms/epoch - 22ms/step\n",
            "Epoch 237/300\n",
            "13/13 - 0s - loss: 1.5121 - accuracy: 0.4421 - val_loss: 1.6818 - val_accuracy: 0.4679 - 295ms/epoch - 23ms/step\n",
            "Epoch 238/300\n",
            "13/13 - 0s - loss: 1.4301 - accuracy: 0.4766 - val_loss: 1.6861 - val_accuracy: 0.4446 - 292ms/epoch - 22ms/step\n",
            "Epoch 239/300\n",
            "13/13 - 0s - loss: 1.4626 - accuracy: 0.4565 - val_loss: 1.7328 - val_accuracy: 0.3994 - 295ms/epoch - 23ms/step\n",
            "Epoch 240/300\n",
            "13/13 - 0s - loss: 1.4607 - accuracy: 0.4565 - val_loss: 1.6699 - val_accuracy: 0.4431 - 290ms/epoch - 22ms/step\n",
            "Epoch 241/300\n",
            "13/13 - 0s - loss: 1.5198 - accuracy: 0.4486 - val_loss: 1.7068 - val_accuracy: 0.4388 - 295ms/epoch - 23ms/step\n",
            "Epoch 242/300\n",
            "13/13 - 0s - loss: 1.4524 - accuracy: 0.4603 - val_loss: 1.7523 - val_accuracy: 0.3936 - 290ms/epoch - 22ms/step\n",
            "Epoch 243/300\n",
            "13/13 - 0s - loss: 1.4072 - accuracy: 0.4880 - val_loss: 1.7742 - val_accuracy: 0.4431 - 286ms/epoch - 22ms/step\n",
            "Epoch 244/300\n",
            "13/13 - 0s - loss: 1.4323 - accuracy: 0.4763 - val_loss: 1.7182 - val_accuracy: 0.4227 - 291ms/epoch - 22ms/step\n",
            "Epoch 245/300\n",
            "13/13 - 0s - loss: 1.6030 - accuracy: 0.4228 - val_loss: 1.7521 - val_accuracy: 0.4023 - 290ms/epoch - 22ms/step\n",
            "Epoch 246/300\n",
            "13/13 - 0s - loss: 1.5199 - accuracy: 0.4449 - val_loss: 1.8734 - val_accuracy: 0.3717 - 296ms/epoch - 23ms/step\n",
            "Epoch 247/300\n",
            "13/13 - 0s - loss: 1.4584 - accuracy: 0.4609 - val_loss: 1.8821 - val_accuracy: 0.4082 - 296ms/epoch - 23ms/step\n",
            "Epoch 248/300\n",
            "13/13 - 0s - loss: 1.4782 - accuracy: 0.4470 - val_loss: 1.9200 - val_accuracy: 0.2886 - 290ms/epoch - 22ms/step\n",
            "Epoch 249/300\n",
            "13/13 - 0s - loss: 1.4289 - accuracy: 0.4659 - val_loss: 1.8796 - val_accuracy: 0.4300 - 289ms/epoch - 22ms/step\n",
            "Epoch 250/300\n",
            "13/13 - 0s - loss: 1.5566 - accuracy: 0.4539 - val_loss: 1.8509 - val_accuracy: 0.4636 - 293ms/epoch - 23ms/step\n",
            "Epoch 251/300\n",
            "13/13 - 0s - loss: 1.4600 - accuracy: 0.4567 - val_loss: 1.8049 - val_accuracy: 0.4067 - 295ms/epoch - 23ms/step\n",
            "Epoch 252/300\n",
            "13/13 - 0s - loss: 1.5028 - accuracy: 0.4447 - val_loss: 1.8029 - val_accuracy: 0.4665 - 291ms/epoch - 22ms/step\n",
            "Epoch 253/300\n",
            "13/13 - 0s - loss: 1.4761 - accuracy: 0.4557 - val_loss: 1.8465 - val_accuracy: 0.3309 - 292ms/epoch - 22ms/step\n",
            "Epoch 254/300\n",
            "13/13 - 0s - loss: 1.4578 - accuracy: 0.4515 - val_loss: 1.6864 - val_accuracy: 0.4767 - 289ms/epoch - 22ms/step\n",
            "Epoch 255/300\n",
            "13/13 - 0s - loss: 1.4304 - accuracy: 0.4732 - val_loss: 1.7999 - val_accuracy: 0.4213 - 290ms/epoch - 22ms/step\n",
            "Epoch 256/300\n",
            "13/13 - 0s - loss: 1.3935 - accuracy: 0.4775 - val_loss: 1.6960 - val_accuracy: 0.4169 - 300ms/epoch - 23ms/step\n",
            "Epoch 257/300\n",
            "13/13 - 0s - loss: 1.4034 - accuracy: 0.4872 - val_loss: 1.8036 - val_accuracy: 0.4052 - 291ms/epoch - 22ms/step\n",
            "Epoch 258/300\n",
            "13/13 - 0s - loss: 1.4696 - accuracy: 0.4466 - val_loss: 1.8178 - val_accuracy: 0.4563 - 293ms/epoch - 23ms/step\n",
            "Epoch 259/300\n",
            "13/13 - 0s - loss: 1.4156 - accuracy: 0.4702 - val_loss: 1.7571 - val_accuracy: 0.4840 - 288ms/epoch - 22ms/step\n",
            "Epoch 260/300\n",
            "13/13 - 0s - loss: 1.4188 - accuracy: 0.4815 - val_loss: 1.6651 - val_accuracy: 0.4679 - 288ms/epoch - 22ms/step\n",
            "Epoch 261/300\n",
            "13/13 - 0s - loss: 1.4182 - accuracy: 0.4703 - val_loss: 1.7865 - val_accuracy: 0.4519 - 295ms/epoch - 23ms/step\n",
            "Epoch 262/300\n",
            "13/13 - 0s - loss: 1.4257 - accuracy: 0.4799 - val_loss: 1.7602 - val_accuracy: 0.4475 - 292ms/epoch - 22ms/step\n",
            "Epoch 263/300\n",
            "13/13 - 0s - loss: 1.4047 - accuracy: 0.4771 - val_loss: 1.6534 - val_accuracy: 0.4679 - 291ms/epoch - 22ms/step\n",
            "Epoch 264/300\n",
            "13/13 - 0s - loss: 1.4131 - accuracy: 0.4736 - val_loss: 1.7257 - val_accuracy: 0.4242 - 293ms/epoch - 23ms/step\n",
            "Epoch 265/300\n",
            "13/13 - 0s - loss: 1.4285 - accuracy: 0.4739 - val_loss: 1.8468 - val_accuracy: 0.3630 - 292ms/epoch - 22ms/step\n",
            "Epoch 266/300\n",
            "13/13 - 0s - loss: 1.4255 - accuracy: 0.4705 - val_loss: 1.7981 - val_accuracy: 0.3965 - 289ms/epoch - 22ms/step\n",
            "Epoch 267/300\n",
            "13/13 - 0s - loss: 1.4155 - accuracy: 0.4732 - val_loss: 1.7877 - val_accuracy: 0.4738 - 296ms/epoch - 23ms/step\n",
            "Epoch 268/300\n",
            "13/13 - 0s - loss: 1.4806 - accuracy: 0.4599 - val_loss: 1.8337 - val_accuracy: 0.4257 - 291ms/epoch - 22ms/step\n",
            "Epoch 269/300\n",
            "13/13 - 0s - loss: 1.5064 - accuracy: 0.4458 - val_loss: 1.8549 - val_accuracy: 0.4417 - 295ms/epoch - 23ms/step\n",
            "Epoch 270/300\n",
            "13/13 - 0s - loss: 1.4733 - accuracy: 0.4695 - val_loss: 1.8097 - val_accuracy: 0.4650 - 294ms/epoch - 23ms/step\n",
            "Epoch 271/300\n",
            "13/13 - 0s - loss: 1.4213 - accuracy: 0.4942 - val_loss: 1.8180 - val_accuracy: 0.4606 - 296ms/epoch - 23ms/step\n",
            "Epoch 272/300\n",
            "13/13 - 0s - loss: 1.5507 - accuracy: 0.4852 - val_loss: 1.8658 - val_accuracy: 0.4534 - 291ms/epoch - 22ms/step\n",
            "Epoch 273/300\n",
            "13/13 - 0s - loss: 1.4532 - accuracy: 0.4548 - val_loss: 1.8498 - val_accuracy: 0.4810 - 293ms/epoch - 23ms/step\n",
            "Epoch 274/300\n",
            "13/13 - 0s - loss: 1.4594 - accuracy: 0.4595 - val_loss: 1.6901 - val_accuracy: 0.4781 - 290ms/epoch - 22ms/step\n",
            "Epoch 275/300\n",
            "13/13 - 0s - loss: 1.4211 - accuracy: 0.4708 - val_loss: 1.7107 - val_accuracy: 0.4796 - 295ms/epoch - 23ms/step\n",
            "Epoch 276/300\n",
            "13/13 - 0s - loss: 1.4952 - accuracy: 0.4538 - val_loss: 1.8164 - val_accuracy: 0.4956 - 293ms/epoch - 23ms/step\n",
            "Epoch 277/300\n",
            "13/13 - 0s - loss: 1.3876 - accuracy: 0.4917 - val_loss: 1.7434 - val_accuracy: 0.4767 - 291ms/epoch - 22ms/step\n",
            "Epoch 278/300\n",
            "13/13 - 0s - loss: 1.4473 - accuracy: 0.4820 - val_loss: 1.9188 - val_accuracy: 0.4723 - 296ms/epoch - 23ms/step\n",
            "Epoch 279/300\n",
            "13/13 - 0s - loss: 1.4051 - accuracy: 0.4872 - val_loss: 1.7125 - val_accuracy: 0.4286 - 286ms/epoch - 22ms/step\n",
            "Epoch 280/300\n",
            "13/13 - 0s - loss: 1.4889 - accuracy: 0.4470 - val_loss: 1.8268 - val_accuracy: 0.3761 - 292ms/epoch - 22ms/step\n",
            "Epoch 281/300\n",
            "13/13 - 0s - loss: 1.4436 - accuracy: 0.4619 - val_loss: 1.8294 - val_accuracy: 0.3746 - 291ms/epoch - 22ms/step\n",
            "Epoch 282/300\n",
            "13/13 - 0s - loss: 1.4247 - accuracy: 0.4718 - val_loss: 1.8017 - val_accuracy: 0.4242 - 294ms/epoch - 23ms/step\n",
            "Epoch 283/300\n",
            "13/13 - 0s - loss: 1.5323 - accuracy: 0.4522 - val_loss: 1.8223 - val_accuracy: 0.4679 - 295ms/epoch - 23ms/step\n",
            "Epoch 284/300\n",
            "13/13 - 0s - loss: 1.4665 - accuracy: 0.4724 - val_loss: 1.8647 - val_accuracy: 0.4096 - 294ms/epoch - 23ms/step\n",
            "Epoch 285/300\n",
            "13/13 - 0s - loss: 1.4323 - accuracy: 0.4792 - val_loss: 1.8085 - val_accuracy: 0.3557 - 290ms/epoch - 22ms/step\n",
            "Epoch 286/300\n",
            "13/13 - 0s - loss: 1.4283 - accuracy: 0.4729 - val_loss: 1.7679 - val_accuracy: 0.4694 - 292ms/epoch - 22ms/step\n",
            "Epoch 287/300\n",
            "13/13 - 0s - loss: 1.4320 - accuracy: 0.4758 - val_loss: 1.8536 - val_accuracy: 0.4198 - 306ms/epoch - 24ms/step\n",
            "Epoch 288/300\n",
            "13/13 - 0s - loss: 1.4182 - accuracy: 0.4846 - val_loss: 1.7557 - val_accuracy: 0.4840 - 293ms/epoch - 23ms/step\n",
            "Epoch 289/300\n",
            "13/13 - 0s - loss: 1.3574 - accuracy: 0.5088 - val_loss: 1.7918 - val_accuracy: 0.4329 - 292ms/epoch - 22ms/step\n",
            "Epoch 290/300\n",
            "13/13 - 0s - loss: 1.3836 - accuracy: 0.4963 - val_loss: 1.7310 - val_accuracy: 0.4767 - 295ms/epoch - 23ms/step\n",
            "Epoch 291/300\n",
            "13/13 - 0s - loss: 1.3889 - accuracy: 0.4886 - val_loss: 1.7856 - val_accuracy: 0.4344 - 293ms/epoch - 23ms/step\n",
            "Epoch 292/300\n",
            "13/13 - 0s - loss: 1.3312 - accuracy: 0.5114 - val_loss: 1.7730 - val_accuracy: 0.4723 - 292ms/epoch - 22ms/step\n",
            "Epoch 293/300\n",
            "13/13 - 0s - loss: 1.3269 - accuracy: 0.5128 - val_loss: 1.8600 - val_accuracy: 0.4913 - 293ms/epoch - 23ms/step\n",
            "Epoch 294/300\n",
            "13/13 - 0s - loss: 1.3319 - accuracy: 0.5195 - val_loss: 2.0182 - val_accuracy: 0.4650 - 298ms/epoch - 23ms/step\n",
            "Epoch 295/300\n",
            "13/13 - 0s - loss: 1.3201 - accuracy: 0.5253 - val_loss: 1.7846 - val_accuracy: 0.4577 - 294ms/epoch - 23ms/step\n",
            "Epoch 296/300\n",
            "13/13 - 0s - loss: 1.3239 - accuracy: 0.5170 - val_loss: 1.6946 - val_accuracy: 0.4767 - 292ms/epoch - 22ms/step\n",
            "Epoch 297/300\n",
            "13/13 - 0s - loss: 1.3033 - accuracy: 0.5297 - val_loss: 1.7230 - val_accuracy: 0.4694 - 290ms/epoch - 22ms/step\n",
            "Epoch 298/300\n",
            "13/13 - 0s - loss: 1.3232 - accuracy: 0.5130 - val_loss: 1.7861 - val_accuracy: 0.4461 - 287ms/epoch - 22ms/step\n",
            "Epoch 299/300\n",
            "13/13 - 0s - loss: 1.3417 - accuracy: 0.5099 - val_loss: 1.6881 - val_accuracy: 0.4883 - 294ms/epoch - 23ms/step\n",
            "Epoch 300/300\n",
            "13/13 - 0s - loss: 1.3460 - accuracy: 0.5045 - val_loss: 1.7610 - val_accuracy: 0.4738 - 291ms/epoch - 22ms/step\n",
            "Model: \"sequential_91\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_182 (Conv2D)         (None, 4, 36, 80)         27440     \n",
            "                                                                 \n",
            " max_pooling2d_182 (MaxPooli  (None, 1, 12, 80)        0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_91 (Bat  (None, 1, 12, 80)        320       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv2d_183 (Conv2D)         (None, 1, 10, 80)         19280     \n",
            "                                                                 \n",
            " max_pooling2d_183 (MaxPooli  (None, 1, 3, 80)         0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " flatten_91 (Flatten)        (None, 240)               0         \n",
            "                                                                 \n",
            " dense_273 (Dense)           (None, 5000)              1205000   \n",
            "                                                                 \n",
            " dropout_182 (Dropout)       (None, 5000)              0         \n",
            "                                                                 \n",
            " dense_274 (Dense)           (None, 5000)              25005000  \n",
            "                                                                 \n",
            " dropout_183 (Dropout)       (None, 5000)              0         \n",
            "                                                                 \n",
            " dense_275 (Dense)           (None, 10)                50010     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 26,307,050\n",
            "Trainable params: 26,306,890\n",
            "Non-trainable params: 160\n",
            "_________________________________________________________________\n",
            "None\n",
            "Result of fold:3\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 2.6569 - accuracy: 0.3451\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 30%|███       | 3/10 [04:40<10:55, 93.58s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(6812, 60, 41)\n",
            "Epoch 1/300\n",
            "12/12 - 1s - loss: 5.1549 - accuracy: 0.1452 - val_loss: 2.3737 - val_accuracy: 0.1686 - 1s/epoch - 90ms/step\n",
            "Epoch 2/300\n",
            "12/12 - 0s - loss: 2.1201 - accuracy: 0.2034 - val_loss: 2.2430 - val_accuracy: 0.2185 - 290ms/epoch - 24ms/step\n",
            "Epoch 3/300\n",
            "12/12 - 0s - loss: 2.0319 - accuracy: 0.2439 - val_loss: 2.1014 - val_accuracy: 0.2463 - 290ms/epoch - 24ms/step\n",
            "Epoch 4/300\n",
            "12/12 - 0s - loss: 1.9516 - accuracy: 0.2770 - val_loss: 2.1357 - val_accuracy: 0.3123 - 289ms/epoch - 24ms/step\n",
            "Epoch 5/300\n",
            "12/12 - 0s - loss: 1.8675 - accuracy: 0.3152 - val_loss: 2.1075 - val_accuracy: 0.2786 - 295ms/epoch - 25ms/step\n",
            "Epoch 6/300\n",
            "12/12 - 0s - loss: 1.7961 - accuracy: 0.3452 - val_loss: 1.8389 - val_accuracy: 0.2375 - 290ms/epoch - 24ms/step\n",
            "Epoch 7/300\n",
            "12/12 - 0s - loss: 1.7840 - accuracy: 0.3506 - val_loss: 1.8441 - val_accuracy: 0.2859 - 290ms/epoch - 24ms/step\n",
            "Epoch 8/300\n",
            "12/12 - 0s - loss: 1.6890 - accuracy: 0.3759 - val_loss: 1.7751 - val_accuracy: 0.3592 - 287ms/epoch - 24ms/step\n",
            "Epoch 9/300\n",
            "12/12 - 0s - loss: 1.6133 - accuracy: 0.4069 - val_loss: 1.7333 - val_accuracy: 0.3548 - 293ms/epoch - 24ms/step\n",
            "Epoch 10/300\n",
            "12/12 - 0s - loss: 1.5810 - accuracy: 0.4171 - val_loss: 1.7271 - val_accuracy: 0.3724 - 296ms/epoch - 25ms/step\n",
            "Epoch 11/300\n",
            "12/12 - 0s - loss: 1.5431 - accuracy: 0.4347 - val_loss: 1.7346 - val_accuracy: 0.3812 - 290ms/epoch - 24ms/step\n",
            "Epoch 12/300\n",
            "12/12 - 0s - loss: 1.4812 - accuracy: 0.4635 - val_loss: 1.7159 - val_accuracy: 0.4648 - 285ms/epoch - 24ms/step\n",
            "Epoch 13/300\n",
            "12/12 - 0s - loss: 1.4577 - accuracy: 0.4705 - val_loss: 1.7473 - val_accuracy: 0.4018 - 291ms/epoch - 24ms/step\n",
            "Epoch 14/300\n",
            "12/12 - 0s - loss: 1.4004 - accuracy: 0.4953 - val_loss: 1.7421 - val_accuracy: 0.3842 - 292ms/epoch - 24ms/step\n",
            "Epoch 15/300\n",
            "12/12 - 0s - loss: 1.4312 - accuracy: 0.4763 - val_loss: 1.9378 - val_accuracy: 0.4399 - 287ms/epoch - 24ms/step\n",
            "Epoch 16/300\n",
            "12/12 - 0s - loss: 1.3848 - accuracy: 0.4958 - val_loss: 1.8121 - val_accuracy: 0.4619 - 296ms/epoch - 25ms/step\n",
            "Epoch 17/300\n",
            "12/12 - 0s - loss: 1.3606 - accuracy: 0.5157 - val_loss: 1.7549 - val_accuracy: 0.4883 - 293ms/epoch - 24ms/step\n",
            "Epoch 18/300\n",
            "12/12 - 0s - loss: 1.3829 - accuracy: 0.5117 - val_loss: 1.8488 - val_accuracy: 0.4428 - 288ms/epoch - 24ms/step\n",
            "Epoch 19/300\n",
            "12/12 - 0s - loss: 1.3788 - accuracy: 0.5085 - val_loss: 1.7960 - val_accuracy: 0.4853 - 286ms/epoch - 24ms/step\n",
            "Epoch 20/300\n",
            "12/12 - 0s - loss: 1.3894 - accuracy: 0.5046 - val_loss: 1.7201 - val_accuracy: 0.4736 - 287ms/epoch - 24ms/step\n",
            "Epoch 21/300\n",
            "12/12 - 0s - loss: 1.2994 - accuracy: 0.5377 - val_loss: 1.6083 - val_accuracy: 0.4751 - 292ms/epoch - 24ms/step\n",
            "Epoch 22/300\n",
            "12/12 - 0s - loss: 1.3460 - accuracy: 0.5212 - val_loss: 1.6868 - val_accuracy: 0.4736 - 289ms/epoch - 24ms/step\n",
            "Epoch 23/300\n",
            "12/12 - 0s - loss: 1.3737 - accuracy: 0.5165 - val_loss: 1.6044 - val_accuracy: 0.4809 - 292ms/epoch - 24ms/step\n",
            "Epoch 24/300\n",
            "12/12 - 0s - loss: 1.3804 - accuracy: 0.5049 - val_loss: 1.6298 - val_accuracy: 0.5000 - 288ms/epoch - 24ms/step\n",
            "Epoch 25/300\n",
            "12/12 - 0s - loss: 1.3150 - accuracy: 0.5429 - val_loss: 1.7145 - val_accuracy: 0.4443 - 287ms/epoch - 24ms/step\n",
            "Epoch 26/300\n",
            "12/12 - 0s - loss: 1.2655 - accuracy: 0.5594 - val_loss: 1.7142 - val_accuracy: 0.4927 - 295ms/epoch - 25ms/step\n",
            "Epoch 27/300\n",
            "12/12 - 0s - loss: 1.2411 - accuracy: 0.5685 - val_loss: 1.5760 - val_accuracy: 0.5279 - 287ms/epoch - 24ms/step\n",
            "Epoch 28/300\n",
            "12/12 - 0s - loss: 1.1920 - accuracy: 0.5754 - val_loss: 1.5330 - val_accuracy: 0.5103 - 283ms/epoch - 24ms/step\n",
            "Epoch 29/300\n",
            "12/12 - 0s - loss: 1.2202 - accuracy: 0.5729 - val_loss: 1.7671 - val_accuracy: 0.4399 - 293ms/epoch - 24ms/step\n",
            "Epoch 30/300\n",
            "12/12 - 0s - loss: 1.2403 - accuracy: 0.5662 - val_loss: 1.6831 - val_accuracy: 0.5103 - 297ms/epoch - 25ms/step\n",
            "Epoch 31/300\n",
            "12/12 - 0s - loss: 1.2748 - accuracy: 0.5670 - val_loss: 1.6181 - val_accuracy: 0.5161 - 296ms/epoch - 25ms/step\n",
            "Epoch 32/300\n",
            "12/12 - 0s - loss: 1.2580 - accuracy: 0.5755 - val_loss: 1.4894 - val_accuracy: 0.5337 - 300ms/epoch - 25ms/step\n",
            "Epoch 33/300\n",
            "12/12 - 0s - loss: 1.1807 - accuracy: 0.5852 - val_loss: 1.7709 - val_accuracy: 0.4399 - 295ms/epoch - 25ms/step\n",
            "Epoch 34/300\n",
            "12/12 - 0s - loss: 1.1419 - accuracy: 0.6016 - val_loss: 1.6427 - val_accuracy: 0.5352 - 294ms/epoch - 25ms/step\n",
            "Epoch 35/300\n",
            "12/12 - 0s - loss: 1.2054 - accuracy: 0.5827 - val_loss: 1.7528 - val_accuracy: 0.5059 - 297ms/epoch - 25ms/step\n",
            "Epoch 36/300\n",
            "12/12 - 0s - loss: 1.1807 - accuracy: 0.5816 - val_loss: 1.7025 - val_accuracy: 0.5176 - 293ms/epoch - 24ms/step\n",
            "Epoch 37/300\n",
            "12/12 - 0s - loss: 1.1366 - accuracy: 0.5995 - val_loss: 1.6790 - val_accuracy: 0.4883 - 295ms/epoch - 25ms/step\n",
            "Epoch 38/300\n",
            "12/12 - 0s - loss: 1.1467 - accuracy: 0.6007 - val_loss: 1.5509 - val_accuracy: 0.5117 - 295ms/epoch - 25ms/step\n",
            "Epoch 39/300\n",
            "12/12 - 0s - loss: 1.0801 - accuracy: 0.6122 - val_loss: 1.6885 - val_accuracy: 0.4545 - 303ms/epoch - 25ms/step\n",
            "Epoch 40/300\n",
            "12/12 - 0s - loss: 1.0381 - accuracy: 0.6228 - val_loss: 1.6845 - val_accuracy: 0.4868 - 296ms/epoch - 25ms/step\n",
            "Epoch 41/300\n",
            "12/12 - 0s - loss: 1.0597 - accuracy: 0.6178 - val_loss: 1.5869 - val_accuracy: 0.5161 - 298ms/epoch - 25ms/step\n",
            "Epoch 42/300\n",
            "12/12 - 0s - loss: 1.0664 - accuracy: 0.6326 - val_loss: 1.4787 - val_accuracy: 0.5323 - 286ms/epoch - 24ms/step\n",
            "Epoch 43/300\n",
            "12/12 - 0s - loss: 1.0283 - accuracy: 0.6299 - val_loss: 1.6075 - val_accuracy: 0.5352 - 290ms/epoch - 24ms/step\n",
            "Epoch 44/300\n",
            "12/12 - 0s - loss: 1.0304 - accuracy: 0.6385 - val_loss: 1.7334 - val_accuracy: 0.5161 - 291ms/epoch - 24ms/step\n",
            "Epoch 45/300\n",
            "12/12 - 0s - loss: 0.9754 - accuracy: 0.6440 - val_loss: 1.5927 - val_accuracy: 0.5323 - 288ms/epoch - 24ms/step\n",
            "Epoch 46/300\n",
            "12/12 - 0s - loss: 0.9933 - accuracy: 0.6454 - val_loss: 1.6974 - val_accuracy: 0.5440 - 293ms/epoch - 24ms/step\n",
            "Epoch 47/300\n",
            "12/12 - 0s - loss: 1.0298 - accuracy: 0.6326 - val_loss: 1.9071 - val_accuracy: 0.4267 - 287ms/epoch - 24ms/step\n",
            "Epoch 48/300\n",
            "12/12 - 0s - loss: 1.0306 - accuracy: 0.6336 - val_loss: 1.7681 - val_accuracy: 0.5235 - 287ms/epoch - 24ms/step\n",
            "Epoch 49/300\n",
            "12/12 - 0s - loss: 1.0291 - accuracy: 0.6310 - val_loss: 1.5825 - val_accuracy: 0.5440 - 293ms/epoch - 24ms/step\n",
            "Epoch 50/300\n",
            "12/12 - 0s - loss: 1.0084 - accuracy: 0.6351 - val_loss: 1.6884 - val_accuracy: 0.5337 - 291ms/epoch - 24ms/step\n",
            "Epoch 51/300\n",
            "12/12 - 0s - loss: 0.9532 - accuracy: 0.6561 - val_loss: 1.9205 - val_accuracy: 0.4765 - 288ms/epoch - 24ms/step\n",
            "Epoch 52/300\n",
            "12/12 - 0s - loss: 0.9555 - accuracy: 0.6527 - val_loss: 1.9851 - val_accuracy: 0.4927 - 287ms/epoch - 24ms/step\n",
            "Epoch 53/300\n",
            "12/12 - 0s - loss: 0.9836 - accuracy: 0.6476 - val_loss: 1.7757 - val_accuracy: 0.5381 - 293ms/epoch - 24ms/step\n",
            "Epoch 54/300\n",
            "12/12 - 0s - loss: 0.9855 - accuracy: 0.6436 - val_loss: 1.8644 - val_accuracy: 0.5015 - 294ms/epoch - 25ms/step\n",
            "Epoch 55/300\n",
            "12/12 - 0s - loss: 1.0159 - accuracy: 0.6519 - val_loss: 1.8613 - val_accuracy: 0.5088 - 297ms/epoch - 25ms/step\n",
            "Epoch 56/300\n",
            "12/12 - 0s - loss: 0.9972 - accuracy: 0.6498 - val_loss: 1.7326 - val_accuracy: 0.5323 - 286ms/epoch - 24ms/step\n",
            "Epoch 57/300\n",
            "12/12 - 0s - loss: 0.9946 - accuracy: 0.6504 - val_loss: 1.7647 - val_accuracy: 0.5235 - 293ms/epoch - 24ms/step\n",
            "Epoch 58/300\n",
            "12/12 - 0s - loss: 1.1405 - accuracy: 0.6230 - val_loss: 1.7272 - val_accuracy: 0.5337 - 290ms/epoch - 24ms/step\n",
            "Epoch 59/300\n",
            "12/12 - 0s - loss: 1.0382 - accuracy: 0.6408 - val_loss: 1.7380 - val_accuracy: 0.4765 - 287ms/epoch - 24ms/step\n",
            "Epoch 60/300\n",
            "12/12 - 0s - loss: 0.9747 - accuracy: 0.6512 - val_loss: 2.0187 - val_accuracy: 0.4663 - 292ms/epoch - 24ms/step\n",
            "Epoch 61/300\n",
            "12/12 - 0s - loss: 0.9301 - accuracy: 0.6628 - val_loss: 1.8053 - val_accuracy: 0.5191 - 295ms/epoch - 25ms/step\n",
            "Epoch 62/300\n",
            "12/12 - 0s - loss: 0.9185 - accuracy: 0.6767 - val_loss: 1.8562 - val_accuracy: 0.5191 - 287ms/epoch - 24ms/step\n",
            "Epoch 63/300\n",
            "12/12 - 0s - loss: 1.0101 - accuracy: 0.6564 - val_loss: 1.6323 - val_accuracy: 0.5161 - 292ms/epoch - 24ms/step\n",
            "Epoch 64/300\n",
            "12/12 - 0s - loss: 0.9827 - accuracy: 0.6434 - val_loss: 1.7037 - val_accuracy: 0.5191 - 294ms/epoch - 24ms/step\n",
            "Epoch 65/300\n",
            "12/12 - 0s - loss: 0.9291 - accuracy: 0.6711 - val_loss: 1.9641 - val_accuracy: 0.5015 - 288ms/epoch - 24ms/step\n",
            "Epoch 66/300\n",
            "12/12 - 0s - loss: 0.9441 - accuracy: 0.6723 - val_loss: 1.9166 - val_accuracy: 0.5381 - 289ms/epoch - 24ms/step\n",
            "Epoch 67/300\n",
            "12/12 - 0s - loss: 1.0336 - accuracy: 0.6680 - val_loss: 1.8289 - val_accuracy: 0.5367 - 285ms/epoch - 24ms/step\n",
            "Epoch 68/300\n",
            "12/12 - 0s - loss: 1.0894 - accuracy: 0.6445 - val_loss: 1.8167 - val_accuracy: 0.5293 - 288ms/epoch - 24ms/step\n",
            "Epoch 69/300\n",
            "12/12 - 0s - loss: 1.0599 - accuracy: 0.6382 - val_loss: 1.9241 - val_accuracy: 0.5191 - 292ms/epoch - 24ms/step\n",
            "Epoch 70/300\n",
            "12/12 - 0s - loss: 1.0624 - accuracy: 0.6535 - val_loss: 1.9003 - val_accuracy: 0.4897 - 292ms/epoch - 24ms/step\n",
            "Epoch 71/300\n",
            "12/12 - 0s - loss: 1.0606 - accuracy: 0.6431 - val_loss: 1.7168 - val_accuracy: 0.5249 - 291ms/epoch - 24ms/step\n",
            "Epoch 72/300\n",
            "12/12 - 0s - loss: 1.0676 - accuracy: 0.6354 - val_loss: 1.7537 - val_accuracy: 0.4370 - 289ms/epoch - 24ms/step\n",
            "Epoch 73/300\n",
            "12/12 - 0s - loss: 1.0440 - accuracy: 0.6349 - val_loss: 1.8337 - val_accuracy: 0.4619 - 290ms/epoch - 24ms/step\n",
            "Epoch 74/300\n",
            "12/12 - 0s - loss: 1.0518 - accuracy: 0.6372 - val_loss: 1.7979 - val_accuracy: 0.5044 - 291ms/epoch - 24ms/step\n",
            "Epoch 75/300\n",
            "12/12 - 0s - loss: 0.9885 - accuracy: 0.6589 - val_loss: 1.7877 - val_accuracy: 0.5264 - 289ms/epoch - 24ms/step\n",
            "Epoch 76/300\n",
            "12/12 - 0s - loss: 1.0064 - accuracy: 0.6504 - val_loss: 1.8398 - val_accuracy: 0.5411 - 293ms/epoch - 24ms/step\n",
            "Epoch 77/300\n",
            "12/12 - 0s - loss: 0.9339 - accuracy: 0.6742 - val_loss: 1.9494 - val_accuracy: 0.5367 - 291ms/epoch - 24ms/step\n",
            "Epoch 78/300\n",
            "12/12 - 0s - loss: 0.9406 - accuracy: 0.6597 - val_loss: 1.8345 - val_accuracy: 0.5235 - 289ms/epoch - 24ms/step\n",
            "Epoch 79/300\n",
            "12/12 - 0s - loss: 0.8605 - accuracy: 0.6953 - val_loss: 1.9045 - val_accuracy: 0.5205 - 289ms/epoch - 24ms/step\n",
            "Epoch 80/300\n",
            "12/12 - 0s - loss: 0.9050 - accuracy: 0.6842 - val_loss: 1.7525 - val_accuracy: 0.5660 - 286ms/epoch - 24ms/step\n",
            "Epoch 81/300\n",
            "12/12 - 0s - loss: 0.9092 - accuracy: 0.6817 - val_loss: 1.7461 - val_accuracy: 0.5235 - 294ms/epoch - 25ms/step\n",
            "Epoch 82/300\n",
            "12/12 - 0s - loss: 0.8940 - accuracy: 0.6799 - val_loss: 1.8550 - val_accuracy: 0.5117 - 298ms/epoch - 25ms/step\n",
            "Epoch 83/300\n",
            "12/12 - 0s - loss: 0.8731 - accuracy: 0.6956 - val_loss: 1.7528 - val_accuracy: 0.5645 - 286ms/epoch - 24ms/step\n",
            "Epoch 84/300\n",
            "12/12 - 0s - loss: 0.8433 - accuracy: 0.7034 - val_loss: 1.9098 - val_accuracy: 0.5161 - 291ms/epoch - 24ms/step\n",
            "Epoch 85/300\n",
            "12/12 - 0s - loss: 0.8648 - accuracy: 0.7011 - val_loss: 1.8387 - val_accuracy: 0.4795 - 291ms/epoch - 24ms/step\n",
            "Epoch 86/300\n",
            "12/12 - 0s - loss: 0.8655 - accuracy: 0.6930 - val_loss: 1.8880 - val_accuracy: 0.5469 - 288ms/epoch - 24ms/step\n",
            "Epoch 87/300\n",
            "12/12 - 0s - loss: 0.8588 - accuracy: 0.7103 - val_loss: 2.1573 - val_accuracy: 0.5411 - 295ms/epoch - 25ms/step\n",
            "Epoch 88/300\n",
            "12/12 - 0s - loss: 0.9152 - accuracy: 0.6936 - val_loss: 1.8239 - val_accuracy: 0.5425 - 288ms/epoch - 24ms/step\n",
            "Epoch 89/300\n",
            "12/12 - 0s - loss: 0.9355 - accuracy: 0.6843 - val_loss: 1.8219 - val_accuracy: 0.5557 - 286ms/epoch - 24ms/step\n",
            "Epoch 90/300\n",
            "12/12 - 0s - loss: 0.9323 - accuracy: 0.6710 - val_loss: 1.9450 - val_accuracy: 0.5132 - 285ms/epoch - 24ms/step\n",
            "Epoch 91/300\n",
            "12/12 - 0s - loss: 0.8980 - accuracy: 0.6930 - val_loss: 1.8060 - val_accuracy: 0.5572 - 284ms/epoch - 24ms/step\n",
            "Epoch 92/300\n",
            "12/12 - 0s - loss: 0.9801 - accuracy: 0.6772 - val_loss: 1.8382 - val_accuracy: 0.5748 - 294ms/epoch - 24ms/step\n",
            "Epoch 93/300\n",
            "12/12 - 0s - loss: 1.0061 - accuracy: 0.6644 - val_loss: 2.0912 - val_accuracy: 0.5000 - 289ms/epoch - 24ms/step\n",
            "Epoch 94/300\n",
            "12/12 - 0s - loss: 0.9514 - accuracy: 0.6786 - val_loss: 2.1053 - val_accuracy: 0.5015 - 287ms/epoch - 24ms/step\n",
            "Epoch 95/300\n",
            "12/12 - 0s - loss: 0.9954 - accuracy: 0.6804 - val_loss: 1.9735 - val_accuracy: 0.4633 - 287ms/epoch - 24ms/step\n",
            "Epoch 96/300\n",
            "12/12 - 0s - loss: 0.9852 - accuracy: 0.6690 - val_loss: 2.0561 - val_accuracy: 0.5161 - 292ms/epoch - 24ms/step\n",
            "Epoch 97/300\n",
            "12/12 - 0s - loss: 1.0220 - accuracy: 0.6791 - val_loss: 1.8808 - val_accuracy: 0.5205 - 291ms/epoch - 24ms/step\n",
            "Epoch 98/300\n",
            "12/12 - 0s - loss: 0.9839 - accuracy: 0.6602 - val_loss: 2.1057 - val_accuracy: 0.4765 - 289ms/epoch - 24ms/step\n",
            "Epoch 99/300\n",
            "12/12 - 0s - loss: 0.8968 - accuracy: 0.6899 - val_loss: 2.0697 - val_accuracy: 0.5484 - 289ms/epoch - 24ms/step\n",
            "Epoch 100/300\n",
            "12/12 - 0s - loss: 0.9201 - accuracy: 0.6902 - val_loss: 2.1911 - val_accuracy: 0.5147 - 290ms/epoch - 24ms/step\n",
            "Epoch 101/300\n",
            "12/12 - 0s - loss: 0.9706 - accuracy: 0.6636 - val_loss: 2.2710 - val_accuracy: 0.5015 - 286ms/epoch - 24ms/step\n",
            "Epoch 102/300\n",
            "12/12 - 0s - loss: 1.0452 - accuracy: 0.6569 - val_loss: 2.2011 - val_accuracy: 0.5000 - 294ms/epoch - 25ms/step\n",
            "Epoch 103/300\n",
            "12/12 - 0s - loss: 0.9178 - accuracy: 0.6876 - val_loss: 1.9401 - val_accuracy: 0.5733 - 291ms/epoch - 24ms/step\n",
            "Epoch 104/300\n",
            "12/12 - 0s - loss: 0.9085 - accuracy: 0.7002 - val_loss: 2.0973 - val_accuracy: 0.5601 - 290ms/epoch - 24ms/step\n",
            "Epoch 105/300\n",
            "12/12 - 0s - loss: 0.8983 - accuracy: 0.6918 - val_loss: 1.9086 - val_accuracy: 0.5513 - 290ms/epoch - 24ms/step\n",
            "Epoch 106/300\n",
            "12/12 - 0s - loss: 0.9354 - accuracy: 0.6894 - val_loss: 2.1162 - val_accuracy: 0.5308 - 298ms/epoch - 25ms/step\n",
            "Epoch 107/300\n",
            "12/12 - 0s - loss: 0.9470 - accuracy: 0.6922 - val_loss: 1.9004 - val_accuracy: 0.5425 - 296ms/epoch - 25ms/step\n",
            "Epoch 108/300\n",
            "12/12 - 0s - loss: 1.0339 - accuracy: 0.6827 - val_loss: 2.2456 - val_accuracy: 0.5293 - 299ms/epoch - 25ms/step\n",
            "Epoch 109/300\n",
            "12/12 - 0s - loss: 0.9369 - accuracy: 0.6842 - val_loss: 2.2465 - val_accuracy: 0.5264 - 299ms/epoch - 25ms/step\n",
            "Epoch 110/300\n",
            "12/12 - 0s - loss: 0.9241 - accuracy: 0.6884 - val_loss: 2.1239 - val_accuracy: 0.5381 - 302ms/epoch - 25ms/step\n",
            "Epoch 111/300\n",
            "12/12 - 0s - loss: 0.8890 - accuracy: 0.7046 - val_loss: 2.4524 - val_accuracy: 0.4927 - 303ms/epoch - 25ms/step\n",
            "Epoch 112/300\n",
            "12/12 - 0s - loss: 0.8979 - accuracy: 0.6954 - val_loss: 2.4578 - val_accuracy: 0.5411 - 295ms/epoch - 25ms/step\n",
            "Epoch 113/300\n",
            "12/12 - 0s - loss: 0.9229 - accuracy: 0.6904 - val_loss: 2.5166 - val_accuracy: 0.5323 - 286ms/epoch - 24ms/step\n",
            "Epoch 114/300\n",
            "12/12 - 0s - loss: 1.0612 - accuracy: 0.6692 - val_loss: 2.3627 - val_accuracy: 0.5367 - 289ms/epoch - 24ms/step\n",
            "Epoch 115/300\n",
            "12/12 - 0s - loss: 1.0355 - accuracy: 0.6798 - val_loss: 2.3765 - val_accuracy: 0.4868 - 291ms/epoch - 24ms/step\n",
            "Epoch 116/300\n",
            "12/12 - 0s - loss: 0.9663 - accuracy: 0.6827 - val_loss: 2.0127 - val_accuracy: 0.5528 - 289ms/epoch - 24ms/step\n",
            "Epoch 117/300\n",
            "12/12 - 0s - loss: 0.9439 - accuracy: 0.6879 - val_loss: 2.0249 - val_accuracy: 0.4985 - 290ms/epoch - 24ms/step\n",
            "Epoch 118/300\n",
            "12/12 - 0s - loss: 0.9158 - accuracy: 0.6915 - val_loss: 1.9370 - val_accuracy: 0.5293 - 290ms/epoch - 24ms/step\n",
            "Epoch 119/300\n",
            "12/12 - 0s - loss: 0.8356 - accuracy: 0.7039 - val_loss: 2.0624 - val_accuracy: 0.5425 - 286ms/epoch - 24ms/step\n",
            "Epoch 120/300\n",
            "12/12 - 0s - loss: 0.8491 - accuracy: 0.7031 - val_loss: 2.3563 - val_accuracy: 0.4912 - 291ms/epoch - 24ms/step\n",
            "Epoch 121/300\n",
            "12/12 - 0s - loss: 0.7791 - accuracy: 0.7245 - val_loss: 2.3666 - val_accuracy: 0.5543 - 285ms/epoch - 24ms/step\n",
            "Epoch 122/300\n",
            "12/12 - 0s - loss: 0.7872 - accuracy: 0.7178 - val_loss: 2.2487 - val_accuracy: 0.5499 - 289ms/epoch - 24ms/step\n",
            "Epoch 123/300\n",
            "12/12 - 0s - loss: 0.7448 - accuracy: 0.7352 - val_loss: 2.3686 - val_accuracy: 0.5455 - 287ms/epoch - 24ms/step\n",
            "Epoch 124/300\n",
            "12/12 - 0s - loss: 0.7389 - accuracy: 0.7362 - val_loss: 2.5139 - val_accuracy: 0.5264 - 285ms/epoch - 24ms/step\n",
            "Epoch 125/300\n",
            "12/12 - 0s - loss: 0.7493 - accuracy: 0.7390 - val_loss: 2.6069 - val_accuracy: 0.5117 - 282ms/epoch - 23ms/step\n",
            "Epoch 126/300\n",
            "12/12 - 0s - loss: 0.7866 - accuracy: 0.7207 - val_loss: 2.7892 - val_accuracy: 0.5059 - 290ms/epoch - 24ms/step\n",
            "Epoch 127/300\n",
            "12/12 - 0s - loss: 0.7676 - accuracy: 0.7282 - val_loss: 2.7994 - val_accuracy: 0.5147 - 285ms/epoch - 24ms/step\n",
            "Epoch 128/300\n",
            "12/12 - 0s - loss: 0.7623 - accuracy: 0.7375 - val_loss: 2.7012 - val_accuracy: 0.5718 - 283ms/epoch - 24ms/step\n",
            "Epoch 129/300\n",
            "12/12 - 0s - loss: 0.7165 - accuracy: 0.7455 - val_loss: 2.8966 - val_accuracy: 0.5117 - 286ms/epoch - 24ms/step\n",
            "Epoch 130/300\n",
            "12/12 - 0s - loss: 0.7189 - accuracy: 0.7460 - val_loss: 2.7180 - val_accuracy: 0.5513 - 289ms/epoch - 24ms/step\n",
            "Epoch 131/300\n",
            "12/12 - 0s - loss: 0.7443 - accuracy: 0.7378 - val_loss: 2.7943 - val_accuracy: 0.5748 - 289ms/epoch - 24ms/step\n",
            "Epoch 132/300\n",
            "12/12 - 0s - loss: 0.7695 - accuracy: 0.7392 - val_loss: 2.6297 - val_accuracy: 0.5088 - 287ms/epoch - 24ms/step\n",
            "Epoch 133/300\n",
            "12/12 - 0s - loss: 0.7276 - accuracy: 0.7401 - val_loss: 2.4009 - val_accuracy: 0.5440 - 290ms/epoch - 24ms/step\n",
            "Epoch 134/300\n",
            "12/12 - 0s - loss: 0.7125 - accuracy: 0.7400 - val_loss: 2.5587 - val_accuracy: 0.5352 - 293ms/epoch - 24ms/step\n",
            "Epoch 135/300\n",
            "12/12 - 0s - loss: 0.7109 - accuracy: 0.7489 - val_loss: 2.3672 - val_accuracy: 0.5587 - 291ms/epoch - 24ms/step\n",
            "Epoch 136/300\n",
            "12/12 - 0s - loss: 0.7053 - accuracy: 0.7507 - val_loss: 2.4283 - val_accuracy: 0.5044 - 288ms/epoch - 24ms/step\n",
            "Epoch 137/300\n",
            "12/12 - 0s - loss: 0.6943 - accuracy: 0.7525 - val_loss: 2.3510 - val_accuracy: 0.5630 - 288ms/epoch - 24ms/step\n",
            "Epoch 138/300\n",
            "12/12 - 0s - loss: 0.7208 - accuracy: 0.7560 - val_loss: 2.2951 - val_accuracy: 0.5367 - 289ms/epoch - 24ms/step\n",
            "Epoch 139/300\n",
            "12/12 - 0s - loss: 0.8016 - accuracy: 0.7489 - val_loss: 2.5009 - val_accuracy: 0.5396 - 296ms/epoch - 25ms/step\n",
            "Epoch 140/300\n",
            "12/12 - 0s - loss: 0.7453 - accuracy: 0.7403 - val_loss: 2.5511 - val_accuracy: 0.5528 - 293ms/epoch - 24ms/step\n",
            "Epoch 141/300\n",
            "12/12 - 0s - loss: 0.7606 - accuracy: 0.7439 - val_loss: 2.6213 - val_accuracy: 0.5396 - 287ms/epoch - 24ms/step\n",
            "Epoch 142/300\n",
            "12/12 - 0s - loss: 0.7975 - accuracy: 0.7220 - val_loss: 2.3886 - val_accuracy: 0.5381 - 290ms/epoch - 24ms/step\n",
            "Epoch 143/300\n",
            "12/12 - 0s - loss: 0.7830 - accuracy: 0.7266 - val_loss: 2.5532 - val_accuracy: 0.5293 - 290ms/epoch - 24ms/step\n",
            "Epoch 144/300\n",
            "12/12 - 0s - loss: 0.7204 - accuracy: 0.7488 - val_loss: 2.4099 - val_accuracy: 0.5455 - 293ms/epoch - 24ms/step\n",
            "Epoch 145/300\n",
            "12/12 - 0s - loss: 0.7009 - accuracy: 0.7468 - val_loss: 2.4514 - val_accuracy: 0.5674 - 290ms/epoch - 24ms/step\n",
            "Epoch 146/300\n",
            "12/12 - 0s - loss: 0.7571 - accuracy: 0.7545 - val_loss: 2.5586 - val_accuracy: 0.5484 - 288ms/epoch - 24ms/step\n",
            "Epoch 147/300\n",
            "12/12 - 0s - loss: 0.7716 - accuracy: 0.7465 - val_loss: 2.3273 - val_accuracy: 0.5499 - 282ms/epoch - 23ms/step\n",
            "Epoch 148/300\n",
            "12/12 - 0s - loss: 0.7834 - accuracy: 0.7486 - val_loss: 2.5044 - val_accuracy: 0.5235 - 287ms/epoch - 24ms/step\n",
            "Epoch 149/300\n",
            "12/12 - 0s - loss: 0.8252 - accuracy: 0.7509 - val_loss: 2.8312 - val_accuracy: 0.5191 - 288ms/epoch - 24ms/step\n",
            "Epoch 150/300\n",
            "12/12 - 0s - loss: 0.7916 - accuracy: 0.7241 - val_loss: 2.9222 - val_accuracy: 0.5161 - 287ms/epoch - 24ms/step\n",
            "Epoch 151/300\n",
            "12/12 - 0s - loss: 0.8376 - accuracy: 0.7176 - val_loss: 2.6434 - val_accuracy: 0.5499 - 287ms/epoch - 24ms/step\n",
            "Epoch 152/300\n",
            "12/12 - 0s - loss: 0.7303 - accuracy: 0.7377 - val_loss: 3.0235 - val_accuracy: 0.5205 - 287ms/epoch - 24ms/step\n",
            "Epoch 153/300\n",
            "12/12 - 0s - loss: 0.7752 - accuracy: 0.7470 - val_loss: 3.1191 - val_accuracy: 0.5147 - 294ms/epoch - 25ms/step\n",
            "Epoch 154/300\n",
            "12/12 - 0s - loss: 0.8267 - accuracy: 0.7393 - val_loss: 2.7970 - val_accuracy: 0.5249 - 286ms/epoch - 24ms/step\n",
            "Epoch 155/300\n",
            "12/12 - 0s - loss: 0.8637 - accuracy: 0.7147 - val_loss: 2.8558 - val_accuracy: 0.4927 - 290ms/epoch - 24ms/step\n",
            "Epoch 156/300\n",
            "12/12 - 0s - loss: 0.8087 - accuracy: 0.7145 - val_loss: 2.9770 - val_accuracy: 0.4765 - 294ms/epoch - 25ms/step\n",
            "Epoch 157/300\n",
            "12/12 - 0s - loss: 0.7676 - accuracy: 0.7416 - val_loss: 2.8158 - val_accuracy: 0.5044 - 290ms/epoch - 24ms/step\n",
            "Epoch 158/300\n",
            "12/12 - 0s - loss: 0.7774 - accuracy: 0.7365 - val_loss: 2.5191 - val_accuracy: 0.4941 - 289ms/epoch - 24ms/step\n",
            "Epoch 159/300\n",
            "12/12 - 0s - loss: 0.8273 - accuracy: 0.7387 - val_loss: 2.6706 - val_accuracy: 0.4941 - 287ms/epoch - 24ms/step\n",
            "Epoch 160/300\n",
            "12/12 - 0s - loss: 0.7638 - accuracy: 0.7509 - val_loss: 2.1837 - val_accuracy: 0.5000 - 287ms/epoch - 24ms/step\n",
            "Epoch 161/300\n",
            "12/12 - 0s - loss: 0.7675 - accuracy: 0.7485 - val_loss: 2.4360 - val_accuracy: 0.5103 - 285ms/epoch - 24ms/step\n",
            "Epoch 162/300\n",
            "12/12 - 0s - loss: 0.7905 - accuracy: 0.7346 - val_loss: 2.4424 - val_accuracy: 0.4956 - 292ms/epoch - 24ms/step\n",
            "Epoch 163/300\n",
            "12/12 - 0s - loss: 0.8102 - accuracy: 0.7481 - val_loss: 2.5226 - val_accuracy: 0.4619 - 293ms/epoch - 24ms/step\n",
            "Epoch 164/300\n",
            "12/12 - 0s - loss: 0.8634 - accuracy: 0.7282 - val_loss: 2.6938 - val_accuracy: 0.5088 - 288ms/epoch - 24ms/step\n",
            "Epoch 165/300\n",
            "12/12 - 0s - loss: 0.9669 - accuracy: 0.7080 - val_loss: 2.3401 - val_accuracy: 0.4765 - 290ms/epoch - 24ms/step\n",
            "Epoch 166/300\n",
            "12/12 - 0s - loss: 0.8678 - accuracy: 0.7176 - val_loss: 2.4407 - val_accuracy: 0.5367 - 289ms/epoch - 24ms/step\n",
            "Epoch 167/300\n",
            "12/12 - 0s - loss: 0.8266 - accuracy: 0.7261 - val_loss: 2.2477 - val_accuracy: 0.5308 - 294ms/epoch - 25ms/step\n",
            "Epoch 168/300\n",
            "12/12 - 0s - loss: 0.9031 - accuracy: 0.7300 - val_loss: 2.2829 - val_accuracy: 0.4751 - 299ms/epoch - 25ms/step\n",
            "Epoch 169/300\n",
            "12/12 - 0s - loss: 0.8265 - accuracy: 0.7334 - val_loss: 2.4566 - val_accuracy: 0.5132 - 285ms/epoch - 24ms/step\n",
            "Epoch 170/300\n",
            "12/12 - 0s - loss: 0.8158 - accuracy: 0.7307 - val_loss: 2.3165 - val_accuracy: 0.5484 - 290ms/epoch - 24ms/step\n",
            "Epoch 171/300\n",
            "12/12 - 0s - loss: 0.7858 - accuracy: 0.7392 - val_loss: 2.3301 - val_accuracy: 0.5205 - 290ms/epoch - 24ms/step\n",
            "Epoch 172/300\n",
            "12/12 - 0s - loss: 0.7905 - accuracy: 0.7330 - val_loss: 2.4355 - val_accuracy: 0.4956 - 290ms/epoch - 24ms/step\n",
            "Epoch 173/300\n",
            "12/12 - 0s - loss: 0.7544 - accuracy: 0.7506 - val_loss: 2.2736 - val_accuracy: 0.5455 - 293ms/epoch - 24ms/step\n",
            "Epoch 174/300\n",
            "12/12 - 0s - loss: 0.8320 - accuracy: 0.7243 - val_loss: 2.5295 - val_accuracy: 0.4868 - 291ms/epoch - 24ms/step\n",
            "Epoch 175/300\n",
            "12/12 - 0s - loss: 0.8820 - accuracy: 0.7132 - val_loss: 2.9309 - val_accuracy: 0.4927 - 289ms/epoch - 24ms/step\n",
            "Epoch 176/300\n",
            "12/12 - 0s - loss: 0.9402 - accuracy: 0.7127 - val_loss: 2.3130 - val_accuracy: 0.4956 - 292ms/epoch - 24ms/step\n",
            "Epoch 177/300\n",
            "12/12 - 0s - loss: 0.8235 - accuracy: 0.7210 - val_loss: 2.2015 - val_accuracy: 0.5161 - 286ms/epoch - 24ms/step\n",
            "Epoch 178/300\n",
            "12/12 - 0s - loss: 0.7682 - accuracy: 0.7398 - val_loss: 2.2316 - val_accuracy: 0.5381 - 293ms/epoch - 24ms/step\n",
            "Epoch 179/300\n",
            "12/12 - 0s - loss: 0.7184 - accuracy: 0.7488 - val_loss: 2.0981 - val_accuracy: 0.5337 - 293ms/epoch - 24ms/step\n",
            "Epoch 180/300\n",
            "12/12 - 0s - loss: 0.7093 - accuracy: 0.7525 - val_loss: 2.1109 - val_accuracy: 0.5132 - 287ms/epoch - 24ms/step\n",
            "Epoch 181/300\n",
            "12/12 - 0s - loss: 0.6469 - accuracy: 0.7680 - val_loss: 2.3154 - val_accuracy: 0.5103 - 290ms/epoch - 24ms/step\n",
            "Epoch 182/300\n",
            "12/12 - 0s - loss: 0.6545 - accuracy: 0.7607 - val_loss: 2.5476 - val_accuracy: 0.5205 - 291ms/epoch - 24ms/step\n",
            "Epoch 183/300\n",
            "12/12 - 0s - loss: 0.6199 - accuracy: 0.7803 - val_loss: 2.3335 - val_accuracy: 0.5073 - 296ms/epoch - 25ms/step\n",
            "Epoch 184/300\n",
            "12/12 - 0s - loss: 0.8233 - accuracy: 0.7282 - val_loss: 2.7630 - val_accuracy: 0.4985 - 290ms/epoch - 24ms/step\n",
            "Epoch 185/300\n",
            "12/12 - 0s - loss: 0.8073 - accuracy: 0.7140 - val_loss: 2.5335 - val_accuracy: 0.4971 - 293ms/epoch - 24ms/step\n",
            "Epoch 186/300\n",
            "12/12 - 0s - loss: 0.7813 - accuracy: 0.7303 - val_loss: 2.4833 - val_accuracy: 0.5323 - 289ms/epoch - 24ms/step\n",
            "Epoch 187/300\n",
            "12/12 - 0s - loss: 0.7349 - accuracy: 0.7498 - val_loss: 2.4893 - val_accuracy: 0.5557 - 288ms/epoch - 24ms/step\n",
            "Epoch 188/300\n",
            "12/12 - 0s - loss: 0.7243 - accuracy: 0.7501 - val_loss: 2.6141 - val_accuracy: 0.5645 - 289ms/epoch - 24ms/step\n",
            "Epoch 189/300\n",
            "12/12 - 0s - loss: 0.6663 - accuracy: 0.7620 - val_loss: 2.7550 - val_accuracy: 0.5249 - 292ms/epoch - 24ms/step\n",
            "Epoch 190/300\n",
            "12/12 - 0s - loss: 0.7095 - accuracy: 0.7566 - val_loss: 2.8597 - val_accuracy: 0.5674 - 288ms/epoch - 24ms/step\n",
            "Epoch 191/300\n",
            "12/12 - 0s - loss: 0.7153 - accuracy: 0.7721 - val_loss: 2.7146 - val_accuracy: 0.5205 - 286ms/epoch - 24ms/step\n",
            "Epoch 192/300\n",
            "12/12 - 0s - loss: 0.7415 - accuracy: 0.7607 - val_loss: 2.9520 - val_accuracy: 0.5396 - 291ms/epoch - 24ms/step\n",
            "Epoch 193/300\n",
            "12/12 - 0s - loss: 0.7474 - accuracy: 0.7525 - val_loss: 2.7257 - val_accuracy: 0.5073 - 287ms/epoch - 24ms/step\n",
            "Epoch 194/300\n",
            "12/12 - 0s - loss: 0.7023 - accuracy: 0.7654 - val_loss: 2.4006 - val_accuracy: 0.5352 - 292ms/epoch - 24ms/step\n",
            "Epoch 195/300\n",
            "12/12 - 0s - loss: 0.7020 - accuracy: 0.7659 - val_loss: 2.5031 - val_accuracy: 0.5264 - 290ms/epoch - 24ms/step\n",
            "Epoch 196/300\n",
            "12/12 - 0s - loss: 0.6931 - accuracy: 0.7618 - val_loss: 2.4419 - val_accuracy: 0.5147 - 288ms/epoch - 24ms/step\n",
            "Epoch 197/300\n",
            "12/12 - 0s - loss: 0.6706 - accuracy: 0.7674 - val_loss: 2.5634 - val_accuracy: 0.5484 - 283ms/epoch - 24ms/step\n",
            "Epoch 198/300\n",
            "12/12 - 0s - loss: 0.6950 - accuracy: 0.7697 - val_loss: 2.8888 - val_accuracy: 0.5323 - 289ms/epoch - 24ms/step\n",
            "Epoch 199/300\n",
            "12/12 - 0s - loss: 0.6965 - accuracy: 0.7646 - val_loss: 2.7279 - val_accuracy: 0.4809 - 290ms/epoch - 24ms/step\n",
            "Epoch 200/300\n",
            "12/12 - 0s - loss: 0.7199 - accuracy: 0.7612 - val_loss: 2.3959 - val_accuracy: 0.5411 - 282ms/epoch - 24ms/step\n",
            "Epoch 201/300\n",
            "12/12 - 0s - loss: 0.6418 - accuracy: 0.7781 - val_loss: 2.9282 - val_accuracy: 0.5161 - 289ms/epoch - 24ms/step\n",
            "Epoch 202/300\n",
            "12/12 - 0s - loss: 0.7263 - accuracy: 0.7471 - val_loss: 2.4878 - val_accuracy: 0.5264 - 285ms/epoch - 24ms/step\n",
            "Epoch 203/300\n",
            "12/12 - 0s - loss: 0.6811 - accuracy: 0.7581 - val_loss: 2.5252 - val_accuracy: 0.5147 - 289ms/epoch - 24ms/step\n",
            "Epoch 204/300\n",
            "12/12 - 0s - loss: 0.6397 - accuracy: 0.7762 - val_loss: 2.8767 - val_accuracy: 0.5411 - 288ms/epoch - 24ms/step\n",
            "Epoch 205/300\n",
            "12/12 - 0s - loss: 0.7951 - accuracy: 0.7803 - val_loss: 2.5706 - val_accuracy: 0.5220 - 292ms/epoch - 24ms/step\n",
            "Epoch 206/300\n",
            "12/12 - 0s - loss: 0.9471 - accuracy: 0.7447 - val_loss: 2.9753 - val_accuracy: 0.4604 - 292ms/epoch - 24ms/step\n",
            "Epoch 207/300\n",
            "12/12 - 0s - loss: 1.0657 - accuracy: 0.7328 - val_loss: 2.7239 - val_accuracy: 0.5308 - 296ms/epoch - 25ms/step\n",
            "Epoch 208/300\n",
            "12/12 - 0s - loss: 0.9873 - accuracy: 0.7132 - val_loss: 2.7833 - val_accuracy: 0.5176 - 300ms/epoch - 25ms/step\n",
            "Epoch 209/300\n",
            "12/12 - 0s - loss: 1.0768 - accuracy: 0.7137 - val_loss: 2.2471 - val_accuracy: 0.5264 - 292ms/epoch - 24ms/step\n",
            "Epoch 210/300\n",
            "12/12 - 0s - loss: 0.9068 - accuracy: 0.7155 - val_loss: 2.3190 - val_accuracy: 0.4897 - 294ms/epoch - 25ms/step\n",
            "Epoch 211/300\n",
            "12/12 - 0s - loss: 0.8357 - accuracy: 0.7299 - val_loss: 2.4770 - val_accuracy: 0.5205 - 289ms/epoch - 24ms/step\n",
            "Epoch 212/300\n",
            "12/12 - 0s - loss: 0.8134 - accuracy: 0.7460 - val_loss: 2.3172 - val_accuracy: 0.5235 - 294ms/epoch - 24ms/step\n",
            "Epoch 213/300\n",
            "12/12 - 0s - loss: 0.7476 - accuracy: 0.7478 - val_loss: 2.4420 - val_accuracy: 0.5117 - 300ms/epoch - 25ms/step\n",
            "Epoch 214/300\n",
            "12/12 - 0s - loss: 0.7656 - accuracy: 0.7408 - val_loss: 2.9663 - val_accuracy: 0.5015 - 303ms/epoch - 25ms/step\n",
            "Epoch 215/300\n",
            "12/12 - 0s - loss: 0.7297 - accuracy: 0.7560 - val_loss: 2.5593 - val_accuracy: 0.5176 - 298ms/epoch - 25ms/step\n",
            "Epoch 216/300\n",
            "12/12 - 0s - loss: 0.6798 - accuracy: 0.7687 - val_loss: 2.8562 - val_accuracy: 0.5161 - 295ms/epoch - 25ms/step\n",
            "Epoch 217/300\n",
            "12/12 - 0s - loss: 0.7024 - accuracy: 0.7705 - val_loss: 2.9614 - val_accuracy: 0.5308 - 296ms/epoch - 25ms/step\n",
            "Epoch 218/300\n",
            "12/12 - 0s - loss: 0.7218 - accuracy: 0.7427 - val_loss: 3.0741 - val_accuracy: 0.4956 - 299ms/epoch - 25ms/step\n",
            "Epoch 219/300\n",
            "12/12 - 0s - loss: 0.7688 - accuracy: 0.7509 - val_loss: 3.5712 - val_accuracy: 0.5073 - 300ms/epoch - 25ms/step\n",
            "Epoch 220/300\n",
            "12/12 - 0s - loss: 0.7064 - accuracy: 0.7566 - val_loss: 2.9582 - val_accuracy: 0.5396 - 297ms/epoch - 25ms/step\n",
            "Epoch 221/300\n",
            "12/12 - 0s - loss: 0.6920 - accuracy: 0.7773 - val_loss: 3.2593 - val_accuracy: 0.5029 - 290ms/epoch - 24ms/step\n",
            "Epoch 222/300\n",
            "12/12 - 0s - loss: 0.6882 - accuracy: 0.7679 - val_loss: 3.0394 - val_accuracy: 0.5029 - 298ms/epoch - 25ms/step\n",
            "Epoch 223/300\n",
            "12/12 - 0s - loss: 0.7201 - accuracy: 0.7529 - val_loss: 2.9392 - val_accuracy: 0.5088 - 292ms/epoch - 24ms/step\n",
            "Epoch 224/300\n",
            "12/12 - 0s - loss: 0.7310 - accuracy: 0.7511 - val_loss: 3.2243 - val_accuracy: 0.5117 - 294ms/epoch - 25ms/step\n",
            "Epoch 225/300\n",
            "12/12 - 0s - loss: 0.8302 - accuracy: 0.7548 - val_loss: 3.2231 - val_accuracy: 0.5220 - 294ms/epoch - 24ms/step\n",
            "Epoch 226/300\n",
            "12/12 - 0s - loss: 0.8829 - accuracy: 0.7413 - val_loss: 3.8331 - val_accuracy: 0.4971 - 292ms/epoch - 24ms/step\n",
            "Epoch 227/300\n",
            "12/12 - 0s - loss: 0.8581 - accuracy: 0.7480 - val_loss: 3.4981 - val_accuracy: 0.4707 - 293ms/epoch - 24ms/step\n",
            "Epoch 228/300\n",
            "12/12 - 0s - loss: 0.8684 - accuracy: 0.7315 - val_loss: 3.0212 - val_accuracy: 0.5191 - 290ms/epoch - 24ms/step\n",
            "Epoch 229/300\n",
            "12/12 - 0s - loss: 0.9368 - accuracy: 0.7253 - val_loss: 3.2679 - val_accuracy: 0.5205 - 292ms/epoch - 24ms/step\n",
            "Epoch 230/300\n",
            "12/12 - 0s - loss: 0.8317 - accuracy: 0.7462 - val_loss: 3.7964 - val_accuracy: 0.5249 - 288ms/epoch - 24ms/step\n",
            "Epoch 231/300\n",
            "12/12 - 0s - loss: 0.9091 - accuracy: 0.7370 - val_loss: 3.3716 - val_accuracy: 0.5176 - 290ms/epoch - 24ms/step\n",
            "Epoch 232/300\n",
            "12/12 - 0s - loss: 0.7323 - accuracy: 0.7537 - val_loss: 3.3021 - val_accuracy: 0.5455 - 288ms/epoch - 24ms/step\n",
            "Epoch 233/300\n",
            "12/12 - 0s - loss: 0.7692 - accuracy: 0.7555 - val_loss: 2.9140 - val_accuracy: 0.5308 - 294ms/epoch - 24ms/step\n",
            "Epoch 234/300\n",
            "12/12 - 0s - loss: 0.9158 - accuracy: 0.7393 - val_loss: 3.2432 - val_accuracy: 0.4707 - 289ms/epoch - 24ms/step\n",
            "Epoch 235/300\n",
            "12/12 - 0s - loss: 0.8299 - accuracy: 0.7351 - val_loss: 3.1986 - val_accuracy: 0.5264 - 294ms/epoch - 25ms/step\n",
            "Epoch 236/300\n",
            "12/12 - 0s - loss: 0.8518 - accuracy: 0.7243 - val_loss: 3.1698 - val_accuracy: 0.5029 - 293ms/epoch - 24ms/step\n",
            "Epoch 237/300\n",
            "12/12 - 0s - loss: 0.8023 - accuracy: 0.7343 - val_loss: 3.1928 - val_accuracy: 0.4927 - 287ms/epoch - 24ms/step\n",
            "Epoch 238/300\n",
            "12/12 - 0s - loss: 0.7571 - accuracy: 0.7467 - val_loss: 3.3944 - val_accuracy: 0.4883 - 297ms/epoch - 25ms/step\n",
            "Epoch 239/300\n",
            "12/12 - 0s - loss: 0.7139 - accuracy: 0.7568 - val_loss: 4.2332 - val_accuracy: 0.5132 - 293ms/epoch - 24ms/step\n",
            "Epoch 240/300\n",
            "12/12 - 0s - loss: 0.6888 - accuracy: 0.7653 - val_loss: 3.5478 - val_accuracy: 0.5191 - 285ms/epoch - 24ms/step\n",
            "Epoch 241/300\n",
            "12/12 - 0s - loss: 0.8130 - accuracy: 0.7638 - val_loss: 3.3044 - val_accuracy: 0.5411 - 289ms/epoch - 24ms/step\n",
            "Epoch 242/300\n",
            "12/12 - 0s - loss: 0.7561 - accuracy: 0.7454 - val_loss: 3.0887 - val_accuracy: 0.5088 - 295ms/epoch - 25ms/step\n",
            "Epoch 243/300\n",
            "12/12 - 0s - loss: 0.7183 - accuracy: 0.7535 - val_loss: 3.1135 - val_accuracy: 0.5205 - 292ms/epoch - 24ms/step\n",
            "Epoch 244/300\n",
            "12/12 - 0s - loss: 0.7173 - accuracy: 0.7716 - val_loss: 3.3675 - val_accuracy: 0.5220 - 293ms/epoch - 24ms/step\n",
            "Epoch 245/300\n",
            "12/12 - 0s - loss: 0.7450 - accuracy: 0.7602 - val_loss: 3.0285 - val_accuracy: 0.5279 - 288ms/epoch - 24ms/step\n",
            "Epoch 246/300\n",
            "12/12 - 0s - loss: 0.6996 - accuracy: 0.7648 - val_loss: 2.8422 - val_accuracy: 0.5337 - 295ms/epoch - 25ms/step\n",
            "Epoch 247/300\n",
            "12/12 - 0s - loss: 0.6710 - accuracy: 0.7643 - val_loss: 2.9115 - val_accuracy: 0.5161 - 289ms/epoch - 24ms/step\n",
            "Epoch 248/300\n",
            "12/12 - 0s - loss: 0.6480 - accuracy: 0.7723 - val_loss: 3.2061 - val_accuracy: 0.5205 - 288ms/epoch - 24ms/step\n",
            "Epoch 249/300\n",
            "12/12 - 0s - loss: 0.6504 - accuracy: 0.7775 - val_loss: 3.4245 - val_accuracy: 0.5513 - 289ms/epoch - 24ms/step\n",
            "Epoch 250/300\n",
            "12/12 - 0s - loss: 0.6006 - accuracy: 0.7928 - val_loss: 3.3123 - val_accuracy: 0.5279 - 292ms/epoch - 24ms/step\n",
            "Epoch 251/300\n",
            "12/12 - 0s - loss: 0.5985 - accuracy: 0.7883 - val_loss: 3.1934 - val_accuracy: 0.5381 - 288ms/epoch - 24ms/step\n",
            "Epoch 252/300\n",
            "12/12 - 0s - loss: 0.6398 - accuracy: 0.7778 - val_loss: 3.1492 - val_accuracy: 0.5249 - 289ms/epoch - 24ms/step\n",
            "Epoch 253/300\n",
            "12/12 - 0s - loss: 0.6286 - accuracy: 0.7759 - val_loss: 2.9894 - val_accuracy: 0.5088 - 283ms/epoch - 24ms/step\n",
            "Epoch 254/300\n",
            "12/12 - 0s - loss: 0.6525 - accuracy: 0.7803 - val_loss: 3.0991 - val_accuracy: 0.5147 - 288ms/epoch - 24ms/step\n",
            "Epoch 255/300\n",
            "12/12 - 0s - loss: 0.6189 - accuracy: 0.7778 - val_loss: 3.5021 - val_accuracy: 0.5059 - 286ms/epoch - 24ms/step\n",
            "Epoch 256/300\n",
            "12/12 - 0s - loss: 0.5934 - accuracy: 0.7892 - val_loss: 3.6601 - val_accuracy: 0.5499 - 285ms/epoch - 24ms/step\n",
            "Epoch 257/300\n",
            "12/12 - 0s - loss: 0.7499 - accuracy: 0.7812 - val_loss: 4.0363 - val_accuracy: 0.4927 - 294ms/epoch - 25ms/step\n",
            "Epoch 258/300\n",
            "12/12 - 0s - loss: 0.7061 - accuracy: 0.7803 - val_loss: 3.7947 - val_accuracy: 0.4868 - 292ms/epoch - 24ms/step\n",
            "Epoch 259/300\n",
            "12/12 - 0s - loss: 0.9387 - accuracy: 0.7680 - val_loss: 3.2694 - val_accuracy: 0.5293 - 289ms/epoch - 24ms/step\n",
            "Epoch 260/300\n",
            "12/12 - 0s - loss: 1.0470 - accuracy: 0.7470 - val_loss: 3.2332 - val_accuracy: 0.5220 - 291ms/epoch - 24ms/step\n",
            "Epoch 261/300\n",
            "12/12 - 0s - loss: 0.8163 - accuracy: 0.7468 - val_loss: 2.7905 - val_accuracy: 0.5103 - 291ms/epoch - 24ms/step\n",
            "Epoch 262/300\n",
            "12/12 - 0s - loss: 0.8198 - accuracy: 0.7499 - val_loss: 3.5472 - val_accuracy: 0.4971 - 297ms/epoch - 25ms/step\n",
            "Epoch 263/300\n",
            "12/12 - 0s - loss: 0.9314 - accuracy: 0.7458 - val_loss: 3.7042 - val_accuracy: 0.5147 - 292ms/epoch - 24ms/step\n",
            "Epoch 264/300\n",
            "12/12 - 0s - loss: 0.9163 - accuracy: 0.7362 - val_loss: 4.1610 - val_accuracy: 0.4941 - 291ms/epoch - 24ms/step\n",
            "Epoch 265/300\n",
            "12/12 - 0s - loss: 0.8924 - accuracy: 0.7299 - val_loss: 3.6515 - val_accuracy: 0.5323 - 286ms/epoch - 24ms/step\n",
            "Epoch 266/300\n",
            "12/12 - 0s - loss: 0.7521 - accuracy: 0.7576 - val_loss: 4.2040 - val_accuracy: 0.5337 - 292ms/epoch - 24ms/step\n",
            "Epoch 267/300\n",
            "12/12 - 0s - loss: 0.7010 - accuracy: 0.7626 - val_loss: 4.5108 - val_accuracy: 0.5205 - 291ms/epoch - 24ms/step\n",
            "Epoch 268/300\n",
            "12/12 - 0s - loss: 0.9489 - accuracy: 0.7390 - val_loss: 4.2416 - val_accuracy: 0.4853 - 293ms/epoch - 24ms/step\n",
            "Epoch 269/300\n",
            "12/12 - 0s - loss: 0.9668 - accuracy: 0.7333 - val_loss: 3.8302 - val_accuracy: 0.5484 - 285ms/epoch - 24ms/step\n",
            "Epoch 270/300\n",
            "12/12 - 0s - loss: 0.8516 - accuracy: 0.7326 - val_loss: 3.8180 - val_accuracy: 0.4663 - 295ms/epoch - 25ms/step\n",
            "Epoch 271/300\n",
            "12/12 - 0s - loss: 0.8035 - accuracy: 0.7300 - val_loss: 3.9727 - val_accuracy: 0.4751 - 293ms/epoch - 24ms/step\n",
            "Epoch 272/300\n",
            "12/12 - 0s - loss: 0.7582 - accuracy: 0.7483 - val_loss: 3.7181 - val_accuracy: 0.4941 - 291ms/epoch - 24ms/step\n",
            "Epoch 273/300\n",
            "12/12 - 0s - loss: 0.7351 - accuracy: 0.7519 - val_loss: 3.8757 - val_accuracy: 0.5059 - 292ms/epoch - 24ms/step\n",
            "Epoch 274/300\n",
            "12/12 - 0s - loss: 0.6677 - accuracy: 0.7801 - val_loss: 3.6020 - val_accuracy: 0.5029 - 286ms/epoch - 24ms/step\n",
            "Epoch 275/300\n",
            "12/12 - 0s - loss: 0.6678 - accuracy: 0.7754 - val_loss: 3.9146 - val_accuracy: 0.5117 - 290ms/epoch - 24ms/step\n",
            "Epoch 276/300\n",
            "12/12 - 0s - loss: 0.6548 - accuracy: 0.7777 - val_loss: 4.0815 - val_accuracy: 0.5205 - 289ms/epoch - 24ms/step\n",
            "Epoch 277/300\n",
            "12/12 - 0s - loss: 0.7143 - accuracy: 0.7803 - val_loss: 5.3533 - val_accuracy: 0.5176 - 291ms/epoch - 24ms/step\n",
            "Epoch 278/300\n",
            "12/12 - 0s - loss: 0.6180 - accuracy: 0.7912 - val_loss: 5.9980 - val_accuracy: 0.5073 - 290ms/epoch - 24ms/step\n",
            "Epoch 279/300\n",
            "12/12 - 0s - loss: 0.6608 - accuracy: 0.7739 - val_loss: 4.3028 - val_accuracy: 0.5337 - 291ms/epoch - 24ms/step\n",
            "Epoch 280/300\n",
            "12/12 - 0s - loss: 0.6348 - accuracy: 0.7770 - val_loss: 4.2437 - val_accuracy: 0.4971 - 290ms/epoch - 24ms/step\n",
            "Epoch 281/300\n",
            "12/12 - 0s - loss: 0.6196 - accuracy: 0.7896 - val_loss: 4.3152 - val_accuracy: 0.4912 - 283ms/epoch - 24ms/step\n",
            "Epoch 282/300\n",
            "12/12 - 0s - loss: 0.6030 - accuracy: 0.7847 - val_loss: 4.6922 - val_accuracy: 0.5601 - 289ms/epoch - 24ms/step\n",
            "Epoch 283/300\n",
            "12/12 - 0s - loss: 0.5958 - accuracy: 0.8033 - val_loss: 5.4232 - val_accuracy: 0.5337 - 293ms/epoch - 24ms/step\n",
            "Epoch 284/300\n",
            "12/12 - 0s - loss: 0.5913 - accuracy: 0.7943 - val_loss: 5.9302 - val_accuracy: 0.5455 - 285ms/epoch - 24ms/step\n",
            "Epoch 285/300\n",
            "12/12 - 0s - loss: 0.5538 - accuracy: 0.8075 - val_loss: 6.0744 - val_accuracy: 0.5455 - 286ms/epoch - 24ms/step\n",
            "Epoch 286/300\n",
            "12/12 - 0s - loss: 0.6166 - accuracy: 0.7778 - val_loss: 5.9565 - val_accuracy: 0.5499 - 290ms/epoch - 24ms/step\n",
            "Epoch 287/300\n",
            "12/12 - 0s - loss: 0.6046 - accuracy: 0.7974 - val_loss: 5.9639 - val_accuracy: 0.4927 - 294ms/epoch - 24ms/step\n",
            "Epoch 288/300\n",
            "12/12 - 0s - loss: 0.5626 - accuracy: 0.8052 - val_loss: 6.0424 - val_accuracy: 0.5103 - 291ms/epoch - 24ms/step\n",
            "Epoch 289/300\n",
            "12/12 - 0s - loss: 0.6119 - accuracy: 0.7886 - val_loss: 6.3257 - val_accuracy: 0.5264 - 290ms/epoch - 24ms/step\n",
            "Epoch 290/300\n",
            "12/12 - 0s - loss: 0.6236 - accuracy: 0.7933 - val_loss: 6.0158 - val_accuracy: 0.5205 - 289ms/epoch - 24ms/step\n",
            "Epoch 291/300\n",
            "12/12 - 0s - loss: 0.6007 - accuracy: 0.7905 - val_loss: 5.5377 - val_accuracy: 0.5293 - 291ms/epoch - 24ms/step\n",
            "Epoch 292/300\n",
            "12/12 - 0s - loss: 0.5807 - accuracy: 0.7980 - val_loss: 4.8997 - val_accuracy: 0.5161 - 291ms/epoch - 24ms/step\n",
            "Epoch 293/300\n",
            "12/12 - 0s - loss: 0.5741 - accuracy: 0.8029 - val_loss: 5.1936 - val_accuracy: 0.5337 - 293ms/epoch - 24ms/step\n",
            "Epoch 294/300\n",
            "12/12 - 0s - loss: 0.5752 - accuracy: 0.7958 - val_loss: 5.4993 - val_accuracy: 0.5073 - 286ms/epoch - 24ms/step\n",
            "Epoch 295/300\n",
            "12/12 - 0s - loss: 0.5651 - accuracy: 0.8038 - val_loss: 5.0906 - val_accuracy: 0.5235 - 289ms/epoch - 24ms/step\n",
            "Epoch 296/300\n",
            "12/12 - 0s - loss: 0.5379 - accuracy: 0.8215 - val_loss: 5.2072 - val_accuracy: 0.5528 - 290ms/epoch - 24ms/step\n",
            "Epoch 297/300\n",
            "12/12 - 0s - loss: 0.5473 - accuracy: 0.8122 - val_loss: 5.0542 - val_accuracy: 0.5308 - 289ms/epoch - 24ms/step\n",
            "Epoch 298/300\n",
            "12/12 - 0s - loss: 0.5561 - accuracy: 0.8029 - val_loss: 5.0579 - val_accuracy: 0.5455 - 285ms/epoch - 24ms/step\n",
            "Epoch 299/300\n",
            "12/12 - 0s - loss: 0.5402 - accuracy: 0.8111 - val_loss: 5.3336 - val_accuracy: 0.5220 - 288ms/epoch - 24ms/step\n",
            "Epoch 300/300\n",
            "12/12 - 0s - loss: 0.5567 - accuracy: 0.8010 - val_loss: 5.4960 - val_accuracy: 0.5161 - 287ms/epoch - 24ms/step\n",
            "Model: \"sequential_93\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_186 (Conv2D)         (None, 4, 36, 80)         27440     \n",
            "                                                                 \n",
            " max_pooling2d_186 (MaxPooli  (None, 1, 12, 80)        0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_93 (Bat  (None, 1, 12, 80)        320       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv2d_187 (Conv2D)         (None, 1, 10, 80)         19280     \n",
            "                                                                 \n",
            " max_pooling2d_187 (MaxPooli  (None, 1, 3, 80)         0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " flatten_93 (Flatten)        (None, 240)               0         \n",
            "                                                                 \n",
            " dense_279 (Dense)           (None, 5000)              1205000   \n",
            "                                                                 \n",
            " dropout_186 (Dropout)       (None, 5000)              0         \n",
            "                                                                 \n",
            " dense_280 (Dense)           (None, 5000)              25005000  \n",
            "                                                                 \n",
            " dropout_187 (Dropout)       (None, 5000)              0         \n",
            "                                                                 \n",
            " dense_281 (Dense)           (None, 10)                50010     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 26,307,050\n",
            "Trainable params: 26,306,890\n",
            "Non-trainable params: 160\n",
            "_________________________________________________________________\n",
            "None\n",
            "Result of fold:4\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 4.6138 - accuracy: 0.4895\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 40%|████      | 4/10 [06:12<09:18, 93.06s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(6864, 60, 41)\n",
            "Epoch 1/300\n",
            "13/13 - 1s - loss: 5.8882 - accuracy: 0.1454 - val_loss: 2.2446 - val_accuracy: 0.1878 - 1s/epoch - 79ms/step\n",
            "Epoch 2/300\n",
            "13/13 - 0s - loss: 2.1425 - accuracy: 0.2072 - val_loss: 2.2327 - val_accuracy: 0.1994 - 298ms/epoch - 23ms/step\n",
            "Epoch 3/300\n",
            "13/13 - 0s - loss: 2.1129 - accuracy: 0.2215 - val_loss: 2.1343 - val_accuracy: 0.1892 - 291ms/epoch - 22ms/step\n",
            "Epoch 4/300\n",
            "13/13 - 0s - loss: 2.0710 - accuracy: 0.2229 - val_loss: 2.0080 - val_accuracy: 0.2111 - 293ms/epoch - 23ms/step\n",
            "Epoch 5/300\n",
            "13/13 - 0s - loss: 2.0355 - accuracy: 0.2409 - val_loss: 1.9745 - val_accuracy: 0.2489 - 292ms/epoch - 22ms/step\n",
            "Epoch 6/300\n",
            "13/13 - 0s - loss: 2.0146 - accuracy: 0.2534 - val_loss: 1.9741 - val_accuracy: 0.3144 - 293ms/epoch - 23ms/step\n",
            "Epoch 7/300\n",
            "13/13 - 0s - loss: 1.9793 - accuracy: 0.2684 - val_loss: 1.9478 - val_accuracy: 0.3231 - 291ms/epoch - 22ms/step\n",
            "Epoch 8/300\n",
            "13/13 - 0s - loss: 1.9762 - accuracy: 0.2704 - val_loss: 2.0553 - val_accuracy: 0.2169 - 300ms/epoch - 23ms/step\n",
            "Epoch 9/300\n",
            "13/13 - 0s - loss: 1.9667 - accuracy: 0.2728 - val_loss: 1.9513 - val_accuracy: 0.2460 - 296ms/epoch - 23ms/step\n",
            "Epoch 10/300\n",
            "13/13 - 0s - loss: 1.9082 - accuracy: 0.3031 - val_loss: 2.0027 - val_accuracy: 0.2242 - 300ms/epoch - 23ms/step\n",
            "Epoch 11/300\n",
            "13/13 - 0s - loss: 1.8843 - accuracy: 0.3050 - val_loss: 1.8571 - val_accuracy: 0.3508 - 292ms/epoch - 22ms/step\n",
            "Epoch 12/300\n",
            "13/13 - 0s - loss: 1.8590 - accuracy: 0.3267 - val_loss: 1.9545 - val_accuracy: 0.3406 - 294ms/epoch - 23ms/step\n",
            "Epoch 13/300\n",
            "13/13 - 0s - loss: 1.8400 - accuracy: 0.3115 - val_loss: 1.7946 - val_accuracy: 0.3362 - 293ms/epoch - 23ms/step\n",
            "Epoch 14/300\n",
            "13/13 - 0s - loss: 1.8084 - accuracy: 0.3286 - val_loss: 1.8276 - val_accuracy: 0.3202 - 290ms/epoch - 22ms/step\n",
            "Epoch 15/300\n",
            "13/13 - 0s - loss: 1.7996 - accuracy: 0.3325 - val_loss: 1.7444 - val_accuracy: 0.4119 - 295ms/epoch - 23ms/step\n",
            "Epoch 16/300\n",
            "13/13 - 0s - loss: 1.7671 - accuracy: 0.3602 - val_loss: 1.7967 - val_accuracy: 0.3755 - 293ms/epoch - 23ms/step\n",
            "Epoch 17/300\n",
            "13/13 - 0s - loss: 1.7551 - accuracy: 0.3579 - val_loss: 1.7485 - val_accuracy: 0.3872 - 290ms/epoch - 22ms/step\n",
            "Epoch 18/300\n",
            "13/13 - 0s - loss: 1.6939 - accuracy: 0.4015 - val_loss: 1.7503 - val_accuracy: 0.3785 - 288ms/epoch - 22ms/step\n",
            "Epoch 19/300\n",
            "13/13 - 0s - loss: 1.7014 - accuracy: 0.3835 - val_loss: 1.8902 - val_accuracy: 0.4032 - 291ms/epoch - 22ms/step\n",
            "Epoch 20/300\n",
            "13/13 - 0s - loss: 1.7887 - accuracy: 0.3751 - val_loss: 1.8334 - val_accuracy: 0.3770 - 294ms/epoch - 23ms/step\n",
            "Epoch 21/300\n",
            "13/13 - 0s - loss: 1.7882 - accuracy: 0.3621 - val_loss: 1.9283 - val_accuracy: 0.4032 - 288ms/epoch - 22ms/step\n",
            "Epoch 22/300\n",
            "13/13 - 0s - loss: 1.7416 - accuracy: 0.3774 - val_loss: 1.7663 - val_accuracy: 0.3988 - 293ms/epoch - 23ms/step\n",
            "Epoch 23/300\n",
            "13/13 - 0s - loss: 1.6912 - accuracy: 0.3947 - val_loss: 1.7186 - val_accuracy: 0.3886 - 293ms/epoch - 23ms/step\n",
            "Epoch 24/300\n",
            "13/13 - 0s - loss: 1.6209 - accuracy: 0.4206 - val_loss: 1.7851 - val_accuracy: 0.4381 - 301ms/epoch - 23ms/step\n",
            "Epoch 25/300\n",
            "13/13 - 0s - loss: 1.6264 - accuracy: 0.4285 - val_loss: 1.7980 - val_accuracy: 0.4338 - 289ms/epoch - 22ms/step\n",
            "Epoch 26/300\n",
            "13/13 - 0s - loss: 1.6486 - accuracy: 0.4144 - val_loss: 1.7363 - val_accuracy: 0.4425 - 292ms/epoch - 22ms/step\n",
            "Epoch 27/300\n",
            "13/13 - 0s - loss: 1.6408 - accuracy: 0.4238 - val_loss: 1.8209 - val_accuracy: 0.3654 - 292ms/epoch - 22ms/step\n",
            "Epoch 28/300\n",
            "13/13 - 0s - loss: 1.5901 - accuracy: 0.4282 - val_loss: 1.6693 - val_accuracy: 0.4571 - 292ms/epoch - 22ms/step\n",
            "Epoch 29/300\n",
            "13/13 - 0s - loss: 1.5555 - accuracy: 0.4502 - val_loss: 1.6968 - val_accuracy: 0.4148 - 299ms/epoch - 23ms/step\n",
            "Epoch 30/300\n",
            "13/13 - 0s - loss: 1.5523 - accuracy: 0.4462 - val_loss: 1.7909 - val_accuracy: 0.3988 - 305ms/epoch - 23ms/step\n",
            "Epoch 31/300\n",
            "13/13 - 0s - loss: 1.5542 - accuracy: 0.4606 - val_loss: 1.7111 - val_accuracy: 0.4556 - 298ms/epoch - 23ms/step\n",
            "Epoch 32/300\n",
            "13/13 - 0s - loss: 1.5961 - accuracy: 0.4318 - val_loss: 1.7105 - val_accuracy: 0.4629 - 299ms/epoch - 23ms/step\n",
            "Epoch 33/300\n",
            "13/13 - 0s - loss: 1.6049 - accuracy: 0.4237 - val_loss: 1.8441 - val_accuracy: 0.4032 - 307ms/epoch - 24ms/step\n",
            "Epoch 34/300\n",
            "13/13 - 0s - loss: 1.5815 - accuracy: 0.4329 - val_loss: 1.7975 - val_accuracy: 0.3988 - 305ms/epoch - 23ms/step\n",
            "Epoch 35/300\n",
            "13/13 - 0s - loss: 1.6073 - accuracy: 0.4439 - val_loss: 1.8912 - val_accuracy: 0.3988 - 303ms/epoch - 23ms/step\n",
            "Epoch 36/300\n",
            "13/13 - 0s - loss: 1.6250 - accuracy: 0.4322 - val_loss: 1.8728 - val_accuracy: 0.4076 - 302ms/epoch - 23ms/step\n",
            "Epoch 37/300\n",
            "13/13 - 0s - loss: 1.6251 - accuracy: 0.4298 - val_loss: 1.7246 - val_accuracy: 0.4134 - 302ms/epoch - 23ms/step\n",
            "Epoch 38/300\n",
            "13/13 - 0s - loss: 1.6278 - accuracy: 0.4251 - val_loss: 1.8250 - val_accuracy: 0.4148 - 292ms/epoch - 22ms/step\n",
            "Epoch 39/300\n",
            "13/13 - 0s - loss: 1.7188 - accuracy: 0.4107 - val_loss: 1.8752 - val_accuracy: 0.3537 - 292ms/epoch - 22ms/step\n",
            "Epoch 40/300\n",
            "13/13 - 0s - loss: 1.5963 - accuracy: 0.4358 - val_loss: 1.9055 - val_accuracy: 0.4323 - 292ms/epoch - 22ms/step\n",
            "Epoch 41/300\n",
            "13/13 - 0s - loss: 1.6346 - accuracy: 0.4201 - val_loss: 1.7877 - val_accuracy: 0.4338 - 287ms/epoch - 22ms/step\n",
            "Epoch 42/300\n",
            "13/13 - 0s - loss: 1.5593 - accuracy: 0.4439 - val_loss: 1.7326 - val_accuracy: 0.4279 - 294ms/epoch - 23ms/step\n",
            "Epoch 43/300\n",
            "13/13 - 0s - loss: 1.5441 - accuracy: 0.4565 - val_loss: 1.7400 - val_accuracy: 0.4090 - 287ms/epoch - 22ms/step\n",
            "Epoch 44/300\n",
            "13/13 - 0s - loss: 1.5392 - accuracy: 0.4620 - val_loss: 1.6169 - val_accuracy: 0.4629 - 299ms/epoch - 23ms/step\n",
            "Epoch 45/300\n",
            "13/13 - 0s - loss: 1.5155 - accuracy: 0.4624 - val_loss: 1.6769 - val_accuracy: 0.4309 - 297ms/epoch - 23ms/step\n",
            "Epoch 46/300\n",
            "13/13 - 0s - loss: 1.5649 - accuracy: 0.4596 - val_loss: 1.7295 - val_accuracy: 0.4352 - 295ms/epoch - 23ms/step\n",
            "Epoch 47/300\n",
            "13/13 - 0s - loss: 1.6300 - accuracy: 0.4444 - val_loss: 1.8445 - val_accuracy: 0.3304 - 296ms/epoch - 23ms/step\n",
            "Epoch 48/300\n",
            "13/13 - 0s - loss: 1.5317 - accuracy: 0.4760 - val_loss: 1.6853 - val_accuracy: 0.4527 - 292ms/epoch - 22ms/step\n",
            "Epoch 49/300\n",
            "13/13 - 0s - loss: 1.4973 - accuracy: 0.4705 - val_loss: 1.6720 - val_accuracy: 0.4061 - 294ms/epoch - 23ms/step\n",
            "Epoch 50/300\n",
            "13/13 - 0s - loss: 1.5303 - accuracy: 0.4667 - val_loss: 1.7617 - val_accuracy: 0.3770 - 295ms/epoch - 23ms/step\n",
            "Epoch 51/300\n",
            "13/13 - 0s - loss: 1.5438 - accuracy: 0.4632 - val_loss: 1.6623 - val_accuracy: 0.4279 - 292ms/epoch - 22ms/step\n",
            "Epoch 52/300\n",
            "13/13 - 0s - loss: 1.4812 - accuracy: 0.4753 - val_loss: 1.5780 - val_accuracy: 0.4556 - 292ms/epoch - 22ms/step\n",
            "Epoch 53/300\n",
            "13/13 - 0s - loss: 1.4318 - accuracy: 0.4949 - val_loss: 1.6496 - val_accuracy: 0.4891 - 294ms/epoch - 23ms/step\n",
            "Epoch 54/300\n",
            "13/13 - 0s - loss: 1.4577 - accuracy: 0.4960 - val_loss: 1.6733 - val_accuracy: 0.4571 - 289ms/epoch - 22ms/step\n",
            "Epoch 55/300\n",
            "13/13 - 0s - loss: 1.4316 - accuracy: 0.5035 - val_loss: 1.5599 - val_accuracy: 0.5167 - 291ms/epoch - 22ms/step\n",
            "Epoch 56/300\n",
            "13/13 - 0s - loss: 1.3776 - accuracy: 0.5357 - val_loss: 1.5783 - val_accuracy: 0.5066 - 293ms/epoch - 23ms/step\n",
            "Epoch 57/300\n",
            "13/13 - 0s - loss: 1.4215 - accuracy: 0.5127 - val_loss: 1.6750 - val_accuracy: 0.4731 - 298ms/epoch - 23ms/step\n",
            "Epoch 58/300\n",
            "13/13 - 0s - loss: 1.4265 - accuracy: 0.5294 - val_loss: 1.7378 - val_accuracy: 0.4847 - 295ms/epoch - 23ms/step\n",
            "Epoch 59/300\n",
            "13/13 - 0s - loss: 1.4261 - accuracy: 0.5108 - val_loss: 1.6299 - val_accuracy: 0.4803 - 291ms/epoch - 22ms/step\n",
            "Epoch 60/300\n",
            "13/13 - 0s - loss: 1.4511 - accuracy: 0.4944 - val_loss: 1.6590 - val_accuracy: 0.5255 - 292ms/epoch - 22ms/step\n",
            "Epoch 61/300\n",
            "13/13 - 0s - loss: 1.4168 - accuracy: 0.5206 - val_loss: 1.7084 - val_accuracy: 0.5124 - 297ms/epoch - 23ms/step\n",
            "Epoch 62/300\n",
            "13/13 - 0s - loss: 1.3590 - accuracy: 0.5294 - val_loss: 1.6228 - val_accuracy: 0.5109 - 293ms/epoch - 23ms/step\n",
            "Epoch 63/300\n",
            "13/13 - 0s - loss: 1.3639 - accuracy: 0.5255 - val_loss: 1.6601 - val_accuracy: 0.4396 - 295ms/epoch - 23ms/step\n",
            "Epoch 64/300\n",
            "13/13 - 0s - loss: 1.3756 - accuracy: 0.5276 - val_loss: 1.7860 - val_accuracy: 0.4731 - 291ms/epoch - 22ms/step\n",
            "Epoch 65/300\n",
            "13/13 - 0s - loss: 1.3548 - accuracy: 0.5240 - val_loss: 1.7173 - val_accuracy: 0.4090 - 294ms/epoch - 23ms/step\n",
            "Epoch 66/300\n",
            "13/13 - 0s - loss: 1.3944 - accuracy: 0.5185 - val_loss: 1.7323 - val_accuracy: 0.4003 - 294ms/epoch - 23ms/step\n",
            "Epoch 67/300\n",
            "13/13 - 0s - loss: 1.5247 - accuracy: 0.4952 - val_loss: 1.7796 - val_accuracy: 0.4614 - 297ms/epoch - 23ms/step\n",
            "Epoch 68/300\n",
            "13/13 - 0s - loss: 1.4493 - accuracy: 0.5187 - val_loss: 1.6348 - val_accuracy: 0.4993 - 292ms/epoch - 22ms/step\n",
            "Epoch 69/300\n",
            "13/13 - 0s - loss: 1.4866 - accuracy: 0.5184 - val_loss: 1.6777 - val_accuracy: 0.4658 - 291ms/epoch - 22ms/step\n",
            "Epoch 70/300\n",
            "13/13 - 0s - loss: 1.5000 - accuracy: 0.4925 - val_loss: 2.0331 - val_accuracy: 0.3959 - 297ms/epoch - 23ms/step\n",
            "Epoch 71/300\n",
            "13/13 - 0s - loss: 1.5328 - accuracy: 0.4776 - val_loss: 1.8571 - val_accuracy: 0.4119 - 294ms/epoch - 23ms/step\n",
            "Epoch 72/300\n",
            "13/13 - 0s - loss: 1.5944 - accuracy: 0.4654 - val_loss: 1.6783 - val_accuracy: 0.4498 - 292ms/epoch - 22ms/step\n",
            "Epoch 73/300\n",
            "13/13 - 0s - loss: 1.5701 - accuracy: 0.4526 - val_loss: 1.7245 - val_accuracy: 0.3916 - 293ms/epoch - 23ms/step\n",
            "Epoch 74/300\n",
            "13/13 - 0s - loss: 1.5392 - accuracy: 0.4627 - val_loss: 1.6828 - val_accuracy: 0.4585 - 293ms/epoch - 23ms/step\n",
            "Epoch 75/300\n",
            "13/13 - 0s - loss: 1.5779 - accuracy: 0.4648 - val_loss: 1.7507 - val_accuracy: 0.4265 - 302ms/epoch - 23ms/step\n",
            "Epoch 76/300\n",
            "13/13 - 0s - loss: 1.5578 - accuracy: 0.4560 - val_loss: 1.6557 - val_accuracy: 0.4279 - 289ms/epoch - 22ms/step\n",
            "Epoch 77/300\n",
            "13/13 - 0s - loss: 1.4886 - accuracy: 0.4781 - val_loss: 1.6972 - val_accuracy: 0.4250 - 292ms/epoch - 22ms/step\n",
            "Epoch 78/300\n",
            "13/13 - 0s - loss: 1.4791 - accuracy: 0.4777 - val_loss: 1.7163 - val_accuracy: 0.4716 - 292ms/epoch - 22ms/step\n",
            "Epoch 79/300\n",
            "13/13 - 0s - loss: 1.4724 - accuracy: 0.4897 - val_loss: 1.7047 - val_accuracy: 0.4571 - 298ms/epoch - 23ms/step\n",
            "Epoch 80/300\n",
            "13/13 - 0s - loss: 1.5111 - accuracy: 0.4789 - val_loss: 1.6620 - val_accuracy: 0.4498 - 292ms/epoch - 22ms/step\n",
            "Epoch 81/300\n",
            "13/13 - 0s - loss: 1.5151 - accuracy: 0.4845 - val_loss: 1.7024 - val_accuracy: 0.4192 - 293ms/epoch - 23ms/step\n",
            "Epoch 82/300\n",
            "13/13 - 0s - loss: 1.4699 - accuracy: 0.4844 - val_loss: 1.6929 - val_accuracy: 0.4556 - 289ms/epoch - 22ms/step\n",
            "Epoch 83/300\n",
            "13/13 - 0s - loss: 1.4428 - accuracy: 0.4949 - val_loss: 1.7206 - val_accuracy: 0.4454 - 294ms/epoch - 23ms/step\n",
            "Epoch 84/300\n",
            "13/13 - 0s - loss: 1.5451 - accuracy: 0.4599 - val_loss: 1.9127 - val_accuracy: 0.4047 - 301ms/epoch - 23ms/step\n",
            "Epoch 85/300\n",
            "13/13 - 0s - loss: 1.5063 - accuracy: 0.4747 - val_loss: 1.7449 - val_accuracy: 0.4134 - 293ms/epoch - 23ms/step\n",
            "Epoch 86/300\n",
            "13/13 - 0s - loss: 1.5186 - accuracy: 0.4769 - val_loss: 1.8593 - val_accuracy: 0.4556 - 297ms/epoch - 23ms/step\n",
            "Epoch 87/300\n",
            "13/13 - 0s - loss: 1.6574 - accuracy: 0.4352 - val_loss: 1.8461 - val_accuracy: 0.3945 - 297ms/epoch - 23ms/step\n",
            "Epoch 88/300\n",
            "13/13 - 0s - loss: 1.5660 - accuracy: 0.4423 - val_loss: 1.8487 - val_accuracy: 0.4105 - 299ms/epoch - 23ms/step\n",
            "Epoch 89/300\n",
            "13/13 - 0s - loss: 1.4844 - accuracy: 0.4633 - val_loss: 1.7386 - val_accuracy: 0.4410 - 292ms/epoch - 22ms/step\n",
            "Epoch 90/300\n",
            "13/13 - 0s - loss: 1.5419 - accuracy: 0.4514 - val_loss: 1.7906 - val_accuracy: 0.3552 - 294ms/epoch - 23ms/step\n",
            "Epoch 91/300\n",
            "13/13 - 0s - loss: 1.4616 - accuracy: 0.4807 - val_loss: 1.7339 - val_accuracy: 0.4760 - 297ms/epoch - 23ms/step\n",
            "Epoch 92/300\n",
            "13/13 - 0s - loss: 1.8984 - accuracy: 0.3698 - val_loss: 1.9529 - val_accuracy: 0.2868 - 292ms/epoch - 22ms/step\n",
            "Epoch 93/300\n",
            "13/13 - 0s - loss: 1.7821 - accuracy: 0.3631 - val_loss: 1.7743 - val_accuracy: 0.4250 - 290ms/epoch - 22ms/step\n",
            "Epoch 94/300\n",
            "13/13 - 0s - loss: 1.7442 - accuracy: 0.3668 - val_loss: 1.8182 - val_accuracy: 0.3974 - 295ms/epoch - 23ms/step\n",
            "Epoch 95/300\n",
            "13/13 - 0s - loss: 1.7898 - accuracy: 0.3756 - val_loss: 1.8951 - val_accuracy: 0.4003 - 298ms/epoch - 23ms/step\n",
            "Epoch 96/300\n",
            "13/13 - 0s - loss: 1.7374 - accuracy: 0.3913 - val_loss: 1.8411 - val_accuracy: 0.3450 - 297ms/epoch - 23ms/step\n",
            "Epoch 97/300\n",
            "13/13 - 0s - loss: 1.6962 - accuracy: 0.3848 - val_loss: 1.8443 - val_accuracy: 0.4032 - 300ms/epoch - 23ms/step\n",
            "Epoch 98/300\n",
            "13/13 - 0s - loss: 1.6290 - accuracy: 0.4154 - val_loss: 1.7880 - val_accuracy: 0.4178 - 296ms/epoch - 23ms/step\n",
            "Epoch 99/300\n",
            "13/13 - 0s - loss: 1.6505 - accuracy: 0.4097 - val_loss: 1.8464 - val_accuracy: 0.4148 - 293ms/epoch - 23ms/step\n",
            "Epoch 100/300\n",
            "13/13 - 0s - loss: 1.5880 - accuracy: 0.4355 - val_loss: 1.7684 - val_accuracy: 0.4105 - 295ms/epoch - 23ms/step\n",
            "Epoch 101/300\n",
            "13/13 - 0s - loss: 1.5840 - accuracy: 0.4185 - val_loss: 1.8137 - val_accuracy: 0.4061 - 293ms/epoch - 23ms/step\n",
            "Epoch 102/300\n",
            "13/13 - 0s - loss: 1.5837 - accuracy: 0.4321 - val_loss: 1.8147 - val_accuracy: 0.4236 - 293ms/epoch - 23ms/step\n",
            "Epoch 103/300\n",
            "13/13 - 0s - loss: 1.5210 - accuracy: 0.4460 - val_loss: 2.6457 - val_accuracy: 0.4221 - 292ms/epoch - 22ms/step\n",
            "Epoch 104/300\n",
            "13/13 - 0s - loss: 1.6682 - accuracy: 0.4433 - val_loss: 1.8002 - val_accuracy: 0.4221 - 293ms/epoch - 23ms/step\n",
            "Epoch 105/300\n",
            "13/13 - 0s - loss: 1.5632 - accuracy: 0.4282 - val_loss: 1.7911 - val_accuracy: 0.4192 - 289ms/epoch - 22ms/step\n",
            "Epoch 106/300\n",
            "13/13 - 0s - loss: 1.5294 - accuracy: 0.4520 - val_loss: 1.7993 - val_accuracy: 0.4134 - 295ms/epoch - 23ms/step\n",
            "Epoch 107/300\n",
            "13/13 - 0s - loss: 1.5252 - accuracy: 0.4510 - val_loss: 1.7770 - val_accuracy: 0.4323 - 295ms/epoch - 23ms/step\n",
            "Epoch 108/300\n",
            "13/13 - 0s - loss: 1.5766 - accuracy: 0.4347 - val_loss: 1.7475 - val_accuracy: 0.3770 - 291ms/epoch - 22ms/step\n",
            "Epoch 109/300\n",
            "13/13 - 0s - loss: 1.4835 - accuracy: 0.4591 - val_loss: 1.7274 - val_accuracy: 0.4352 - 291ms/epoch - 22ms/step\n",
            "Epoch 110/300\n",
            "13/13 - 0s - loss: 1.4649 - accuracy: 0.4701 - val_loss: 1.7162 - val_accuracy: 0.3959 - 293ms/epoch - 23ms/step\n",
            "Epoch 111/300\n",
            "13/13 - 0s - loss: 1.5314 - accuracy: 0.4557 - val_loss: 1.6427 - val_accuracy: 0.4381 - 292ms/epoch - 22ms/step\n",
            "Epoch 112/300\n",
            "13/13 - 0s - loss: 1.4851 - accuracy: 0.4700 - val_loss: 1.7983 - val_accuracy: 0.4076 - 296ms/epoch - 23ms/step\n",
            "Epoch 113/300\n",
            "13/13 - 0s - loss: 1.5371 - accuracy: 0.4473 - val_loss: 1.8669 - val_accuracy: 0.3872 - 290ms/epoch - 22ms/step\n",
            "Epoch 114/300\n",
            "13/13 - 0s - loss: 1.5633 - accuracy: 0.4449 - val_loss: 1.7142 - val_accuracy: 0.4381 - 295ms/epoch - 23ms/step\n",
            "Epoch 115/300\n",
            "13/13 - 0s - loss: 1.5317 - accuracy: 0.4557 - val_loss: 1.7231 - val_accuracy: 0.4163 - 294ms/epoch - 23ms/step\n",
            "Epoch 116/300\n",
            "13/13 - 0s - loss: 1.5270 - accuracy: 0.4641 - val_loss: 1.7984 - val_accuracy: 0.4236 - 292ms/epoch - 22ms/step\n",
            "Epoch 117/300\n",
            "13/13 - 0s - loss: 1.5752 - accuracy: 0.4480 - val_loss: 1.8327 - val_accuracy: 0.3697 - 293ms/epoch - 23ms/step\n",
            "Epoch 118/300\n",
            "13/13 - 0s - loss: 1.5333 - accuracy: 0.4609 - val_loss: 1.7184 - val_accuracy: 0.4731 - 290ms/epoch - 22ms/step\n",
            "Epoch 119/300\n",
            "13/13 - 0s - loss: 1.4689 - accuracy: 0.4748 - val_loss: 1.6979 - val_accuracy: 0.4076 - 298ms/epoch - 23ms/step\n",
            "Epoch 120/300\n",
            "13/13 - 0s - loss: 1.4228 - accuracy: 0.4832 - val_loss: 1.6778 - val_accuracy: 0.4818 - 297ms/epoch - 23ms/step\n",
            "Epoch 121/300\n",
            "13/13 - 0s - loss: 1.3878 - accuracy: 0.4858 - val_loss: 1.7635 - val_accuracy: 0.4658 - 290ms/epoch - 22ms/step\n",
            "Epoch 122/300\n",
            "13/13 - 0s - loss: 1.4368 - accuracy: 0.4907 - val_loss: 1.6275 - val_accuracy: 0.4702 - 287ms/epoch - 22ms/step\n",
            "Epoch 123/300\n",
            "13/13 - 0s - loss: 1.4583 - accuracy: 0.4832 - val_loss: 1.9420 - val_accuracy: 0.3988 - 289ms/epoch - 22ms/step\n",
            "Epoch 124/300\n",
            "13/13 - 0s - loss: 1.4744 - accuracy: 0.4732 - val_loss: 1.7108 - val_accuracy: 0.4207 - 296ms/epoch - 23ms/step\n",
            "Epoch 125/300\n",
            "13/13 - 0s - loss: 1.5501 - accuracy: 0.4606 - val_loss: 1.7638 - val_accuracy: 0.4105 - 289ms/epoch - 22ms/step\n",
            "Epoch 126/300\n",
            "13/13 - 0s - loss: 1.4811 - accuracy: 0.4651 - val_loss: 1.8488 - val_accuracy: 0.4090 - 290ms/epoch - 22ms/step\n",
            "Epoch 127/300\n",
            "13/13 - 0s - loss: 1.4988 - accuracy: 0.4648 - val_loss: 1.8239 - val_accuracy: 0.3741 - 290ms/epoch - 22ms/step\n",
            "Epoch 128/300\n",
            "13/13 - 0s - loss: 1.4855 - accuracy: 0.4698 - val_loss: 1.8173 - val_accuracy: 0.3712 - 295ms/epoch - 23ms/step\n",
            "Epoch 129/300\n",
            "13/13 - 0s - loss: 1.4546 - accuracy: 0.4769 - val_loss: 1.6901 - val_accuracy: 0.4236 - 290ms/epoch - 22ms/step\n",
            "Epoch 130/300\n",
            "13/13 - 0s - loss: 1.5891 - accuracy: 0.4811 - val_loss: 1.7402 - val_accuracy: 0.3988 - 293ms/epoch - 23ms/step\n",
            "Epoch 131/300\n",
            "13/13 - 0s - loss: 1.4774 - accuracy: 0.4751 - val_loss: 1.6731 - val_accuracy: 0.3552 - 291ms/epoch - 22ms/step\n",
            "Epoch 132/300\n",
            "13/13 - 0s - loss: 1.4558 - accuracy: 0.4787 - val_loss: 1.6967 - val_accuracy: 0.4410 - 295ms/epoch - 23ms/step\n",
            "Epoch 133/300\n",
            "13/13 - 0s - loss: 1.4536 - accuracy: 0.4776 - val_loss: 1.7207 - val_accuracy: 0.4207 - 293ms/epoch - 23ms/step\n",
            "Epoch 134/300\n",
            "13/13 - 0s - loss: 1.4886 - accuracy: 0.4614 - val_loss: 1.7847 - val_accuracy: 0.4163 - 292ms/epoch - 22ms/step\n",
            "Epoch 135/300\n",
            "13/13 - 0s - loss: 1.5106 - accuracy: 0.4667 - val_loss: 1.8208 - val_accuracy: 0.3843 - 290ms/epoch - 22ms/step\n",
            "Epoch 136/300\n",
            "13/13 - 0s - loss: 1.4622 - accuracy: 0.4871 - val_loss: 1.8239 - val_accuracy: 0.3872 - 295ms/epoch - 23ms/step\n",
            "Epoch 137/300\n",
            "13/13 - 0s - loss: 1.4001 - accuracy: 0.4884 - val_loss: 1.7152 - val_accuracy: 0.4090 - 289ms/epoch - 22ms/step\n",
            "Epoch 138/300\n",
            "13/13 - 0s - loss: 1.4200 - accuracy: 0.4926 - val_loss: 1.7856 - val_accuracy: 0.3916 - 296ms/epoch - 23ms/step\n",
            "Epoch 139/300\n",
            "13/13 - 0s - loss: 1.5034 - accuracy: 0.4692 - val_loss: 1.7896 - val_accuracy: 0.3901 - 296ms/epoch - 23ms/step\n",
            "Epoch 140/300\n",
            "13/13 - 0s - loss: 1.4579 - accuracy: 0.4722 - val_loss: 1.7702 - val_accuracy: 0.4061 - 296ms/epoch - 23ms/step\n",
            "Epoch 141/300\n",
            "13/13 - 0s - loss: 1.4724 - accuracy: 0.4808 - val_loss: 1.6870 - val_accuracy: 0.4294 - 291ms/epoch - 22ms/step\n",
            "Epoch 142/300\n",
            "13/13 - 0s - loss: 1.4524 - accuracy: 0.4841 - val_loss: 1.6798 - val_accuracy: 0.4498 - 292ms/epoch - 22ms/step\n",
            "Epoch 143/300\n",
            "13/13 - 0s - loss: 1.5194 - accuracy: 0.4526 - val_loss: 1.7316 - val_accuracy: 0.4250 - 295ms/epoch - 23ms/step\n",
            "Epoch 144/300\n",
            "13/13 - 0s - loss: 1.6403 - accuracy: 0.4204 - val_loss: 1.7215 - val_accuracy: 0.3392 - 296ms/epoch - 23ms/step\n",
            "Epoch 145/300\n",
            "13/13 - 0s - loss: 1.6506 - accuracy: 0.4212 - val_loss: 1.8223 - val_accuracy: 0.3261 - 294ms/epoch - 23ms/step\n",
            "Epoch 146/300\n",
            "13/13 - 0s - loss: 1.5911 - accuracy: 0.4198 - val_loss: 1.8025 - val_accuracy: 0.3828 - 299ms/epoch - 23ms/step\n",
            "Epoch 147/300\n",
            "13/13 - 0s - loss: 1.5213 - accuracy: 0.4471 - val_loss: 1.8170 - val_accuracy: 0.3857 - 296ms/epoch - 23ms/step\n",
            "Epoch 148/300\n",
            "13/13 - 0s - loss: 1.6137 - accuracy: 0.4208 - val_loss: 1.6712 - val_accuracy: 0.4338 - 295ms/epoch - 23ms/step\n",
            "Epoch 149/300\n",
            "13/13 - 0s - loss: 1.5779 - accuracy: 0.4426 - val_loss: 1.6703 - val_accuracy: 0.4279 - 296ms/epoch - 23ms/step\n",
            "Epoch 150/300\n",
            "13/13 - 0s - loss: 1.6145 - accuracy: 0.4394 - val_loss: 1.6346 - val_accuracy: 0.4716 - 294ms/epoch - 23ms/step\n",
            "Epoch 151/300\n",
            "13/13 - 0s - loss: 1.5207 - accuracy: 0.4512 - val_loss: 1.7184 - val_accuracy: 0.4585 - 296ms/epoch - 23ms/step\n",
            "Epoch 152/300\n",
            "13/13 - 0s - loss: 1.5007 - accuracy: 0.4471 - val_loss: 1.6851 - val_accuracy: 0.3974 - 290ms/epoch - 22ms/step\n",
            "Epoch 153/300\n",
            "13/13 - 0s - loss: 1.5084 - accuracy: 0.4439 - val_loss: 1.7288 - val_accuracy: 0.4279 - 291ms/epoch - 22ms/step\n",
            "Epoch 154/300\n",
            "13/13 - 0s - loss: 1.4940 - accuracy: 0.4429 - val_loss: 1.6600 - val_accuracy: 0.3843 - 298ms/epoch - 23ms/step\n",
            "Epoch 155/300\n",
            "13/13 - 0s - loss: 1.5099 - accuracy: 0.4671 - val_loss: 1.6962 - val_accuracy: 0.4309 - 296ms/epoch - 23ms/step\n",
            "Epoch 156/300\n",
            "13/13 - 0s - loss: 1.4904 - accuracy: 0.4486 - val_loss: 1.6635 - val_accuracy: 0.3843 - 294ms/epoch - 23ms/step\n",
            "Epoch 157/300\n",
            "13/13 - 0s - loss: 1.4505 - accuracy: 0.4671 - val_loss: 1.7055 - val_accuracy: 0.4381 - 291ms/epoch - 22ms/step\n",
            "Epoch 158/300\n",
            "13/13 - 0s - loss: 1.4275 - accuracy: 0.4776 - val_loss: 1.6079 - val_accuracy: 0.4585 - 295ms/epoch - 23ms/step\n",
            "Epoch 159/300\n",
            "13/13 - 0s - loss: 1.4460 - accuracy: 0.4633 - val_loss: 1.6720 - val_accuracy: 0.3930 - 294ms/epoch - 23ms/step\n",
            "Epoch 160/300\n",
            "13/13 - 0s - loss: 1.4804 - accuracy: 0.4662 - val_loss: 1.6950 - val_accuracy: 0.4454 - 292ms/epoch - 22ms/step\n",
            "Epoch 161/300\n",
            "13/13 - 0s - loss: 1.4791 - accuracy: 0.4548 - val_loss: 1.6657 - val_accuracy: 0.4207 - 288ms/epoch - 22ms/step\n",
            "Epoch 162/300\n",
            "13/13 - 0s - loss: 1.4400 - accuracy: 0.4761 - val_loss: 1.6016 - val_accuracy: 0.4774 - 290ms/epoch - 22ms/step\n",
            "Epoch 163/300\n",
            "13/13 - 0s - loss: 1.4217 - accuracy: 0.4947 - val_loss: 1.5986 - val_accuracy: 0.4105 - 290ms/epoch - 22ms/step\n",
            "Epoch 164/300\n",
            "13/13 - 0s - loss: 1.5051 - accuracy: 0.4517 - val_loss: 1.6931 - val_accuracy: 0.3697 - 290ms/epoch - 22ms/step\n",
            "Epoch 165/300\n",
            "13/13 - 0s - loss: 1.5585 - accuracy: 0.4229 - val_loss: 1.7269 - val_accuracy: 0.4163 - 289ms/epoch - 22ms/step\n",
            "Epoch 166/300\n",
            "13/13 - 0s - loss: 1.5486 - accuracy: 0.4277 - val_loss: 1.9563 - val_accuracy: 0.3071 - 292ms/epoch - 22ms/step\n",
            "Epoch 167/300\n",
            "13/13 - 0s - loss: 1.5088 - accuracy: 0.4400 - val_loss: 1.8705 - val_accuracy: 0.3071 - 303ms/epoch - 23ms/step\n",
            "Epoch 168/300\n",
            "13/13 - 0s - loss: 1.5255 - accuracy: 0.4449 - val_loss: 1.8341 - val_accuracy: 0.3741 - 306ms/epoch - 24ms/step\n",
            "Epoch 169/300\n",
            "13/13 - 0s - loss: 1.5118 - accuracy: 0.4541 - val_loss: 1.8314 - val_accuracy: 0.3595 - 306ms/epoch - 24ms/step\n",
            "Epoch 170/300\n",
            "13/13 - 0s - loss: 1.5184 - accuracy: 0.4334 - val_loss: 1.7961 - val_accuracy: 0.3843 - 316ms/epoch - 24ms/step\n",
            "Epoch 171/300\n",
            "13/13 - 0s - loss: 1.4368 - accuracy: 0.4740 - val_loss: 1.8786 - val_accuracy: 0.4061 - 312ms/epoch - 24ms/step\n",
            "Epoch 172/300\n",
            "13/13 - 0s - loss: 1.4667 - accuracy: 0.4624 - val_loss: 1.7869 - val_accuracy: 0.3683 - 296ms/epoch - 23ms/step\n",
            "Epoch 173/300\n",
            "13/13 - 0s - loss: 1.4520 - accuracy: 0.4688 - val_loss: 1.6799 - val_accuracy: 0.4440 - 306ms/epoch - 24ms/step\n",
            "Epoch 174/300\n",
            "13/13 - 0s - loss: 1.4129 - accuracy: 0.4881 - val_loss: 1.6575 - val_accuracy: 0.4119 - 297ms/epoch - 23ms/step\n",
            "Epoch 175/300\n",
            "13/13 - 0s - loss: 1.3754 - accuracy: 0.4909 - val_loss: 1.6501 - val_accuracy: 0.4352 - 292ms/epoch - 22ms/step\n",
            "Epoch 176/300\n",
            "13/13 - 0s - loss: 1.3508 - accuracy: 0.5036 - val_loss: 1.6218 - val_accuracy: 0.4323 - 296ms/epoch - 23ms/step\n",
            "Epoch 177/300\n",
            "13/13 - 0s - loss: 1.4122 - accuracy: 0.4845 - val_loss: 1.6217 - val_accuracy: 0.4541 - 291ms/epoch - 22ms/step\n",
            "Epoch 178/300\n",
            "13/13 - 0s - loss: 1.5089 - accuracy: 0.4672 - val_loss: 1.7700 - val_accuracy: 0.4469 - 296ms/epoch - 23ms/step\n",
            "Epoch 179/300\n",
            "13/13 - 0s - loss: 1.5028 - accuracy: 0.4599 - val_loss: 1.7361 - val_accuracy: 0.4309 - 294ms/epoch - 23ms/step\n",
            "Epoch 180/300\n",
            "13/13 - 0s - loss: 1.5195 - accuracy: 0.4502 - val_loss: 1.6638 - val_accuracy: 0.4731 - 293ms/epoch - 23ms/step\n",
            "Epoch 181/300\n",
            "13/13 - 0s - loss: 1.5095 - accuracy: 0.4612 - val_loss: 1.6161 - val_accuracy: 0.4163 - 294ms/epoch - 23ms/step\n",
            "Epoch 182/300\n",
            "13/13 - 0s - loss: 1.4812 - accuracy: 0.4616 - val_loss: 1.6519 - val_accuracy: 0.4367 - 294ms/epoch - 23ms/step\n",
            "Epoch 183/300\n",
            "13/13 - 0s - loss: 1.3879 - accuracy: 0.4936 - val_loss: 1.6494 - val_accuracy: 0.4469 - 298ms/epoch - 23ms/step\n",
            "Epoch 184/300\n",
            "13/13 - 0s - loss: 1.3926 - accuracy: 0.4844 - val_loss: 1.6407 - val_accuracy: 0.3814 - 301ms/epoch - 23ms/step\n",
            "Epoch 185/300\n",
            "13/13 - 0s - loss: 1.3848 - accuracy: 0.5045 - val_loss: 1.9173 - val_accuracy: 0.4076 - 292ms/epoch - 22ms/step\n",
            "Epoch 186/300\n",
            "13/13 - 0s - loss: 1.4301 - accuracy: 0.4857 - val_loss: 1.7950 - val_accuracy: 0.3959 - 294ms/epoch - 23ms/step\n",
            "Epoch 187/300\n",
            "13/13 - 0s - loss: 1.4572 - accuracy: 0.4755 - val_loss: 1.8152 - val_accuracy: 0.4163 - 293ms/epoch - 23ms/step\n",
            "Epoch 188/300\n",
            "13/13 - 0s - loss: 1.4254 - accuracy: 0.4855 - val_loss: 1.7791 - val_accuracy: 0.3974 - 295ms/epoch - 23ms/step\n",
            "Epoch 189/300\n",
            "13/13 - 0s - loss: 1.4260 - accuracy: 0.4868 - val_loss: 1.7445 - val_accuracy: 0.4381 - 296ms/epoch - 23ms/step\n",
            "Epoch 190/300\n",
            "13/13 - 0s - loss: 1.3648 - accuracy: 0.5019 - val_loss: 1.6623 - val_accuracy: 0.4512 - 298ms/epoch - 23ms/step\n",
            "Epoch 191/300\n",
            "13/13 - 0s - loss: 1.3632 - accuracy: 0.5079 - val_loss: 1.7274 - val_accuracy: 0.4250 - 300ms/epoch - 23ms/step\n",
            "Epoch 192/300\n",
            "13/13 - 0s - loss: 1.3192 - accuracy: 0.5278 - val_loss: 1.7050 - val_accuracy: 0.4250 - 301ms/epoch - 23ms/step\n",
            "Epoch 193/300\n",
            "13/13 - 0s - loss: 1.3132 - accuracy: 0.5187 - val_loss: 1.6560 - val_accuracy: 0.4425 - 292ms/epoch - 22ms/step\n",
            "Epoch 194/300\n",
            "13/13 - 0s - loss: 1.3247 - accuracy: 0.5258 - val_loss: 1.6431 - val_accuracy: 0.4571 - 292ms/epoch - 22ms/step\n",
            "Epoch 195/300\n",
            "13/13 - 0s - loss: 1.2878 - accuracy: 0.5381 - val_loss: 1.7015 - val_accuracy: 0.4585 - 294ms/epoch - 23ms/step\n",
            "Epoch 196/300\n",
            "13/13 - 0s - loss: 1.3082 - accuracy: 0.5158 - val_loss: 1.7136 - val_accuracy: 0.4047 - 301ms/epoch - 23ms/step\n",
            "Epoch 197/300\n",
            "13/13 - 0s - loss: 1.3364 - accuracy: 0.5168 - val_loss: 1.5709 - val_accuracy: 0.4541 - 291ms/epoch - 22ms/step\n",
            "Epoch 198/300\n",
            "13/13 - 0s - loss: 1.2956 - accuracy: 0.5331 - val_loss: 1.5919 - val_accuracy: 0.4571 - 291ms/epoch - 22ms/step\n",
            "Epoch 199/300\n",
            "13/13 - 0s - loss: 1.3022 - accuracy: 0.5292 - val_loss: 1.5609 - val_accuracy: 0.4469 - 295ms/epoch - 23ms/step\n",
            "Epoch 200/300\n",
            "13/13 - 0s - loss: 1.3018 - accuracy: 0.5227 - val_loss: 1.5878 - val_accuracy: 0.4585 - 294ms/epoch - 23ms/step\n",
            "Epoch 201/300\n",
            "13/13 - 0s - loss: 1.3228 - accuracy: 0.5236 - val_loss: 1.5388 - val_accuracy: 0.4818 - 291ms/epoch - 22ms/step\n",
            "Epoch 202/300\n",
            "13/13 - 0s - loss: 1.2989 - accuracy: 0.5210 - val_loss: 1.5923 - val_accuracy: 0.4585 - 296ms/epoch - 23ms/step\n",
            "Epoch 203/300\n",
            "13/13 - 0s - loss: 1.2640 - accuracy: 0.5412 - val_loss: 1.5198 - val_accuracy: 0.4847 - 295ms/epoch - 23ms/step\n",
            "Epoch 204/300\n",
            "13/13 - 0s - loss: 1.3758 - accuracy: 0.5014 - val_loss: 1.6884 - val_accuracy: 0.4629 - 294ms/epoch - 23ms/step\n",
            "Epoch 205/300\n",
            "13/13 - 0s - loss: 1.3541 - accuracy: 0.4998 - val_loss: 1.5175 - val_accuracy: 0.4862 - 289ms/epoch - 22ms/step\n",
            "Epoch 206/300\n",
            "13/13 - 0s - loss: 1.3531 - accuracy: 0.5103 - val_loss: 1.5180 - val_accuracy: 0.4818 - 289ms/epoch - 22ms/step\n",
            "Epoch 207/300\n",
            "13/13 - 0s - loss: 1.4815 - accuracy: 0.4680 - val_loss: 1.6992 - val_accuracy: 0.3959 - 293ms/epoch - 23ms/step\n",
            "Epoch 208/300\n",
            "13/13 - 0s - loss: 1.6334 - accuracy: 0.4240 - val_loss: 1.7923 - val_accuracy: 0.3770 - 288ms/epoch - 22ms/step\n",
            "Epoch 209/300\n",
            "13/13 - 0s - loss: 1.5782 - accuracy: 0.4523 - val_loss: 1.7276 - val_accuracy: 0.4716 - 293ms/epoch - 23ms/step\n",
            "Epoch 210/300\n",
            "13/13 - 0s - loss: 1.5228 - accuracy: 0.4499 - val_loss: 1.6910 - val_accuracy: 0.4862 - 290ms/epoch - 22ms/step\n",
            "Epoch 211/300\n",
            "13/13 - 0s - loss: 1.5143 - accuracy: 0.4473 - val_loss: 1.6332 - val_accuracy: 0.4454 - 292ms/epoch - 22ms/step\n",
            "Epoch 212/300\n",
            "13/13 - 0s - loss: 1.5128 - accuracy: 0.4551 - val_loss: 1.7720 - val_accuracy: 0.4236 - 295ms/epoch - 23ms/step\n",
            "Epoch 213/300\n",
            "13/13 - 0s - loss: 1.7353 - accuracy: 0.3796 - val_loss: 1.8198 - val_accuracy: 0.4410 - 297ms/epoch - 23ms/step\n",
            "Epoch 214/300\n",
            "13/13 - 0s - loss: 1.5356 - accuracy: 0.4433 - val_loss: 1.8183 - val_accuracy: 0.3814 - 289ms/epoch - 22ms/step\n",
            "Epoch 215/300\n",
            "13/13 - 0s - loss: 1.4816 - accuracy: 0.4794 - val_loss: 2.1233 - val_accuracy: 0.4265 - 296ms/epoch - 23ms/step\n",
            "Epoch 216/300\n",
            "13/13 - 0s - loss: 1.4553 - accuracy: 0.4918 - val_loss: 1.6956 - val_accuracy: 0.4352 - 299ms/epoch - 23ms/step\n",
            "Epoch 217/300\n",
            "13/13 - 0s - loss: 1.4155 - accuracy: 0.5022 - val_loss: 2.0149 - val_accuracy: 0.3581 - 303ms/epoch - 23ms/step\n",
            "Epoch 218/300\n",
            "13/13 - 0s - loss: 1.4570 - accuracy: 0.4917 - val_loss: 1.6534 - val_accuracy: 0.4047 - 296ms/epoch - 23ms/step\n",
            "Epoch 219/300\n",
            "13/13 - 0s - loss: 1.3710 - accuracy: 0.5104 - val_loss: 1.6030 - val_accuracy: 0.4352 - 295ms/epoch - 23ms/step\n",
            "Epoch 220/300\n",
            "13/13 - 0s - loss: 1.3599 - accuracy: 0.5075 - val_loss: 1.6820 - val_accuracy: 0.4716 - 290ms/epoch - 22ms/step\n",
            "Epoch 221/300\n",
            "13/13 - 0s - loss: 1.4003 - accuracy: 0.5019 - val_loss: 1.6782 - val_accuracy: 0.4338 - 293ms/epoch - 23ms/step\n",
            "Epoch 222/300\n",
            "13/13 - 0s - loss: 1.4950 - accuracy: 0.4925 - val_loss: 1.6200 - val_accuracy: 0.4207 - 295ms/epoch - 23ms/step\n",
            "Epoch 223/300\n",
            "13/13 - 0s - loss: 1.5297 - accuracy: 0.4925 - val_loss: 1.8632 - val_accuracy: 0.3828 - 295ms/epoch - 23ms/step\n",
            "Epoch 224/300\n",
            "13/13 - 0s - loss: 1.4344 - accuracy: 0.4889 - val_loss: 1.6628 - val_accuracy: 0.4032 - 287ms/epoch - 22ms/step\n",
            "Epoch 225/300\n",
            "13/13 - 0s - loss: 1.3919 - accuracy: 0.4967 - val_loss: 1.7028 - val_accuracy: 0.4017 - 289ms/epoch - 22ms/step\n",
            "Epoch 226/300\n",
            "13/13 - 0s - loss: 1.3939 - accuracy: 0.4938 - val_loss: 1.7537 - val_accuracy: 0.4134 - 298ms/epoch - 23ms/step\n",
            "Epoch 227/300\n",
            "13/13 - 0s - loss: 1.4461 - accuracy: 0.4946 - val_loss: 1.8504 - val_accuracy: 0.3392 - 294ms/epoch - 23ms/step\n",
            "Epoch 228/300\n",
            "13/13 - 0s - loss: 1.4164 - accuracy: 0.4933 - val_loss: 1.7374 - val_accuracy: 0.3886 - 295ms/epoch - 23ms/step\n",
            "Epoch 229/300\n",
            "13/13 - 0s - loss: 1.3868 - accuracy: 0.4980 - val_loss: 1.6597 - val_accuracy: 0.4250 - 288ms/epoch - 22ms/step\n",
            "Epoch 230/300\n",
            "13/13 - 0s - loss: 1.3565 - accuracy: 0.5028 - val_loss: 1.6220 - val_accuracy: 0.4367 - 291ms/epoch - 22ms/step\n",
            "Epoch 231/300\n",
            "13/13 - 0s - loss: 1.3973 - accuracy: 0.4954 - val_loss: 1.7240 - val_accuracy: 0.4250 - 290ms/epoch - 22ms/step\n",
            "Epoch 232/300\n",
            "13/13 - 0s - loss: 1.4206 - accuracy: 0.4910 - val_loss: 1.7185 - val_accuracy: 0.4381 - 294ms/epoch - 23ms/step\n",
            "Epoch 233/300\n",
            "13/13 - 0s - loss: 1.3622 - accuracy: 0.5067 - val_loss: 1.7366 - val_accuracy: 0.3886 - 290ms/epoch - 22ms/step\n",
            "Epoch 234/300\n",
            "13/13 - 0s - loss: 1.3997 - accuracy: 0.4955 - val_loss: 1.7898 - val_accuracy: 0.3581 - 293ms/epoch - 23ms/step\n",
            "Epoch 235/300\n",
            "13/13 - 0s - loss: 1.3571 - accuracy: 0.5049 - val_loss: 1.6995 - val_accuracy: 0.3872 - 291ms/epoch - 22ms/step\n",
            "Epoch 236/300\n",
            "13/13 - 0s - loss: 1.3156 - accuracy: 0.5106 - val_loss: 1.7959 - val_accuracy: 0.4148 - 293ms/epoch - 23ms/step\n",
            "Epoch 237/300\n",
            "13/13 - 0s - loss: 1.3732 - accuracy: 0.4972 - val_loss: 1.9056 - val_accuracy: 0.4338 - 291ms/epoch - 22ms/step\n",
            "Epoch 238/300\n",
            "13/13 - 0s - loss: 1.4051 - accuracy: 0.4875 - val_loss: 1.7221 - val_accuracy: 0.4309 - 292ms/epoch - 22ms/step\n",
            "Epoch 239/300\n",
            "13/13 - 0s - loss: 1.4571 - accuracy: 0.4862 - val_loss: 1.8846 - val_accuracy: 0.3508 - 291ms/epoch - 22ms/step\n",
            "Epoch 240/300\n",
            "13/13 - 0s - loss: 1.5925 - accuracy: 0.4104 - val_loss: 1.7423 - val_accuracy: 0.3814 - 291ms/epoch - 22ms/step\n",
            "Epoch 241/300\n",
            "13/13 - 0s - loss: 1.5047 - accuracy: 0.4520 - val_loss: 1.8785 - val_accuracy: 0.3508 - 290ms/epoch - 22ms/step\n",
            "Epoch 242/300\n",
            "13/13 - 0s - loss: 1.4210 - accuracy: 0.4787 - val_loss: 2.0357 - val_accuracy: 0.3159 - 292ms/epoch - 22ms/step\n",
            "Epoch 243/300\n",
            "13/13 - 0s - loss: 1.4217 - accuracy: 0.4866 - val_loss: 1.8913 - val_accuracy: 0.3872 - 292ms/epoch - 22ms/step\n",
            "Epoch 244/300\n",
            "13/13 - 0s - loss: 1.4212 - accuracy: 0.4839 - val_loss: 1.8214 - val_accuracy: 0.3130 - 290ms/epoch - 22ms/step\n",
            "Epoch 245/300\n",
            "13/13 - 0s - loss: 1.4544 - accuracy: 0.4653 - val_loss: 1.8185 - val_accuracy: 0.4119 - 293ms/epoch - 23ms/step\n",
            "Epoch 246/300\n",
            "13/13 - 0s - loss: 1.4242 - accuracy: 0.4805 - val_loss: 1.7274 - val_accuracy: 0.4469 - 297ms/epoch - 23ms/step\n",
            "Epoch 247/300\n",
            "13/13 - 0s - loss: 1.4601 - accuracy: 0.4664 - val_loss: 1.7238 - val_accuracy: 0.4498 - 293ms/epoch - 23ms/step\n",
            "Epoch 248/300\n",
            "13/13 - 0s - loss: 1.4522 - accuracy: 0.4667 - val_loss: 1.9073 - val_accuracy: 0.3493 - 292ms/epoch - 22ms/step\n",
            "Epoch 249/300\n",
            "13/13 - 0s - loss: 1.4200 - accuracy: 0.4771 - val_loss: 1.7789 - val_accuracy: 0.4032 - 292ms/epoch - 22ms/step\n",
            "Epoch 250/300\n",
            "13/13 - 0s - loss: 1.4449 - accuracy: 0.4807 - val_loss: 1.6834 - val_accuracy: 0.3959 - 293ms/epoch - 23ms/step\n",
            "Epoch 251/300\n",
            "13/13 - 0s - loss: 1.4444 - accuracy: 0.4777 - val_loss: 1.6926 - val_accuracy: 0.4381 - 297ms/epoch - 23ms/step\n",
            "Epoch 252/300\n",
            "13/13 - 0s - loss: 1.3789 - accuracy: 0.4862 - val_loss: 1.6918 - val_accuracy: 0.4571 - 296ms/epoch - 23ms/step\n",
            "Epoch 253/300\n",
            "13/13 - 0s - loss: 1.3364 - accuracy: 0.5119 - val_loss: 1.6574 - val_accuracy: 0.4527 - 291ms/epoch - 22ms/step\n",
            "Epoch 254/300\n",
            "13/13 - 0s - loss: 1.3469 - accuracy: 0.5043 - val_loss: 1.7051 - val_accuracy: 0.4643 - 294ms/epoch - 23ms/step\n",
            "Epoch 255/300\n",
            "13/13 - 0s - loss: 1.3232 - accuracy: 0.5121 - val_loss: 1.6560 - val_accuracy: 0.4702 - 298ms/epoch - 23ms/step\n",
            "Epoch 256/300\n",
            "13/13 - 0s - loss: 1.3020 - accuracy: 0.5210 - val_loss: 1.7579 - val_accuracy: 0.4556 - 291ms/epoch - 22ms/step\n",
            "Epoch 257/300\n",
            "13/13 - 0s - loss: 1.3140 - accuracy: 0.5258 - val_loss: 1.7475 - val_accuracy: 0.4163 - 293ms/epoch - 23ms/step\n",
            "Epoch 258/300\n",
            "13/13 - 0s - loss: 1.3372 - accuracy: 0.5279 - val_loss: 1.6416 - val_accuracy: 0.4207 - 297ms/epoch - 23ms/step\n",
            "Epoch 259/300\n",
            "13/13 - 0s - loss: 1.2912 - accuracy: 0.5260 - val_loss: 1.5837 - val_accuracy: 0.4745 - 293ms/epoch - 23ms/step\n",
            "Epoch 260/300\n",
            "13/13 - 0s - loss: 1.2682 - accuracy: 0.5350 - val_loss: 1.6431 - val_accuracy: 0.4876 - 290ms/epoch - 22ms/step\n",
            "Epoch 261/300\n",
            "13/13 - 0s - loss: 1.3222 - accuracy: 0.5077 - val_loss: 1.7058 - val_accuracy: 0.4003 - 289ms/epoch - 22ms/step\n",
            "Epoch 262/300\n",
            "13/13 - 0s - loss: 1.3811 - accuracy: 0.4964 - val_loss: 1.7305 - val_accuracy: 0.3988 - 293ms/epoch - 23ms/step\n",
            "Epoch 263/300\n",
            "13/13 - 0s - loss: 1.3326 - accuracy: 0.5229 - val_loss: 1.5879 - val_accuracy: 0.4512 - 295ms/epoch - 23ms/step\n",
            "Epoch 264/300\n",
            "13/13 - 0s - loss: 1.4653 - accuracy: 0.5088 - val_loss: 1.7586 - val_accuracy: 0.4163 - 292ms/epoch - 22ms/step\n",
            "Epoch 265/300\n",
            "13/13 - 0s - loss: 1.3192 - accuracy: 0.5079 - val_loss: 1.7928 - val_accuracy: 0.4309 - 288ms/epoch - 22ms/step\n",
            "Epoch 266/300\n",
            "13/13 - 0s - loss: 1.2950 - accuracy: 0.5342 - val_loss: 1.8059 - val_accuracy: 0.4396 - 291ms/epoch - 22ms/step\n",
            "Epoch 267/300\n",
            "13/13 - 0s - loss: 1.3466 - accuracy: 0.5215 - val_loss: 1.6768 - val_accuracy: 0.4629 - 303ms/epoch - 23ms/step\n",
            "Epoch 268/300\n",
            "13/13 - 0s - loss: 1.3534 - accuracy: 0.5083 - val_loss: 1.8174 - val_accuracy: 0.4367 - 292ms/epoch - 22ms/step\n",
            "Epoch 269/300\n",
            "13/13 - 0s - loss: 1.3900 - accuracy: 0.5119 - val_loss: 1.7808 - val_accuracy: 0.3231 - 290ms/epoch - 22ms/step\n",
            "Epoch 270/300\n",
            "13/13 - 0s - loss: 1.3445 - accuracy: 0.5124 - val_loss: 1.6910 - val_accuracy: 0.3799 - 294ms/epoch - 23ms/step\n",
            "Epoch 271/300\n",
            "13/13 - 0s - loss: 1.3681 - accuracy: 0.5271 - val_loss: 1.6983 - val_accuracy: 0.4440 - 298ms/epoch - 23ms/step\n",
            "Epoch 272/300\n",
            "13/13 - 0s - loss: 1.3079 - accuracy: 0.5168 - val_loss: 1.6652 - val_accuracy: 0.4090 - 299ms/epoch - 23ms/step\n",
            "Epoch 273/300\n",
            "13/13 - 0s - loss: 1.4410 - accuracy: 0.4792 - val_loss: 1.8775 - val_accuracy: 0.3508 - 291ms/epoch - 22ms/step\n",
            "Epoch 274/300\n",
            "13/13 - 0s - loss: 1.4033 - accuracy: 0.4912 - val_loss: 1.7351 - val_accuracy: 0.4105 - 291ms/epoch - 22ms/step\n",
            "Epoch 275/300\n",
            "13/13 - 0s - loss: 1.4011 - accuracy: 0.4965 - val_loss: 1.6651 - val_accuracy: 0.3916 - 294ms/epoch - 23ms/step\n",
            "Epoch 276/300\n",
            "13/13 - 0s - loss: 1.5181 - accuracy: 0.4713 - val_loss: 1.8068 - val_accuracy: 0.3159 - 304ms/epoch - 23ms/step\n",
            "Epoch 277/300\n",
            "13/13 - 0s - loss: 1.5795 - accuracy: 0.4687 - val_loss: 1.8725 - val_accuracy: 0.4527 - 300ms/epoch - 23ms/step\n",
            "Epoch 278/300\n",
            "13/13 - 0s - loss: 1.5753 - accuracy: 0.4530 - val_loss: 1.6906 - val_accuracy: 0.4731 - 295ms/epoch - 23ms/step\n",
            "Epoch 279/300\n",
            "13/13 - 0s - loss: 1.4851 - accuracy: 0.4700 - val_loss: 1.7510 - val_accuracy: 0.4119 - 297ms/epoch - 23ms/step\n",
            "Epoch 280/300\n",
            "13/13 - 0s - loss: 1.4662 - accuracy: 0.4721 - val_loss: 1.6650 - val_accuracy: 0.4614 - 299ms/epoch - 23ms/step\n",
            "Epoch 281/300\n",
            "13/13 - 0s - loss: 1.4401 - accuracy: 0.4973 - val_loss: 1.7734 - val_accuracy: 0.4221 - 297ms/epoch - 23ms/step\n",
            "Epoch 282/300\n",
            "13/13 - 0s - loss: 1.3657 - accuracy: 0.5030 - val_loss: 1.6561 - val_accuracy: 0.4614 - 292ms/epoch - 22ms/step\n",
            "Epoch 283/300\n",
            "13/13 - 0s - loss: 1.3896 - accuracy: 0.4962 - val_loss: 1.7327 - val_accuracy: 0.4541 - 289ms/epoch - 22ms/step\n",
            "Epoch 284/300\n",
            "13/13 - 0s - loss: 1.3609 - accuracy: 0.5059 - val_loss: 1.7332 - val_accuracy: 0.4614 - 295ms/epoch - 23ms/step\n",
            "Epoch 285/300\n",
            "13/13 - 0s - loss: 1.3981 - accuracy: 0.5025 - val_loss: 1.7436 - val_accuracy: 0.4163 - 295ms/epoch - 23ms/step\n",
            "Epoch 286/300\n",
            "13/13 - 0s - loss: 1.4897 - accuracy: 0.4645 - val_loss: 1.8455 - val_accuracy: 0.4090 - 288ms/epoch - 22ms/step\n",
            "Epoch 287/300\n",
            "13/13 - 0s - loss: 1.5674 - accuracy: 0.4282 - val_loss: 1.9242 - val_accuracy: 0.4381 - 293ms/epoch - 23ms/step\n",
            "Epoch 288/300\n",
            "13/13 - 0s - loss: 1.4957 - accuracy: 0.4609 - val_loss: 1.6817 - val_accuracy: 0.4556 - 288ms/epoch - 22ms/step\n",
            "Epoch 289/300\n",
            "13/13 - 0s - loss: 1.4497 - accuracy: 0.4729 - val_loss: 1.7273 - val_accuracy: 0.3974 - 295ms/epoch - 23ms/step\n",
            "Epoch 290/300\n",
            "13/13 - 0s - loss: 1.3882 - accuracy: 0.4866 - val_loss: 1.6424 - val_accuracy: 0.4309 - 291ms/epoch - 22ms/step\n",
            "Epoch 291/300\n",
            "13/13 - 0s - loss: 1.3715 - accuracy: 0.4959 - val_loss: 1.6669 - val_accuracy: 0.4047 - 291ms/epoch - 22ms/step\n",
            "Epoch 292/300\n",
            "13/13 - 0s - loss: 1.4228 - accuracy: 0.5014 - val_loss: 1.5916 - val_accuracy: 0.4440 - 292ms/epoch - 22ms/step\n",
            "Epoch 293/300\n",
            "13/13 - 0s - loss: 1.3709 - accuracy: 0.4943 - val_loss: 1.6733 - val_accuracy: 0.3974 - 293ms/epoch - 23ms/step\n",
            "Epoch 294/300\n",
            "13/13 - 0s - loss: 1.3627 - accuracy: 0.4913 - val_loss: 1.6905 - val_accuracy: 0.4221 - 292ms/epoch - 22ms/step\n",
            "Epoch 295/300\n",
            "13/13 - 0s - loss: 1.3613 - accuracy: 0.5059 - val_loss: 1.7087 - val_accuracy: 0.4760 - 290ms/epoch - 22ms/step\n",
            "Epoch 296/300\n",
            "13/13 - 0s - loss: 1.4817 - accuracy: 0.4567 - val_loss: 2.0368 - val_accuracy: 0.3857 - 297ms/epoch - 23ms/step\n",
            "Epoch 297/300\n",
            "13/13 - 0s - loss: 1.4185 - accuracy: 0.4999 - val_loss: 1.8070 - val_accuracy: 0.4469 - 297ms/epoch - 23ms/step\n",
            "Epoch 298/300\n",
            "13/13 - 0s - loss: 1.4218 - accuracy: 0.4896 - val_loss: 1.8745 - val_accuracy: 0.3130 - 294ms/epoch - 23ms/step\n",
            "Epoch 299/300\n",
            "13/13 - 0s - loss: 1.3908 - accuracy: 0.4975 - val_loss: 1.6676 - val_accuracy: 0.4163 - 295ms/epoch - 23ms/step\n",
            "Epoch 300/300\n",
            "13/13 - 0s - loss: 1.3666 - accuracy: 0.5054 - val_loss: 1.7580 - val_accuracy: 0.4119 - 292ms/epoch - 22ms/step\n",
            "Model: \"sequential_95\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_190 (Conv2D)         (None, 4, 36, 80)         27440     \n",
            "                                                                 \n",
            " max_pooling2d_190 (MaxPooli  (None, 1, 12, 80)        0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_95 (Bat  (None, 1, 12, 80)        320       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv2d_191 (Conv2D)         (None, 1, 10, 80)         19280     \n",
            "                                                                 \n",
            " max_pooling2d_191 (MaxPooli  (None, 1, 3, 80)         0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " flatten_95 (Flatten)        (None, 240)               0         \n",
            "                                                                 \n",
            " dense_285 (Dense)           (None, 5000)              1205000   \n",
            "                                                                 \n",
            " dropout_190 (Dropout)       (None, 5000)              0         \n",
            "                                                                 \n",
            " dense_286 (Dense)           (None, 5000)              25005000  \n",
            "                                                                 \n",
            " dropout_191 (Dropout)       (None, 5000)              0         \n",
            "                                                                 \n",
            " dense_287 (Dense)           (None, 10)                50010     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 26,307,050\n",
            "Trainable params: 26,306,890\n",
            "Non-trainable params: 160\n",
            "_________________________________________________________________\n",
            "None\n",
            "Result of fold:5\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 2.1783 - accuracy: 0.3292\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 50%|█████     | 5/10 [07:47<07:47, 93.55s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(6953, 60, 41)\n",
            "Epoch 1/300\n",
            "13/13 - 1s - loss: 5.1714 - accuracy: 0.1525 - val_loss: 2.2511 - val_accuracy: 0.1193 - 1s/epoch - 80ms/step\n",
            "Epoch 2/300\n",
            "13/13 - 0s - loss: 2.0887 - accuracy: 0.2228 - val_loss: 2.1518 - val_accuracy: 0.2055 - 294ms/epoch - 23ms/step\n",
            "Epoch 3/300\n",
            "13/13 - 0s - loss: 1.9649 - accuracy: 0.2679 - val_loss: 1.9972 - val_accuracy: 0.2500 - 298ms/epoch - 23ms/step\n",
            "Epoch 4/300\n",
            "13/13 - 0s - loss: 1.8773 - accuracy: 0.3129 - val_loss: 1.9518 - val_accuracy: 0.3175 - 291ms/epoch - 22ms/step\n",
            "Epoch 5/300\n",
            "13/13 - 0s - loss: 1.8711 - accuracy: 0.3177 - val_loss: 1.7893 - val_accuracy: 0.3549 - 294ms/epoch - 23ms/step\n",
            "Epoch 6/300\n",
            "13/13 - 0s - loss: 1.7347 - accuracy: 0.3692 - val_loss: 1.7849 - val_accuracy: 0.3736 - 293ms/epoch - 23ms/step\n",
            "Epoch 7/300\n",
            "13/13 - 0s - loss: 1.6949 - accuracy: 0.3861 - val_loss: 1.6873 - val_accuracy: 0.3908 - 297ms/epoch - 23ms/step\n",
            "Epoch 8/300\n",
            "13/13 - 0s - loss: 1.6408 - accuracy: 0.4069 - val_loss: 1.7853 - val_accuracy: 0.3017 - 295ms/epoch - 23ms/step\n",
            "Epoch 9/300\n",
            "13/13 - 0s - loss: 1.7192 - accuracy: 0.3749 - val_loss: 1.7102 - val_accuracy: 0.3333 - 296ms/epoch - 23ms/step\n",
            "Epoch 10/300\n",
            "13/13 - 0s - loss: 1.6264 - accuracy: 0.4136 - val_loss: 1.6447 - val_accuracy: 0.4181 - 291ms/epoch - 22ms/step\n",
            "Epoch 11/300\n",
            "13/13 - 0s - loss: 1.5756 - accuracy: 0.4333 - val_loss: 1.7204 - val_accuracy: 0.4368 - 298ms/epoch - 23ms/step\n",
            "Epoch 12/300\n",
            "13/13 - 0s - loss: 1.4896 - accuracy: 0.4691 - val_loss: 1.6915 - val_accuracy: 0.4641 - 298ms/epoch - 23ms/step\n",
            "Epoch 13/300\n",
            "13/13 - 0s - loss: 1.4656 - accuracy: 0.4763 - val_loss: 1.7669 - val_accuracy: 0.4267 - 303ms/epoch - 23ms/step\n",
            "Epoch 14/300\n",
            "13/13 - 0s - loss: 1.4284 - accuracy: 0.4940 - val_loss: 1.6014 - val_accuracy: 0.4842 - 297ms/epoch - 23ms/step\n",
            "Epoch 15/300\n",
            "13/13 - 0s - loss: 1.4431 - accuracy: 0.4751 - val_loss: 1.6471 - val_accuracy: 0.4497 - 297ms/epoch - 23ms/step\n",
            "Epoch 16/300\n",
            "13/13 - 0s - loss: 1.4741 - accuracy: 0.4739 - val_loss: 1.7917 - val_accuracy: 0.4195 - 296ms/epoch - 23ms/step\n",
            "Epoch 17/300\n",
            "13/13 - 0s - loss: 1.3643 - accuracy: 0.5170 - val_loss: 1.6225 - val_accuracy: 0.4598 - 289ms/epoch - 22ms/step\n",
            "Epoch 18/300\n",
            "13/13 - 0s - loss: 1.4507 - accuracy: 0.4907 - val_loss: 1.6368 - val_accuracy: 0.4167 - 294ms/epoch - 23ms/step\n",
            "Epoch 19/300\n",
            "13/13 - 0s - loss: 1.4187 - accuracy: 0.4950 - val_loss: 1.6528 - val_accuracy: 0.4612 - 299ms/epoch - 23ms/step\n",
            "Epoch 20/300\n",
            "13/13 - 0s - loss: 1.4025 - accuracy: 0.5140 - val_loss: 1.6383 - val_accuracy: 0.4080 - 298ms/epoch - 23ms/step\n",
            "Epoch 21/300\n",
            "13/13 - 0s - loss: 1.3615 - accuracy: 0.5218 - val_loss: 1.6180 - val_accuracy: 0.4899 - 300ms/epoch - 23ms/step\n",
            "Epoch 22/300\n",
            "13/13 - 0s - loss: 1.2890 - accuracy: 0.5418 - val_loss: 1.5704 - val_accuracy: 0.4971 - 298ms/epoch - 23ms/step\n",
            "Epoch 23/300\n",
            "13/13 - 0s - loss: 1.3013 - accuracy: 0.5426 - val_loss: 1.5780 - val_accuracy: 0.5201 - 296ms/epoch - 23ms/step\n",
            "Epoch 24/300\n",
            "13/13 - 0s - loss: 1.2954 - accuracy: 0.5386 - val_loss: 1.8216 - val_accuracy: 0.4741 - 298ms/epoch - 23ms/step\n",
            "Epoch 25/300\n",
            "13/13 - 0s - loss: 1.2698 - accuracy: 0.5463 - val_loss: 1.6317 - val_accuracy: 0.4943 - 307ms/epoch - 24ms/step\n",
            "Epoch 26/300\n",
            "13/13 - 0s - loss: 1.2442 - accuracy: 0.5627 - val_loss: 1.7219 - val_accuracy: 0.4986 - 304ms/epoch - 23ms/step\n",
            "Epoch 27/300\n",
            "13/13 - 0s - loss: 1.2256 - accuracy: 0.5686 - val_loss: 1.6234 - val_accuracy: 0.5273 - 298ms/epoch - 23ms/step\n",
            "Epoch 28/300\n",
            "13/13 - 0s - loss: 1.2177 - accuracy: 0.5747 - val_loss: 1.5239 - val_accuracy: 0.5359 - 306ms/epoch - 24ms/step\n",
            "Epoch 29/300\n",
            "13/13 - 0s - loss: 1.2192 - accuracy: 0.5736 - val_loss: 1.6565 - val_accuracy: 0.5057 - 308ms/epoch - 24ms/step\n",
            "Epoch 30/300\n",
            "13/13 - 0s - loss: 1.2102 - accuracy: 0.5841 - val_loss: 1.5545 - val_accuracy: 0.5216 - 304ms/epoch - 23ms/step\n",
            "Epoch 31/300\n",
            "13/13 - 0s - loss: 1.2526 - accuracy: 0.5718 - val_loss: 1.7238 - val_accuracy: 0.4296 - 301ms/epoch - 23ms/step\n",
            "Epoch 32/300\n",
            "13/13 - 0s - loss: 1.2712 - accuracy: 0.5608 - val_loss: 1.6549 - val_accuracy: 0.5158 - 304ms/epoch - 23ms/step\n",
            "Epoch 33/300\n",
            "13/13 - 0s - loss: 1.2001 - accuracy: 0.5825 - val_loss: 1.5714 - val_accuracy: 0.4871 - 305ms/epoch - 23ms/step\n",
            "Epoch 34/300\n",
            "13/13 - 0s - loss: 1.1688 - accuracy: 0.5897 - val_loss: 1.6166 - val_accuracy: 0.4727 - 299ms/epoch - 23ms/step\n",
            "Epoch 35/300\n",
            "13/13 - 0s - loss: 1.1735 - accuracy: 0.5923 - val_loss: 1.5307 - val_accuracy: 0.5402 - 294ms/epoch - 23ms/step\n",
            "Epoch 36/300\n",
            "13/13 - 0s - loss: 1.1517 - accuracy: 0.5923 - val_loss: 1.6411 - val_accuracy: 0.5388 - 298ms/epoch - 23ms/step\n",
            "Epoch 37/300\n",
            "13/13 - 0s - loss: 1.1512 - accuracy: 0.6024 - val_loss: 1.6922 - val_accuracy: 0.4986 - 299ms/epoch - 23ms/step\n",
            "Epoch 38/300\n",
            "13/13 - 0s - loss: 1.1272 - accuracy: 0.6043 - val_loss: 1.5609 - val_accuracy: 0.5230 - 301ms/epoch - 23ms/step\n",
            "Epoch 39/300\n",
            "13/13 - 0s - loss: 1.0581 - accuracy: 0.6246 - val_loss: 1.6594 - val_accuracy: 0.5029 - 296ms/epoch - 23ms/step\n",
            "Epoch 40/300\n",
            "13/13 - 0s - loss: 1.0617 - accuracy: 0.6263 - val_loss: 1.8006 - val_accuracy: 0.5503 - 292ms/epoch - 22ms/step\n",
            "Epoch 41/300\n",
            "13/13 - 0s - loss: 1.0895 - accuracy: 0.6220 - val_loss: 1.6781 - val_accuracy: 0.5417 - 294ms/epoch - 23ms/step\n",
            "Epoch 42/300\n",
            "13/13 - 0s - loss: 1.1509 - accuracy: 0.6019 - val_loss: 1.7051 - val_accuracy: 0.5316 - 294ms/epoch - 23ms/step\n",
            "Epoch 43/300\n",
            "13/13 - 0s - loss: 1.1388 - accuracy: 0.5998 - val_loss: 1.6968 - val_accuracy: 0.5144 - 295ms/epoch - 23ms/step\n",
            "Epoch 44/300\n",
            "13/13 - 0s - loss: 1.1636 - accuracy: 0.5843 - val_loss: 1.7477 - val_accuracy: 0.5244 - 291ms/epoch - 22ms/step\n",
            "Epoch 45/300\n",
            "13/13 - 0s - loss: 1.1068 - accuracy: 0.6131 - val_loss: 1.7562 - val_accuracy: 0.5259 - 298ms/epoch - 23ms/step\n",
            "Epoch 46/300\n",
            "13/13 - 0s - loss: 1.1119 - accuracy: 0.6164 - val_loss: 1.7959 - val_accuracy: 0.5043 - 291ms/epoch - 22ms/step\n",
            "Epoch 47/300\n",
            "13/13 - 0s - loss: 1.1807 - accuracy: 0.5981 - val_loss: 1.6453 - val_accuracy: 0.4799 - 295ms/epoch - 23ms/step\n",
            "Epoch 48/300\n",
            "13/13 - 0s - loss: 1.1143 - accuracy: 0.6188 - val_loss: 1.5858 - val_accuracy: 0.5072 - 296ms/epoch - 23ms/step\n",
            "Epoch 49/300\n",
            "13/13 - 0s - loss: 1.0772 - accuracy: 0.6235 - val_loss: 1.6624 - val_accuracy: 0.4928 - 294ms/epoch - 23ms/step\n",
            "Epoch 50/300\n",
            "13/13 - 0s - loss: 1.0829 - accuracy: 0.6246 - val_loss: 1.6803 - val_accuracy: 0.5101 - 296ms/epoch - 23ms/step\n",
            "Epoch 51/300\n",
            "13/13 - 0s - loss: 1.0489 - accuracy: 0.6393 - val_loss: 1.7327 - val_accuracy: 0.5489 - 296ms/epoch - 23ms/step\n",
            "Epoch 52/300\n",
            "13/13 - 0s - loss: 1.0854 - accuracy: 0.6326 - val_loss: 1.6488 - val_accuracy: 0.4727 - 299ms/epoch - 23ms/step\n",
            "Epoch 53/300\n",
            "13/13 - 0s - loss: 1.1029 - accuracy: 0.6249 - val_loss: 1.6656 - val_accuracy: 0.5072 - 298ms/epoch - 23ms/step\n",
            "Epoch 54/300\n",
            "13/13 - 0s - loss: 1.0649 - accuracy: 0.6243 - val_loss: 1.9124 - val_accuracy: 0.5029 - 295ms/epoch - 23ms/step\n",
            "Epoch 55/300\n",
            "13/13 - 0s - loss: 1.0615 - accuracy: 0.6431 - val_loss: 1.7300 - val_accuracy: 0.5359 - 293ms/epoch - 23ms/step\n",
            "Epoch 56/300\n",
            "13/13 - 0s - loss: 1.1009 - accuracy: 0.6246 - val_loss: 1.7290 - val_accuracy: 0.4727 - 301ms/epoch - 23ms/step\n",
            "Epoch 57/300\n",
            "13/13 - 0s - loss: 1.0140 - accuracy: 0.6412 - val_loss: 1.6036 - val_accuracy: 0.5517 - 298ms/epoch - 23ms/step\n",
            "Epoch 58/300\n",
            "13/13 - 0s - loss: 1.0050 - accuracy: 0.6474 - val_loss: 1.7338 - val_accuracy: 0.4598 - 300ms/epoch - 23ms/step\n",
            "Epoch 59/300\n",
            "13/13 - 0s - loss: 1.0405 - accuracy: 0.6479 - val_loss: 1.8173 - val_accuracy: 0.5273 - 300ms/epoch - 23ms/step\n",
            "Epoch 60/300\n",
            "13/13 - 0s - loss: 1.0301 - accuracy: 0.6465 - val_loss: 1.7877 - val_accuracy: 0.5330 - 294ms/epoch - 23ms/step\n",
            "Epoch 61/300\n",
            "13/13 - 0s - loss: 1.0973 - accuracy: 0.6460 - val_loss: 1.5483 - val_accuracy: 0.4871 - 297ms/epoch - 23ms/step\n",
            "Epoch 62/300\n",
            "13/13 - 0s - loss: 1.1511 - accuracy: 0.6076 - val_loss: 1.6262 - val_accuracy: 0.5000 - 296ms/epoch - 23ms/step\n",
            "Epoch 63/300\n",
            "13/13 - 0s - loss: 1.0859 - accuracy: 0.6375 - val_loss: 1.6943 - val_accuracy: 0.4626 - 292ms/epoch - 22ms/step\n",
            "Epoch 64/300\n",
            "13/13 - 0s - loss: 1.0298 - accuracy: 0.6460 - val_loss: 1.8569 - val_accuracy: 0.5014 - 292ms/epoch - 22ms/step\n",
            "Epoch 65/300\n",
            "13/13 - 0s - loss: 1.0901 - accuracy: 0.6533 - val_loss: 1.7158 - val_accuracy: 0.4813 - 290ms/epoch - 22ms/step\n",
            "Epoch 66/300\n",
            "13/13 - 0s - loss: 1.0399 - accuracy: 0.6471 - val_loss: 1.6540 - val_accuracy: 0.5230 - 296ms/epoch - 23ms/step\n",
            "Epoch 67/300\n",
            "13/13 - 0s - loss: 0.9682 - accuracy: 0.6610 - val_loss: 1.6817 - val_accuracy: 0.5230 - 291ms/epoch - 22ms/step\n",
            "Epoch 68/300\n",
            "13/13 - 0s - loss: 1.0371 - accuracy: 0.6474 - val_loss: 1.7835 - val_accuracy: 0.4511 - 299ms/epoch - 23ms/step\n",
            "Epoch 69/300\n",
            "13/13 - 0s - loss: 1.0549 - accuracy: 0.6418 - val_loss: 1.9754 - val_accuracy: 0.5000 - 296ms/epoch - 23ms/step\n",
            "Epoch 70/300\n",
            "13/13 - 0s - loss: 0.9602 - accuracy: 0.6719 - val_loss: 1.9667 - val_accuracy: 0.5474 - 299ms/epoch - 23ms/step\n",
            "Epoch 71/300\n",
            "13/13 - 0s - loss: 0.9801 - accuracy: 0.6556 - val_loss: 1.9275 - val_accuracy: 0.5043 - 300ms/epoch - 23ms/step\n",
            "Epoch 72/300\n",
            "13/13 - 0s - loss: 1.0583 - accuracy: 0.6391 - val_loss: 1.9330 - val_accuracy: 0.4583 - 292ms/epoch - 22ms/step\n",
            "Epoch 73/300\n",
            "13/13 - 0s - loss: 1.0189 - accuracy: 0.6529 - val_loss: 2.1639 - val_accuracy: 0.5216 - 300ms/epoch - 23ms/step\n",
            "Epoch 74/300\n",
            "13/13 - 0s - loss: 0.9535 - accuracy: 0.6727 - val_loss: 1.8806 - val_accuracy: 0.5216 - 291ms/epoch - 22ms/step\n",
            "Epoch 75/300\n",
            "13/13 - 0s - loss: 0.9503 - accuracy: 0.6783 - val_loss: 1.9033 - val_accuracy: 0.5359 - 295ms/epoch - 23ms/step\n",
            "Epoch 76/300\n",
            "13/13 - 0s - loss: 1.0129 - accuracy: 0.6671 - val_loss: 1.8214 - val_accuracy: 0.4784 - 293ms/epoch - 23ms/step\n",
            "Epoch 77/300\n",
            "13/13 - 0s - loss: 0.9524 - accuracy: 0.6818 - val_loss: 1.8949 - val_accuracy: 0.5115 - 294ms/epoch - 23ms/step\n",
            "Epoch 78/300\n",
            "13/13 - 0s - loss: 0.9889 - accuracy: 0.6712 - val_loss: 1.8221 - val_accuracy: 0.5632 - 293ms/epoch - 23ms/step\n",
            "Epoch 79/300\n",
            "13/13 - 0s - loss: 0.9651 - accuracy: 0.6812 - val_loss: 1.9834 - val_accuracy: 0.5172 - 299ms/epoch - 23ms/step\n",
            "Epoch 80/300\n",
            "13/13 - 0s - loss: 0.9965 - accuracy: 0.6602 - val_loss: 1.9575 - val_accuracy: 0.4770 - 298ms/epoch - 23ms/step\n",
            "Epoch 81/300\n",
            "13/13 - 0s - loss: 0.9609 - accuracy: 0.6695 - val_loss: 1.9257 - val_accuracy: 0.5431 - 295ms/epoch - 23ms/step\n",
            "Epoch 82/300\n",
            "13/13 - 0s - loss: 0.9440 - accuracy: 0.6698 - val_loss: 1.9058 - val_accuracy: 0.5187 - 294ms/epoch - 23ms/step\n",
            "Epoch 83/300\n",
            "13/13 - 0s - loss: 0.9912 - accuracy: 0.6613 - val_loss: 1.7181 - val_accuracy: 0.4698 - 295ms/epoch - 23ms/step\n",
            "Epoch 84/300\n",
            "13/13 - 0s - loss: 0.9543 - accuracy: 0.6642 - val_loss: 1.9085 - val_accuracy: 0.5302 - 301ms/epoch - 23ms/step\n",
            "Epoch 85/300\n",
            "13/13 - 0s - loss: 0.9167 - accuracy: 0.6823 - val_loss: 1.7545 - val_accuracy: 0.4885 - 296ms/epoch - 23ms/step\n",
            "Epoch 86/300\n",
            "13/13 - 0s - loss: 0.8813 - accuracy: 0.6912 - val_loss: 1.8177 - val_accuracy: 0.5029 - 295ms/epoch - 23ms/step\n",
            "Epoch 87/300\n",
            "13/13 - 0s - loss: 0.9016 - accuracy: 0.6799 - val_loss: 2.0473 - val_accuracy: 0.4670 - 293ms/epoch - 23ms/step\n",
            "Epoch 88/300\n",
            "13/13 - 0s - loss: 1.0573 - accuracy: 0.6492 - val_loss: 1.7393 - val_accuracy: 0.4583 - 298ms/epoch - 23ms/step\n",
            "Epoch 89/300\n",
            "13/13 - 0s - loss: 1.0138 - accuracy: 0.6626 - val_loss: 1.7969 - val_accuracy: 0.5259 - 294ms/epoch - 23ms/step\n",
            "Epoch 90/300\n",
            "13/13 - 0s - loss: 1.0300 - accuracy: 0.6645 - val_loss: 1.9705 - val_accuracy: 0.4799 - 297ms/epoch - 23ms/step\n",
            "Epoch 91/300\n",
            "13/13 - 0s - loss: 0.9656 - accuracy: 0.6744 - val_loss: 1.5793 - val_accuracy: 0.5172 - 295ms/epoch - 23ms/step\n",
            "Epoch 92/300\n",
            "13/13 - 0s - loss: 0.9981 - accuracy: 0.6642 - val_loss: 1.8109 - val_accuracy: 0.4957 - 295ms/epoch - 23ms/step\n",
            "Epoch 93/300\n",
            "13/13 - 0s - loss: 0.9712 - accuracy: 0.6805 - val_loss: 1.7842 - val_accuracy: 0.5460 - 297ms/epoch - 23ms/step\n",
            "Epoch 94/300\n",
            "13/13 - 0s - loss: 0.9818 - accuracy: 0.6776 - val_loss: 1.6913 - val_accuracy: 0.5072 - 296ms/epoch - 23ms/step\n",
            "Epoch 95/300\n",
            "13/13 - 0s - loss: 1.0635 - accuracy: 0.6487 - val_loss: 1.8143 - val_accuracy: 0.4756 - 301ms/epoch - 23ms/step\n",
            "Epoch 96/300\n",
            "13/13 - 0s - loss: 0.9732 - accuracy: 0.6679 - val_loss: 1.8972 - val_accuracy: 0.4899 - 301ms/epoch - 23ms/step\n",
            "Epoch 97/300\n",
            "13/13 - 0s - loss: 1.0309 - accuracy: 0.6634 - val_loss: 1.8885 - val_accuracy: 0.5014 - 299ms/epoch - 23ms/step\n",
            "Epoch 98/300\n",
            "13/13 - 0s - loss: 1.0126 - accuracy: 0.6698 - val_loss: 2.0173 - val_accuracy: 0.4943 - 292ms/epoch - 22ms/step\n",
            "Epoch 99/300\n",
            "13/13 - 0s - loss: 1.0411 - accuracy: 0.6510 - val_loss: 2.0295 - val_accuracy: 0.4655 - 299ms/epoch - 23ms/step\n",
            "Epoch 100/300\n",
            "13/13 - 0s - loss: 0.9754 - accuracy: 0.6663 - val_loss: 1.9053 - val_accuracy: 0.5043 - 298ms/epoch - 23ms/step\n",
            "Epoch 101/300\n",
            "13/13 - 0s - loss: 0.9520 - accuracy: 0.6698 - val_loss: 1.7342 - val_accuracy: 0.5201 - 295ms/epoch - 23ms/step\n",
            "Epoch 102/300\n",
            "13/13 - 0s - loss: 0.9365 - accuracy: 0.6912 - val_loss: 1.8132 - val_accuracy: 0.4871 - 290ms/epoch - 22ms/step\n",
            "Epoch 103/300\n",
            "13/13 - 0s - loss: 1.0788 - accuracy: 0.6577 - val_loss: 1.8269 - val_accuracy: 0.5316 - 299ms/epoch - 23ms/step\n",
            "Epoch 104/300\n",
            "13/13 - 0s - loss: 1.1671 - accuracy: 0.6337 - val_loss: 1.9034 - val_accuracy: 0.4856 - 295ms/epoch - 23ms/step\n",
            "Epoch 105/300\n",
            "13/13 - 0s - loss: 1.0781 - accuracy: 0.6335 - val_loss: 1.8238 - val_accuracy: 0.5129 - 293ms/epoch - 23ms/step\n",
            "Epoch 106/300\n",
            "13/13 - 0s - loss: 1.0884 - accuracy: 0.6455 - val_loss: 1.9219 - val_accuracy: 0.4914 - 293ms/epoch - 23ms/step\n",
            "Epoch 107/300\n",
            "13/13 - 0s - loss: 0.9839 - accuracy: 0.6578 - val_loss: 1.7990 - val_accuracy: 0.5115 - 297ms/epoch - 23ms/step\n",
            "Epoch 108/300\n",
            "13/13 - 0s - loss: 0.9981 - accuracy: 0.6602 - val_loss: 1.9251 - val_accuracy: 0.4440 - 292ms/epoch - 22ms/step\n",
            "Epoch 109/300\n",
            "13/13 - 0s - loss: 0.9400 - accuracy: 0.6845 - val_loss: 1.7593 - val_accuracy: 0.5330 - 295ms/epoch - 23ms/step\n",
            "Epoch 110/300\n",
            "13/13 - 0s - loss: 0.9623 - accuracy: 0.6639 - val_loss: 1.7830 - val_accuracy: 0.4957 - 296ms/epoch - 23ms/step\n",
            "Epoch 111/300\n",
            "13/13 - 0s - loss: 0.9998 - accuracy: 0.6581 - val_loss: 1.7704 - val_accuracy: 0.4856 - 289ms/epoch - 22ms/step\n",
            "Epoch 112/300\n",
            "13/13 - 0s - loss: 0.9217 - accuracy: 0.6847 - val_loss: 1.7295 - val_accuracy: 0.5330 - 291ms/epoch - 22ms/step\n",
            "Epoch 113/300\n",
            "13/13 - 0s - loss: 0.8976 - accuracy: 0.6898 - val_loss: 1.7955 - val_accuracy: 0.5216 - 295ms/epoch - 23ms/step\n",
            "Epoch 114/300\n",
            "13/13 - 0s - loss: 0.8925 - accuracy: 0.6866 - val_loss: 2.0168 - val_accuracy: 0.4741 - 303ms/epoch - 23ms/step\n",
            "Epoch 115/300\n",
            "13/13 - 0s - loss: 0.9222 - accuracy: 0.6767 - val_loss: 1.9427 - val_accuracy: 0.5287 - 296ms/epoch - 23ms/step\n",
            "Epoch 116/300\n",
            "13/13 - 0s - loss: 0.9309 - accuracy: 0.6805 - val_loss: 2.1021 - val_accuracy: 0.4784 - 299ms/epoch - 23ms/step\n",
            "Epoch 117/300\n",
            "13/13 - 0s - loss: 0.9280 - accuracy: 0.6733 - val_loss: 2.0382 - val_accuracy: 0.5172 - 298ms/epoch - 23ms/step\n",
            "Epoch 118/300\n",
            "13/13 - 0s - loss: 0.9165 - accuracy: 0.6776 - val_loss: 1.8135 - val_accuracy: 0.5029 - 297ms/epoch - 23ms/step\n",
            "Epoch 119/300\n",
            "13/13 - 0s - loss: 0.9362 - accuracy: 0.6682 - val_loss: 1.8168 - val_accuracy: 0.5115 - 294ms/epoch - 23ms/step\n",
            "Epoch 120/300\n",
            "13/13 - 0s - loss: 0.9595 - accuracy: 0.6637 - val_loss: 2.0955 - val_accuracy: 0.5388 - 301ms/epoch - 23ms/step\n",
            "Epoch 121/300\n",
            "13/13 - 0s - loss: 0.9278 - accuracy: 0.6740 - val_loss: 1.7774 - val_accuracy: 0.4885 - 299ms/epoch - 23ms/step\n",
            "Epoch 122/300\n",
            "13/13 - 0s - loss: 0.8919 - accuracy: 0.6895 - val_loss: 1.7049 - val_accuracy: 0.5129 - 298ms/epoch - 23ms/step\n",
            "Epoch 123/300\n",
            "13/13 - 0s - loss: 0.8717 - accuracy: 0.6909 - val_loss: 1.8242 - val_accuracy: 0.5158 - 299ms/epoch - 23ms/step\n",
            "Epoch 124/300\n",
            "13/13 - 0s - loss: 0.8903 - accuracy: 0.6896 - val_loss: 1.8473 - val_accuracy: 0.5517 - 293ms/epoch - 23ms/step\n",
            "Epoch 125/300\n",
            "13/13 - 0s - loss: 0.9375 - accuracy: 0.6877 - val_loss: 1.9844 - val_accuracy: 0.4655 - 295ms/epoch - 23ms/step\n",
            "Epoch 126/300\n",
            "13/13 - 0s - loss: 1.2841 - accuracy: 0.6525 - val_loss: 1.7872 - val_accuracy: 0.5172 - 297ms/epoch - 23ms/step\n",
            "Epoch 127/300\n",
            "13/13 - 0s - loss: 1.0994 - accuracy: 0.6300 - val_loss: 1.7587 - val_accuracy: 0.4641 - 298ms/epoch - 23ms/step\n",
            "Epoch 128/300\n",
            "13/13 - 0s - loss: 1.0698 - accuracy: 0.6589 - val_loss: 1.8024 - val_accuracy: 0.5144 - 295ms/epoch - 23ms/step\n",
            "Epoch 129/300\n",
            "13/13 - 0s - loss: 0.9893 - accuracy: 0.6564 - val_loss: 1.8419 - val_accuracy: 0.5187 - 294ms/epoch - 23ms/step\n",
            "Epoch 130/300\n",
            "13/13 - 0s - loss: 0.9574 - accuracy: 0.6693 - val_loss: 2.2431 - val_accuracy: 0.5316 - 299ms/epoch - 23ms/step\n",
            "Epoch 131/300\n",
            "13/13 - 0s - loss: 1.0480 - accuracy: 0.6484 - val_loss: 1.6660 - val_accuracy: 0.4986 - 298ms/epoch - 23ms/step\n",
            "Epoch 132/300\n",
            "13/13 - 0s - loss: 0.9610 - accuracy: 0.6738 - val_loss: 1.8936 - val_accuracy: 0.5029 - 293ms/epoch - 23ms/step\n",
            "Epoch 133/300\n",
            "13/13 - 0s - loss: 1.0008 - accuracy: 0.6575 - val_loss: 2.1522 - val_accuracy: 0.4799 - 291ms/epoch - 22ms/step\n",
            "Epoch 134/300\n",
            "13/13 - 0s - loss: 0.9506 - accuracy: 0.6820 - val_loss: 2.1471 - val_accuracy: 0.5402 - 294ms/epoch - 23ms/step\n",
            "Epoch 135/300\n",
            "13/13 - 0s - loss: 0.8827 - accuracy: 0.6904 - val_loss: 2.2235 - val_accuracy: 0.4828 - 298ms/epoch - 23ms/step\n",
            "Epoch 136/300\n",
            "13/13 - 0s - loss: 0.9398 - accuracy: 0.6697 - val_loss: 2.1560 - val_accuracy: 0.5359 - 296ms/epoch - 23ms/step\n",
            "Epoch 137/300\n",
            "13/13 - 0s - loss: 0.9697 - accuracy: 0.6605 - val_loss: 2.0089 - val_accuracy: 0.5546 - 293ms/epoch - 23ms/step\n",
            "Epoch 138/300\n",
            "13/13 - 0s - loss: 0.9163 - accuracy: 0.6860 - val_loss: 2.0842 - val_accuracy: 0.5560 - 294ms/epoch - 23ms/step\n",
            "Epoch 139/300\n",
            "13/13 - 0s - loss: 0.9079 - accuracy: 0.6922 - val_loss: 2.0831 - val_accuracy: 0.5632 - 296ms/epoch - 23ms/step\n",
            "Epoch 140/300\n",
            "13/13 - 0s - loss: 0.9026 - accuracy: 0.6860 - val_loss: 1.9789 - val_accuracy: 0.5144 - 299ms/epoch - 23ms/step\n",
            "Epoch 141/300\n",
            "13/13 - 0s - loss: 0.8998 - accuracy: 0.6829 - val_loss: 1.9909 - val_accuracy: 0.5043 - 301ms/epoch - 23ms/step\n",
            "Epoch 142/300\n",
            "13/13 - 0s - loss: 0.9315 - accuracy: 0.6629 - val_loss: 2.1628 - val_accuracy: 0.4914 - 296ms/epoch - 23ms/step\n",
            "Epoch 143/300\n",
            "13/13 - 0s - loss: 0.9131 - accuracy: 0.6703 - val_loss: 2.2576 - val_accuracy: 0.5216 - 297ms/epoch - 23ms/step\n",
            "Epoch 144/300\n",
            "13/13 - 0s - loss: 0.9326 - accuracy: 0.6864 - val_loss: 2.1633 - val_accuracy: 0.5445 - 299ms/epoch - 23ms/step\n",
            "Epoch 145/300\n",
            "13/13 - 0s - loss: 0.8978 - accuracy: 0.6907 - val_loss: 1.9910 - val_accuracy: 0.4943 - 296ms/epoch - 23ms/step\n",
            "Epoch 146/300\n",
            "13/13 - 0s - loss: 0.9361 - accuracy: 0.6845 - val_loss: 1.7809 - val_accuracy: 0.5374 - 297ms/epoch - 23ms/step\n",
            "Epoch 147/300\n",
            "13/13 - 0s - loss: 0.8735 - accuracy: 0.6903 - val_loss: 1.9937 - val_accuracy: 0.4856 - 307ms/epoch - 24ms/step\n",
            "Epoch 148/300\n",
            "13/13 - 0s - loss: 0.8703 - accuracy: 0.7000 - val_loss: 2.3265 - val_accuracy: 0.4713 - 297ms/epoch - 23ms/step\n",
            "Epoch 149/300\n",
            "13/13 - 0s - loss: 0.8826 - accuracy: 0.6852 - val_loss: 1.9265 - val_accuracy: 0.4957 - 294ms/epoch - 23ms/step\n",
            "Epoch 150/300\n",
            "13/13 - 0s - loss: 0.8355 - accuracy: 0.6992 - val_loss: 2.2254 - val_accuracy: 0.5201 - 297ms/epoch - 23ms/step\n",
            "Epoch 151/300\n",
            "13/13 - 0s - loss: 0.8386 - accuracy: 0.6986 - val_loss: 2.4083 - val_accuracy: 0.5158 - 292ms/epoch - 22ms/step\n",
            "Epoch 152/300\n",
            "13/13 - 0s - loss: 0.8240 - accuracy: 0.7146 - val_loss: 2.2421 - val_accuracy: 0.5273 - 295ms/epoch - 23ms/step\n",
            "Epoch 153/300\n",
            "13/13 - 0s - loss: 0.8466 - accuracy: 0.6994 - val_loss: 1.7643 - val_accuracy: 0.5402 - 296ms/epoch - 23ms/step\n",
            "Epoch 154/300\n",
            "13/13 - 0s - loss: 0.9410 - accuracy: 0.6760 - val_loss: 1.8565 - val_accuracy: 0.5043 - 291ms/epoch - 22ms/step\n",
            "Epoch 155/300\n",
            "13/13 - 0s - loss: 0.9545 - accuracy: 0.6629 - val_loss: 1.8802 - val_accuracy: 0.4770 - 295ms/epoch - 23ms/step\n",
            "Epoch 156/300\n",
            "13/13 - 0s - loss: 0.9738 - accuracy: 0.6626 - val_loss: 1.9350 - val_accuracy: 0.5129 - 294ms/epoch - 23ms/step\n",
            "Epoch 157/300\n",
            "13/13 - 0s - loss: 0.9315 - accuracy: 0.6893 - val_loss: 1.9204 - val_accuracy: 0.4899 - 297ms/epoch - 23ms/step\n",
            "Epoch 158/300\n",
            "13/13 - 0s - loss: 0.8516 - accuracy: 0.7029 - val_loss: 2.3024 - val_accuracy: 0.5187 - 301ms/epoch - 23ms/step\n",
            "Epoch 159/300\n",
            "13/13 - 0s - loss: 0.8897 - accuracy: 0.6914 - val_loss: 2.0941 - val_accuracy: 0.4741 - 304ms/epoch - 23ms/step\n",
            "Epoch 160/300\n",
            "13/13 - 0s - loss: 0.9123 - accuracy: 0.6826 - val_loss: 1.8331 - val_accuracy: 0.5445 - 299ms/epoch - 23ms/step\n",
            "Epoch 161/300\n",
            "13/13 - 0s - loss: 0.8575 - accuracy: 0.7019 - val_loss: 2.1633 - val_accuracy: 0.5474 - 297ms/epoch - 23ms/step\n",
            "Epoch 162/300\n",
            "13/13 - 0s - loss: 0.9283 - accuracy: 0.6965 - val_loss: 2.0404 - val_accuracy: 0.4914 - 294ms/epoch - 23ms/step\n",
            "Epoch 163/300\n",
            "13/13 - 0s - loss: 0.8912 - accuracy: 0.6845 - val_loss: 1.9855 - val_accuracy: 0.4756 - 295ms/epoch - 23ms/step\n",
            "Epoch 164/300\n",
            "13/13 - 0s - loss: 0.8467 - accuracy: 0.6928 - val_loss: 2.2244 - val_accuracy: 0.5201 - 301ms/epoch - 23ms/step\n",
            "Epoch 165/300\n",
            "13/13 - 0s - loss: 0.8154 - accuracy: 0.7058 - val_loss: 2.2160 - val_accuracy: 0.4971 - 295ms/epoch - 23ms/step\n",
            "Epoch 166/300\n",
            "13/13 - 0s - loss: 0.8738 - accuracy: 0.7112 - val_loss: 1.9274 - val_accuracy: 0.5029 - 290ms/epoch - 22ms/step\n",
            "Epoch 167/300\n",
            "13/13 - 0s - loss: 0.8346 - accuracy: 0.7078 - val_loss: 1.8311 - val_accuracy: 0.5661 - 295ms/epoch - 23ms/step\n",
            "Epoch 168/300\n",
            "13/13 - 0s - loss: 0.7868 - accuracy: 0.7162 - val_loss: 1.9654 - val_accuracy: 0.5259 - 297ms/epoch - 23ms/step\n",
            "Epoch 169/300\n",
            "13/13 - 0s - loss: 0.8239 - accuracy: 0.7099 - val_loss: 2.2898 - val_accuracy: 0.4727 - 297ms/epoch - 23ms/step\n",
            "Epoch 170/300\n",
            "13/13 - 0s - loss: 0.7936 - accuracy: 0.7219 - val_loss: 2.1277 - val_accuracy: 0.5445 - 295ms/epoch - 23ms/step\n",
            "Epoch 171/300\n",
            "13/13 - 0s - loss: 0.9349 - accuracy: 0.7166 - val_loss: 2.7258 - val_accuracy: 0.4957 - 298ms/epoch - 23ms/step\n",
            "Epoch 172/300\n",
            "13/13 - 0s - loss: 1.0022 - accuracy: 0.6875 - val_loss: 2.2708 - val_accuracy: 0.4741 - 293ms/epoch - 23ms/step\n",
            "Epoch 173/300\n",
            "13/13 - 0s - loss: 0.9452 - accuracy: 0.6733 - val_loss: 2.0891 - val_accuracy: 0.4756 - 294ms/epoch - 23ms/step\n",
            "Epoch 174/300\n",
            "13/13 - 0s - loss: 0.9914 - accuracy: 0.6728 - val_loss: 2.1028 - val_accuracy: 0.4483 - 296ms/epoch - 23ms/step\n",
            "Epoch 175/300\n",
            "13/13 - 0s - loss: 0.9488 - accuracy: 0.6736 - val_loss: 2.1196 - val_accuracy: 0.5172 - 292ms/epoch - 22ms/step\n",
            "Epoch 176/300\n",
            "13/13 - 0s - loss: 0.9999 - accuracy: 0.6893 - val_loss: 1.8106 - val_accuracy: 0.5101 - 292ms/epoch - 22ms/step\n",
            "Epoch 177/300\n",
            "13/13 - 0s - loss: 0.8991 - accuracy: 0.6874 - val_loss: 1.8987 - val_accuracy: 0.4856 - 298ms/epoch - 23ms/step\n",
            "Epoch 178/300\n",
            "13/13 - 0s - loss: 0.8917 - accuracy: 0.6943 - val_loss: 2.0080 - val_accuracy: 0.4971 - 291ms/epoch - 22ms/step\n",
            "Epoch 179/300\n",
            "13/13 - 0s - loss: 0.9101 - accuracy: 0.6880 - val_loss: 1.7691 - val_accuracy: 0.4741 - 293ms/epoch - 23ms/step\n",
            "Epoch 180/300\n",
            "13/13 - 0s - loss: 0.8554 - accuracy: 0.6939 - val_loss: 1.7129 - val_accuracy: 0.5115 - 297ms/epoch - 23ms/step\n",
            "Epoch 181/300\n",
            "13/13 - 0s - loss: 0.8261 - accuracy: 0.7138 - val_loss: 2.0509 - val_accuracy: 0.5000 - 297ms/epoch - 23ms/step\n",
            "Epoch 182/300\n",
            "13/13 - 0s - loss: 0.8844 - accuracy: 0.6991 - val_loss: 2.0712 - val_accuracy: 0.4928 - 301ms/epoch - 23ms/step\n",
            "Epoch 183/300\n",
            "13/13 - 0s - loss: 0.8642 - accuracy: 0.6971 - val_loss: 1.9390 - val_accuracy: 0.5201 - 297ms/epoch - 23ms/step\n",
            "Epoch 184/300\n",
            "13/13 - 0s - loss: 0.8629 - accuracy: 0.6991 - val_loss: 1.8352 - val_accuracy: 0.5359 - 295ms/epoch - 23ms/step\n",
            "Epoch 185/300\n",
            "13/13 - 0s - loss: 0.8093 - accuracy: 0.7170 - val_loss: 1.9518 - val_accuracy: 0.4943 - 295ms/epoch - 23ms/step\n",
            "Epoch 186/300\n",
            "13/13 - 0s - loss: 0.7944 - accuracy: 0.7174 - val_loss: 1.8819 - val_accuracy: 0.5460 - 297ms/epoch - 23ms/step\n",
            "Epoch 187/300\n",
            "13/13 - 0s - loss: 0.7829 - accuracy: 0.7293 - val_loss: 2.0019 - val_accuracy: 0.5431 - 297ms/epoch - 23ms/step\n",
            "Epoch 188/300\n",
            "13/13 - 0s - loss: 0.7970 - accuracy: 0.7226 - val_loss: 1.9863 - val_accuracy: 0.5029 - 298ms/epoch - 23ms/step\n",
            "Epoch 189/300\n",
            "13/13 - 0s - loss: 0.7695 - accuracy: 0.7318 - val_loss: 2.4096 - val_accuracy: 0.5043 - 299ms/epoch - 23ms/step\n",
            "Epoch 190/300\n",
            "13/13 - 0s - loss: 0.8136 - accuracy: 0.7259 - val_loss: 2.0559 - val_accuracy: 0.5172 - 300ms/epoch - 23ms/step\n",
            "Epoch 191/300\n",
            "13/13 - 0s - loss: 0.7516 - accuracy: 0.7309 - val_loss: 2.2496 - val_accuracy: 0.4928 - 295ms/epoch - 23ms/step\n",
            "Epoch 192/300\n",
            "13/13 - 0s - loss: 0.8608 - accuracy: 0.7131 - val_loss: 2.8659 - val_accuracy: 0.4885 - 297ms/epoch - 23ms/step\n",
            "Epoch 193/300\n",
            "13/13 - 0s - loss: 0.9244 - accuracy: 0.7142 - val_loss: 1.8559 - val_accuracy: 0.4914 - 298ms/epoch - 23ms/step\n",
            "Epoch 194/300\n",
            "13/13 - 0s - loss: 0.9045 - accuracy: 0.7106 - val_loss: 2.2298 - val_accuracy: 0.4641 - 300ms/epoch - 23ms/step\n",
            "Epoch 195/300\n",
            "13/13 - 0s - loss: 0.9383 - accuracy: 0.6907 - val_loss: 2.6152 - val_accuracy: 0.4741 - 306ms/epoch - 24ms/step\n",
            "Epoch 196/300\n",
            "13/13 - 0s - loss: 1.0304 - accuracy: 0.6821 - val_loss: 2.0760 - val_accuracy: 0.5187 - 297ms/epoch - 23ms/step\n",
            "Epoch 197/300\n",
            "13/13 - 0s - loss: 0.9350 - accuracy: 0.6880 - val_loss: 1.8064 - val_accuracy: 0.5273 - 295ms/epoch - 23ms/step\n",
            "Epoch 198/300\n",
            "13/13 - 0s - loss: 0.9503 - accuracy: 0.6907 - val_loss: 1.8111 - val_accuracy: 0.5402 - 297ms/epoch - 23ms/step\n",
            "Epoch 199/300\n",
            "13/13 - 0s - loss: 0.8928 - accuracy: 0.6856 - val_loss: 1.8501 - val_accuracy: 0.5216 - 291ms/epoch - 22ms/step\n",
            "Epoch 200/300\n",
            "13/13 - 0s - loss: 0.9850 - accuracy: 0.6994 - val_loss: 1.7606 - val_accuracy: 0.5201 - 294ms/epoch - 23ms/step\n",
            "Epoch 201/300\n",
            "13/13 - 0s - loss: 0.9006 - accuracy: 0.7048 - val_loss: 1.9670 - val_accuracy: 0.5359 - 297ms/epoch - 23ms/step\n",
            "Epoch 202/300\n",
            "13/13 - 0s - loss: 0.8356 - accuracy: 0.7181 - val_loss: 2.0421 - val_accuracy: 0.5000 - 299ms/epoch - 23ms/step\n",
            "Epoch 203/300\n",
            "13/13 - 0s - loss: 0.8367 - accuracy: 0.7149 - val_loss: 1.9901 - val_accuracy: 0.5101 - 295ms/epoch - 23ms/step\n",
            "Epoch 204/300\n",
            "13/13 - 0s - loss: 0.8534 - accuracy: 0.7005 - val_loss: 2.0394 - val_accuracy: 0.5431 - 295ms/epoch - 23ms/step\n",
            "Epoch 205/300\n",
            "13/13 - 0s - loss: 0.8423 - accuracy: 0.7045 - val_loss: 2.2249 - val_accuracy: 0.5431 - 295ms/epoch - 23ms/step\n",
            "Epoch 206/300\n",
            "13/13 - 0s - loss: 0.8059 - accuracy: 0.7293 - val_loss: 2.1143 - val_accuracy: 0.5216 - 293ms/epoch - 23ms/step\n",
            "Epoch 207/300\n",
            "13/13 - 0s - loss: 0.8191 - accuracy: 0.7154 - val_loss: 1.9601 - val_accuracy: 0.4986 - 293ms/epoch - 23ms/step\n",
            "Epoch 208/300\n",
            "13/13 - 0s - loss: 0.8984 - accuracy: 0.6983 - val_loss: 1.9849 - val_accuracy: 0.5158 - 293ms/epoch - 23ms/step\n",
            "Epoch 209/300\n",
            "13/13 - 0s - loss: 0.9854 - accuracy: 0.6823 - val_loss: 1.8690 - val_accuracy: 0.4828 - 294ms/epoch - 23ms/step\n",
            "Epoch 210/300\n",
            "13/13 - 0s - loss: 0.9503 - accuracy: 0.6708 - val_loss: 1.8789 - val_accuracy: 0.4842 - 295ms/epoch - 23ms/step\n",
            "Epoch 211/300\n",
            "13/13 - 0s - loss: 0.9001 - accuracy: 0.6915 - val_loss: 2.1286 - val_accuracy: 0.4713 - 291ms/epoch - 22ms/step\n",
            "Epoch 212/300\n",
            "13/13 - 0s - loss: 0.8434 - accuracy: 0.7146 - val_loss: 1.8135 - val_accuracy: 0.4914 - 293ms/epoch - 23ms/step\n",
            "Epoch 213/300\n",
            "13/13 - 0s - loss: 0.8556 - accuracy: 0.7002 - val_loss: 1.8885 - val_accuracy: 0.5014 - 303ms/epoch - 23ms/step\n",
            "Epoch 214/300\n",
            "13/13 - 0s - loss: 0.8225 - accuracy: 0.7094 - val_loss: 1.7712 - val_accuracy: 0.5287 - 302ms/epoch - 23ms/step\n",
            "Epoch 215/300\n",
            "13/13 - 0s - loss: 0.7903 - accuracy: 0.7186 - val_loss: 2.0345 - val_accuracy: 0.5287 - 292ms/epoch - 22ms/step\n",
            "Epoch 216/300\n",
            "13/13 - 0s - loss: 0.7839 - accuracy: 0.7198 - val_loss: 1.9792 - val_accuracy: 0.5216 - 296ms/epoch - 23ms/step\n",
            "Epoch 217/300\n",
            "13/13 - 0s - loss: 0.7912 - accuracy: 0.7205 - val_loss: 1.8982 - val_accuracy: 0.5417 - 298ms/epoch - 23ms/step\n",
            "Epoch 218/300\n",
            "13/13 - 0s - loss: 0.7718 - accuracy: 0.7245 - val_loss: 2.0466 - val_accuracy: 0.5115 - 304ms/epoch - 23ms/step\n",
            "Epoch 219/300\n",
            "13/13 - 0s - loss: 0.7845 - accuracy: 0.7179 - val_loss: 2.1032 - val_accuracy: 0.4784 - 302ms/epoch - 23ms/step\n",
            "Epoch 220/300\n",
            "13/13 - 0s - loss: 0.8261 - accuracy: 0.7149 - val_loss: 2.0184 - val_accuracy: 0.5101 - 295ms/epoch - 23ms/step\n",
            "Epoch 221/300\n",
            "13/13 - 0s - loss: 0.7898 - accuracy: 0.7195 - val_loss: 2.2301 - val_accuracy: 0.5302 - 302ms/epoch - 23ms/step\n",
            "Epoch 222/300\n",
            "13/13 - 0s - loss: 0.8076 - accuracy: 0.7077 - val_loss: 2.6221 - val_accuracy: 0.5086 - 298ms/epoch - 23ms/step\n",
            "Epoch 223/300\n",
            "13/13 - 0s - loss: 0.8134 - accuracy: 0.7184 - val_loss: 2.2156 - val_accuracy: 0.5388 - 297ms/epoch - 23ms/step\n",
            "Epoch 224/300\n",
            "13/13 - 0s - loss: 0.8540 - accuracy: 0.7243 - val_loss: 2.0811 - val_accuracy: 0.5029 - 300ms/epoch - 23ms/step\n",
            "Epoch 225/300\n",
            "13/13 - 0s - loss: 0.9479 - accuracy: 0.6981 - val_loss: 2.0098 - val_accuracy: 0.4871 - 297ms/epoch - 23ms/step\n",
            "Epoch 226/300\n",
            "13/13 - 0s - loss: 0.9143 - accuracy: 0.6837 - val_loss: 2.1820 - val_accuracy: 0.4483 - 297ms/epoch - 23ms/step\n",
            "Epoch 227/300\n",
            "13/13 - 0s - loss: 0.8656 - accuracy: 0.7067 - val_loss: 2.1666 - val_accuracy: 0.4713 - 295ms/epoch - 23ms/step\n",
            "Epoch 228/300\n",
            "13/13 - 0s - loss: 0.8164 - accuracy: 0.7211 - val_loss: 2.1607 - val_accuracy: 0.5101 - 298ms/epoch - 23ms/step\n",
            "Epoch 229/300\n",
            "13/13 - 0s - loss: 0.7935 - accuracy: 0.7213 - val_loss: 2.0010 - val_accuracy: 0.5187 - 299ms/epoch - 23ms/step\n",
            "Epoch 230/300\n",
            "13/13 - 0s - loss: 0.8056 - accuracy: 0.7160 - val_loss: 2.0931 - val_accuracy: 0.5144 - 295ms/epoch - 23ms/step\n",
            "Epoch 231/300\n",
            "13/13 - 0s - loss: 0.7880 - accuracy: 0.7262 - val_loss: 2.5416 - val_accuracy: 0.5230 - 300ms/epoch - 23ms/step\n",
            "Epoch 232/300\n",
            "13/13 - 0s - loss: 0.7582 - accuracy: 0.7358 - val_loss: 2.2401 - val_accuracy: 0.5417 - 300ms/epoch - 23ms/step\n",
            "Epoch 233/300\n",
            "13/13 - 0s - loss: 0.7298 - accuracy: 0.7406 - val_loss: 2.5417 - val_accuracy: 0.5359 - 291ms/epoch - 22ms/step\n",
            "Epoch 234/300\n",
            "13/13 - 0s - loss: 0.7625 - accuracy: 0.7291 - val_loss: 2.3100 - val_accuracy: 0.5431 - 300ms/epoch - 23ms/step\n",
            "Epoch 235/300\n",
            "13/13 - 0s - loss: 0.7297 - accuracy: 0.7412 - val_loss: 2.0709 - val_accuracy: 0.5259 - 297ms/epoch - 23ms/step\n",
            "Epoch 236/300\n",
            "13/13 - 0s - loss: 0.7326 - accuracy: 0.7507 - val_loss: 1.9525 - val_accuracy: 0.5302 - 295ms/epoch - 23ms/step\n",
            "Epoch 237/300\n",
            "13/13 - 0s - loss: 0.6901 - accuracy: 0.7524 - val_loss: 1.9422 - val_accuracy: 0.5532 - 292ms/epoch - 22ms/step\n",
            "Epoch 238/300\n",
            "13/13 - 0s - loss: 0.7355 - accuracy: 0.7492 - val_loss: 1.9158 - val_accuracy: 0.5316 - 293ms/epoch - 23ms/step\n",
            "Epoch 239/300\n",
            "13/13 - 0s - loss: 0.7843 - accuracy: 0.7302 - val_loss: 2.2274 - val_accuracy: 0.5014 - 296ms/epoch - 23ms/step\n",
            "Epoch 240/300\n",
            "13/13 - 0s - loss: 0.7894 - accuracy: 0.7238 - val_loss: 1.9568 - val_accuracy: 0.5014 - 293ms/epoch - 23ms/step\n",
            "Epoch 241/300\n",
            "13/13 - 0s - loss: 0.7749 - accuracy: 0.7355 - val_loss: 1.8076 - val_accuracy: 0.5503 - 292ms/epoch - 22ms/step\n",
            "Epoch 242/300\n",
            "13/13 - 0s - loss: 0.7744 - accuracy: 0.7337 - val_loss: 2.2761 - val_accuracy: 0.5129 - 298ms/epoch - 23ms/step\n",
            "Epoch 243/300\n",
            "13/13 - 0s - loss: 0.8742 - accuracy: 0.7281 - val_loss: 2.2295 - val_accuracy: 0.5259 - 294ms/epoch - 23ms/step\n",
            "Epoch 244/300\n",
            "13/13 - 0s - loss: 0.8163 - accuracy: 0.7253 - val_loss: 2.1834 - val_accuracy: 0.5201 - 291ms/epoch - 22ms/step\n",
            "Epoch 245/300\n",
            "13/13 - 0s - loss: 0.7534 - accuracy: 0.7457 - val_loss: 2.2721 - val_accuracy: 0.5345 - 289ms/epoch - 22ms/step\n",
            "Epoch 246/300\n",
            "13/13 - 0s - loss: 0.7888 - accuracy: 0.7353 - val_loss: 2.0639 - val_accuracy: 0.4871 - 295ms/epoch - 23ms/step\n",
            "Epoch 247/300\n",
            "13/13 - 0s - loss: 0.8622 - accuracy: 0.7144 - val_loss: 1.8028 - val_accuracy: 0.5316 - 292ms/epoch - 22ms/step\n",
            "Epoch 248/300\n",
            "13/13 - 0s - loss: 0.9313 - accuracy: 0.6794 - val_loss: 1.9759 - val_accuracy: 0.4871 - 292ms/epoch - 22ms/step\n",
            "Epoch 249/300\n",
            "13/13 - 0s - loss: 0.8388 - accuracy: 0.7070 - val_loss: 1.8052 - val_accuracy: 0.5115 - 295ms/epoch - 23ms/step\n",
            "Epoch 250/300\n",
            "13/13 - 0s - loss: 0.7824 - accuracy: 0.7256 - val_loss: 1.9134 - val_accuracy: 0.5431 - 302ms/epoch - 23ms/step\n",
            "Epoch 251/300\n",
            "13/13 - 0s - loss: 0.8391 - accuracy: 0.7114 - val_loss: 1.9260 - val_accuracy: 0.5187 - 293ms/epoch - 23ms/step\n",
            "Epoch 252/300\n",
            "13/13 - 0s - loss: 0.7918 - accuracy: 0.7214 - val_loss: 2.0616 - val_accuracy: 0.5158 - 293ms/epoch - 23ms/step\n",
            "Epoch 253/300\n",
            "13/13 - 0s - loss: 0.7633 - accuracy: 0.7377 - val_loss: 2.0013 - val_accuracy: 0.5101 - 295ms/epoch - 23ms/step\n",
            "Epoch 254/300\n",
            "13/13 - 0s - loss: 0.7676 - accuracy: 0.7401 - val_loss: 2.0622 - val_accuracy: 0.5359 - 299ms/epoch - 23ms/step\n",
            "Epoch 255/300\n",
            "13/13 - 0s - loss: 0.7236 - accuracy: 0.7452 - val_loss: 2.1977 - val_accuracy: 0.5000 - 301ms/epoch - 23ms/step\n",
            "Epoch 256/300\n",
            "13/13 - 0s - loss: 0.7398 - accuracy: 0.7438 - val_loss: 2.1265 - val_accuracy: 0.5273 - 294ms/epoch - 23ms/step\n",
            "Epoch 257/300\n",
            "13/13 - 0s - loss: 0.8068 - accuracy: 0.7286 - val_loss: 2.1812 - val_accuracy: 0.5043 - 294ms/epoch - 23ms/step\n",
            "Epoch 258/300\n",
            "13/13 - 0s - loss: 0.8121 - accuracy: 0.7358 - val_loss: 2.3651 - val_accuracy: 0.5187 - 294ms/epoch - 23ms/step\n",
            "Epoch 259/300\n",
            "13/13 - 0s - loss: 0.9059 - accuracy: 0.6965 - val_loss: 2.0809 - val_accuracy: 0.4828 - 299ms/epoch - 23ms/step\n",
            "Epoch 260/300\n",
            "13/13 - 0s - loss: 1.0512 - accuracy: 0.6791 - val_loss: 2.1574 - val_accuracy: 0.5316 - 294ms/epoch - 23ms/step\n",
            "Epoch 261/300\n",
            "13/13 - 0s - loss: 0.9577 - accuracy: 0.6907 - val_loss: 2.2131 - val_accuracy: 0.5014 - 293ms/epoch - 23ms/step\n",
            "Epoch 262/300\n",
            "13/13 - 0s - loss: 0.8544 - accuracy: 0.6987 - val_loss: 2.1865 - val_accuracy: 0.5144 - 296ms/epoch - 23ms/step\n",
            "Epoch 263/300\n",
            "13/13 - 0s - loss: 0.9067 - accuracy: 0.7005 - val_loss: 2.0900 - val_accuracy: 0.5000 - 294ms/epoch - 23ms/step\n",
            "Epoch 264/300\n",
            "13/13 - 0s - loss: 0.8473 - accuracy: 0.7122 - val_loss: 1.7409 - val_accuracy: 0.5158 - 290ms/epoch - 22ms/step\n",
            "Epoch 265/300\n",
            "13/13 - 0s - loss: 0.8128 - accuracy: 0.7267 - val_loss: 1.8049 - val_accuracy: 0.5560 - 294ms/epoch - 23ms/step\n",
            "Epoch 266/300\n",
            "13/13 - 0s - loss: 0.7521 - accuracy: 0.7414 - val_loss: 1.9721 - val_accuracy: 0.5402 - 295ms/epoch - 23ms/step\n",
            "Epoch 267/300\n",
            "13/13 - 0s - loss: 0.7288 - accuracy: 0.7449 - val_loss: 1.9913 - val_accuracy: 0.5503 - 299ms/epoch - 23ms/step\n",
            "Epoch 268/300\n",
            "13/13 - 0s - loss: 0.7557 - accuracy: 0.7406 - val_loss: 1.9627 - val_accuracy: 0.5417 - 295ms/epoch - 23ms/step\n",
            "Epoch 269/300\n",
            "13/13 - 0s - loss: 0.8057 - accuracy: 0.7203 - val_loss: 1.9189 - val_accuracy: 0.5101 - 298ms/epoch - 23ms/step\n",
            "Epoch 270/300\n",
            "13/13 - 0s - loss: 0.8430 - accuracy: 0.7281 - val_loss: 2.0144 - val_accuracy: 0.5187 - 294ms/epoch - 23ms/step\n",
            "Epoch 271/300\n",
            "13/13 - 0s - loss: 0.8666 - accuracy: 0.7072 - val_loss: 2.0196 - val_accuracy: 0.5273 - 290ms/epoch - 22ms/step\n",
            "Epoch 272/300\n",
            "13/13 - 0s - loss: 0.9264 - accuracy: 0.6925 - val_loss: 1.9352 - val_accuracy: 0.5086 - 295ms/epoch - 23ms/step\n",
            "Epoch 273/300\n",
            "13/13 - 0s - loss: 0.9119 - accuracy: 0.6941 - val_loss: 2.5324 - val_accuracy: 0.5158 - 298ms/epoch - 23ms/step\n",
            "Epoch 274/300\n",
            "13/13 - 0s - loss: 0.9613 - accuracy: 0.6933 - val_loss: 2.1097 - val_accuracy: 0.5187 - 296ms/epoch - 23ms/step\n",
            "Epoch 275/300\n",
            "13/13 - 0s - loss: 0.8784 - accuracy: 0.7010 - val_loss: 1.9204 - val_accuracy: 0.5374 - 290ms/epoch - 22ms/step\n",
            "Epoch 276/300\n",
            "13/13 - 0s - loss: 0.8008 - accuracy: 0.7257 - val_loss: 2.0390 - val_accuracy: 0.5000 - 292ms/epoch - 22ms/step\n",
            "Epoch 277/300\n",
            "13/13 - 0s - loss: 0.8003 - accuracy: 0.7214 - val_loss: 2.0635 - val_accuracy: 0.5417 - 303ms/epoch - 23ms/step\n",
            "Epoch 278/300\n",
            "13/13 - 0s - loss: 0.7420 - accuracy: 0.7376 - val_loss: 2.1259 - val_accuracy: 0.5201 - 291ms/epoch - 22ms/step\n",
            "Epoch 279/300\n",
            "13/13 - 0s - loss: 0.7542 - accuracy: 0.7331 - val_loss: 2.4172 - val_accuracy: 0.5345 - 296ms/epoch - 23ms/step\n",
            "Epoch 280/300\n",
            "13/13 - 0s - loss: 0.7761 - accuracy: 0.7427 - val_loss: 2.3406 - val_accuracy: 0.5330 - 302ms/epoch - 23ms/step\n",
            "Epoch 281/300\n",
            "13/13 - 0s - loss: 0.7907 - accuracy: 0.7305 - val_loss: 1.9991 - val_accuracy: 0.5345 - 296ms/epoch - 23ms/step\n",
            "Epoch 282/300\n",
            "13/13 - 0s - loss: 0.7279 - accuracy: 0.7545 - val_loss: 1.9819 - val_accuracy: 0.5316 - 294ms/epoch - 23ms/step\n",
            "Epoch 283/300\n",
            "13/13 - 0s - loss: 0.7420 - accuracy: 0.7454 - val_loss: 2.0206 - val_accuracy: 0.5244 - 293ms/epoch - 23ms/step\n",
            "Epoch 284/300\n",
            "13/13 - 0s - loss: 0.7212 - accuracy: 0.7425 - val_loss: 2.1169 - val_accuracy: 0.5402 - 301ms/epoch - 23ms/step\n",
            "Epoch 285/300\n",
            "13/13 - 0s - loss: 0.7188 - accuracy: 0.7430 - val_loss: 2.3073 - val_accuracy: 0.5172 - 297ms/epoch - 23ms/step\n",
            "Epoch 286/300\n",
            "13/13 - 0s - loss: 0.6902 - accuracy: 0.7569 - val_loss: 2.3764 - val_accuracy: 0.5532 - 293ms/epoch - 23ms/step\n",
            "Epoch 287/300\n",
            "13/13 - 0s - loss: 0.7078 - accuracy: 0.7478 - val_loss: 2.0622 - val_accuracy: 0.5618 - 299ms/epoch - 23ms/step\n",
            "Epoch 288/300\n",
            "13/13 - 0s - loss: 0.7291 - accuracy: 0.7475 - val_loss: 2.0404 - val_accuracy: 0.5043 - 295ms/epoch - 23ms/step\n",
            "Epoch 289/300\n",
            "13/13 - 0s - loss: 0.7048 - accuracy: 0.7451 - val_loss: 2.4185 - val_accuracy: 0.5144 - 290ms/epoch - 22ms/step\n",
            "Epoch 290/300\n",
            "13/13 - 0s - loss: 0.7335 - accuracy: 0.7393 - val_loss: 2.1482 - val_accuracy: 0.4957 - 293ms/epoch - 23ms/step\n",
            "Epoch 291/300\n",
            "13/13 - 0s - loss: 0.7855 - accuracy: 0.7221 - val_loss: 1.7918 - val_accuracy: 0.5072 - 290ms/epoch - 22ms/step\n",
            "Epoch 292/300\n",
            "13/13 - 0s - loss: 0.7973 - accuracy: 0.7373 - val_loss: 2.1235 - val_accuracy: 0.5402 - 296ms/epoch - 23ms/step\n",
            "Epoch 293/300\n",
            "13/13 - 0s - loss: 0.7612 - accuracy: 0.7403 - val_loss: 2.2425 - val_accuracy: 0.5532 - 293ms/epoch - 23ms/step\n",
            "Epoch 294/300\n",
            "13/13 - 0s - loss: 0.8331 - accuracy: 0.7480 - val_loss: 2.3424 - val_accuracy: 0.5086 - 296ms/epoch - 23ms/step\n",
            "Epoch 295/300\n",
            "13/13 - 0s - loss: 1.0249 - accuracy: 0.7294 - val_loss: 2.9820 - val_accuracy: 0.5374 - 290ms/epoch - 22ms/step\n",
            "Epoch 296/300\n",
            "13/13 - 0s - loss: 0.9037 - accuracy: 0.7200 - val_loss: 2.3246 - val_accuracy: 0.5316 - 298ms/epoch - 23ms/step\n",
            "Epoch 297/300\n",
            "13/13 - 0s - loss: 0.9173 - accuracy: 0.7110 - val_loss: 2.6620 - val_accuracy: 0.4957 - 297ms/epoch - 23ms/step\n",
            "Epoch 298/300\n",
            "13/13 - 0s - loss: 0.9145 - accuracy: 0.6989 - val_loss: 2.3315 - val_accuracy: 0.5043 - 295ms/epoch - 23ms/step\n",
            "Epoch 299/300\n",
            "13/13 - 0s - loss: 0.8887 - accuracy: 0.6957 - val_loss: 2.3427 - val_accuracy: 0.5158 - 295ms/epoch - 23ms/step\n",
            "Epoch 300/300\n",
            "13/13 - 0s - loss: 0.8792 - accuracy: 0.7112 - val_loss: 2.5621 - val_accuracy: 0.4986 - 295ms/epoch - 23ms/step\n",
            "Model: \"sequential_97\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_194 (Conv2D)         (None, 4, 36, 80)         27440     \n",
            "                                                                 \n",
            " max_pooling2d_194 (MaxPooli  (None, 1, 12, 80)        0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_97 (Bat  (None, 1, 12, 80)        320       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv2d_195 (Conv2D)         (None, 1, 10, 80)         19280     \n",
            "                                                                 \n",
            " max_pooling2d_195 (MaxPooli  (None, 1, 3, 80)         0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " flatten_97 (Flatten)        (None, 240)               0         \n",
            "                                                                 \n",
            " dense_291 (Dense)           (None, 5000)              1205000   \n",
            "                                                                 \n",
            " dropout_194 (Dropout)       (None, 5000)              0         \n",
            "                                                                 \n",
            " dense_292 (Dense)           (None, 5000)              25005000  \n",
            "                                                                 \n",
            " dropout_195 (Dropout)       (None, 5000)              0         \n",
            "                                                                 \n",
            " dense_293 (Dense)           (None, 10)                50010     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 26,307,050\n",
            "Trainable params: 26,306,890\n",
            "Non-trainable params: 160\n",
            "_________________________________________________________________\n",
            "None\n",
            "Result of fold:6\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 3.3623 - accuracy: 0.5229\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 60%|██████    | 6/10 [09:21<06:14, 93.66s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(6932, 60, 41)\n",
            "Epoch 1/300\n",
            "13/13 - 1s - loss: 5.3434 - accuracy: 0.1494 - val_loss: 2.2179 - val_accuracy: 0.1657 - 1s/epoch - 81ms/step\n",
            "Epoch 2/300\n",
            "13/13 - 0s - loss: 2.1240 - accuracy: 0.2143 - val_loss: 2.1395 - val_accuracy: 0.1902 - 298ms/epoch - 23ms/step\n",
            "Epoch 3/300\n",
            "13/13 - 0s - loss: 2.0676 - accuracy: 0.2499 - val_loss: 2.1405 - val_accuracy: 0.1816 - 296ms/epoch - 23ms/step\n",
            "Epoch 4/300\n",
            "13/13 - 0s - loss: 2.0046 - accuracy: 0.2712 - val_loss: 1.9697 - val_accuracy: 0.2104 - 292ms/epoch - 22ms/step\n",
            "Epoch 5/300\n",
            "13/13 - 0s - loss: 1.9272 - accuracy: 0.3014 - val_loss: 1.9241 - val_accuracy: 0.2017 - 291ms/epoch - 22ms/step\n",
            "Epoch 6/300\n",
            "13/13 - 0s - loss: 1.8574 - accuracy: 0.3182 - val_loss: 1.8354 - val_accuracy: 0.2925 - 295ms/epoch - 23ms/step\n",
            "Epoch 7/300\n",
            "13/13 - 0s - loss: 1.8462 - accuracy: 0.3288 - val_loss: 1.8242 - val_accuracy: 0.3343 - 298ms/epoch - 23ms/step\n",
            "Epoch 8/300\n",
            "13/13 - 0s - loss: 1.7142 - accuracy: 0.3663 - val_loss: 1.7904 - val_accuracy: 0.3285 - 298ms/epoch - 23ms/step\n",
            "Epoch 9/300\n",
            "13/13 - 0s - loss: 1.7020 - accuracy: 0.3836 - val_loss: 1.8778 - val_accuracy: 0.3055 - 298ms/epoch - 23ms/step\n",
            "Epoch 10/300\n",
            "13/13 - 0s - loss: 1.6581 - accuracy: 0.4006 - val_loss: 1.7201 - val_accuracy: 0.3329 - 295ms/epoch - 23ms/step\n",
            "Epoch 11/300\n",
            "13/13 - 0s - loss: 1.5784 - accuracy: 0.4176 - val_loss: 1.8258 - val_accuracy: 0.3314 - 304ms/epoch - 23ms/step\n",
            "Epoch 12/300\n",
            "13/13 - 0s - loss: 1.5627 - accuracy: 0.4234 - val_loss: 1.6371 - val_accuracy: 0.3588 - 295ms/epoch - 23ms/step\n",
            "Epoch 13/300\n",
            "13/13 - 0s - loss: 1.4659 - accuracy: 0.4723 - val_loss: 1.6665 - val_accuracy: 0.4092 - 294ms/epoch - 23ms/step\n",
            "Epoch 14/300\n",
            "13/13 - 0s - loss: 1.4404 - accuracy: 0.4788 - val_loss: 1.7663 - val_accuracy: 0.4020 - 298ms/epoch - 23ms/step\n",
            "Epoch 15/300\n",
            "13/13 - 0s - loss: 1.4973 - accuracy: 0.4599 - val_loss: 1.6504 - val_accuracy: 0.4380 - 294ms/epoch - 23ms/step\n",
            "Epoch 16/300\n",
            "13/13 - 0s - loss: 1.4205 - accuracy: 0.4845 - val_loss: 1.8196 - val_accuracy: 0.3890 - 291ms/epoch - 22ms/step\n",
            "Epoch 17/300\n",
            "13/13 - 0s - loss: 1.3912 - accuracy: 0.5010 - val_loss: 1.7216 - val_accuracy: 0.4078 - 293ms/epoch - 23ms/step\n",
            "Epoch 18/300\n",
            "13/13 - 0s - loss: 1.4197 - accuracy: 0.4870 - val_loss: 1.6936 - val_accuracy: 0.4597 - 296ms/epoch - 23ms/step\n",
            "Epoch 19/300\n",
            "13/13 - 0s - loss: 1.3879 - accuracy: 0.5058 - val_loss: 1.6258 - val_accuracy: 0.4452 - 291ms/epoch - 22ms/step\n",
            "Epoch 20/300\n",
            "13/13 - 0s - loss: 1.4028 - accuracy: 0.5040 - val_loss: 1.6442 - val_accuracy: 0.4207 - 292ms/epoch - 22ms/step\n",
            "Epoch 21/300\n",
            "13/13 - 0s - loss: 1.3477 - accuracy: 0.5180 - val_loss: 1.6433 - val_accuracy: 0.4020 - 297ms/epoch - 23ms/step\n",
            "Epoch 22/300\n",
            "13/13 - 0s - loss: 1.3303 - accuracy: 0.5265 - val_loss: 1.7039 - val_accuracy: 0.4467 - 297ms/epoch - 23ms/step\n",
            "Epoch 23/300\n",
            "13/13 - 0s - loss: 1.3339 - accuracy: 0.5245 - val_loss: 1.7099 - val_accuracy: 0.4092 - 292ms/epoch - 22ms/step\n",
            "Epoch 24/300\n",
            "13/13 - 0s - loss: 1.3084 - accuracy: 0.5366 - val_loss: 1.6378 - val_accuracy: 0.4294 - 298ms/epoch - 23ms/step\n",
            "Epoch 25/300\n",
            "13/13 - 0s - loss: 1.2737 - accuracy: 0.5450 - val_loss: 1.6638 - val_accuracy: 0.3963 - 292ms/epoch - 22ms/step\n",
            "Epoch 26/300\n",
            "13/13 - 0s - loss: 1.4214 - accuracy: 0.4997 - val_loss: 1.7408 - val_accuracy: 0.3963 - 296ms/epoch - 23ms/step\n",
            "Epoch 27/300\n",
            "13/13 - 0s - loss: 1.3593 - accuracy: 0.5019 - val_loss: 1.6192 - val_accuracy: 0.4553 - 295ms/epoch - 23ms/step\n",
            "Epoch 28/300\n",
            "13/13 - 0s - loss: 1.3897 - accuracy: 0.5136 - val_loss: 1.6947 - val_accuracy: 0.4539 - 301ms/epoch - 23ms/step\n",
            "Epoch 29/300\n",
            "13/13 - 0s - loss: 1.3175 - accuracy: 0.5279 - val_loss: 1.6598 - val_accuracy: 0.3991 - 300ms/epoch - 23ms/step\n",
            "Epoch 30/300\n",
            "13/13 - 0s - loss: 1.2466 - accuracy: 0.5596 - val_loss: 1.7045 - val_accuracy: 0.4164 - 300ms/epoch - 23ms/step\n",
            "Epoch 31/300\n",
            "13/13 - 0s - loss: 1.3069 - accuracy: 0.5409 - val_loss: 1.5927 - val_accuracy: 0.4467 - 293ms/epoch - 23ms/step\n",
            "Epoch 32/300\n",
            "13/13 - 0s - loss: 1.2748 - accuracy: 0.5494 - val_loss: 1.7748 - val_accuracy: 0.4035 - 297ms/epoch - 23ms/step\n",
            "Epoch 33/300\n",
            "13/13 - 0s - loss: 1.2401 - accuracy: 0.5699 - val_loss: 1.7183 - val_accuracy: 0.4280 - 304ms/epoch - 23ms/step\n",
            "Epoch 34/300\n",
            "13/13 - 0s - loss: 1.2471 - accuracy: 0.5600 - val_loss: 1.5995 - val_accuracy: 0.4611 - 299ms/epoch - 23ms/step\n",
            "Epoch 35/300\n",
            "13/13 - 0s - loss: 1.2941 - accuracy: 0.5507 - val_loss: 1.7187 - val_accuracy: 0.4899 - 295ms/epoch - 23ms/step\n",
            "Epoch 36/300\n",
            "13/13 - 0s - loss: 1.2689 - accuracy: 0.5617 - val_loss: 1.6864 - val_accuracy: 0.4424 - 300ms/epoch - 23ms/step\n",
            "Epoch 37/300\n",
            "13/13 - 0s - loss: 1.2033 - accuracy: 0.5773 - val_loss: 1.6697 - val_accuracy: 0.4568 - 297ms/epoch - 23ms/step\n",
            "Epoch 38/300\n",
            "13/13 - 0s - loss: 1.2762 - accuracy: 0.5564 - val_loss: 1.6621 - val_accuracy: 0.4164 - 304ms/epoch - 23ms/step\n",
            "Epoch 39/300\n",
            "13/13 - 0s - loss: 1.2634 - accuracy: 0.5556 - val_loss: 1.5824 - val_accuracy: 0.4683 - 300ms/epoch - 23ms/step\n",
            "Epoch 40/300\n",
            "13/13 - 0s - loss: 1.2012 - accuracy: 0.5721 - val_loss: 1.5708 - val_accuracy: 0.4683 - 301ms/epoch - 23ms/step\n",
            "Epoch 41/300\n",
            "13/13 - 0s - loss: 1.2102 - accuracy: 0.5733 - val_loss: 1.6016 - val_accuracy: 0.4870 - 296ms/epoch - 23ms/step\n",
            "Epoch 42/300\n",
            "13/13 - 0s - loss: 1.1678 - accuracy: 0.5885 - val_loss: 1.5937 - val_accuracy: 0.4813 - 308ms/epoch - 24ms/step\n",
            "Epoch 43/300\n",
            "13/13 - 0s - loss: 1.1369 - accuracy: 0.6015 - val_loss: 1.5656 - val_accuracy: 0.4697 - 298ms/epoch - 23ms/step\n",
            "Epoch 44/300\n",
            "13/13 - 0s - loss: 1.1791 - accuracy: 0.5899 - val_loss: 1.5471 - val_accuracy: 0.4798 - 297ms/epoch - 23ms/step\n",
            "Epoch 45/300\n",
            "13/13 - 0s - loss: 1.1130 - accuracy: 0.6050 - val_loss: 1.5290 - val_accuracy: 0.4741 - 301ms/epoch - 23ms/step\n",
            "Epoch 46/300\n",
            "13/13 - 0s - loss: 1.1017 - accuracy: 0.6105 - val_loss: 1.5475 - val_accuracy: 0.5187 - 305ms/epoch - 23ms/step\n",
            "Epoch 47/300\n",
            "13/13 - 0s - loss: 1.1251 - accuracy: 0.6103 - val_loss: 1.4479 - val_accuracy: 0.5303 - 298ms/epoch - 23ms/step\n",
            "Epoch 48/300\n",
            "13/13 - 0s - loss: 1.1060 - accuracy: 0.6071 - val_loss: 1.5888 - val_accuracy: 0.4827 - 299ms/epoch - 23ms/step\n",
            "Epoch 49/300\n",
            "13/13 - 0s - loss: 1.0624 - accuracy: 0.6157 - val_loss: 1.7111 - val_accuracy: 0.4625 - 309ms/epoch - 24ms/step\n",
            "Epoch 50/300\n",
            "13/13 - 0s - loss: 1.1658 - accuracy: 0.5968 - val_loss: 1.7721 - val_accuracy: 0.4424 - 307ms/epoch - 24ms/step\n",
            "Epoch 51/300\n",
            "13/13 - 0s - loss: 1.1278 - accuracy: 0.6068 - val_loss: 1.6032 - val_accuracy: 0.4625 - 302ms/epoch - 23ms/step\n",
            "Epoch 52/300\n",
            "13/13 - 0s - loss: 1.0985 - accuracy: 0.6276 - val_loss: 1.6955 - val_accuracy: 0.5043 - 303ms/epoch - 23ms/step\n",
            "Epoch 53/300\n",
            "13/13 - 0s - loss: 1.0871 - accuracy: 0.6252 - val_loss: 1.6389 - val_accuracy: 0.4914 - 305ms/epoch - 23ms/step\n",
            "Epoch 54/300\n",
            "13/13 - 0s - loss: 1.1211 - accuracy: 0.6228 - val_loss: 1.7052 - val_accuracy: 0.4697 - 311ms/epoch - 24ms/step\n",
            "Epoch 55/300\n",
            "13/13 - 0s - loss: 1.1378 - accuracy: 0.6023 - val_loss: 1.6917 - val_accuracy: 0.4899 - 314ms/epoch - 24ms/step\n",
            "Epoch 56/300\n",
            "13/13 - 0s - loss: 1.1512 - accuracy: 0.6031 - val_loss: 1.6396 - val_accuracy: 0.5115 - 303ms/epoch - 23ms/step\n",
            "Epoch 57/300\n",
            "13/13 - 0s - loss: 1.0928 - accuracy: 0.6206 - val_loss: 1.9111 - val_accuracy: 0.4798 - 303ms/epoch - 23ms/step\n",
            "Epoch 58/300\n",
            "13/13 - 0s - loss: 1.2704 - accuracy: 0.5822 - val_loss: 1.8098 - val_accuracy: 0.4870 - 301ms/epoch - 23ms/step\n",
            "Epoch 59/300\n",
            "13/13 - 0s - loss: 1.2018 - accuracy: 0.5819 - val_loss: 1.8100 - val_accuracy: 0.4928 - 300ms/epoch - 23ms/step\n",
            "Epoch 60/300\n",
            "13/13 - 0s - loss: 1.1569 - accuracy: 0.6095 - val_loss: 1.6767 - val_accuracy: 0.5058 - 299ms/epoch - 23ms/step\n",
            "Epoch 61/300\n",
            "13/13 - 0s - loss: 1.1790 - accuracy: 0.6036 - val_loss: 1.6742 - val_accuracy: 0.5058 - 293ms/epoch - 23ms/step\n",
            "Epoch 62/300\n",
            "13/13 - 0s - loss: 1.1600 - accuracy: 0.6015 - val_loss: 1.8085 - val_accuracy: 0.4928 - 296ms/epoch - 23ms/step\n",
            "Epoch 63/300\n",
            "13/13 - 0s - loss: 1.0859 - accuracy: 0.6294 - val_loss: 1.6837 - val_accuracy: 0.4625 - 300ms/epoch - 23ms/step\n",
            "Epoch 64/300\n",
            "13/13 - 0s - loss: 1.1237 - accuracy: 0.6238 - val_loss: 1.7606 - val_accuracy: 0.5144 - 293ms/epoch - 23ms/step\n",
            "Epoch 65/300\n",
            "13/13 - 0s - loss: 1.0701 - accuracy: 0.6244 - val_loss: 1.6842 - val_accuracy: 0.4971 - 295ms/epoch - 23ms/step\n",
            "Epoch 66/300\n",
            "13/13 - 0s - loss: 1.0356 - accuracy: 0.6294 - val_loss: 1.6641 - val_accuracy: 0.5461 - 292ms/epoch - 22ms/step\n",
            "Epoch 67/300\n",
            "13/13 - 0s - loss: 1.0580 - accuracy: 0.6371 - val_loss: 1.7105 - val_accuracy: 0.4438 - 303ms/epoch - 23ms/step\n",
            "Epoch 68/300\n",
            "13/13 - 0s - loss: 1.1970 - accuracy: 0.6000 - val_loss: 1.6831 - val_accuracy: 0.4467 - 300ms/epoch - 23ms/step\n",
            "Epoch 69/300\n",
            "13/13 - 0s - loss: 1.1202 - accuracy: 0.6132 - val_loss: 1.6093 - val_accuracy: 0.4366 - 298ms/epoch - 23ms/step\n",
            "Epoch 70/300\n",
            "13/13 - 0s - loss: 1.0826 - accuracy: 0.6241 - val_loss: 1.6666 - val_accuracy: 0.5187 - 293ms/epoch - 23ms/step\n",
            "Epoch 71/300\n",
            "13/13 - 0s - loss: 1.0770 - accuracy: 0.6302 - val_loss: 1.7205 - val_accuracy: 0.4870 - 292ms/epoch - 22ms/step\n",
            "Epoch 72/300\n",
            "13/13 - 0s - loss: 1.1626 - accuracy: 0.6029 - val_loss: 1.5645 - val_accuracy: 0.4611 - 297ms/epoch - 23ms/step\n",
            "Epoch 73/300\n",
            "13/13 - 0s - loss: 1.1652 - accuracy: 0.5999 - val_loss: 1.8234 - val_accuracy: 0.4092 - 297ms/epoch - 23ms/step\n",
            "Epoch 74/300\n",
            "13/13 - 0s - loss: 1.1840 - accuracy: 0.5999 - val_loss: 1.6743 - val_accuracy: 0.4625 - 296ms/epoch - 23ms/step\n",
            "Epoch 75/300\n",
            "13/13 - 0s - loss: 1.2079 - accuracy: 0.5941 - val_loss: 1.5695 - val_accuracy: 0.4524 - 295ms/epoch - 23ms/step\n",
            "Epoch 76/300\n",
            "13/13 - 0s - loss: 1.1421 - accuracy: 0.6088 - val_loss: 1.6979 - val_accuracy: 0.4669 - 292ms/epoch - 22ms/step\n",
            "Epoch 77/300\n",
            "13/13 - 0s - loss: 1.0828 - accuracy: 0.6262 - val_loss: 1.7625 - val_accuracy: 0.4539 - 295ms/epoch - 23ms/step\n",
            "Epoch 78/300\n",
            "13/13 - 0s - loss: 1.0952 - accuracy: 0.6194 - val_loss: 1.7721 - val_accuracy: 0.4352 - 297ms/epoch - 23ms/step\n",
            "Epoch 79/300\n",
            "13/13 - 0s - loss: 1.0544 - accuracy: 0.6417 - val_loss: 1.7345 - val_accuracy: 0.4539 - 298ms/epoch - 23ms/step\n",
            "Epoch 80/300\n",
            "13/13 - 0s - loss: 1.0767 - accuracy: 0.6257 - val_loss: 1.7113 - val_accuracy: 0.4697 - 293ms/epoch - 23ms/step\n",
            "Epoch 81/300\n",
            "13/13 - 0s - loss: 1.0730 - accuracy: 0.6428 - val_loss: 1.6628 - val_accuracy: 0.4611 - 301ms/epoch - 23ms/step\n",
            "Epoch 82/300\n",
            "13/13 - 0s - loss: 1.0203 - accuracy: 0.6500 - val_loss: 1.8327 - val_accuracy: 0.4798 - 295ms/epoch - 23ms/step\n",
            "Epoch 83/300\n",
            "13/13 - 0s - loss: 0.9953 - accuracy: 0.6496 - val_loss: 1.7859 - val_accuracy: 0.4582 - 301ms/epoch - 23ms/step\n",
            "Epoch 84/300\n",
            "13/13 - 0s - loss: 1.0043 - accuracy: 0.6430 - val_loss: 1.6763 - val_accuracy: 0.5000 - 303ms/epoch - 23ms/step\n",
            "Epoch 85/300\n",
            "13/13 - 0s - loss: 1.0363 - accuracy: 0.6414 - val_loss: 1.6640 - val_accuracy: 0.4885 - 293ms/epoch - 23ms/step\n",
            "Epoch 86/300\n",
            "13/13 - 0s - loss: 1.0014 - accuracy: 0.6475 - val_loss: 1.7402 - val_accuracy: 0.5086 - 298ms/epoch - 23ms/step\n",
            "Epoch 87/300\n",
            "13/13 - 0s - loss: 1.0087 - accuracy: 0.6452 - val_loss: 1.7123 - val_accuracy: 0.5634 - 305ms/epoch - 23ms/step\n",
            "Epoch 88/300\n",
            "13/13 - 0s - loss: 0.9849 - accuracy: 0.6488 - val_loss: 1.7154 - val_accuracy: 0.4957 - 301ms/epoch - 23ms/step\n",
            "Epoch 89/300\n",
            "13/13 - 0s - loss: 1.0039 - accuracy: 0.6367 - val_loss: 1.7114 - val_accuracy: 0.4870 - 296ms/epoch - 23ms/step\n",
            "Epoch 90/300\n",
            "13/13 - 0s - loss: 0.9810 - accuracy: 0.6523 - val_loss: 2.0015 - val_accuracy: 0.5360 - 297ms/epoch - 23ms/step\n",
            "Epoch 91/300\n",
            "13/13 - 0s - loss: 0.9554 - accuracy: 0.6622 - val_loss: 1.8018 - val_accuracy: 0.4971 - 296ms/epoch - 23ms/step\n",
            "Epoch 92/300\n",
            "13/13 - 0s - loss: 0.9443 - accuracy: 0.6634 - val_loss: 1.7907 - val_accuracy: 0.5548 - 295ms/epoch - 23ms/step\n",
            "Epoch 93/300\n",
            "13/13 - 0s - loss: 0.9805 - accuracy: 0.6592 - val_loss: 1.8314 - val_accuracy: 0.5303 - 293ms/epoch - 23ms/step\n",
            "Epoch 94/300\n",
            "13/13 - 0s - loss: 1.0490 - accuracy: 0.6491 - val_loss: 1.7814 - val_accuracy: 0.4971 - 297ms/epoch - 23ms/step\n",
            "Epoch 95/300\n",
            "13/13 - 0s - loss: 1.1132 - accuracy: 0.6241 - val_loss: 1.9321 - val_accuracy: 0.4438 - 299ms/epoch - 23ms/step\n",
            "Epoch 96/300\n",
            "13/13 - 0s - loss: 1.0855 - accuracy: 0.6286 - val_loss: 1.7535 - val_accuracy: 0.4352 - 302ms/epoch - 23ms/step\n",
            "Epoch 97/300\n",
            "13/13 - 0s - loss: 1.0497 - accuracy: 0.6438 - val_loss: 1.7906 - val_accuracy: 0.4524 - 294ms/epoch - 23ms/step\n",
            "Epoch 98/300\n",
            "13/13 - 0s - loss: 0.9915 - accuracy: 0.6483 - val_loss: 1.8524 - val_accuracy: 0.4669 - 299ms/epoch - 23ms/step\n",
            "Epoch 99/300\n",
            "13/13 - 0s - loss: 0.9733 - accuracy: 0.6632 - val_loss: 1.7226 - val_accuracy: 0.5072 - 297ms/epoch - 23ms/step\n",
            "Epoch 100/300\n",
            "13/13 - 0s - loss: 1.0370 - accuracy: 0.6408 - val_loss: 1.5931 - val_accuracy: 0.5331 - 297ms/epoch - 23ms/step\n",
            "Epoch 101/300\n",
            "13/13 - 0s - loss: 1.0251 - accuracy: 0.6476 - val_loss: 1.6104 - val_accuracy: 0.4942 - 305ms/epoch - 23ms/step\n",
            "Epoch 102/300\n",
            "13/13 - 0s - loss: 1.0980 - accuracy: 0.6379 - val_loss: 1.5833 - val_accuracy: 0.4784 - 322ms/epoch - 25ms/step\n",
            "Epoch 103/300\n",
            "13/13 - 0s - loss: 1.0759 - accuracy: 0.6460 - val_loss: 1.7693 - val_accuracy: 0.4424 - 300ms/epoch - 23ms/step\n",
            "Epoch 104/300\n",
            "13/13 - 0s - loss: 1.0901 - accuracy: 0.6276 - val_loss: 2.1282 - val_accuracy: 0.3804 - 302ms/epoch - 23ms/step\n",
            "Epoch 105/300\n",
            "13/13 - 0s - loss: 1.0331 - accuracy: 0.6385 - val_loss: 1.8429 - val_accuracy: 0.4986 - 297ms/epoch - 23ms/step\n",
            "Epoch 106/300\n",
            "13/13 - 0s - loss: 0.9737 - accuracy: 0.6626 - val_loss: 1.7211 - val_accuracy: 0.4856 - 300ms/epoch - 23ms/step\n",
            "Epoch 107/300\n",
            "13/13 - 0s - loss: 0.9521 - accuracy: 0.6579 - val_loss: 1.7175 - val_accuracy: 0.5101 - 299ms/epoch - 23ms/step\n",
            "Epoch 108/300\n",
            "13/13 - 0s - loss: 0.9822 - accuracy: 0.6600 - val_loss: 1.6820 - val_accuracy: 0.5231 - 299ms/epoch - 23ms/step\n",
            "Epoch 109/300\n",
            "13/13 - 0s - loss: 1.0252 - accuracy: 0.6454 - val_loss: 1.8802 - val_accuracy: 0.4971 - 299ms/epoch - 23ms/step\n",
            "Epoch 110/300\n",
            "13/13 - 0s - loss: 1.0122 - accuracy: 0.6517 - val_loss: 1.8606 - val_accuracy: 0.4784 - 305ms/epoch - 23ms/step\n",
            "Epoch 111/300\n",
            "13/13 - 0s - loss: 1.1069 - accuracy: 0.6391 - val_loss: 1.9053 - val_accuracy: 0.5403 - 306ms/epoch - 24ms/step\n",
            "Epoch 112/300\n",
            "13/13 - 0s - loss: 1.0388 - accuracy: 0.6321 - val_loss: 1.6804 - val_accuracy: 0.5159 - 302ms/epoch - 23ms/step\n",
            "Epoch 113/300\n",
            "13/13 - 0s - loss: 1.0236 - accuracy: 0.6460 - val_loss: 1.6134 - val_accuracy: 0.5288 - 303ms/epoch - 23ms/step\n",
            "Epoch 114/300\n",
            "13/13 - 0s - loss: 1.0200 - accuracy: 0.6468 - val_loss: 1.6853 - val_accuracy: 0.4813 - 299ms/epoch - 23ms/step\n",
            "Epoch 115/300\n",
            "13/13 - 0s - loss: 0.9799 - accuracy: 0.6544 - val_loss: 1.6661 - val_accuracy: 0.4568 - 298ms/epoch - 23ms/step\n",
            "Epoch 116/300\n",
            "13/13 - 0s - loss: 0.9357 - accuracy: 0.6666 - val_loss: 1.6991 - val_accuracy: 0.5288 - 293ms/epoch - 23ms/step\n",
            "Epoch 117/300\n",
            "13/13 - 0s - loss: 0.9146 - accuracy: 0.6773 - val_loss: 1.7527 - val_accuracy: 0.4769 - 296ms/epoch - 23ms/step\n",
            "Epoch 118/300\n",
            "13/13 - 0s - loss: 0.9714 - accuracy: 0.6736 - val_loss: 1.8857 - val_accuracy: 0.4568 - 293ms/epoch - 23ms/step\n",
            "Epoch 119/300\n",
            "13/13 - 0s - loss: 1.0254 - accuracy: 0.6637 - val_loss: 1.8472 - val_accuracy: 0.4928 - 299ms/epoch - 23ms/step\n",
            "Epoch 120/300\n",
            "13/13 - 0s - loss: 0.9781 - accuracy: 0.6597 - val_loss: 1.8016 - val_accuracy: 0.5086 - 298ms/epoch - 23ms/step\n",
            "Epoch 121/300\n",
            "13/13 - 0s - loss: 0.9941 - accuracy: 0.6497 - val_loss: 1.8298 - val_accuracy: 0.4654 - 296ms/epoch - 23ms/step\n",
            "Epoch 122/300\n",
            "13/13 - 0s - loss: 0.9762 - accuracy: 0.6558 - val_loss: 1.9961 - val_accuracy: 0.4481 - 293ms/epoch - 23ms/step\n",
            "Epoch 123/300\n",
            "13/13 - 0s - loss: 0.9270 - accuracy: 0.6710 - val_loss: 1.7894 - val_accuracy: 0.4798 - 302ms/epoch - 23ms/step\n",
            "Epoch 124/300\n",
            "13/13 - 0s - loss: 0.9106 - accuracy: 0.6876 - val_loss: 1.8966 - val_accuracy: 0.4885 - 299ms/epoch - 23ms/step\n",
            "Epoch 125/300\n",
            "13/13 - 0s - loss: 0.8936 - accuracy: 0.6860 - val_loss: 1.8453 - val_accuracy: 0.5130 - 295ms/epoch - 23ms/step\n",
            "Epoch 126/300\n",
            "13/13 - 0s - loss: 0.9126 - accuracy: 0.6789 - val_loss: 1.9601 - val_accuracy: 0.4611 - 295ms/epoch - 23ms/step\n",
            "Epoch 127/300\n",
            "13/13 - 0s - loss: 0.9592 - accuracy: 0.6811 - val_loss: 1.8726 - val_accuracy: 0.4957 - 296ms/epoch - 23ms/step\n",
            "Epoch 128/300\n",
            "13/13 - 0s - loss: 0.9151 - accuracy: 0.6757 - val_loss: 1.9207 - val_accuracy: 0.4654 - 294ms/epoch - 23ms/step\n",
            "Epoch 129/300\n",
            "13/13 - 0s - loss: 0.9112 - accuracy: 0.6757 - val_loss: 1.9467 - val_accuracy: 0.4726 - 296ms/epoch - 23ms/step\n",
            "Epoch 130/300\n",
            "13/13 - 0s - loss: 0.9230 - accuracy: 0.6739 - val_loss: 2.0573 - val_accuracy: 0.4582 - 301ms/epoch - 23ms/step\n",
            "Epoch 131/300\n",
            "13/13 - 0s - loss: 0.9294 - accuracy: 0.6802 - val_loss: 2.0431 - val_accuracy: 0.4683 - 315ms/epoch - 24ms/step\n",
            "Epoch 132/300\n",
            "13/13 - 0s - loss: 0.9347 - accuracy: 0.6811 - val_loss: 2.0778 - val_accuracy: 0.4712 - 318ms/epoch - 24ms/step\n",
            "Epoch 133/300\n",
            "13/13 - 0s - loss: 0.8718 - accuracy: 0.6879 - val_loss: 1.9352 - val_accuracy: 0.4914 - 308ms/epoch - 24ms/step\n",
            "Epoch 134/300\n",
            "13/13 - 0s - loss: 0.9074 - accuracy: 0.6848 - val_loss: 1.8418 - val_accuracy: 0.4856 - 304ms/epoch - 23ms/step\n",
            "Epoch 135/300\n",
            "13/13 - 0s - loss: 0.9702 - accuracy: 0.6752 - val_loss: 1.8286 - val_accuracy: 0.4813 - 299ms/epoch - 23ms/step\n",
            "Epoch 136/300\n",
            "13/13 - 0s - loss: 0.8976 - accuracy: 0.6903 - val_loss: 1.8338 - val_accuracy: 0.4928 - 302ms/epoch - 23ms/step\n",
            "Epoch 137/300\n",
            "13/13 - 0s - loss: 0.8808 - accuracy: 0.6912 - val_loss: 1.7137 - val_accuracy: 0.5086 - 302ms/epoch - 23ms/step\n",
            "Epoch 138/300\n",
            "13/13 - 0s - loss: 0.8800 - accuracy: 0.6914 - val_loss: 1.8205 - val_accuracy: 0.5115 - 308ms/epoch - 24ms/step\n",
            "Epoch 139/300\n",
            "13/13 - 0s - loss: 0.8431 - accuracy: 0.7062 - val_loss: 2.0752 - val_accuracy: 0.4870 - 301ms/epoch - 23ms/step\n",
            "Epoch 140/300\n",
            "13/13 - 0s - loss: 0.9030 - accuracy: 0.6819 - val_loss: 2.0144 - val_accuracy: 0.5159 - 303ms/epoch - 23ms/step\n",
            "Epoch 141/300\n",
            "13/13 - 0s - loss: 0.9022 - accuracy: 0.6754 - val_loss: 2.0753 - val_accuracy: 0.5202 - 301ms/epoch - 23ms/step\n",
            "Epoch 142/300\n",
            "13/13 - 0s - loss: 0.8798 - accuracy: 0.7002 - val_loss: 1.9923 - val_accuracy: 0.4755 - 304ms/epoch - 23ms/step\n",
            "Epoch 143/300\n",
            "13/13 - 0s - loss: 0.9729 - accuracy: 0.6680 - val_loss: 2.1185 - val_accuracy: 0.4741 - 301ms/epoch - 23ms/step\n",
            "Epoch 144/300\n",
            "13/13 - 0s - loss: 1.2109 - accuracy: 0.6185 - val_loss: 2.0238 - val_accuracy: 0.4669 - 307ms/epoch - 24ms/step\n",
            "Epoch 145/300\n",
            "13/13 - 0s - loss: 1.1858 - accuracy: 0.6193 - val_loss: 1.6493 - val_accuracy: 0.5014 - 304ms/epoch - 23ms/step\n",
            "Epoch 146/300\n",
            "13/13 - 0s - loss: 1.1523 - accuracy: 0.6138 - val_loss: 1.6430 - val_accuracy: 0.5029 - 305ms/epoch - 23ms/step\n",
            "Epoch 147/300\n",
            "13/13 - 0s - loss: 1.1600 - accuracy: 0.6315 - val_loss: 1.7658 - val_accuracy: 0.5043 - 305ms/epoch - 23ms/step\n",
            "Epoch 148/300\n",
            "13/13 - 0s - loss: 1.0766 - accuracy: 0.6271 - val_loss: 1.9658 - val_accuracy: 0.5216 - 298ms/epoch - 23ms/step\n",
            "Epoch 149/300\n",
            "13/13 - 0s - loss: 1.0724 - accuracy: 0.6399 - val_loss: 1.7632 - val_accuracy: 0.4856 - 305ms/epoch - 23ms/step\n",
            "Epoch 150/300\n",
            "13/13 - 0s - loss: 0.9913 - accuracy: 0.6600 - val_loss: 1.7159 - val_accuracy: 0.4755 - 307ms/epoch - 24ms/step\n",
            "Epoch 151/300\n",
            "13/13 - 0s - loss: 0.9913 - accuracy: 0.6730 - val_loss: 1.7705 - val_accuracy: 0.4755 - 301ms/epoch - 23ms/step\n",
            "Epoch 152/300\n",
            "13/13 - 0s - loss: 1.0514 - accuracy: 0.6484 - val_loss: 1.8849 - val_accuracy: 0.4553 - 304ms/epoch - 23ms/step\n",
            "Epoch 153/300\n",
            "13/13 - 0s - loss: 1.0189 - accuracy: 0.6693 - val_loss: 1.7116 - val_accuracy: 0.5130 - 309ms/epoch - 24ms/step\n",
            "Epoch 154/300\n",
            "13/13 - 0s - loss: 1.0229 - accuracy: 0.6613 - val_loss: 1.9248 - val_accuracy: 0.5086 - 305ms/epoch - 23ms/step\n",
            "Epoch 155/300\n",
            "13/13 - 0s - loss: 1.0947 - accuracy: 0.6515 - val_loss: 2.3205 - val_accuracy: 0.4841 - 306ms/epoch - 24ms/step\n",
            "Epoch 156/300\n",
            "13/13 - 0s - loss: 1.0219 - accuracy: 0.6608 - val_loss: 1.9636 - val_accuracy: 0.5014 - 305ms/epoch - 23ms/step\n",
            "Epoch 157/300\n",
            "13/13 - 0s - loss: 1.0429 - accuracy: 0.6693 - val_loss: 2.5753 - val_accuracy: 0.4741 - 308ms/epoch - 24ms/step\n",
            "Epoch 158/300\n",
            "13/13 - 0s - loss: 1.0848 - accuracy: 0.6694 - val_loss: 2.5517 - val_accuracy: 0.4568 - 301ms/epoch - 23ms/step\n",
            "Epoch 159/300\n",
            "13/13 - 0s - loss: 1.0982 - accuracy: 0.6536 - val_loss: 2.3286 - val_accuracy: 0.4337 - 302ms/epoch - 23ms/step\n",
            "Epoch 160/300\n",
            "13/13 - 0s - loss: 1.0706 - accuracy: 0.6318 - val_loss: 2.3322 - val_accuracy: 0.4597 - 298ms/epoch - 23ms/step\n",
            "Epoch 161/300\n",
            "13/13 - 0s - loss: 1.0215 - accuracy: 0.6619 - val_loss: 2.8973 - val_accuracy: 0.4986 - 303ms/epoch - 23ms/step\n",
            "Epoch 162/300\n",
            "13/13 - 0s - loss: 1.1052 - accuracy: 0.6587 - val_loss: 3.2815 - val_accuracy: 0.4841 - 302ms/epoch - 23ms/step\n",
            "Epoch 163/300\n",
            "13/13 - 0s - loss: 1.2465 - accuracy: 0.6398 - val_loss: 2.0272 - val_accuracy: 0.4654 - 304ms/epoch - 23ms/step\n",
            "Epoch 164/300\n",
            "13/13 - 0s - loss: 1.1906 - accuracy: 0.6020 - val_loss: 1.9779 - val_accuracy: 0.4524 - 295ms/epoch - 23ms/step\n",
            "Epoch 165/300\n",
            "13/13 - 0s - loss: 1.1264 - accuracy: 0.6252 - val_loss: 2.0039 - val_accuracy: 0.5029 - 302ms/epoch - 23ms/step\n",
            "Epoch 166/300\n",
            "13/13 - 0s - loss: 1.0938 - accuracy: 0.6369 - val_loss: 2.2573 - val_accuracy: 0.5072 - 300ms/epoch - 23ms/step\n",
            "Epoch 167/300\n",
            "13/13 - 0s - loss: 1.0085 - accuracy: 0.6529 - val_loss: 2.3022 - val_accuracy: 0.5014 - 302ms/epoch - 23ms/step\n",
            "Epoch 168/300\n",
            "13/13 - 0s - loss: 0.9689 - accuracy: 0.6701 - val_loss: 2.2139 - val_accuracy: 0.5086 - 300ms/epoch - 23ms/step\n",
            "Epoch 169/300\n",
            "13/13 - 0s - loss: 0.9648 - accuracy: 0.6614 - val_loss: 2.0927 - val_accuracy: 0.5216 - 299ms/epoch - 23ms/step\n",
            "Epoch 170/300\n",
            "13/13 - 0s - loss: 0.9326 - accuracy: 0.6767 - val_loss: 2.1016 - val_accuracy: 0.4957 - 287ms/epoch - 22ms/step\n",
            "Epoch 171/300\n",
            "13/13 - 0s - loss: 0.9887 - accuracy: 0.6640 - val_loss: 2.0747 - val_accuracy: 0.4870 - 296ms/epoch - 23ms/step\n",
            "Epoch 172/300\n",
            "13/13 - 0s - loss: 0.8836 - accuracy: 0.6799 - val_loss: 2.2345 - val_accuracy: 0.5187 - 294ms/epoch - 23ms/step\n",
            "Epoch 173/300\n",
            "13/13 - 0s - loss: 0.9242 - accuracy: 0.6868 - val_loss: 2.3100 - val_accuracy: 0.4841 - 297ms/epoch - 23ms/step\n",
            "Epoch 174/300\n",
            "13/13 - 0s - loss: 0.9007 - accuracy: 0.6941 - val_loss: 2.3114 - val_accuracy: 0.4856 - 296ms/epoch - 23ms/step\n",
            "Epoch 175/300\n",
            "13/13 - 0s - loss: 1.3057 - accuracy: 0.6369 - val_loss: 1.9183 - val_accuracy: 0.4135 - 298ms/epoch - 23ms/step\n",
            "Epoch 176/300\n",
            "13/13 - 0s - loss: 1.0406 - accuracy: 0.6419 - val_loss: 1.7957 - val_accuracy: 0.5274 - 299ms/epoch - 23ms/step\n",
            "Epoch 177/300\n",
            "13/13 - 0s - loss: 0.9981 - accuracy: 0.6694 - val_loss: 1.9548 - val_accuracy: 0.4784 - 297ms/epoch - 23ms/step\n",
            "Epoch 178/300\n",
            "13/13 - 0s - loss: 1.0014 - accuracy: 0.6560 - val_loss: 1.8882 - val_accuracy: 0.4942 - 298ms/epoch - 23ms/step\n",
            "Epoch 179/300\n",
            "13/13 - 0s - loss: 0.9681 - accuracy: 0.6579 - val_loss: 1.8660 - val_accuracy: 0.4813 - 300ms/epoch - 23ms/step\n",
            "Epoch 180/300\n",
            "13/13 - 0s - loss: 0.9598 - accuracy: 0.6661 - val_loss: 1.9947 - val_accuracy: 0.5331 - 300ms/epoch - 23ms/step\n",
            "Epoch 181/300\n",
            "13/13 - 0s - loss: 0.9838 - accuracy: 0.6685 - val_loss: 1.8881 - val_accuracy: 0.5461 - 306ms/epoch - 24ms/step\n",
            "Epoch 182/300\n",
            "13/13 - 0s - loss: 0.9716 - accuracy: 0.6760 - val_loss: 2.0255 - val_accuracy: 0.4885 - 297ms/epoch - 23ms/step\n",
            "Epoch 183/300\n",
            "13/13 - 0s - loss: 0.9420 - accuracy: 0.6848 - val_loss: 2.1345 - val_accuracy: 0.4827 - 300ms/epoch - 23ms/step\n",
            "Epoch 184/300\n",
            "13/13 - 0s - loss: 0.9154 - accuracy: 0.6845 - val_loss: 2.2245 - val_accuracy: 0.5144 - 301ms/epoch - 23ms/step\n",
            "Epoch 185/300\n",
            "13/13 - 0s - loss: 0.8562 - accuracy: 0.6901 - val_loss: 2.4582 - val_accuracy: 0.4669 - 298ms/epoch - 23ms/step\n",
            "Epoch 186/300\n",
            "13/13 - 0s - loss: 0.9070 - accuracy: 0.6988 - val_loss: 2.1758 - val_accuracy: 0.4611 - 295ms/epoch - 23ms/step\n",
            "Epoch 187/300\n",
            "13/13 - 0s - loss: 0.9332 - accuracy: 0.6837 - val_loss: 2.2513 - val_accuracy: 0.4755 - 300ms/epoch - 23ms/step\n",
            "Epoch 188/300\n",
            "13/13 - 0s - loss: 0.8741 - accuracy: 0.6937 - val_loss: 2.2901 - val_accuracy: 0.5418 - 298ms/epoch - 23ms/step\n",
            "Epoch 189/300\n",
            "13/13 - 0s - loss: 0.9406 - accuracy: 0.6937 - val_loss: 2.0172 - val_accuracy: 0.4712 - 299ms/epoch - 23ms/step\n",
            "Epoch 190/300\n",
            "13/13 - 0s - loss: 0.9011 - accuracy: 0.6839 - val_loss: 1.9423 - val_accuracy: 0.5173 - 296ms/epoch - 23ms/step\n",
            "Epoch 191/300\n",
            "13/13 - 0s - loss: 0.8762 - accuracy: 0.6925 - val_loss: 2.0308 - val_accuracy: 0.5159 - 294ms/epoch - 23ms/step\n",
            "Epoch 192/300\n",
            "13/13 - 0s - loss: 0.8738 - accuracy: 0.6906 - val_loss: 2.1006 - val_accuracy: 0.4986 - 299ms/epoch - 23ms/step\n",
            "Epoch 193/300\n",
            "13/13 - 0s - loss: 0.8555 - accuracy: 0.7063 - val_loss: 2.3145 - val_accuracy: 0.5043 - 301ms/epoch - 23ms/step\n",
            "Epoch 194/300\n",
            "13/13 - 0s - loss: 0.8865 - accuracy: 0.6922 - val_loss: 2.2604 - val_accuracy: 0.4928 - 301ms/epoch - 23ms/step\n",
            "Epoch 195/300\n",
            "13/13 - 0s - loss: 0.9203 - accuracy: 0.6864 - val_loss: 2.2135 - val_accuracy: 0.4755 - 295ms/epoch - 23ms/step\n",
            "Epoch 196/300\n",
            "13/13 - 0s - loss: 0.8937 - accuracy: 0.6858 - val_loss: 2.2192 - val_accuracy: 0.5043 - 296ms/epoch - 23ms/step\n",
            "Epoch 197/300\n",
            "13/13 - 0s - loss: 0.8760 - accuracy: 0.6956 - val_loss: 2.2846 - val_accuracy: 0.4870 - 298ms/epoch - 23ms/step\n",
            "Epoch 198/300\n",
            "13/13 - 0s - loss: 0.8681 - accuracy: 0.6980 - val_loss: 2.3350 - val_accuracy: 0.4971 - 298ms/epoch - 23ms/step\n",
            "Epoch 199/300\n",
            "13/13 - 0s - loss: 0.8394 - accuracy: 0.7106 - val_loss: 2.3630 - val_accuracy: 0.5504 - 300ms/epoch - 23ms/step\n",
            "Epoch 200/300\n",
            "13/13 - 0s - loss: 0.8102 - accuracy: 0.7114 - val_loss: 2.3629 - val_accuracy: 0.5086 - 296ms/epoch - 23ms/step\n",
            "Epoch 201/300\n",
            "13/13 - 0s - loss: 0.8699 - accuracy: 0.6890 - val_loss: 2.2626 - val_accuracy: 0.4467 - 300ms/epoch - 23ms/step\n",
            "Epoch 202/300\n",
            "13/13 - 0s - loss: 0.8684 - accuracy: 0.6912 - val_loss: 2.5041 - val_accuracy: 0.4726 - 301ms/epoch - 23ms/step\n",
            "Epoch 203/300\n",
            "13/13 - 0s - loss: 0.9347 - accuracy: 0.6669 - val_loss: 2.2541 - val_accuracy: 0.5043 - 293ms/epoch - 23ms/step\n",
            "Epoch 204/300\n",
            "13/13 - 0s - loss: 0.9248 - accuracy: 0.6920 - val_loss: 2.3035 - val_accuracy: 0.5144 - 297ms/epoch - 23ms/step\n",
            "Epoch 205/300\n",
            "13/13 - 0s - loss: 0.9180 - accuracy: 0.6691 - val_loss: 2.4347 - val_accuracy: 0.5101 - 298ms/epoch - 23ms/step\n",
            "Epoch 206/300\n",
            "13/13 - 0s - loss: 0.8839 - accuracy: 0.6954 - val_loss: 2.5296 - val_accuracy: 0.5000 - 303ms/epoch - 23ms/step\n",
            "Epoch 207/300\n",
            "13/13 - 0s - loss: 0.8304 - accuracy: 0.7042 - val_loss: 2.7322 - val_accuracy: 0.4957 - 296ms/epoch - 23ms/step\n",
            "Epoch 208/300\n",
            "13/13 - 0s - loss: 0.8288 - accuracy: 0.7026 - val_loss: 2.7057 - val_accuracy: 0.4971 - 294ms/epoch - 23ms/step\n",
            "Epoch 209/300\n",
            "13/13 - 0s - loss: 0.8642 - accuracy: 0.6965 - val_loss: 2.3910 - val_accuracy: 0.5432 - 296ms/epoch - 23ms/step\n",
            "Epoch 210/300\n",
            "13/13 - 0s - loss: 0.8484 - accuracy: 0.6978 - val_loss: 2.3386 - val_accuracy: 0.5490 - 296ms/epoch - 23ms/step\n",
            "Epoch 211/300\n",
            "13/13 - 0s - loss: 0.8381 - accuracy: 0.7142 - val_loss: 2.3080 - val_accuracy: 0.4971 - 297ms/epoch - 23ms/step\n",
            "Epoch 212/300\n",
            "13/13 - 0s - loss: 0.9044 - accuracy: 0.6802 - val_loss: 2.1342 - val_accuracy: 0.4409 - 293ms/epoch - 23ms/step\n",
            "Epoch 213/300\n",
            "13/13 - 0s - loss: 0.9023 - accuracy: 0.6898 - val_loss: 2.2731 - val_accuracy: 0.4827 - 302ms/epoch - 23ms/step\n",
            "Epoch 214/300\n",
            "13/13 - 0s - loss: 0.8692 - accuracy: 0.6993 - val_loss: 2.3880 - val_accuracy: 0.4741 - 303ms/epoch - 23ms/step\n",
            "Epoch 215/300\n",
            "13/13 - 0s - loss: 0.9219 - accuracy: 0.6792 - val_loss: 2.1875 - val_accuracy: 0.4438 - 296ms/epoch - 23ms/step\n",
            "Epoch 216/300\n",
            "13/13 - 0s - loss: 0.8796 - accuracy: 0.6847 - val_loss: 2.0463 - val_accuracy: 0.5159 - 303ms/epoch - 23ms/step\n",
            "Epoch 217/300\n",
            "13/13 - 0s - loss: 0.8787 - accuracy: 0.7012 - val_loss: 2.3046 - val_accuracy: 0.4928 - 299ms/epoch - 23ms/step\n",
            "Epoch 218/300\n",
            "13/13 - 0s - loss: 0.8326 - accuracy: 0.7105 - val_loss: 2.7228 - val_accuracy: 0.5043 - 301ms/epoch - 23ms/step\n",
            "Epoch 219/300\n",
            "13/13 - 0s - loss: 0.8671 - accuracy: 0.7084 - val_loss: 2.6397 - val_accuracy: 0.5245 - 301ms/epoch - 23ms/step\n",
            "Epoch 220/300\n",
            "13/13 - 0s - loss: 0.8548 - accuracy: 0.7086 - val_loss: 2.0437 - val_accuracy: 0.4856 - 303ms/epoch - 23ms/step\n",
            "Epoch 221/300\n",
            "13/13 - 0s - loss: 0.9019 - accuracy: 0.6946 - val_loss: 1.9465 - val_accuracy: 0.5216 - 302ms/epoch - 23ms/step\n",
            "Epoch 222/300\n",
            "13/13 - 0s - loss: 0.8694 - accuracy: 0.6940 - val_loss: 1.9913 - val_accuracy: 0.4697 - 298ms/epoch - 23ms/step\n",
            "Epoch 223/300\n",
            "13/13 - 0s - loss: 0.9237 - accuracy: 0.7042 - val_loss: 2.0720 - val_accuracy: 0.4856 - 296ms/epoch - 23ms/step\n",
            "Epoch 224/300\n",
            "13/13 - 0s - loss: 0.8464 - accuracy: 0.7156 - val_loss: 1.9674 - val_accuracy: 0.5072 - 302ms/epoch - 23ms/step\n",
            "Epoch 225/300\n",
            "13/13 - 0s - loss: 0.8709 - accuracy: 0.7002 - val_loss: 1.9105 - val_accuracy: 0.4856 - 294ms/epoch - 23ms/step\n",
            "Epoch 226/300\n",
            "13/13 - 0s - loss: 0.8760 - accuracy: 0.7018 - val_loss: 2.2436 - val_accuracy: 0.5331 - 300ms/epoch - 23ms/step\n",
            "Epoch 227/300\n",
            "13/13 - 0s - loss: 0.8571 - accuracy: 0.7002 - val_loss: 2.1577 - val_accuracy: 0.5058 - 300ms/epoch - 23ms/step\n",
            "Epoch 228/300\n",
            "13/13 - 0s - loss: 0.8201 - accuracy: 0.7164 - val_loss: 2.2314 - val_accuracy: 0.5288 - 303ms/epoch - 23ms/step\n",
            "Epoch 229/300\n",
            "13/13 - 0s - loss: 0.7877 - accuracy: 0.7228 - val_loss: 2.1484 - val_accuracy: 0.5086 - 296ms/epoch - 23ms/step\n",
            "Epoch 230/300\n",
            "13/13 - 0s - loss: 0.7946 - accuracy: 0.7161 - val_loss: 2.3141 - val_accuracy: 0.5231 - 301ms/epoch - 23ms/step\n",
            "Epoch 231/300\n",
            "13/13 - 0s - loss: 0.8221 - accuracy: 0.7026 - val_loss: 2.4668 - val_accuracy: 0.4841 - 303ms/epoch - 23ms/step\n",
            "Epoch 232/300\n",
            "13/13 - 0s - loss: 0.7867 - accuracy: 0.7185 - val_loss: 2.5211 - val_accuracy: 0.4798 - 297ms/epoch - 23ms/step\n",
            "Epoch 233/300\n",
            "13/13 - 0s - loss: 0.7959 - accuracy: 0.7254 - val_loss: 2.5363 - val_accuracy: 0.5029 - 297ms/epoch - 23ms/step\n",
            "Epoch 234/300\n",
            "13/13 - 0s - loss: 0.7612 - accuracy: 0.7223 - val_loss: 2.6733 - val_accuracy: 0.5029 - 296ms/epoch - 23ms/step\n",
            "Epoch 235/300\n",
            "13/13 - 0s - loss: 0.8350 - accuracy: 0.7142 - val_loss: 2.5059 - val_accuracy: 0.5043 - 303ms/epoch - 23ms/step\n",
            "Epoch 236/300\n",
            "13/13 - 0s - loss: 0.8511 - accuracy: 0.7084 - val_loss: 2.1010 - val_accuracy: 0.4942 - 300ms/epoch - 23ms/step\n",
            "Epoch 237/300\n",
            "13/13 - 0s - loss: 0.8734 - accuracy: 0.6914 - val_loss: 2.0233 - val_accuracy: 0.4856 - 306ms/epoch - 24ms/step\n",
            "Epoch 238/300\n",
            "13/13 - 0s - loss: 0.9230 - accuracy: 0.7026 - val_loss: 2.2937 - val_accuracy: 0.4899 - 300ms/epoch - 23ms/step\n",
            "Epoch 239/300\n",
            "13/13 - 0s - loss: 0.8439 - accuracy: 0.7098 - val_loss: 2.3604 - val_accuracy: 0.4986 - 301ms/epoch - 23ms/step\n",
            "Epoch 240/300\n",
            "13/13 - 0s - loss: 0.8318 - accuracy: 0.7121 - val_loss: 2.3740 - val_accuracy: 0.4986 - 303ms/epoch - 23ms/step\n",
            "Epoch 241/300\n",
            "13/13 - 0s - loss: 0.8595 - accuracy: 0.6967 - val_loss: 2.1207 - val_accuracy: 0.5014 - 296ms/epoch - 23ms/step\n",
            "Epoch 242/300\n",
            "13/13 - 0s - loss: 0.8569 - accuracy: 0.6949 - val_loss: 2.2800 - val_accuracy: 0.5000 - 297ms/epoch - 23ms/step\n",
            "Epoch 243/300\n",
            "13/13 - 0s - loss: 0.8880 - accuracy: 0.7134 - val_loss: 2.0682 - val_accuracy: 0.4597 - 300ms/epoch - 23ms/step\n",
            "Epoch 244/300\n",
            "13/13 - 0s - loss: 0.8838 - accuracy: 0.6973 - val_loss: 2.3424 - val_accuracy: 0.4827 - 302ms/epoch - 23ms/step\n",
            "Epoch 245/300\n",
            "13/13 - 0s - loss: 0.8714 - accuracy: 0.7079 - val_loss: 1.8725 - val_accuracy: 0.5202 - 305ms/epoch - 23ms/step\n",
            "Epoch 246/300\n",
            "13/13 - 0s - loss: 0.8330 - accuracy: 0.6948 - val_loss: 1.7711 - val_accuracy: 0.5533 - 308ms/epoch - 24ms/step\n",
            "Epoch 247/300\n",
            "13/13 - 0s - loss: 0.8151 - accuracy: 0.7118 - val_loss: 1.9036 - val_accuracy: 0.5130 - 312ms/epoch - 24ms/step\n",
            "Epoch 248/300\n",
            "13/13 - 0s - loss: 0.7592 - accuracy: 0.7296 - val_loss: 2.3645 - val_accuracy: 0.5389 - 305ms/epoch - 23ms/step\n",
            "Epoch 249/300\n",
            "13/13 - 0s - loss: 0.7691 - accuracy: 0.7302 - val_loss: 2.4605 - val_accuracy: 0.5231 - 301ms/epoch - 23ms/step\n",
            "Epoch 250/300\n",
            "13/13 - 0s - loss: 0.7422 - accuracy: 0.7390 - val_loss: 2.5544 - val_accuracy: 0.5086 - 307ms/epoch - 24ms/step\n",
            "Epoch 251/300\n",
            "13/13 - 0s - loss: 0.7799 - accuracy: 0.7256 - val_loss: 2.5666 - val_accuracy: 0.5086 - 305ms/epoch - 23ms/step\n",
            "Epoch 252/300\n",
            "13/13 - 0s - loss: 0.8065 - accuracy: 0.7175 - val_loss: 2.4093 - val_accuracy: 0.4841 - 299ms/epoch - 23ms/step\n",
            "Epoch 253/300\n",
            "13/13 - 0s - loss: 0.8064 - accuracy: 0.7126 - val_loss: 2.5579 - val_accuracy: 0.5101 - 297ms/epoch - 23ms/step\n",
            "Epoch 254/300\n",
            "13/13 - 0s - loss: 0.8057 - accuracy: 0.7124 - val_loss: 2.8642 - val_accuracy: 0.4914 - 297ms/epoch - 23ms/step\n",
            "Epoch 255/300\n",
            "13/13 - 0s - loss: 0.7882 - accuracy: 0.7283 - val_loss: 2.6879 - val_accuracy: 0.4755 - 304ms/epoch - 23ms/step\n",
            "Epoch 256/300\n",
            "13/13 - 0s - loss: 0.8348 - accuracy: 0.7172 - val_loss: 2.2984 - val_accuracy: 0.5014 - 295ms/epoch - 23ms/step\n",
            "Epoch 257/300\n",
            "13/13 - 0s - loss: 0.8348 - accuracy: 0.7119 - val_loss: 2.8895 - val_accuracy: 0.4942 - 297ms/epoch - 23ms/step\n",
            "Epoch 258/300\n",
            "13/13 - 0s - loss: 0.8287 - accuracy: 0.7180 - val_loss: 2.5924 - val_accuracy: 0.5014 - 300ms/epoch - 23ms/step\n",
            "Epoch 259/300\n",
            "13/13 - 0s - loss: 0.8003 - accuracy: 0.7238 - val_loss: 2.3941 - val_accuracy: 0.4942 - 301ms/epoch - 23ms/step\n",
            "Epoch 260/300\n",
            "13/13 - 0s - loss: 0.8634 - accuracy: 0.7177 - val_loss: 2.4494 - val_accuracy: 0.4625 - 307ms/epoch - 24ms/step\n",
            "Epoch 261/300\n",
            "13/13 - 0s - loss: 0.9591 - accuracy: 0.6797 - val_loss: 2.5872 - val_accuracy: 0.4870 - 301ms/epoch - 23ms/step\n",
            "Epoch 262/300\n",
            "13/13 - 0s - loss: 0.8912 - accuracy: 0.6919 - val_loss: 2.6492 - val_accuracy: 0.5072 - 305ms/epoch - 23ms/step\n",
            "Epoch 263/300\n",
            "13/13 - 0s - loss: 0.7951 - accuracy: 0.7180 - val_loss: 2.6923 - val_accuracy: 0.4942 - 303ms/epoch - 23ms/step\n",
            "Epoch 264/300\n",
            "13/13 - 0s - loss: 0.8261 - accuracy: 0.7129 - val_loss: 2.7273 - val_accuracy: 0.4798 - 307ms/epoch - 24ms/step\n",
            "Epoch 265/300\n",
            "13/13 - 0s - loss: 0.9081 - accuracy: 0.6914 - val_loss: 2.6810 - val_accuracy: 0.4928 - 302ms/epoch - 23ms/step\n",
            "Epoch 266/300\n",
            "13/13 - 0s - loss: 0.9905 - accuracy: 0.7002 - val_loss: 2.7903 - val_accuracy: 0.4481 - 302ms/epoch - 23ms/step\n",
            "Epoch 267/300\n",
            "13/13 - 0s - loss: 0.7942 - accuracy: 0.7227 - val_loss: 2.8153 - val_accuracy: 0.4957 - 299ms/epoch - 23ms/step\n",
            "Epoch 268/300\n",
            "13/13 - 0s - loss: 0.7968 - accuracy: 0.7365 - val_loss: 2.7010 - val_accuracy: 0.5072 - 305ms/epoch - 23ms/step\n",
            "Epoch 269/300\n",
            "13/13 - 0s - loss: 0.8057 - accuracy: 0.7215 - val_loss: 2.7601 - val_accuracy: 0.4395 - 304ms/epoch - 23ms/step\n",
            "Epoch 270/300\n",
            "13/13 - 0s - loss: 0.8207 - accuracy: 0.7137 - val_loss: 2.4643 - val_accuracy: 0.4769 - 303ms/epoch - 23ms/step\n",
            "Epoch 271/300\n",
            "13/13 - 0s - loss: 0.8207 - accuracy: 0.7084 - val_loss: 2.2464 - val_accuracy: 0.4899 - 301ms/epoch - 23ms/step\n",
            "Epoch 272/300\n",
            "13/13 - 0s - loss: 0.8216 - accuracy: 0.7108 - val_loss: 2.2848 - val_accuracy: 0.4597 - 304ms/epoch - 23ms/step\n",
            "Epoch 273/300\n",
            "13/13 - 0s - loss: 0.9072 - accuracy: 0.6871 - val_loss: 2.2738 - val_accuracy: 0.4784 - 306ms/epoch - 24ms/step\n",
            "Epoch 274/300\n",
            "13/13 - 0s - loss: 0.9131 - accuracy: 0.6866 - val_loss: 2.0659 - val_accuracy: 0.4625 - 304ms/epoch - 23ms/step\n",
            "Epoch 275/300\n",
            "13/13 - 0s - loss: 0.8859 - accuracy: 0.6951 - val_loss: 2.0935 - val_accuracy: 0.5187 - 299ms/epoch - 23ms/step\n",
            "Epoch 276/300\n",
            "13/13 - 0s - loss: 0.8116 - accuracy: 0.7140 - val_loss: 2.0299 - val_accuracy: 0.5101 - 304ms/epoch - 23ms/step\n",
            "Epoch 277/300\n",
            "13/13 - 0s - loss: 0.8523 - accuracy: 0.7078 - val_loss: 2.0905 - val_accuracy: 0.5014 - 303ms/epoch - 23ms/step\n",
            "Epoch 278/300\n",
            "13/13 - 0s - loss: 0.8230 - accuracy: 0.7156 - val_loss: 2.2823 - val_accuracy: 0.5043 - 305ms/epoch - 23ms/step\n",
            "Epoch 279/300\n",
            "13/13 - 0s - loss: 0.8127 - accuracy: 0.7203 - val_loss: 2.3333 - val_accuracy: 0.5101 - 296ms/epoch - 23ms/step\n",
            "Epoch 280/300\n",
            "13/13 - 0s - loss: 0.9016 - accuracy: 0.7147 - val_loss: 2.1881 - val_accuracy: 0.4755 - 298ms/epoch - 23ms/step\n",
            "Epoch 281/300\n",
            "13/13 - 0s - loss: 0.9258 - accuracy: 0.6856 - val_loss: 2.3718 - val_accuracy: 0.4712 - 305ms/epoch - 23ms/step\n",
            "Epoch 282/300\n",
            "13/13 - 0s - loss: 0.9065 - accuracy: 0.6957 - val_loss: 2.1877 - val_accuracy: 0.4726 - 307ms/epoch - 24ms/step\n",
            "Epoch 283/300\n",
            "13/13 - 0s - loss: 0.8813 - accuracy: 0.6996 - val_loss: 2.3480 - val_accuracy: 0.4769 - 307ms/epoch - 24ms/step\n",
            "Epoch 284/300\n",
            "13/13 - 0s - loss: 0.9390 - accuracy: 0.6871 - val_loss: 2.2941 - val_accuracy: 0.5130 - 298ms/epoch - 23ms/step\n",
            "Epoch 285/300\n",
            "13/13 - 0s - loss: 0.8357 - accuracy: 0.7047 - val_loss: 2.4239 - val_accuracy: 0.5389 - 308ms/epoch - 24ms/step\n",
            "Epoch 286/300\n",
            "13/13 - 0s - loss: 0.7939 - accuracy: 0.7137 - val_loss: 2.6979 - val_accuracy: 0.5130 - 299ms/epoch - 23ms/step\n",
            "Epoch 287/300\n",
            "13/13 - 0s - loss: 0.8162 - accuracy: 0.7143 - val_loss: 2.4663 - val_accuracy: 0.4986 - 313ms/epoch - 24ms/step\n",
            "Epoch 288/300\n",
            "13/13 - 0s - loss: 0.7750 - accuracy: 0.7248 - val_loss: 2.3615 - val_accuracy: 0.5029 - 311ms/epoch - 24ms/step\n",
            "Epoch 289/300\n",
            "13/13 - 0s - loss: 0.7438 - accuracy: 0.7365 - val_loss: 2.4164 - val_accuracy: 0.5072 - 322ms/epoch - 25ms/step\n",
            "Epoch 290/300\n",
            "13/13 - 0s - loss: 0.7467 - accuracy: 0.7400 - val_loss: 2.7603 - val_accuracy: 0.5101 - 331ms/epoch - 25ms/step\n",
            "Epoch 291/300\n",
            "13/13 - 0s - loss: 0.8094 - accuracy: 0.7206 - val_loss: 2.3805 - val_accuracy: 0.4841 - 316ms/epoch - 24ms/step\n",
            "Epoch 292/300\n",
            "13/13 - 0s - loss: 0.8317 - accuracy: 0.7158 - val_loss: 2.3260 - val_accuracy: 0.4971 - 318ms/epoch - 24ms/step\n",
            "Epoch 293/300\n",
            "13/13 - 0s - loss: 0.8090 - accuracy: 0.7180 - val_loss: 2.2686 - val_accuracy: 0.5130 - 322ms/epoch - 25ms/step\n",
            "Epoch 294/300\n",
            "13/13 - 0s - loss: 0.7718 - accuracy: 0.7182 - val_loss: 2.0904 - val_accuracy: 0.5086 - 315ms/epoch - 24ms/step\n",
            "Epoch 295/300\n",
            "13/13 - 0s - loss: 0.7604 - accuracy: 0.7316 - val_loss: 2.4114 - val_accuracy: 0.5072 - 320ms/epoch - 25ms/step\n",
            "Epoch 296/300\n",
            "13/13 - 0s - loss: 0.7475 - accuracy: 0.7307 - val_loss: 2.2629 - val_accuracy: 0.5274 - 305ms/epoch - 23ms/step\n",
            "Epoch 297/300\n",
            "13/13 - 0s - loss: 0.7314 - accuracy: 0.7405 - val_loss: 2.3948 - val_accuracy: 0.5086 - 309ms/epoch - 24ms/step\n",
            "Epoch 298/300\n",
            "13/13 - 0s - loss: 0.7066 - accuracy: 0.7477 - val_loss: 2.7284 - val_accuracy: 0.4971 - 305ms/epoch - 23ms/step\n",
            "Epoch 299/300\n",
            "13/13 - 0s - loss: 0.7056 - accuracy: 0.7417 - val_loss: 2.5788 - val_accuracy: 0.5259 - 308ms/epoch - 24ms/step\n",
            "Epoch 300/300\n",
            "13/13 - 0s - loss: 0.8378 - accuracy: 0.7265 - val_loss: 2.3552 - val_accuracy: 0.4380 - 300ms/epoch - 23ms/step\n",
            "Model: \"sequential_99\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_198 (Conv2D)         (None, 4, 36, 80)         27440     \n",
            "                                                                 \n",
            " max_pooling2d_198 (MaxPooli  (None, 1, 12, 80)        0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_99 (Bat  (None, 1, 12, 80)        320       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv2d_199 (Conv2D)         (None, 1, 10, 80)         19280     \n",
            "                                                                 \n",
            " max_pooling2d_199 (MaxPooli  (None, 1, 3, 80)         0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " flatten_99 (Flatten)        (None, 240)               0         \n",
            "                                                                 \n",
            " dense_297 (Dense)           (None, 5000)              1205000   \n",
            "                                                                 \n",
            " dropout_198 (Dropout)       (None, 5000)              0         \n",
            "                                                                 \n",
            " dense_298 (Dense)           (None, 5000)              25005000  \n",
            "                                                                 \n",
            " dropout_199 (Dropout)       (None, 5000)              0         \n",
            "                                                                 \n",
            " dense_299 (Dense)           (None, 10)                50010     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 26,307,050\n",
            "Trainable params: 26,306,890\n",
            "Non-trainable params: 160\n",
            "_________________________________________________________________\n",
            "None\n",
            "Result of fold:7\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 2.3737 - accuracy: 0.3865\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 70%|███████   | 7/10 [11:46<05:31, 110.60s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(6966, 60, 41)\n",
            "Epoch 1/300\n",
            "13/13 - 1s - loss: 6.0029 - accuracy: 0.1372 - val_loss: 2.2730 - val_accuracy: 0.1521 - 1s/epoch - 84ms/step\n",
            "Epoch 2/300\n",
            "13/13 - 0s - loss: 2.1759 - accuracy: 0.1807 - val_loss: 2.4015 - val_accuracy: 0.1693 - 310ms/epoch - 24ms/step\n",
            "Epoch 3/300\n",
            "13/13 - 0s - loss: 2.1187 - accuracy: 0.2042 - val_loss: 2.1531 - val_accuracy: 0.2037 - 306ms/epoch - 24ms/step\n",
            "Epoch 4/300\n",
            "13/13 - 0s - loss: 2.0654 - accuracy: 0.2329 - val_loss: 2.1097 - val_accuracy: 0.1535 - 302ms/epoch - 23ms/step\n",
            "Epoch 5/300\n",
            "13/13 - 0s - loss: 2.0216 - accuracy: 0.2605 - val_loss: 1.9414 - val_accuracy: 0.2568 - 299ms/epoch - 23ms/step\n",
            "Epoch 6/300\n",
            "13/13 - 0s - loss: 1.9480 - accuracy: 0.2777 - val_loss: 1.8862 - val_accuracy: 0.2511 - 304ms/epoch - 23ms/step\n",
            "Epoch 7/300\n",
            "13/13 - 0s - loss: 1.9199 - accuracy: 0.2905 - val_loss: 1.9282 - val_accuracy: 0.2726 - 297ms/epoch - 23ms/step\n",
            "Epoch 8/300\n",
            "13/13 - 0s - loss: 1.9002 - accuracy: 0.2924 - val_loss: 1.8698 - val_accuracy: 0.2941 - 296ms/epoch - 23ms/step\n",
            "Epoch 9/300\n",
            "13/13 - 0s - loss: 1.8701 - accuracy: 0.3130 - val_loss: 1.8711 - val_accuracy: 0.2898 - 304ms/epoch - 23ms/step\n",
            "Epoch 10/300\n",
            "13/13 - 0s - loss: 1.7754 - accuracy: 0.3430 - val_loss: 1.7567 - val_accuracy: 0.3515 - 299ms/epoch - 23ms/step\n",
            "Epoch 11/300\n",
            "13/13 - 0s - loss: 1.7322 - accuracy: 0.3575 - val_loss: 1.7454 - val_accuracy: 0.3242 - 309ms/epoch - 24ms/step\n",
            "Epoch 12/300\n",
            "13/13 - 0s - loss: 1.7051 - accuracy: 0.3795 - val_loss: 1.7518 - val_accuracy: 0.3486 - 309ms/epoch - 24ms/step\n",
            "Epoch 13/300\n",
            "13/13 - 0s - loss: 1.6869 - accuracy: 0.3889 - val_loss: 1.7446 - val_accuracy: 0.3400 - 306ms/epoch - 24ms/step\n",
            "Epoch 14/300\n",
            "13/13 - 0s - loss: 1.6514 - accuracy: 0.3989 - val_loss: 1.7776 - val_accuracy: 0.3802 - 301ms/epoch - 23ms/step\n",
            "Epoch 15/300\n",
            "13/13 - 0s - loss: 1.5809 - accuracy: 0.4331 - val_loss: 1.7469 - val_accuracy: 0.3558 - 302ms/epoch - 23ms/step\n",
            "Epoch 16/300\n",
            "13/13 - 0s - loss: 1.6150 - accuracy: 0.4245 - val_loss: 1.7343 - val_accuracy: 0.3945 - 299ms/epoch - 23ms/step\n",
            "Epoch 17/300\n",
            "13/13 - 0s - loss: 1.5695 - accuracy: 0.4313 - val_loss: 1.7168 - val_accuracy: 0.4648 - 302ms/epoch - 23ms/step\n",
            "Epoch 18/300\n",
            "13/13 - 0s - loss: 1.5128 - accuracy: 0.4533 - val_loss: 1.7964 - val_accuracy: 0.3974 - 302ms/epoch - 23ms/step\n",
            "Epoch 19/300\n",
            "13/13 - 0s - loss: 1.5779 - accuracy: 0.4281 - val_loss: 1.7500 - val_accuracy: 0.3615 - 298ms/epoch - 23ms/step\n",
            "Epoch 20/300\n",
            "13/13 - 0s - loss: 1.5360 - accuracy: 0.4505 - val_loss: 1.7710 - val_accuracy: 0.3859 - 306ms/epoch - 24ms/step\n",
            "Epoch 21/300\n",
            "13/13 - 0s - loss: 1.4790 - accuracy: 0.4667 - val_loss: 1.7357 - val_accuracy: 0.4634 - 312ms/epoch - 24ms/step\n",
            "Epoch 22/300\n",
            "13/13 - 0s - loss: 1.4366 - accuracy: 0.4843 - val_loss: 1.6830 - val_accuracy: 0.4792 - 311ms/epoch - 24ms/step\n",
            "Epoch 23/300\n",
            "13/13 - 0s - loss: 1.4211 - accuracy: 0.4907 - val_loss: 1.6968 - val_accuracy: 0.4591 - 309ms/epoch - 24ms/step\n",
            "Epoch 24/300\n",
            "13/13 - 0s - loss: 1.4190 - accuracy: 0.4891 - val_loss: 1.7238 - val_accuracy: 0.4362 - 301ms/epoch - 23ms/step\n",
            "Epoch 25/300\n",
            "13/13 - 0s - loss: 1.4224 - accuracy: 0.4945 - val_loss: 1.6183 - val_accuracy: 0.5108 - 305ms/epoch - 23ms/step\n",
            "Epoch 26/300\n",
            "13/13 - 0s - loss: 1.4358 - accuracy: 0.4891 - val_loss: 1.6844 - val_accuracy: 0.4821 - 303ms/epoch - 23ms/step\n",
            "Epoch 27/300\n",
            "13/13 - 0s - loss: 1.4196 - accuracy: 0.4985 - val_loss: 1.5968 - val_accuracy: 0.4907 - 301ms/epoch - 23ms/step\n",
            "Epoch 28/300\n",
            "13/13 - 0s - loss: 1.3339 - accuracy: 0.5246 - val_loss: 1.7241 - val_accuracy: 0.4462 - 311ms/epoch - 24ms/step\n",
            "Epoch 29/300\n",
            "13/13 - 0s - loss: 1.3233 - accuracy: 0.5272 - val_loss: 1.6495 - val_accuracy: 0.4448 - 308ms/epoch - 24ms/step\n",
            "Epoch 30/300\n",
            "13/13 - 0s - loss: 1.2923 - accuracy: 0.5364 - val_loss: 1.6295 - val_accuracy: 0.4677 - 308ms/epoch - 24ms/step\n",
            "Epoch 31/300\n",
            "13/13 - 0s - loss: 1.2937 - accuracy: 0.5374 - val_loss: 1.6747 - val_accuracy: 0.4921 - 315ms/epoch - 24ms/step\n",
            "Epoch 32/300\n",
            "13/13 - 0s - loss: 1.2717 - accuracy: 0.5431 - val_loss: 1.6643 - val_accuracy: 0.4763 - 308ms/epoch - 24ms/step\n",
            "Epoch 33/300\n",
            "13/13 - 0s - loss: 1.2816 - accuracy: 0.5446 - val_loss: 1.5755 - val_accuracy: 0.5308 - 303ms/epoch - 23ms/step\n",
            "Epoch 34/300\n",
            "13/13 - 0s - loss: 1.2386 - accuracy: 0.5668 - val_loss: 1.5374 - val_accuracy: 0.5079 - 305ms/epoch - 23ms/step\n",
            "Epoch 35/300\n",
            "13/13 - 0s - loss: 1.2778 - accuracy: 0.5518 - val_loss: 1.6154 - val_accuracy: 0.4548 - 311ms/epoch - 24ms/step\n",
            "Epoch 36/300\n",
            "13/13 - 0s - loss: 1.2574 - accuracy: 0.5484 - val_loss: 1.4969 - val_accuracy: 0.5265 - 304ms/epoch - 23ms/step\n",
            "Epoch 37/300\n",
            "13/13 - 0s - loss: 1.2076 - accuracy: 0.5712 - val_loss: 1.5939 - val_accuracy: 0.4993 - 322ms/epoch - 25ms/step\n",
            "Epoch 38/300\n",
            "13/13 - 0s - loss: 1.2174 - accuracy: 0.5719 - val_loss: 1.6052 - val_accuracy: 0.5366 - 303ms/epoch - 23ms/step\n",
            "Epoch 39/300\n",
            "13/13 - 0s - loss: 1.3013 - accuracy: 0.5435 - val_loss: 1.6062 - val_accuracy: 0.4534 - 309ms/epoch - 24ms/step\n",
            "Epoch 40/300\n",
            "13/13 - 0s - loss: 1.2622 - accuracy: 0.5530 - val_loss: 1.5840 - val_accuracy: 0.4978 - 304ms/epoch - 23ms/step\n",
            "Epoch 41/300\n",
            "13/13 - 0s - loss: 1.2503 - accuracy: 0.5644 - val_loss: 1.6459 - val_accuracy: 0.5065 - 302ms/epoch - 23ms/step\n",
            "Epoch 42/300\n",
            "13/13 - 0s - loss: 1.2497 - accuracy: 0.5570 - val_loss: 1.7259 - val_accuracy: 0.4993 - 307ms/epoch - 24ms/step\n",
            "Epoch 43/300\n",
            "13/13 - 0s - loss: 1.2145 - accuracy: 0.5719 - val_loss: 1.5485 - val_accuracy: 0.5136 - 309ms/epoch - 24ms/step\n",
            "Epoch 44/300\n",
            "13/13 - 0s - loss: 1.2224 - accuracy: 0.5723 - val_loss: 1.5980 - val_accuracy: 0.4835 - 299ms/epoch - 23ms/step\n",
            "Epoch 45/300\n",
            "13/13 - 0s - loss: 1.1560 - accuracy: 0.5947 - val_loss: 1.4967 - val_accuracy: 0.5265 - 299ms/epoch - 23ms/step\n",
            "Epoch 46/300\n",
            "13/13 - 0s - loss: 1.1642 - accuracy: 0.5913 - val_loss: 1.5696 - val_accuracy: 0.5308 - 303ms/epoch - 23ms/step\n",
            "Epoch 47/300\n",
            "13/13 - 0s - loss: 1.2571 - accuracy: 0.5802 - val_loss: 1.4967 - val_accuracy: 0.5409 - 305ms/epoch - 23ms/step\n",
            "Epoch 48/300\n",
            "13/13 - 0s - loss: 1.2825 - accuracy: 0.5567 - val_loss: 1.5523 - val_accuracy: 0.5352 - 313ms/epoch - 24ms/step\n",
            "Epoch 49/300\n",
            "13/13 - 0s - loss: 1.2799 - accuracy: 0.5483 - val_loss: 1.6115 - val_accuracy: 0.4677 - 305ms/epoch - 23ms/step\n",
            "Epoch 50/300\n",
            "13/13 - 0s - loss: 1.2312 - accuracy: 0.5827 - val_loss: 1.4780 - val_accuracy: 0.5122 - 302ms/epoch - 23ms/step\n",
            "Epoch 51/300\n",
            "13/13 - 0s - loss: 1.1938 - accuracy: 0.5961 - val_loss: 1.6777 - val_accuracy: 0.4505 - 307ms/epoch - 24ms/step\n",
            "Epoch 52/300\n",
            "13/13 - 0s - loss: 1.2593 - accuracy: 0.5774 - val_loss: 1.5699 - val_accuracy: 0.5165 - 307ms/epoch - 24ms/step\n",
            "Epoch 53/300\n",
            "13/13 - 0s - loss: 1.1763 - accuracy: 0.5861 - val_loss: 1.5457 - val_accuracy: 0.5509 - 303ms/epoch - 23ms/step\n",
            "Epoch 54/300\n",
            "13/13 - 0s - loss: 1.1248 - accuracy: 0.6038 - val_loss: 1.5545 - val_accuracy: 0.5136 - 298ms/epoch - 23ms/step\n",
            "Epoch 55/300\n",
            "13/13 - 0s - loss: 1.1089 - accuracy: 0.6054 - val_loss: 1.6166 - val_accuracy: 0.5509 - 304ms/epoch - 23ms/step\n",
            "Epoch 56/300\n",
            "13/13 - 0s - loss: 1.0787 - accuracy: 0.6176 - val_loss: 1.5634 - val_accuracy: 0.5481 - 308ms/epoch - 24ms/step\n",
            "Epoch 57/300\n",
            "13/13 - 0s - loss: 1.1238 - accuracy: 0.6141 - val_loss: 1.5759 - val_accuracy: 0.5294 - 303ms/epoch - 23ms/step\n",
            "Epoch 58/300\n",
            "13/13 - 0s - loss: 1.1518 - accuracy: 0.5948 - val_loss: 1.5567 - val_accuracy: 0.5265 - 303ms/epoch - 23ms/step\n",
            "Epoch 59/300\n",
            "13/13 - 0s - loss: 1.1092 - accuracy: 0.6066 - val_loss: 1.5118 - val_accuracy: 0.5165 - 301ms/epoch - 23ms/step\n",
            "Epoch 60/300\n",
            "13/13 - 0s - loss: 1.0950 - accuracy: 0.6175 - val_loss: 1.5227 - val_accuracy: 0.5294 - 305ms/epoch - 23ms/step\n",
            "Epoch 61/300\n",
            "13/13 - 0s - loss: 1.0832 - accuracy: 0.6259 - val_loss: 1.5356 - val_accuracy: 0.5265 - 304ms/epoch - 23ms/step\n",
            "Epoch 62/300\n",
            "13/13 - 0s - loss: 1.0537 - accuracy: 0.6251 - val_loss: 1.5974 - val_accuracy: 0.5151 - 302ms/epoch - 23ms/step\n",
            "Epoch 63/300\n",
            "13/13 - 0s - loss: 1.0243 - accuracy: 0.6384 - val_loss: 1.6295 - val_accuracy: 0.4648 - 305ms/epoch - 23ms/step\n",
            "Epoch 64/300\n",
            "13/13 - 0s - loss: 1.1298 - accuracy: 0.6148 - val_loss: 1.4374 - val_accuracy: 0.5481 - 308ms/epoch - 24ms/step\n",
            "Epoch 65/300\n",
            "13/13 - 0s - loss: 1.1276 - accuracy: 0.6031 - val_loss: 1.5284 - val_accuracy: 0.4978 - 299ms/epoch - 23ms/step\n",
            "Epoch 66/300\n",
            "13/13 - 0s - loss: 1.1420 - accuracy: 0.5958 - val_loss: 1.8464 - val_accuracy: 0.4720 - 306ms/epoch - 24ms/step\n",
            "Epoch 67/300\n",
            "13/13 - 0s - loss: 1.0618 - accuracy: 0.6221 - val_loss: 1.6090 - val_accuracy: 0.5079 - 302ms/epoch - 23ms/step\n",
            "Epoch 68/300\n",
            "13/13 - 0s - loss: 1.0828 - accuracy: 0.6291 - val_loss: 1.6197 - val_accuracy: 0.5136 - 306ms/epoch - 24ms/step\n",
            "Epoch 69/300\n",
            "13/13 - 0s - loss: 1.1247 - accuracy: 0.6156 - val_loss: 1.5359 - val_accuracy: 0.5308 - 304ms/epoch - 23ms/step\n",
            "Epoch 70/300\n",
            "13/13 - 0s - loss: 1.1120 - accuracy: 0.6162 - val_loss: 1.6271 - val_accuracy: 0.5151 - 300ms/epoch - 23ms/step\n",
            "Epoch 71/300\n",
            "13/13 - 0s - loss: 1.2240 - accuracy: 0.6009 - val_loss: 1.6331 - val_accuracy: 0.4663 - 305ms/epoch - 23ms/step\n",
            "Epoch 72/300\n",
            "13/13 - 0s - loss: 1.1901 - accuracy: 0.5877 - val_loss: 1.5930 - val_accuracy: 0.4935 - 298ms/epoch - 23ms/step\n",
            "Epoch 73/300\n",
            "13/13 - 0s - loss: 1.1166 - accuracy: 0.6154 - val_loss: 1.7727 - val_accuracy: 0.5194 - 301ms/epoch - 23ms/step\n",
            "Epoch 74/300\n",
            "13/13 - 0s - loss: 1.1434 - accuracy: 0.6058 - val_loss: 1.5597 - val_accuracy: 0.5036 - 303ms/epoch - 23ms/step\n",
            "Epoch 75/300\n",
            "13/13 - 0s - loss: 1.1350 - accuracy: 0.6140 - val_loss: 1.5543 - val_accuracy: 0.4964 - 301ms/epoch - 23ms/step\n",
            "Epoch 76/300\n",
            "13/13 - 0s - loss: 1.1026 - accuracy: 0.6173 - val_loss: 1.5607 - val_accuracy: 0.5438 - 305ms/epoch - 23ms/step\n",
            "Epoch 77/300\n",
            "13/13 - 0s - loss: 1.0973 - accuracy: 0.6186 - val_loss: 1.6037 - val_accuracy: 0.5050 - 310ms/epoch - 24ms/step\n",
            "Epoch 78/300\n",
            "13/13 - 0s - loss: 1.0706 - accuracy: 0.6317 - val_loss: 1.4965 - val_accuracy: 0.5395 - 304ms/epoch - 23ms/step\n",
            "Epoch 79/300\n",
            "13/13 - 0s - loss: 1.1137 - accuracy: 0.6263 - val_loss: 1.5702 - val_accuracy: 0.4677 - 303ms/epoch - 23ms/step\n",
            "Epoch 80/300\n",
            "13/13 - 0s - loss: 1.1177 - accuracy: 0.6170 - val_loss: 1.5957 - val_accuracy: 0.4706 - 304ms/epoch - 23ms/step\n",
            "Epoch 81/300\n",
            "13/13 - 0s - loss: 1.0578 - accuracy: 0.6365 - val_loss: 1.6242 - val_accuracy: 0.5179 - 303ms/epoch - 23ms/step\n",
            "Epoch 82/300\n",
            "13/13 - 0s - loss: 1.0237 - accuracy: 0.6440 - val_loss: 1.6511 - val_accuracy: 0.4878 - 309ms/epoch - 24ms/step\n",
            "Epoch 83/300\n",
            "13/13 - 0s - loss: 1.0631 - accuracy: 0.6480 - val_loss: 1.6578 - val_accuracy: 0.5308 - 304ms/epoch - 23ms/step\n",
            "Epoch 84/300\n",
            "13/13 - 0s - loss: 1.1034 - accuracy: 0.6200 - val_loss: 1.5736 - val_accuracy: 0.5237 - 299ms/epoch - 23ms/step\n",
            "Epoch 85/300\n",
            "13/13 - 0s - loss: 1.0876 - accuracy: 0.6296 - val_loss: 1.5716 - val_accuracy: 0.5122 - 309ms/epoch - 24ms/step\n",
            "Epoch 86/300\n",
            "13/13 - 0s - loss: 1.0777 - accuracy: 0.6253 - val_loss: 1.5378 - val_accuracy: 0.5237 - 304ms/epoch - 23ms/step\n",
            "Epoch 87/300\n",
            "13/13 - 0s - loss: 1.0496 - accuracy: 0.6454 - val_loss: 1.6333 - val_accuracy: 0.5409 - 303ms/epoch - 23ms/step\n",
            "Epoch 88/300\n",
            "13/13 - 0s - loss: 1.0443 - accuracy: 0.6390 - val_loss: 1.6010 - val_accuracy: 0.5036 - 307ms/epoch - 24ms/step\n",
            "Epoch 89/300\n",
            "13/13 - 0s - loss: 1.1055 - accuracy: 0.6291 - val_loss: 1.4605 - val_accuracy: 0.5409 - 305ms/epoch - 23ms/step\n",
            "Epoch 90/300\n",
            "13/13 - 0s - loss: 1.0895 - accuracy: 0.6398 - val_loss: 1.9333 - val_accuracy: 0.5222 - 296ms/epoch - 23ms/step\n",
            "Epoch 91/300\n",
            "13/13 - 0s - loss: 1.0575 - accuracy: 0.6505 - val_loss: 1.7417 - val_accuracy: 0.4720 - 306ms/epoch - 24ms/step\n",
            "Epoch 92/300\n",
            "13/13 - 0s - loss: 1.0664 - accuracy: 0.6452 - val_loss: 1.6726 - val_accuracy: 0.4821 - 306ms/epoch - 24ms/step\n",
            "Epoch 93/300\n",
            "13/13 - 0s - loss: 1.0666 - accuracy: 0.6371 - val_loss: 1.5757 - val_accuracy: 0.5294 - 303ms/epoch - 23ms/step\n",
            "Epoch 94/300\n",
            "13/13 - 0s - loss: 1.0342 - accuracy: 0.6422 - val_loss: 1.6603 - val_accuracy: 0.4978 - 308ms/epoch - 24ms/step\n",
            "Epoch 95/300\n",
            "13/13 - 0s - loss: 1.1416 - accuracy: 0.6168 - val_loss: 1.8786 - val_accuracy: 0.4577 - 303ms/epoch - 23ms/step\n",
            "Epoch 96/300\n",
            "13/13 - 0s - loss: 1.1566 - accuracy: 0.6109 - val_loss: 1.6489 - val_accuracy: 0.5423 - 302ms/epoch - 23ms/step\n",
            "Epoch 97/300\n",
            "13/13 - 0s - loss: 1.1416 - accuracy: 0.6168 - val_loss: 1.7420 - val_accuracy: 0.4763 - 306ms/epoch - 24ms/step\n",
            "Epoch 98/300\n",
            "13/13 - 0s - loss: 1.1168 - accuracy: 0.6159 - val_loss: 1.5500 - val_accuracy: 0.4605 - 304ms/epoch - 23ms/step\n",
            "Epoch 99/300\n",
            "13/13 - 0s - loss: 1.0745 - accuracy: 0.6306 - val_loss: 1.6380 - val_accuracy: 0.5136 - 300ms/epoch - 23ms/step\n",
            "Epoch 100/300\n",
            "13/13 - 0s - loss: 1.1266 - accuracy: 0.6360 - val_loss: 1.8799 - val_accuracy: 0.4562 - 308ms/epoch - 24ms/step\n",
            "Epoch 101/300\n",
            "13/13 - 0s - loss: 1.1816 - accuracy: 0.6124 - val_loss: 1.9839 - val_accuracy: 0.4605 - 305ms/epoch - 23ms/step\n",
            "Epoch 102/300\n",
            "13/13 - 0s - loss: 1.1673 - accuracy: 0.5999 - val_loss: 1.7491 - val_accuracy: 0.4907 - 304ms/epoch - 23ms/step\n",
            "Epoch 103/300\n",
            "13/13 - 0s - loss: 1.1970 - accuracy: 0.6009 - val_loss: 1.7942 - val_accuracy: 0.4735 - 306ms/epoch - 24ms/step\n",
            "Epoch 104/300\n",
            "13/13 - 0s - loss: 1.1233 - accuracy: 0.6240 - val_loss: 1.8004 - val_accuracy: 0.4806 - 303ms/epoch - 23ms/step\n",
            "Epoch 105/300\n",
            "13/13 - 0s - loss: 1.1153 - accuracy: 0.6258 - val_loss: 1.8417 - val_accuracy: 0.4763 - 301ms/epoch - 23ms/step\n",
            "Epoch 106/300\n",
            "13/13 - 0s - loss: 1.0888 - accuracy: 0.6196 - val_loss: 1.6913 - val_accuracy: 0.5194 - 300ms/epoch - 23ms/step\n",
            "Epoch 107/300\n",
            "13/13 - 0s - loss: 1.0127 - accuracy: 0.6532 - val_loss: 1.8014 - val_accuracy: 0.5265 - 311ms/epoch - 24ms/step\n",
            "Epoch 108/300\n",
            "13/13 - 0s - loss: 1.0263 - accuracy: 0.6583 - val_loss: 1.7495 - val_accuracy: 0.5265 - 305ms/epoch - 23ms/step\n",
            "Epoch 109/300\n",
            "13/13 - 0s - loss: 1.0176 - accuracy: 0.6427 - val_loss: 1.7149 - val_accuracy: 0.5093 - 302ms/epoch - 23ms/step\n",
            "Epoch 110/300\n",
            "13/13 - 0s - loss: 1.0257 - accuracy: 0.6524 - val_loss: 1.6669 - val_accuracy: 0.5438 - 307ms/epoch - 24ms/step\n",
            "Epoch 111/300\n",
            "13/13 - 0s - loss: 1.1516 - accuracy: 0.6170 - val_loss: 1.7888 - val_accuracy: 0.4993 - 301ms/epoch - 23ms/step\n",
            "Epoch 112/300\n",
            "13/13 - 0s - loss: 1.1754 - accuracy: 0.6186 - val_loss: 2.0129 - val_accuracy: 0.4505 - 298ms/epoch - 23ms/step\n",
            "Epoch 113/300\n",
            "13/13 - 0s - loss: 1.1070 - accuracy: 0.6374 - val_loss: 1.8179 - val_accuracy: 0.4204 - 305ms/epoch - 23ms/step\n",
            "Epoch 114/300\n",
            "13/13 - 0s - loss: 1.1571 - accuracy: 0.6108 - val_loss: 1.6962 - val_accuracy: 0.4648 - 305ms/epoch - 23ms/step\n",
            "Epoch 115/300\n",
            "13/13 - 0s - loss: 1.1651 - accuracy: 0.6022 - val_loss: 1.5538 - val_accuracy: 0.5065 - 300ms/epoch - 23ms/step\n",
            "Epoch 116/300\n",
            "13/13 - 0s - loss: 1.1063 - accuracy: 0.6322 - val_loss: 1.5279 - val_accuracy: 0.5050 - 303ms/epoch - 23ms/step\n",
            "Epoch 117/300\n",
            "13/13 - 0s - loss: 1.1340 - accuracy: 0.6280 - val_loss: 1.5273 - val_accuracy: 0.5208 - 307ms/epoch - 24ms/step\n",
            "Epoch 118/300\n",
            "13/13 - 0s - loss: 1.0468 - accuracy: 0.6420 - val_loss: 1.6273 - val_accuracy: 0.5308 - 313ms/epoch - 24ms/step\n",
            "Epoch 119/300\n",
            "13/13 - 0s - loss: 1.1140 - accuracy: 0.6400 - val_loss: 1.5506 - val_accuracy: 0.5079 - 312ms/epoch - 24ms/step\n",
            "Epoch 120/300\n",
            "13/13 - 0s - loss: 1.0787 - accuracy: 0.6234 - val_loss: 1.5419 - val_accuracy: 0.5036 - 306ms/epoch - 24ms/step\n",
            "Epoch 121/300\n",
            "13/13 - 0s - loss: 1.0435 - accuracy: 0.6365 - val_loss: 1.5585 - val_accuracy: 0.4907 - 311ms/epoch - 24ms/step\n",
            "Epoch 122/300\n",
            "13/13 - 0s - loss: 1.0171 - accuracy: 0.6582 - val_loss: 1.5997 - val_accuracy: 0.4892 - 311ms/epoch - 24ms/step\n",
            "Epoch 123/300\n",
            "13/13 - 0s - loss: 0.9764 - accuracy: 0.6518 - val_loss: 1.5386 - val_accuracy: 0.5122 - 311ms/epoch - 24ms/step\n",
            "Epoch 124/300\n",
            "13/13 - 0s - loss: 0.9737 - accuracy: 0.6594 - val_loss: 1.6040 - val_accuracy: 0.5395 - 315ms/epoch - 24ms/step\n",
            "Epoch 125/300\n",
            "13/13 - 0s - loss: 0.9675 - accuracy: 0.6677 - val_loss: 1.5804 - val_accuracy: 0.5466 - 309ms/epoch - 24ms/step\n",
            "Epoch 126/300\n",
            "13/13 - 0s - loss: 0.9902 - accuracy: 0.6583 - val_loss: 1.6320 - val_accuracy: 0.5294 - 304ms/epoch - 23ms/step\n",
            "Epoch 127/300\n",
            "13/13 - 0s - loss: 0.9659 - accuracy: 0.6523 - val_loss: 1.8098 - val_accuracy: 0.5208 - 310ms/epoch - 24ms/step\n",
            "Epoch 128/300\n",
            "13/13 - 0s - loss: 0.9862 - accuracy: 0.6700 - val_loss: 1.7130 - val_accuracy: 0.5251 - 307ms/epoch - 24ms/step\n",
            "Epoch 129/300\n",
            "13/13 - 0s - loss: 1.0551 - accuracy: 0.6502 - val_loss: 1.5738 - val_accuracy: 0.4921 - 298ms/epoch - 23ms/step\n",
            "Epoch 130/300\n",
            "13/13 - 0s - loss: 1.0211 - accuracy: 0.6500 - val_loss: 1.6150 - val_accuracy: 0.4835 - 309ms/epoch - 24ms/step\n",
            "Epoch 131/300\n",
            "13/13 - 0s - loss: 1.0476 - accuracy: 0.6387 - val_loss: 1.6025 - val_accuracy: 0.5108 - 304ms/epoch - 23ms/step\n",
            "Epoch 132/300\n",
            "13/13 - 0s - loss: 1.0128 - accuracy: 0.6492 - val_loss: 1.6816 - val_accuracy: 0.5065 - 311ms/epoch - 24ms/step\n",
            "Epoch 133/300\n",
            "13/13 - 0s - loss: 0.9788 - accuracy: 0.6553 - val_loss: 1.9419 - val_accuracy: 0.4476 - 310ms/epoch - 24ms/step\n",
            "Epoch 134/300\n",
            "13/13 - 0s - loss: 0.9599 - accuracy: 0.6642 - val_loss: 1.6900 - val_accuracy: 0.5237 - 306ms/epoch - 24ms/step\n",
            "Epoch 135/300\n",
            "13/13 - 0s - loss: 1.0466 - accuracy: 0.6346 - val_loss: 1.7098 - val_accuracy: 0.5007 - 305ms/epoch - 23ms/step\n",
            "Epoch 136/300\n",
            "13/13 - 0s - loss: 0.9653 - accuracy: 0.6556 - val_loss: 1.7860 - val_accuracy: 0.5265 - 315ms/epoch - 24ms/step\n",
            "Epoch 137/300\n",
            "13/13 - 0s - loss: 0.9168 - accuracy: 0.6757 - val_loss: 2.1282 - val_accuracy: 0.4835 - 312ms/epoch - 24ms/step\n",
            "Epoch 138/300\n",
            "13/13 - 0s - loss: 0.8944 - accuracy: 0.6835 - val_loss: 2.0551 - val_accuracy: 0.5423 - 310ms/epoch - 24ms/step\n",
            "Epoch 139/300\n",
            "13/13 - 0s - loss: 0.9312 - accuracy: 0.6845 - val_loss: 2.0236 - val_accuracy: 0.4964 - 304ms/epoch - 23ms/step\n",
            "Epoch 140/300\n",
            "13/13 - 0s - loss: 0.9735 - accuracy: 0.6588 - val_loss: 1.9776 - val_accuracy: 0.5308 - 303ms/epoch - 23ms/step\n",
            "Epoch 141/300\n",
            "13/13 - 0s - loss: 0.8994 - accuracy: 0.6834 - val_loss: 1.8262 - val_accuracy: 0.5337 - 304ms/epoch - 23ms/step\n",
            "Epoch 142/300\n",
            "13/13 - 0s - loss: 0.9272 - accuracy: 0.6743 - val_loss: 1.7641 - val_accuracy: 0.4792 - 318ms/epoch - 24ms/step\n",
            "Epoch 143/300\n",
            "13/13 - 0s - loss: 1.0122 - accuracy: 0.6712 - val_loss: 2.0065 - val_accuracy: 0.4878 - 310ms/epoch - 24ms/step\n",
            "Epoch 144/300\n",
            "13/13 - 0s - loss: 1.0494 - accuracy: 0.6519 - val_loss: 2.0899 - val_accuracy: 0.5409 - 312ms/epoch - 24ms/step\n",
            "Epoch 145/300\n",
            "13/13 - 0s - loss: 1.0244 - accuracy: 0.6665 - val_loss: 1.8813 - val_accuracy: 0.5108 - 311ms/epoch - 24ms/step\n",
            "Epoch 146/300\n",
            "13/13 - 0s - loss: 1.0399 - accuracy: 0.6548 - val_loss: 1.6920 - val_accuracy: 0.5007 - 303ms/epoch - 23ms/step\n",
            "Epoch 147/300\n",
            "13/13 - 0s - loss: 0.9531 - accuracy: 0.6690 - val_loss: 1.6691 - val_accuracy: 0.5065 - 314ms/epoch - 24ms/step\n",
            "Epoch 148/300\n",
            "13/13 - 0s - loss: 0.9372 - accuracy: 0.6811 - val_loss: 1.7857 - val_accuracy: 0.5007 - 308ms/epoch - 24ms/step\n",
            "Epoch 149/300\n",
            "13/13 - 0s - loss: 0.9964 - accuracy: 0.6572 - val_loss: 1.7847 - val_accuracy: 0.4950 - 312ms/epoch - 24ms/step\n",
            "Epoch 150/300\n",
            "13/13 - 0s - loss: 0.9213 - accuracy: 0.6813 - val_loss: 1.9595 - val_accuracy: 0.5022 - 309ms/epoch - 24ms/step\n",
            "Epoch 151/300\n",
            "13/13 - 0s - loss: 0.9265 - accuracy: 0.6866 - val_loss: 1.9704 - val_accuracy: 0.5208 - 301ms/epoch - 23ms/step\n",
            "Epoch 152/300\n",
            "13/13 - 0s - loss: 0.9944 - accuracy: 0.6602 - val_loss: 2.0054 - val_accuracy: 0.5208 - 304ms/epoch - 23ms/step\n",
            "Epoch 153/300\n",
            "13/13 - 0s - loss: 0.9241 - accuracy: 0.6727 - val_loss: 1.9709 - val_accuracy: 0.5337 - 305ms/epoch - 23ms/step\n",
            "Epoch 154/300\n",
            "13/13 - 0s - loss: 0.9035 - accuracy: 0.6874 - val_loss: 2.1273 - val_accuracy: 0.4978 - 307ms/epoch - 24ms/step\n",
            "Epoch 155/300\n",
            "13/13 - 0s - loss: 0.9450 - accuracy: 0.6913 - val_loss: 1.7095 - val_accuracy: 0.5122 - 305ms/epoch - 23ms/step\n",
            "Epoch 156/300\n",
            "13/13 - 0s - loss: 0.9699 - accuracy: 0.6799 - val_loss: 1.6688 - val_accuracy: 0.4735 - 311ms/epoch - 24ms/step\n",
            "Epoch 157/300\n",
            "13/13 - 0s - loss: 0.9549 - accuracy: 0.6813 - val_loss: 1.7951 - val_accuracy: 0.4978 - 308ms/epoch - 24ms/step\n",
            "Epoch 158/300\n",
            "13/13 - 0s - loss: 0.8912 - accuracy: 0.6901 - val_loss: 1.9265 - val_accuracy: 0.5308 - 304ms/epoch - 23ms/step\n",
            "Epoch 159/300\n",
            "13/13 - 0s - loss: 0.9445 - accuracy: 0.6657 - val_loss: 1.9514 - val_accuracy: 0.4935 - 309ms/epoch - 24ms/step\n",
            "Epoch 160/300\n",
            "13/13 - 0s - loss: 0.9470 - accuracy: 0.6696 - val_loss: 2.4218 - val_accuracy: 0.5136 - 328ms/epoch - 25ms/step\n",
            "Epoch 161/300\n",
            "13/13 - 0s - loss: 0.9916 - accuracy: 0.6703 - val_loss: 2.5887 - val_accuracy: 0.4605 - 310ms/epoch - 24ms/step\n",
            "Epoch 162/300\n",
            "13/13 - 0s - loss: 0.9185 - accuracy: 0.6846 - val_loss: 1.8517 - val_accuracy: 0.4935 - 311ms/epoch - 24ms/step\n",
            "Epoch 163/300\n",
            "13/13 - 0s - loss: 0.8555 - accuracy: 0.6963 - val_loss: 1.9754 - val_accuracy: 0.5050 - 311ms/epoch - 24ms/step\n",
            "Epoch 164/300\n",
            "13/13 - 0s - loss: 0.8565 - accuracy: 0.6998 - val_loss: 1.7254 - val_accuracy: 0.5466 - 310ms/epoch - 24ms/step\n",
            "Epoch 165/300\n",
            "13/13 - 0s - loss: 0.9139 - accuracy: 0.6891 - val_loss: 1.9272 - val_accuracy: 0.5079 - 305ms/epoch - 23ms/step\n",
            "Epoch 166/300\n",
            "13/13 - 0s - loss: 0.8977 - accuracy: 0.6960 - val_loss: 1.6811 - val_accuracy: 0.4950 - 304ms/epoch - 23ms/step\n",
            "Epoch 167/300\n",
            "13/13 - 0s - loss: 0.9153 - accuracy: 0.6851 - val_loss: 1.9341 - val_accuracy: 0.5093 - 310ms/epoch - 24ms/step\n",
            "Epoch 168/300\n",
            "13/13 - 0s - loss: 0.8700 - accuracy: 0.7030 - val_loss: 1.7280 - val_accuracy: 0.4849 - 309ms/epoch - 24ms/step\n",
            "Epoch 169/300\n",
            "13/13 - 0s - loss: 0.9180 - accuracy: 0.6870 - val_loss: 1.5787 - val_accuracy: 0.4692 - 304ms/epoch - 23ms/step\n",
            "Epoch 170/300\n",
            "13/13 - 0s - loss: 0.9122 - accuracy: 0.6885 - val_loss: 1.7318 - val_accuracy: 0.5308 - 307ms/epoch - 24ms/step\n",
            "Epoch 171/300\n",
            "13/13 - 0s - loss: 0.8727 - accuracy: 0.6956 - val_loss: 1.6620 - val_accuracy: 0.5093 - 308ms/epoch - 24ms/step\n",
            "Epoch 172/300\n",
            "13/13 - 0s - loss: 0.9262 - accuracy: 0.6899 - val_loss: 1.7845 - val_accuracy: 0.5509 - 310ms/epoch - 24ms/step\n",
            "Epoch 173/300\n",
            "13/13 - 0s - loss: 0.8869 - accuracy: 0.6883 - val_loss: 1.6807 - val_accuracy: 0.5079 - 312ms/epoch - 24ms/step\n",
            "Epoch 174/300\n",
            "13/13 - 0s - loss: 0.9061 - accuracy: 0.6848 - val_loss: 1.9426 - val_accuracy: 0.5022 - 309ms/epoch - 24ms/step\n",
            "Epoch 175/300\n",
            "13/13 - 0s - loss: 1.0649 - accuracy: 0.6390 - val_loss: 1.8404 - val_accuracy: 0.4821 - 309ms/epoch - 24ms/step\n",
            "Epoch 176/300\n",
            "13/13 - 0s - loss: 1.0135 - accuracy: 0.6428 - val_loss: 1.7867 - val_accuracy: 0.4892 - 302ms/epoch - 23ms/step\n",
            "Epoch 177/300\n",
            "13/13 - 0s - loss: 0.9265 - accuracy: 0.6799 - val_loss: 1.7642 - val_accuracy: 0.5423 - 305ms/epoch - 23ms/step\n",
            "Epoch 178/300\n",
            "13/13 - 0s - loss: 0.9146 - accuracy: 0.6827 - val_loss: 1.6518 - val_accuracy: 0.5294 - 303ms/epoch - 23ms/step\n",
            "Epoch 179/300\n",
            "13/13 - 0s - loss: 0.9026 - accuracy: 0.6814 - val_loss: 1.8749 - val_accuracy: 0.4849 - 305ms/epoch - 23ms/step\n",
            "Epoch 180/300\n",
            "13/13 - 0s - loss: 0.9444 - accuracy: 0.6775 - val_loss: 1.9141 - val_accuracy: 0.5065 - 313ms/epoch - 24ms/step\n",
            "Epoch 181/300\n",
            "13/13 - 0s - loss: 1.0023 - accuracy: 0.6837 - val_loss: 1.7985 - val_accuracy: 0.5208 - 302ms/epoch - 23ms/step\n",
            "Epoch 182/300\n",
            "13/13 - 0s - loss: 1.0993 - accuracy: 0.6598 - val_loss: 1.5475 - val_accuracy: 0.5222 - 307ms/epoch - 24ms/step\n",
            "Epoch 183/300\n",
            "13/13 - 0s - loss: 1.0475 - accuracy: 0.6575 - val_loss: 2.5262 - val_accuracy: 0.4792 - 305ms/epoch - 23ms/step\n",
            "Epoch 184/300\n",
            "13/13 - 0s - loss: 1.4093 - accuracy: 0.5778 - val_loss: 1.7175 - val_accuracy: 0.4390 - 306ms/epoch - 24ms/step\n",
            "Epoch 185/300\n",
            "13/13 - 0s - loss: 1.5402 - accuracy: 0.4996 - val_loss: 1.7120 - val_accuracy: 0.4060 - 314ms/epoch - 24ms/step\n",
            "Epoch 186/300\n",
            "13/13 - 0s - loss: 1.5008 - accuracy: 0.5023 - val_loss: 2.9347 - val_accuracy: 0.4060 - 315ms/epoch - 24ms/step\n",
            "Epoch 187/300\n",
            "13/13 - 0s - loss: 1.3994 - accuracy: 0.5144 - val_loss: 2.9109 - val_accuracy: 0.4749 - 316ms/epoch - 24ms/step\n",
            "Epoch 188/300\n",
            "13/13 - 0s - loss: 1.4476 - accuracy: 0.5124 - val_loss: 1.7105 - val_accuracy: 0.4792 - 316ms/epoch - 24ms/step\n",
            "Epoch 189/300\n",
            "13/13 - 0s - loss: 1.4241 - accuracy: 0.5074 - val_loss: 1.7276 - val_accuracy: 0.4448 - 314ms/epoch - 24ms/step\n",
            "Epoch 190/300\n",
            "13/13 - 0s - loss: 1.4743 - accuracy: 0.4873 - val_loss: 1.8344 - val_accuracy: 0.4146 - 311ms/epoch - 24ms/step\n",
            "Epoch 191/300\n",
            "13/13 - 0s - loss: 1.3360 - accuracy: 0.5248 - val_loss: 1.9572 - val_accuracy: 0.4261 - 310ms/epoch - 24ms/step\n",
            "Epoch 192/300\n",
            "13/13 - 0s - loss: 1.4901 - accuracy: 0.5572 - val_loss: 1.8588 - val_accuracy: 0.4290 - 311ms/epoch - 24ms/step\n",
            "Epoch 193/300\n",
            "13/13 - 0s - loss: 1.3023 - accuracy: 0.5470 - val_loss: 1.7322 - val_accuracy: 0.4003 - 300ms/epoch - 23ms/step\n",
            "Epoch 194/300\n",
            "13/13 - 0s - loss: 1.2838 - accuracy: 0.5594 - val_loss: 1.8376 - val_accuracy: 0.4103 - 308ms/epoch - 24ms/step\n",
            "Epoch 195/300\n",
            "13/13 - 0s - loss: 1.2880 - accuracy: 0.5746 - val_loss: 1.7593 - val_accuracy: 0.4448 - 315ms/epoch - 24ms/step\n",
            "Epoch 196/300\n",
            "13/13 - 0s - loss: 1.2391 - accuracy: 0.5762 - val_loss: 2.3012 - val_accuracy: 0.4362 - 305ms/epoch - 23ms/step\n",
            "Epoch 197/300\n",
            "13/13 - 0s - loss: 1.2421 - accuracy: 0.5795 - val_loss: 2.0940 - val_accuracy: 0.4261 - 300ms/epoch - 23ms/step\n",
            "Epoch 198/300\n",
            "13/13 - 0s - loss: 1.2467 - accuracy: 0.5959 - val_loss: 2.2281 - val_accuracy: 0.4706 - 304ms/epoch - 23ms/step\n",
            "Epoch 199/300\n",
            "13/13 - 0s - loss: 1.2213 - accuracy: 0.5843 - val_loss: 2.7249 - val_accuracy: 0.4677 - 313ms/epoch - 24ms/step\n",
            "Epoch 200/300\n",
            "13/13 - 0s - loss: 1.1690 - accuracy: 0.6030 - val_loss: 2.4778 - val_accuracy: 0.4405 - 302ms/epoch - 23ms/step\n",
            "Epoch 201/300\n",
            "13/13 - 0s - loss: 1.2572 - accuracy: 0.5800 - val_loss: 1.7668 - val_accuracy: 0.4735 - 309ms/epoch - 24ms/step\n",
            "Epoch 202/300\n",
            "13/13 - 0s - loss: 1.3006 - accuracy: 0.5782 - val_loss: 4.2361 - val_accuracy: 0.4620 - 305ms/epoch - 23ms/step\n",
            "Epoch 203/300\n",
            "13/13 - 0s - loss: 1.2575 - accuracy: 0.5795 - val_loss: 3.3824 - val_accuracy: 0.4261 - 307ms/epoch - 24ms/step\n",
            "Epoch 204/300\n",
            "13/13 - 0s - loss: 1.3012 - accuracy: 0.5645 - val_loss: 2.1330 - val_accuracy: 0.3831 - 310ms/epoch - 24ms/step\n",
            "Epoch 205/300\n",
            "13/13 - 0s - loss: 1.2541 - accuracy: 0.5853 - val_loss: 2.4385 - val_accuracy: 0.4921 - 312ms/epoch - 24ms/step\n",
            "Epoch 206/300\n",
            "13/13 - 0s - loss: 1.2291 - accuracy: 0.5856 - val_loss: 2.4118 - val_accuracy: 0.4835 - 310ms/epoch - 24ms/step\n",
            "Epoch 207/300\n",
            "13/13 - 0s - loss: 1.2117 - accuracy: 0.6017 - val_loss: 2.6073 - val_accuracy: 0.4634 - 302ms/epoch - 23ms/step\n",
            "Epoch 208/300\n",
            "13/13 - 0s - loss: 1.1954 - accuracy: 0.6015 - val_loss: 2.8311 - val_accuracy: 0.4376 - 309ms/epoch - 24ms/step\n",
            "Epoch 209/300\n",
            "13/13 - 0s - loss: 1.1277 - accuracy: 0.6191 - val_loss: 3.9645 - val_accuracy: 0.4864 - 304ms/epoch - 23ms/step\n",
            "Epoch 210/300\n",
            "13/13 - 0s - loss: 1.1260 - accuracy: 0.6093 - val_loss: 4.0664 - val_accuracy: 0.4878 - 311ms/epoch - 24ms/step\n",
            "Epoch 211/300\n",
            "13/13 - 0s - loss: 1.1097 - accuracy: 0.6143 - val_loss: 3.9521 - val_accuracy: 0.4562 - 307ms/epoch - 24ms/step\n",
            "Epoch 212/300\n",
            "13/13 - 0s - loss: 1.1324 - accuracy: 0.6168 - val_loss: 2.1598 - val_accuracy: 0.4792 - 304ms/epoch - 23ms/step\n",
            "Epoch 213/300\n",
            "13/13 - 0s - loss: 1.1018 - accuracy: 0.6333 - val_loss: 3.0443 - val_accuracy: 0.4620 - 302ms/epoch - 23ms/step\n",
            "Epoch 214/300\n",
            "13/13 - 0s - loss: 1.0782 - accuracy: 0.6148 - val_loss: 2.6817 - val_accuracy: 0.4677 - 310ms/epoch - 24ms/step\n",
            "Epoch 215/300\n",
            "13/13 - 0s - loss: 1.0765 - accuracy: 0.6322 - val_loss: 1.6736 - val_accuracy: 0.4964 - 308ms/epoch - 24ms/step\n",
            "Epoch 216/300\n",
            "13/13 - 0s - loss: 1.0985 - accuracy: 0.6205 - val_loss: 1.7366 - val_accuracy: 0.5308 - 307ms/epoch - 24ms/step\n",
            "Epoch 217/300\n",
            "13/13 - 0s - loss: 0.9718 - accuracy: 0.6535 - val_loss: 1.7939 - val_accuracy: 0.5481 - 311ms/epoch - 24ms/step\n",
            "Epoch 218/300\n",
            "13/13 - 0s - loss: 0.9948 - accuracy: 0.6534 - val_loss: 2.8282 - val_accuracy: 0.5395 - 314ms/epoch - 24ms/step\n",
            "Epoch 219/300\n",
            "13/13 - 0s - loss: 0.9982 - accuracy: 0.6570 - val_loss: 3.8988 - val_accuracy: 0.5122 - 315ms/epoch - 24ms/step\n",
            "Epoch 220/300\n",
            "13/13 - 0s - loss: 1.0018 - accuracy: 0.6665 - val_loss: 5.1631 - val_accuracy: 0.5409 - 306ms/epoch - 24ms/step\n",
            "Epoch 221/300\n",
            "13/13 - 0s - loss: 0.9825 - accuracy: 0.6700 - val_loss: 3.6843 - val_accuracy: 0.5108 - 305ms/epoch - 23ms/step\n",
            "Epoch 222/300\n",
            "13/13 - 0s - loss: 1.1308 - accuracy: 0.6149 - val_loss: 1.8453 - val_accuracy: 0.4950 - 312ms/epoch - 24ms/step\n",
            "Epoch 223/300\n",
            "13/13 - 0s - loss: 1.0701 - accuracy: 0.6306 - val_loss: 2.0373 - val_accuracy: 0.5050 - 310ms/epoch - 24ms/step\n",
            "Epoch 224/300\n",
            "13/13 - 0s - loss: 1.1942 - accuracy: 0.6339 - val_loss: 2.0780 - val_accuracy: 0.4849 - 306ms/epoch - 24ms/step\n",
            "Epoch 225/300\n",
            "13/13 - 0s - loss: 1.1005 - accuracy: 0.6191 - val_loss: 2.1694 - val_accuracy: 0.4304 - 304ms/epoch - 23ms/step\n",
            "Epoch 226/300\n",
            "13/13 - 0s - loss: 1.0915 - accuracy: 0.6250 - val_loss: 2.4313 - val_accuracy: 0.4964 - 313ms/epoch - 24ms/step\n",
            "Epoch 227/300\n",
            "13/13 - 0s - loss: 1.0377 - accuracy: 0.6366 - val_loss: 2.6536 - val_accuracy: 0.4433 - 313ms/epoch - 24ms/step\n",
            "Epoch 228/300\n",
            "13/13 - 0s - loss: 1.0149 - accuracy: 0.6543 - val_loss: 2.7684 - val_accuracy: 0.4118 - 305ms/epoch - 23ms/step\n",
            "Epoch 229/300\n",
            "13/13 - 0s - loss: 1.0224 - accuracy: 0.6419 - val_loss: 2.5323 - val_accuracy: 0.4333 - 304ms/epoch - 23ms/step\n",
            "Epoch 230/300\n",
            "13/13 - 0s - loss: 0.9806 - accuracy: 0.6566 - val_loss: 3.2715 - val_accuracy: 0.4591 - 301ms/epoch - 23ms/step\n",
            "Epoch 231/300\n",
            "13/13 - 0s - loss: 0.9872 - accuracy: 0.6532 - val_loss: 3.1973 - val_accuracy: 0.4878 - 292ms/epoch - 22ms/step\n",
            "Epoch 232/300\n",
            "13/13 - 0s - loss: 0.9354 - accuracy: 0.6714 - val_loss: 3.0451 - val_accuracy: 0.4978 - 297ms/epoch - 23ms/step\n",
            "Epoch 233/300\n",
            "13/13 - 0s - loss: 0.9747 - accuracy: 0.6653 - val_loss: 2.8331 - val_accuracy: 0.4792 - 311ms/epoch - 24ms/step\n",
            "Epoch 234/300\n",
            "13/13 - 0s - loss: 1.0132 - accuracy: 0.6679 - val_loss: 1.7812 - val_accuracy: 0.5208 - 308ms/epoch - 24ms/step\n",
            "Epoch 235/300\n",
            "13/13 - 0s - loss: 0.9592 - accuracy: 0.6629 - val_loss: 2.4955 - val_accuracy: 0.5065 - 302ms/epoch - 23ms/step\n",
            "Epoch 236/300\n",
            "13/13 - 0s - loss: 0.9323 - accuracy: 0.6792 - val_loss: 2.6847 - val_accuracy: 0.5452 - 305ms/epoch - 23ms/step\n",
            "Epoch 237/300\n",
            "13/13 - 0s - loss: 0.9340 - accuracy: 0.6744 - val_loss: 2.4098 - val_accuracy: 0.5136 - 307ms/epoch - 24ms/step\n",
            "Epoch 238/300\n",
            "13/13 - 0s - loss: 0.8920 - accuracy: 0.6846 - val_loss: 2.3719 - val_accuracy: 0.5007 - 301ms/epoch - 23ms/step\n",
            "Epoch 239/300\n",
            "13/13 - 0s - loss: 0.9306 - accuracy: 0.6765 - val_loss: 2.7730 - val_accuracy: 0.5265 - 306ms/epoch - 24ms/step\n",
            "Epoch 240/300\n",
            "13/13 - 0s - loss: 1.0243 - accuracy: 0.6623 - val_loss: 2.6805 - val_accuracy: 0.4964 - 308ms/epoch - 24ms/step\n",
            "Epoch 241/300\n",
            "13/13 - 0s - loss: 1.1541 - accuracy: 0.6422 - val_loss: 3.1091 - val_accuracy: 0.4735 - 308ms/epoch - 24ms/step\n",
            "Epoch 242/300\n",
            "13/13 - 0s - loss: 1.2133 - accuracy: 0.6259 - val_loss: 1.7103 - val_accuracy: 0.4978 - 310ms/epoch - 24ms/step\n",
            "Epoch 243/300\n",
            "13/13 - 0s - loss: 1.1762 - accuracy: 0.6353 - val_loss: 1.9686 - val_accuracy: 0.4821 - 310ms/epoch - 24ms/step\n",
            "Epoch 244/300\n",
            "13/13 - 0s - loss: 1.0193 - accuracy: 0.6612 - val_loss: 1.9751 - val_accuracy: 0.4735 - 306ms/epoch - 24ms/step\n",
            "Epoch 245/300\n",
            "13/13 - 0s - loss: 1.0712 - accuracy: 0.6452 - val_loss: 2.0756 - val_accuracy: 0.4534 - 304ms/epoch - 23ms/step\n",
            "Epoch 246/300\n",
            "13/13 - 0s - loss: 1.0762 - accuracy: 0.6381 - val_loss: 2.8574 - val_accuracy: 0.4519 - 306ms/epoch - 24ms/step\n",
            "Epoch 247/300\n",
            "13/13 - 0s - loss: 1.0303 - accuracy: 0.6521 - val_loss: 2.6849 - val_accuracy: 0.4907 - 307ms/epoch - 24ms/step\n",
            "Epoch 248/300\n",
            "13/13 - 0s - loss: 1.0479 - accuracy: 0.6464 - val_loss: 2.1046 - val_accuracy: 0.4964 - 308ms/epoch - 24ms/step\n",
            "Epoch 249/300\n",
            "13/13 - 0s - loss: 1.0311 - accuracy: 0.6521 - val_loss: 1.8106 - val_accuracy: 0.4763 - 314ms/epoch - 24ms/step\n",
            "Epoch 250/300\n",
            "13/13 - 0s - loss: 0.9679 - accuracy: 0.6634 - val_loss: 2.4507 - val_accuracy: 0.4548 - 305ms/epoch - 23ms/step\n",
            "Epoch 251/300\n",
            "13/13 - 0s - loss: 0.9899 - accuracy: 0.6741 - val_loss: 3.1659 - val_accuracy: 0.4577 - 306ms/epoch - 24ms/step\n",
            "Epoch 252/300\n",
            "13/13 - 0s - loss: 1.0636 - accuracy: 0.6500 - val_loss: 2.4559 - val_accuracy: 0.4577 - 305ms/epoch - 23ms/step\n",
            "Epoch 253/300\n",
            "13/13 - 0s - loss: 1.1495 - accuracy: 0.6315 - val_loss: 2.0762 - val_accuracy: 0.4878 - 309ms/epoch - 24ms/step\n",
            "Epoch 254/300\n",
            "13/13 - 0s - loss: 1.1203 - accuracy: 0.6180 - val_loss: 1.7441 - val_accuracy: 0.4634 - 314ms/epoch - 24ms/step\n",
            "Epoch 255/300\n",
            "13/13 - 0s - loss: 1.1558 - accuracy: 0.5928 - val_loss: 2.0285 - val_accuracy: 0.4247 - 320ms/epoch - 25ms/step\n",
            "Epoch 256/300\n",
            "13/13 - 0s - loss: 1.1882 - accuracy: 0.5864 - val_loss: 2.0152 - val_accuracy: 0.4476 - 312ms/epoch - 24ms/step\n",
            "Epoch 257/300\n",
            "13/13 - 0s - loss: 1.2085 - accuracy: 0.6026 - val_loss: 2.7388 - val_accuracy: 0.4247 - 307ms/epoch - 24ms/step\n",
            "Epoch 258/300\n",
            "13/13 - 0s - loss: 1.2445 - accuracy: 0.6135 - val_loss: 1.9541 - val_accuracy: 0.4017 - 303ms/epoch - 23ms/step\n",
            "Epoch 259/300\n",
            "13/13 - 0s - loss: 1.2137 - accuracy: 0.5996 - val_loss: 1.8672 - val_accuracy: 0.4763 - 303ms/epoch - 23ms/step\n",
            "Epoch 260/300\n",
            "13/13 - 0s - loss: 1.1474 - accuracy: 0.5987 - val_loss: 2.2794 - val_accuracy: 0.4462 - 301ms/epoch - 23ms/step\n",
            "Epoch 261/300\n",
            "13/13 - 0s - loss: 1.0668 - accuracy: 0.6283 - val_loss: 2.1756 - val_accuracy: 0.5050 - 309ms/epoch - 24ms/step\n",
            "Epoch 262/300\n",
            "13/13 - 0s - loss: 1.1679 - accuracy: 0.6208 - val_loss: 2.4999 - val_accuracy: 0.3989 - 310ms/epoch - 24ms/step\n",
            "Epoch 263/300\n",
            "13/13 - 0s - loss: 1.1971 - accuracy: 0.5974 - val_loss: 2.1679 - val_accuracy: 0.4075 - 307ms/epoch - 24ms/step\n",
            "Epoch 264/300\n",
            "13/13 - 0s - loss: 1.1639 - accuracy: 0.5996 - val_loss: 2.4076 - val_accuracy: 0.4620 - 303ms/epoch - 23ms/step\n",
            "Epoch 265/300\n",
            "13/13 - 0s - loss: 1.1425 - accuracy: 0.6076 - val_loss: 2.0536 - val_accuracy: 0.4161 - 309ms/epoch - 24ms/step\n",
            "Epoch 266/300\n",
            "13/13 - 0s - loss: 1.0795 - accuracy: 0.6267 - val_loss: 1.7797 - val_accuracy: 0.4405 - 309ms/epoch - 24ms/step\n",
            "Epoch 267/300\n",
            "13/13 - 0s - loss: 1.1328 - accuracy: 0.6140 - val_loss: 1.9004 - val_accuracy: 0.4749 - 316ms/epoch - 24ms/step\n",
            "Epoch 268/300\n",
            "13/13 - 0s - loss: 1.0984 - accuracy: 0.6100 - val_loss: 1.9999 - val_accuracy: 0.4835 - 310ms/epoch - 24ms/step\n",
            "Epoch 269/300\n",
            "13/13 - 0s - loss: 1.0583 - accuracy: 0.6293 - val_loss: 2.0555 - val_accuracy: 0.4778 - 311ms/epoch - 24ms/step\n",
            "Epoch 270/300\n",
            "13/13 - 0s - loss: 1.3255 - accuracy: 0.6342 - val_loss: 2.5415 - val_accuracy: 0.4663 - 311ms/epoch - 24ms/step\n",
            "Epoch 271/300\n",
            "13/13 - 0s - loss: 1.1313 - accuracy: 0.6232 - val_loss: 2.4889 - val_accuracy: 0.4806 - 308ms/epoch - 24ms/step\n",
            "Epoch 272/300\n",
            "13/13 - 0s - loss: 1.0724 - accuracy: 0.6183 - val_loss: 2.2353 - val_accuracy: 0.4864 - 308ms/epoch - 24ms/step\n",
            "Epoch 273/300\n",
            "13/13 - 0s - loss: 1.0890 - accuracy: 0.6304 - val_loss: 1.7599 - val_accuracy: 0.5036 - 308ms/epoch - 24ms/step\n",
            "Epoch 274/300\n",
            "13/13 - 0s - loss: 1.0531 - accuracy: 0.6267 - val_loss: 1.8946 - val_accuracy: 0.4634 - 309ms/epoch - 24ms/step\n",
            "Epoch 275/300\n",
            "13/13 - 0s - loss: 1.0398 - accuracy: 0.6323 - val_loss: 1.6103 - val_accuracy: 0.5007 - 308ms/epoch - 24ms/step\n",
            "Epoch 276/300\n",
            "13/13 - 0s - loss: 1.0025 - accuracy: 0.6342 - val_loss: 1.6138 - val_accuracy: 0.5079 - 303ms/epoch - 23ms/step\n",
            "Epoch 277/300\n",
            "13/13 - 0s - loss: 1.0519 - accuracy: 0.6202 - val_loss: 1.7066 - val_accuracy: 0.5065 - 312ms/epoch - 24ms/step\n",
            "Epoch 278/300\n",
            "13/13 - 0s - loss: 1.0232 - accuracy: 0.6317 - val_loss: 1.5804 - val_accuracy: 0.5007 - 311ms/epoch - 24ms/step\n",
            "Epoch 279/300\n",
            "13/13 - 0s - loss: 0.9946 - accuracy: 0.6346 - val_loss: 1.7477 - val_accuracy: 0.4892 - 311ms/epoch - 24ms/step\n",
            "Epoch 280/300\n",
            "13/13 - 0s - loss: 0.9961 - accuracy: 0.6405 - val_loss: 1.5113 - val_accuracy: 0.4792 - 304ms/epoch - 23ms/step\n",
            "Epoch 281/300\n",
            "13/13 - 0s - loss: 0.9712 - accuracy: 0.6518 - val_loss: 1.5720 - val_accuracy: 0.5007 - 303ms/epoch - 23ms/step\n",
            "Epoch 282/300\n",
            "13/13 - 0s - loss: 0.9253 - accuracy: 0.6613 - val_loss: 1.6143 - val_accuracy: 0.5093 - 304ms/epoch - 23ms/step\n",
            "Epoch 283/300\n",
            "13/13 - 0s - loss: 0.9311 - accuracy: 0.6685 - val_loss: 1.5494 - val_accuracy: 0.5179 - 310ms/epoch - 24ms/step\n",
            "Epoch 284/300\n",
            "13/13 - 0s - loss: 0.9050 - accuracy: 0.6685 - val_loss: 1.6557 - val_accuracy: 0.5151 - 303ms/epoch - 23ms/step\n",
            "Epoch 285/300\n",
            "13/13 - 0s - loss: 0.8699 - accuracy: 0.6810 - val_loss: 1.8385 - val_accuracy: 0.5122 - 306ms/epoch - 24ms/step\n",
            "Epoch 286/300\n",
            "13/13 - 0s - loss: 0.9084 - accuracy: 0.6811 - val_loss: 1.8450 - val_accuracy: 0.4735 - 309ms/epoch - 24ms/step\n",
            "Epoch 287/300\n",
            "13/13 - 0s - loss: 0.9287 - accuracy: 0.6637 - val_loss: 1.9368 - val_accuracy: 0.4849 - 312ms/epoch - 24ms/step\n",
            "Epoch 288/300\n",
            "13/13 - 0s - loss: 0.9248 - accuracy: 0.6673 - val_loss: 1.6246 - val_accuracy: 0.5165 - 309ms/epoch - 24ms/step\n",
            "Epoch 289/300\n",
            "13/13 - 0s - loss: 0.9202 - accuracy: 0.6738 - val_loss: 1.7288 - val_accuracy: 0.4749 - 317ms/epoch - 24ms/step\n",
            "Epoch 290/300\n",
            "13/13 - 0s - loss: 0.9113 - accuracy: 0.6795 - val_loss: 1.6723 - val_accuracy: 0.4978 - 298ms/epoch - 23ms/step\n",
            "Epoch 291/300\n",
            "13/13 - 0s - loss: 1.1169 - accuracy: 0.6331 - val_loss: 1.9897 - val_accuracy: 0.4204 - 299ms/epoch - 23ms/step\n",
            "Epoch 292/300\n",
            "13/13 - 0s - loss: 1.0642 - accuracy: 0.6424 - val_loss: 2.0065 - val_accuracy: 0.4620 - 299ms/epoch - 23ms/step\n",
            "Epoch 293/300\n",
            "13/13 - 0s - loss: 1.0511 - accuracy: 0.6497 - val_loss: 2.0144 - val_accuracy: 0.4663 - 301ms/epoch - 23ms/step\n",
            "Epoch 294/300\n",
            "13/13 - 0s - loss: 1.0394 - accuracy: 0.6564 - val_loss: 2.2309 - val_accuracy: 0.4591 - 299ms/epoch - 23ms/step\n",
            "Epoch 295/300\n",
            "13/13 - 0s - loss: 0.9467 - accuracy: 0.6695 - val_loss: 2.2718 - val_accuracy: 0.4405 - 301ms/epoch - 23ms/step\n",
            "Epoch 296/300\n",
            "13/13 - 0s - loss: 0.9428 - accuracy: 0.6732 - val_loss: 2.0393 - val_accuracy: 0.4648 - 306ms/epoch - 24ms/step\n",
            "Epoch 297/300\n",
            "13/13 - 0s - loss: 0.9820 - accuracy: 0.6711 - val_loss: 2.1559 - val_accuracy: 0.4419 - 305ms/epoch - 23ms/step\n",
            "Epoch 298/300\n",
            "13/13 - 0s - loss: 1.0817 - accuracy: 0.6293 - val_loss: 1.9491 - val_accuracy: 0.4476 - 306ms/epoch - 24ms/step\n",
            "Epoch 299/300\n",
            "13/13 - 0s - loss: 1.0380 - accuracy: 0.6347 - val_loss: 2.8253 - val_accuracy: 0.4835 - 313ms/epoch - 24ms/step\n",
            "Epoch 300/300\n",
            "13/13 - 0s - loss: 0.9834 - accuracy: 0.6478 - val_loss: 2.0705 - val_accuracy: 0.4935 - 300ms/epoch - 23ms/step\n",
            "Model: \"sequential_101\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_202 (Conv2D)         (None, 4, 36, 80)         27440     \n",
            "                                                                 \n",
            " max_pooling2d_202 (MaxPooli  (None, 1, 12, 80)        0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_101 (Ba  (None, 1, 12, 80)        320       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " conv2d_203 (Conv2D)         (None, 1, 10, 80)         19280     \n",
            "                                                                 \n",
            " max_pooling2d_203 (MaxPooli  (None, 1, 3, 80)         0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " flatten_101 (Flatten)       (None, 240)               0         \n",
            "                                                                 \n",
            " dense_303 (Dense)           (None, 5000)              1205000   \n",
            "                                                                 \n",
            " dropout_202 (Dropout)       (None, 5000)              0         \n",
            "                                                                 \n",
            " dense_304 (Dense)           (None, 5000)              25005000  \n",
            "                                                                 \n",
            " dropout_203 (Dropout)       (None, 5000)              0         \n",
            "                                                                 \n",
            " dense_305 (Dense)           (None, 10)                50010     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 26,307,050\n",
            "Trainable params: 26,306,890\n",
            "Non-trainable params: 160\n",
            "_________________________________________________________________\n",
            "None\n",
            "Result of fold:8\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 1.7698 - accuracy: 0.5680\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 80%|████████  | 8/10 [13:23<03:32, 106.34s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(6938, 60, 41)\n",
            "Epoch 1/300\n",
            "13/13 - 1s - loss: 5.3483 - accuracy: 0.1326 - val_loss: 2.2465 - val_accuracy: 0.1671 - 1s/epoch - 88ms/step\n",
            "Epoch 2/300\n",
            "13/13 - 0s - loss: 2.1200 - accuracy: 0.2087 - val_loss: 2.0719 - val_accuracy: 0.2334 - 306ms/epoch - 24ms/step\n",
            "Epoch 3/300\n",
            "13/13 - 0s - loss: 2.0541 - accuracy: 0.2406 - val_loss: 2.0258 - val_accuracy: 0.2406 - 307ms/epoch - 24ms/step\n",
            "Epoch 4/300\n",
            "13/13 - 0s - loss: 1.9750 - accuracy: 0.2740 - val_loss: 1.9559 - val_accuracy: 0.2536 - 312ms/epoch - 24ms/step\n",
            "Epoch 5/300\n",
            "13/13 - 0s - loss: 1.9618 - accuracy: 0.2868 - val_loss: 1.8930 - val_accuracy: 0.2839 - 310ms/epoch - 24ms/step\n",
            "Epoch 6/300\n",
            "13/13 - 0s - loss: 1.8772 - accuracy: 0.3129 - val_loss: 1.8027 - val_accuracy: 0.3646 - 304ms/epoch - 23ms/step\n",
            "Epoch 7/300\n",
            "13/13 - 0s - loss: 1.8234 - accuracy: 0.3334 - val_loss: 1.8692 - val_accuracy: 0.3703 - 305ms/epoch - 23ms/step\n",
            "Epoch 8/300\n",
            "13/13 - 0s - loss: 1.7866 - accuracy: 0.3594 - val_loss: 1.8488 - val_accuracy: 0.3040 - 306ms/epoch - 24ms/step\n",
            "Epoch 9/300\n",
            "13/13 - 0s - loss: 1.7122 - accuracy: 0.3696 - val_loss: 1.7578 - val_accuracy: 0.3415 - 303ms/epoch - 23ms/step\n",
            "Epoch 10/300\n",
            "13/13 - 0s - loss: 1.6491 - accuracy: 0.4076 - val_loss: 1.7357 - val_accuracy: 0.3516 - 310ms/epoch - 24ms/step\n",
            "Epoch 11/300\n",
            "13/13 - 0s - loss: 1.6225 - accuracy: 0.4142 - val_loss: 1.7847 - val_accuracy: 0.3501 - 304ms/epoch - 23ms/step\n",
            "Epoch 12/300\n",
            "13/13 - 0s - loss: 1.6281 - accuracy: 0.4185 - val_loss: 1.6970 - val_accuracy: 0.3761 - 302ms/epoch - 23ms/step\n",
            "Epoch 13/300\n",
            "13/13 - 0s - loss: 1.6099 - accuracy: 0.4220 - val_loss: 1.6578 - val_accuracy: 0.3646 - 305ms/epoch - 23ms/step\n",
            "Epoch 14/300\n",
            "13/13 - 0s - loss: 1.5584 - accuracy: 0.4361 - val_loss: 1.7005 - val_accuracy: 0.3977 - 306ms/epoch - 24ms/step\n",
            "Epoch 15/300\n",
            "13/13 - 0s - loss: 1.5021 - accuracy: 0.4598 - val_loss: 1.7661 - val_accuracy: 0.4207 - 302ms/epoch - 23ms/step\n",
            "Epoch 16/300\n",
            "13/13 - 0s - loss: 1.5231 - accuracy: 0.4510 - val_loss: 1.6495 - val_accuracy: 0.4798 - 312ms/epoch - 24ms/step\n",
            "Epoch 17/300\n",
            "13/13 - 0s - loss: 1.5034 - accuracy: 0.4742 - val_loss: 1.5868 - val_accuracy: 0.4625 - 309ms/epoch - 24ms/step\n",
            "Epoch 18/300\n",
            "13/13 - 0s - loss: 1.4458 - accuracy: 0.4825 - val_loss: 1.7155 - val_accuracy: 0.4323 - 309ms/epoch - 24ms/step\n",
            "Epoch 19/300\n",
            "13/13 - 0s - loss: 1.4101 - accuracy: 0.4998 - val_loss: 1.6950 - val_accuracy: 0.3242 - 308ms/epoch - 24ms/step\n",
            "Epoch 20/300\n",
            "13/13 - 0s - loss: 1.3886 - accuracy: 0.5043 - val_loss: 1.7259 - val_accuracy: 0.3040 - 306ms/epoch - 24ms/step\n",
            "Epoch 21/300\n",
            "13/13 - 0s - loss: 1.3494 - accuracy: 0.5237 - val_loss: 1.9041 - val_accuracy: 0.3631 - 304ms/epoch - 23ms/step\n",
            "Epoch 22/300\n",
            "13/13 - 0s - loss: 1.3570 - accuracy: 0.5120 - val_loss: 1.6054 - val_accuracy: 0.4611 - 307ms/epoch - 24ms/step\n",
            "Epoch 23/300\n",
            "13/13 - 0s - loss: 1.3211 - accuracy: 0.5235 - val_loss: 1.6299 - val_accuracy: 0.4193 - 314ms/epoch - 24ms/step\n",
            "Epoch 24/300\n",
            "13/13 - 0s - loss: 1.3215 - accuracy: 0.5285 - val_loss: 1.5526 - val_accuracy: 0.3977 - 294ms/epoch - 23ms/step\n",
            "Epoch 25/300\n",
            "13/13 - 0s - loss: 1.3012 - accuracy: 0.5391 - val_loss: 1.6093 - val_accuracy: 0.4827 - 298ms/epoch - 23ms/step\n",
            "Epoch 26/300\n",
            "13/13 - 0s - loss: 1.2454 - accuracy: 0.5537 - val_loss: 1.5584 - val_accuracy: 0.5101 - 301ms/epoch - 23ms/step\n",
            "Epoch 27/300\n",
            "13/13 - 0s - loss: 1.2580 - accuracy: 0.5512 - val_loss: 1.4708 - val_accuracy: 0.5173 - 307ms/epoch - 24ms/step\n",
            "Epoch 28/300\n",
            "13/13 - 0s - loss: 1.2338 - accuracy: 0.5729 - val_loss: 1.5174 - val_accuracy: 0.5216 - 305ms/epoch - 23ms/step\n",
            "Epoch 29/300\n",
            "13/13 - 0s - loss: 1.2400 - accuracy: 0.5538 - val_loss: 1.4980 - val_accuracy: 0.4755 - 313ms/epoch - 24ms/step\n",
            "Epoch 30/300\n",
            "13/13 - 0s - loss: 1.2426 - accuracy: 0.5553 - val_loss: 1.4602 - val_accuracy: 0.4697 - 303ms/epoch - 23ms/step\n",
            "Epoch 31/300\n",
            "13/13 - 0s - loss: 1.2269 - accuracy: 0.5628 - val_loss: 1.5917 - val_accuracy: 0.3963 - 303ms/epoch - 23ms/step\n",
            "Epoch 32/300\n",
            "13/13 - 0s - loss: 1.2019 - accuracy: 0.5729 - val_loss: 1.5477 - val_accuracy: 0.4885 - 307ms/epoch - 24ms/step\n",
            "Epoch 33/300\n",
            "13/13 - 0s - loss: 1.1822 - accuracy: 0.5721 - val_loss: 1.5485 - val_accuracy: 0.4971 - 312ms/epoch - 24ms/step\n",
            "Epoch 34/300\n",
            "13/13 - 0s - loss: 1.2159 - accuracy: 0.5750 - val_loss: 1.4718 - val_accuracy: 0.4798 - 311ms/epoch - 24ms/step\n",
            "Epoch 35/300\n",
            "13/13 - 0s - loss: 1.2348 - accuracy: 0.5716 - val_loss: 1.4904 - val_accuracy: 0.4813 - 314ms/epoch - 24ms/step\n",
            "Epoch 36/300\n",
            "13/13 - 0s - loss: 1.1923 - accuracy: 0.5809 - val_loss: 1.4953 - val_accuracy: 0.4899 - 314ms/epoch - 24ms/step\n",
            "Epoch 37/300\n",
            "13/13 - 0s - loss: 1.1619 - accuracy: 0.5934 - val_loss: 1.4848 - val_accuracy: 0.4986 - 313ms/epoch - 24ms/step\n",
            "Epoch 38/300\n",
            "13/13 - 0s - loss: 1.1999 - accuracy: 0.5788 - val_loss: 1.4976 - val_accuracy: 0.4813 - 303ms/epoch - 23ms/step\n",
            "Epoch 39/300\n",
            "13/13 - 0s - loss: 1.2169 - accuracy: 0.5801 - val_loss: 1.4348 - val_accuracy: 0.5058 - 310ms/epoch - 24ms/step\n",
            "Epoch 40/300\n",
            "13/13 - 0s - loss: 1.2084 - accuracy: 0.5842 - val_loss: 1.4200 - val_accuracy: 0.5620 - 305ms/epoch - 23ms/step\n",
            "Epoch 41/300\n",
            "13/13 - 0s - loss: 1.1318 - accuracy: 0.6007 - val_loss: 1.4082 - val_accuracy: 0.5533 - 307ms/epoch - 24ms/step\n",
            "Epoch 42/300\n",
            "13/13 - 0s - loss: 1.1681 - accuracy: 0.5985 - val_loss: 1.4078 - val_accuracy: 0.5288 - 303ms/epoch - 23ms/step\n",
            "Epoch 43/300\n",
            "13/13 - 0s - loss: 1.1880 - accuracy: 0.5889 - val_loss: 1.5375 - val_accuracy: 0.4236 - 311ms/epoch - 24ms/step\n",
            "Epoch 44/300\n",
            "13/13 - 0s - loss: 1.1734 - accuracy: 0.5902 - val_loss: 1.4945 - val_accuracy: 0.5058 - 309ms/epoch - 24ms/step\n",
            "Epoch 45/300\n",
            "13/13 - 0s - loss: 1.1762 - accuracy: 0.5841 - val_loss: 1.4703 - val_accuracy: 0.5000 - 308ms/epoch - 24ms/step\n",
            "Epoch 46/300\n",
            "13/13 - 0s - loss: 1.1454 - accuracy: 0.6014 - val_loss: 1.4247 - val_accuracy: 0.5144 - 308ms/epoch - 24ms/step\n",
            "Epoch 47/300\n",
            "13/13 - 0s - loss: 1.1487 - accuracy: 0.6126 - val_loss: 1.4331 - val_accuracy: 0.4798 - 306ms/epoch - 24ms/step\n",
            "Epoch 48/300\n",
            "13/13 - 0s - loss: 1.1513 - accuracy: 0.5991 - val_loss: 1.4847 - val_accuracy: 0.5072 - 301ms/epoch - 23ms/step\n",
            "Epoch 49/300\n",
            "13/13 - 0s - loss: 1.1656 - accuracy: 0.6051 - val_loss: 1.5352 - val_accuracy: 0.5447 - 308ms/epoch - 24ms/step\n",
            "Epoch 50/300\n",
            "13/13 - 0s - loss: 1.1279 - accuracy: 0.6015 - val_loss: 1.4802 - val_accuracy: 0.4885 - 313ms/epoch - 24ms/step\n",
            "Epoch 51/300\n",
            "13/13 - 0s - loss: 1.1797 - accuracy: 0.6063 - val_loss: 1.5091 - val_accuracy: 0.5403 - 302ms/epoch - 23ms/step\n",
            "Epoch 52/300\n",
            "13/13 - 0s - loss: 1.1345 - accuracy: 0.5975 - val_loss: 1.5297 - val_accuracy: 0.4928 - 308ms/epoch - 24ms/step\n",
            "Epoch 53/300\n",
            "13/13 - 0s - loss: 1.0847 - accuracy: 0.6185 - val_loss: 1.5500 - val_accuracy: 0.4813 - 306ms/epoch - 24ms/step\n",
            "Epoch 54/300\n",
            "13/13 - 0s - loss: 1.0531 - accuracy: 0.6347 - val_loss: 1.5869 - val_accuracy: 0.4611 - 305ms/epoch - 23ms/step\n",
            "Epoch 55/300\n",
            "13/13 - 0s - loss: 1.1100 - accuracy: 0.6214 - val_loss: 1.6306 - val_accuracy: 0.4510 - 300ms/epoch - 23ms/step\n",
            "Epoch 56/300\n",
            "13/13 - 0s - loss: 1.0966 - accuracy: 0.6216 - val_loss: 1.5896 - val_accuracy: 0.4841 - 305ms/epoch - 23ms/step\n",
            "Epoch 57/300\n",
            "13/13 - 0s - loss: 1.0642 - accuracy: 0.6291 - val_loss: 1.5689 - val_accuracy: 0.4928 - 308ms/epoch - 24ms/step\n",
            "Epoch 58/300\n",
            "13/13 - 0s - loss: 1.1791 - accuracy: 0.6089 - val_loss: 1.5447 - val_accuracy: 0.4726 - 303ms/epoch - 23ms/step\n",
            "Epoch 59/300\n",
            "13/13 - 0s - loss: 1.1660 - accuracy: 0.6131 - val_loss: 1.5251 - val_accuracy: 0.4755 - 306ms/epoch - 24ms/step\n",
            "Epoch 60/300\n",
            "13/13 - 0s - loss: 1.0702 - accuracy: 0.6208 - val_loss: 1.5108 - val_accuracy: 0.4726 - 304ms/epoch - 23ms/step\n",
            "Epoch 61/300\n",
            "13/13 - 0s - loss: 1.0735 - accuracy: 0.6337 - val_loss: 1.5289 - val_accuracy: 0.4741 - 303ms/epoch - 23ms/step\n",
            "Epoch 62/300\n",
            "13/13 - 0s - loss: 1.0487 - accuracy: 0.6405 - val_loss: 1.5198 - val_accuracy: 0.5029 - 306ms/epoch - 24ms/step\n",
            "Epoch 63/300\n",
            "13/13 - 0s - loss: 1.0704 - accuracy: 0.6384 - val_loss: 1.4806 - val_accuracy: 0.4669 - 309ms/epoch - 24ms/step\n",
            "Epoch 64/300\n",
            "13/13 - 0s - loss: 1.1160 - accuracy: 0.6055 - val_loss: 1.6224 - val_accuracy: 0.4625 - 301ms/epoch - 23ms/step\n",
            "Epoch 65/300\n",
            "13/13 - 0s - loss: 1.1837 - accuracy: 0.5914 - val_loss: 1.4884 - val_accuracy: 0.4697 - 305ms/epoch - 23ms/step\n",
            "Epoch 66/300\n",
            "13/13 - 0s - loss: 1.1227 - accuracy: 0.6111 - val_loss: 1.6981 - val_accuracy: 0.4251 - 307ms/epoch - 24ms/step\n",
            "Epoch 67/300\n",
            "13/13 - 0s - loss: 1.0827 - accuracy: 0.6340 - val_loss: 1.4941 - val_accuracy: 0.5159 - 298ms/epoch - 23ms/step\n",
            "Epoch 68/300\n",
            "13/13 - 0s - loss: 1.0816 - accuracy: 0.6365 - val_loss: 1.5353 - val_accuracy: 0.4841 - 306ms/epoch - 24ms/step\n",
            "Epoch 69/300\n",
            "13/13 - 0s - loss: 1.0588 - accuracy: 0.6397 - val_loss: 1.6861 - val_accuracy: 0.4741 - 299ms/epoch - 23ms/step\n",
            "Epoch 70/300\n",
            "13/13 - 0s - loss: 1.0688 - accuracy: 0.6389 - val_loss: 1.5676 - val_accuracy: 0.4755 - 293ms/epoch - 23ms/step\n",
            "Epoch 71/300\n",
            "13/13 - 0s - loss: 1.0234 - accuracy: 0.6507 - val_loss: 1.5617 - val_accuracy: 0.5029 - 299ms/epoch - 23ms/step\n",
            "Epoch 72/300\n",
            "13/13 - 0s - loss: 1.0245 - accuracy: 0.6429 - val_loss: 1.6264 - val_accuracy: 0.4726 - 296ms/epoch - 23ms/step\n",
            "Epoch 73/300\n",
            "13/13 - 0s - loss: 0.9941 - accuracy: 0.6558 - val_loss: 1.5135 - val_accuracy: 0.5360 - 305ms/epoch - 23ms/step\n",
            "Epoch 74/300\n",
            "13/13 - 0s - loss: 0.9589 - accuracy: 0.6659 - val_loss: 1.5227 - val_accuracy: 0.5490 - 301ms/epoch - 23ms/step\n",
            "Epoch 75/300\n",
            "13/13 - 0s - loss: 0.9263 - accuracy: 0.6733 - val_loss: 1.5919 - val_accuracy: 0.4813 - 300ms/epoch - 23ms/step\n",
            "Epoch 76/300\n",
            "13/13 - 0s - loss: 0.9727 - accuracy: 0.6725 - val_loss: 1.5978 - val_accuracy: 0.5086 - 296ms/epoch - 23ms/step\n",
            "Epoch 77/300\n",
            "13/13 - 0s - loss: 0.9804 - accuracy: 0.6505 - val_loss: 1.6248 - val_accuracy: 0.4885 - 303ms/epoch - 23ms/step\n",
            "Epoch 78/300\n",
            "13/13 - 0s - loss: 1.0610 - accuracy: 0.6400 - val_loss: 1.7193 - val_accuracy: 0.4841 - 297ms/epoch - 23ms/step\n",
            "Epoch 79/300\n",
            "13/13 - 0s - loss: 1.1305 - accuracy: 0.6347 - val_loss: 1.8219 - val_accuracy: 0.4755 - 300ms/epoch - 23ms/step\n",
            "Epoch 80/300\n",
            "13/13 - 0s - loss: 1.1389 - accuracy: 0.6331 - val_loss: 1.6418 - val_accuracy: 0.4784 - 299ms/epoch - 23ms/step\n",
            "Epoch 81/300\n",
            "13/13 - 0s - loss: 1.1082 - accuracy: 0.6156 - val_loss: 1.6291 - val_accuracy: 0.4424 - 303ms/epoch - 23ms/step\n",
            "Epoch 82/300\n",
            "13/13 - 0s - loss: 1.0734 - accuracy: 0.6419 - val_loss: 1.4850 - val_accuracy: 0.4856 - 305ms/epoch - 23ms/step\n",
            "Epoch 83/300\n",
            "13/13 - 0s - loss: 1.0159 - accuracy: 0.6481 - val_loss: 1.5963 - val_accuracy: 0.4784 - 304ms/epoch - 23ms/step\n",
            "Epoch 84/300\n",
            "13/13 - 0s - loss: 1.0052 - accuracy: 0.6478 - val_loss: 1.6178 - val_accuracy: 0.5187 - 309ms/epoch - 24ms/step\n",
            "Epoch 85/300\n",
            "13/13 - 0s - loss: 0.9919 - accuracy: 0.6515 - val_loss: 1.6700 - val_accuracy: 0.4784 - 304ms/epoch - 23ms/step\n",
            "Epoch 86/300\n",
            "13/13 - 0s - loss: 0.9804 - accuracy: 0.6658 - val_loss: 1.6103 - val_accuracy: 0.5216 - 303ms/epoch - 23ms/step\n",
            "Epoch 87/300\n",
            "13/13 - 0s - loss: 0.9793 - accuracy: 0.6683 - val_loss: 1.5296 - val_accuracy: 0.4942 - 302ms/epoch - 23ms/step\n",
            "Epoch 88/300\n",
            "13/13 - 0s - loss: 1.0088 - accuracy: 0.6610 - val_loss: 1.6438 - val_accuracy: 0.4712 - 302ms/epoch - 23ms/step\n",
            "Epoch 89/300\n",
            "13/13 - 0s - loss: 1.0275 - accuracy: 0.6549 - val_loss: 1.8839 - val_accuracy: 0.4568 - 307ms/epoch - 24ms/step\n",
            "Epoch 90/300\n",
            "13/13 - 0s - loss: 1.0091 - accuracy: 0.6560 - val_loss: 1.6826 - val_accuracy: 0.5245 - 310ms/epoch - 24ms/step\n",
            "Epoch 91/300\n",
            "13/13 - 0s - loss: 1.0706 - accuracy: 0.6549 - val_loss: 1.5711 - val_accuracy: 0.4726 - 308ms/epoch - 24ms/step\n",
            "Epoch 92/300\n",
            "13/13 - 0s - loss: 1.0284 - accuracy: 0.6545 - val_loss: 1.4858 - val_accuracy: 0.5159 - 308ms/epoch - 24ms/step\n",
            "Epoch 93/300\n",
            "13/13 - 0s - loss: 1.0540 - accuracy: 0.6533 - val_loss: 1.5023 - val_accuracy: 0.5187 - 312ms/epoch - 24ms/step\n",
            "Epoch 94/300\n",
            "13/13 - 0s - loss: 1.0272 - accuracy: 0.6611 - val_loss: 1.5331 - val_accuracy: 0.5418 - 310ms/epoch - 24ms/step\n",
            "Epoch 95/300\n",
            "13/13 - 0s - loss: 0.9547 - accuracy: 0.6766 - val_loss: 1.5632 - val_accuracy: 0.4813 - 308ms/epoch - 24ms/step\n",
            "Epoch 96/300\n",
            "13/13 - 0s - loss: 1.0068 - accuracy: 0.6648 - val_loss: 1.6126 - val_accuracy: 0.5101 - 309ms/epoch - 24ms/step\n",
            "Epoch 97/300\n",
            "13/13 - 0s - loss: 1.0436 - accuracy: 0.6624 - val_loss: 1.5457 - val_accuracy: 0.4885 - 309ms/epoch - 24ms/step\n",
            "Epoch 98/300\n",
            "13/13 - 0s - loss: 1.0504 - accuracy: 0.6393 - val_loss: 1.6985 - val_accuracy: 0.4308 - 305ms/epoch - 23ms/step\n",
            "Epoch 99/300\n",
            "13/13 - 0s - loss: 1.0106 - accuracy: 0.6581 - val_loss: 1.7755 - val_accuracy: 0.4841 - 302ms/epoch - 23ms/step\n",
            "Epoch 100/300\n",
            "13/13 - 0s - loss: 0.9713 - accuracy: 0.6714 - val_loss: 1.6933 - val_accuracy: 0.4827 - 305ms/epoch - 23ms/step\n",
            "Epoch 101/300\n",
            "13/13 - 0s - loss: 1.0941 - accuracy: 0.6429 - val_loss: 1.5902 - val_accuracy: 0.4553 - 302ms/epoch - 23ms/step\n",
            "Epoch 102/300\n",
            "13/13 - 0s - loss: 1.0585 - accuracy: 0.6406 - val_loss: 1.6201 - val_accuracy: 0.4654 - 299ms/epoch - 23ms/step\n",
            "Epoch 103/300\n",
            "13/13 - 0s - loss: 1.0080 - accuracy: 0.6614 - val_loss: 1.5791 - val_accuracy: 0.5000 - 306ms/epoch - 24ms/step\n",
            "Epoch 104/300\n",
            "13/13 - 0s - loss: 1.0378 - accuracy: 0.6493 - val_loss: 1.6896 - val_accuracy: 0.4049 - 306ms/epoch - 24ms/step\n",
            "Epoch 105/300\n",
            "13/13 - 0s - loss: 1.0810 - accuracy: 0.6467 - val_loss: 1.6435 - val_accuracy: 0.4914 - 299ms/epoch - 23ms/step\n",
            "Epoch 106/300\n",
            "13/13 - 0s - loss: 1.0780 - accuracy: 0.6521 - val_loss: 1.5404 - val_accuracy: 0.5029 - 293ms/epoch - 23ms/step\n",
            "Epoch 107/300\n",
            "13/13 - 0s - loss: 0.9932 - accuracy: 0.6584 - val_loss: 1.6586 - val_accuracy: 0.4870 - 304ms/epoch - 23ms/step\n",
            "Epoch 108/300\n",
            "13/13 - 0s - loss: 0.9551 - accuracy: 0.6730 - val_loss: 1.5761 - val_accuracy: 0.5562 - 313ms/epoch - 24ms/step\n",
            "Epoch 109/300\n",
            "13/13 - 0s - loss: 1.0014 - accuracy: 0.6726 - val_loss: 1.5170 - val_accuracy: 0.4914 - 307ms/epoch - 24ms/step\n",
            "Epoch 110/300\n",
            "13/13 - 0s - loss: 0.9681 - accuracy: 0.6688 - val_loss: 1.6935 - val_accuracy: 0.4928 - 301ms/epoch - 23ms/step\n",
            "Epoch 111/300\n",
            "13/13 - 0s - loss: 0.9409 - accuracy: 0.6752 - val_loss: 1.5624 - val_accuracy: 0.5259 - 306ms/epoch - 24ms/step\n",
            "Epoch 112/300\n",
            "13/13 - 0s - loss: 0.9476 - accuracy: 0.6730 - val_loss: 1.8968 - val_accuracy: 0.4870 - 305ms/epoch - 23ms/step\n",
            "Epoch 113/300\n",
            "13/13 - 0s - loss: 0.9856 - accuracy: 0.6694 - val_loss: 1.8448 - val_accuracy: 0.4798 - 302ms/epoch - 23ms/step\n",
            "Epoch 114/300\n",
            "13/13 - 0s - loss: 0.9639 - accuracy: 0.6856 - val_loss: 1.7982 - val_accuracy: 0.5014 - 307ms/epoch - 24ms/step\n",
            "Epoch 115/300\n",
            "13/13 - 0s - loss: 0.9054 - accuracy: 0.6988 - val_loss: 1.6380 - val_accuracy: 0.5101 - 300ms/epoch - 23ms/step\n",
            "Epoch 116/300\n",
            "13/13 - 0s - loss: 0.9491 - accuracy: 0.6856 - val_loss: 1.6200 - val_accuracy: 0.4885 - 304ms/epoch - 23ms/step\n",
            "Epoch 117/300\n",
            "13/13 - 0s - loss: 0.9206 - accuracy: 0.6847 - val_loss: 1.7917 - val_accuracy: 0.4798 - 304ms/epoch - 23ms/step\n",
            "Epoch 118/300\n",
            "13/13 - 0s - loss: 0.9054 - accuracy: 0.6909 - val_loss: 2.2127 - val_accuracy: 0.4640 - 304ms/epoch - 23ms/step\n",
            "Epoch 119/300\n",
            "13/13 - 0s - loss: 0.9367 - accuracy: 0.6795 - val_loss: 1.7433 - val_accuracy: 0.4755 - 306ms/epoch - 24ms/step\n",
            "Epoch 120/300\n",
            "13/13 - 0s - loss: 0.9505 - accuracy: 0.6765 - val_loss: 1.9825 - val_accuracy: 0.5173 - 301ms/epoch - 23ms/step\n",
            "Epoch 121/300\n",
            "13/13 - 0s - loss: 0.9940 - accuracy: 0.6855 - val_loss: 1.7572 - val_accuracy: 0.4885 - 299ms/epoch - 23ms/step\n",
            "Epoch 122/300\n",
            "13/13 - 0s - loss: 0.9446 - accuracy: 0.6824 - val_loss: 3.4106 - val_accuracy: 0.4697 - 301ms/epoch - 23ms/step\n",
            "Epoch 123/300\n",
            "13/13 - 0s - loss: 1.0138 - accuracy: 0.6677 - val_loss: 1.9119 - val_accuracy: 0.4524 - 301ms/epoch - 23ms/step\n",
            "Epoch 124/300\n",
            "13/13 - 0s - loss: 0.9764 - accuracy: 0.6702 - val_loss: 1.7867 - val_accuracy: 0.4654 - 304ms/epoch - 23ms/step\n",
            "Epoch 125/300\n",
            "13/13 - 0s - loss: 0.9203 - accuracy: 0.6938 - val_loss: 1.7283 - val_accuracy: 0.4971 - 305ms/epoch - 23ms/step\n",
            "Epoch 126/300\n",
            "13/13 - 0s - loss: 0.9118 - accuracy: 0.6895 - val_loss: 1.7636 - val_accuracy: 0.4971 - 307ms/epoch - 24ms/step\n",
            "Epoch 127/300\n",
            "13/13 - 0s - loss: 0.9710 - accuracy: 0.6760 - val_loss: 1.9008 - val_accuracy: 0.4885 - 293ms/epoch - 23ms/step\n",
            "Epoch 128/300\n",
            "13/13 - 0s - loss: 0.9547 - accuracy: 0.6755 - val_loss: 1.7062 - val_accuracy: 0.4841 - 303ms/epoch - 23ms/step\n",
            "Epoch 129/300\n",
            "13/13 - 0s - loss: 0.9507 - accuracy: 0.6789 - val_loss: 1.6674 - val_accuracy: 0.5072 - 307ms/epoch - 24ms/step\n",
            "Epoch 130/300\n",
            "13/13 - 0s - loss: 0.9209 - accuracy: 0.6885 - val_loss: 1.7444 - val_accuracy: 0.5101 - 302ms/epoch - 23ms/step\n",
            "Epoch 131/300\n",
            "13/13 - 0s - loss: 0.9771 - accuracy: 0.6831 - val_loss: 1.8065 - val_accuracy: 0.4942 - 301ms/epoch - 23ms/step\n",
            "Epoch 132/300\n",
            "13/13 - 0s - loss: 0.9954 - accuracy: 0.6778 - val_loss: 1.8217 - val_accuracy: 0.4971 - 300ms/epoch - 23ms/step\n",
            "Epoch 133/300\n",
            "13/13 - 0s - loss: 1.1729 - accuracy: 0.6451 - val_loss: 1.8162 - val_accuracy: 0.4899 - 304ms/epoch - 23ms/step\n",
            "Epoch 134/300\n",
            "13/13 - 0s - loss: 1.1544 - accuracy: 0.6264 - val_loss: 1.7140 - val_accuracy: 0.4784 - 301ms/epoch - 23ms/step\n",
            "Epoch 135/300\n",
            "13/13 - 0s - loss: 1.0815 - accuracy: 0.6448 - val_loss: 1.5499 - val_accuracy: 0.5144 - 300ms/epoch - 23ms/step\n",
            "Epoch 136/300\n",
            "13/13 - 0s - loss: 0.9907 - accuracy: 0.6661 - val_loss: 1.6420 - val_accuracy: 0.4669 - 303ms/epoch - 23ms/step\n",
            "Epoch 137/300\n",
            "13/13 - 0s - loss: 0.9704 - accuracy: 0.6775 - val_loss: 1.7137 - val_accuracy: 0.4971 - 300ms/epoch - 23ms/step\n",
            "Epoch 138/300\n",
            "13/13 - 0s - loss: 0.9622 - accuracy: 0.6792 - val_loss: 1.7132 - val_accuracy: 0.4885 - 304ms/epoch - 23ms/step\n",
            "Epoch 139/300\n",
            "13/13 - 0s - loss: 0.9540 - accuracy: 0.6747 - val_loss: 1.7521 - val_accuracy: 0.5014 - 304ms/epoch - 23ms/step\n",
            "Epoch 140/300\n",
            "13/13 - 0s - loss: 0.9141 - accuracy: 0.6832 - val_loss: 1.8172 - val_accuracy: 0.4942 - 304ms/epoch - 23ms/step\n",
            "Epoch 141/300\n",
            "13/13 - 0s - loss: 0.9080 - accuracy: 0.6899 - val_loss: 1.7533 - val_accuracy: 0.5043 - 302ms/epoch - 23ms/step\n",
            "Epoch 142/300\n",
            "13/13 - 0s - loss: 0.9535 - accuracy: 0.6678 - val_loss: 1.7325 - val_accuracy: 0.4683 - 302ms/epoch - 23ms/step\n",
            "Epoch 143/300\n",
            "13/13 - 0s - loss: 0.9314 - accuracy: 0.6757 - val_loss: 1.8821 - val_accuracy: 0.4957 - 307ms/epoch - 24ms/step\n",
            "Epoch 144/300\n",
            "13/13 - 0s - loss: 0.9476 - accuracy: 0.6829 - val_loss: 1.9833 - val_accuracy: 0.4784 - 298ms/epoch - 23ms/step\n",
            "Epoch 145/300\n",
            "13/13 - 0s - loss: 0.9050 - accuracy: 0.6845 - val_loss: 1.8006 - val_accuracy: 0.4726 - 307ms/epoch - 24ms/step\n",
            "Epoch 146/300\n",
            "13/13 - 0s - loss: 0.8870 - accuracy: 0.6986 - val_loss: 1.7738 - val_accuracy: 0.4784 - 302ms/epoch - 23ms/step\n",
            "Epoch 147/300\n",
            "13/13 - 0s - loss: 0.8776 - accuracy: 0.7117 - val_loss: 1.7235 - val_accuracy: 0.5014 - 301ms/epoch - 23ms/step\n",
            "Epoch 148/300\n",
            "13/13 - 0s - loss: 0.8685 - accuracy: 0.6960 - val_loss: 1.8978 - val_accuracy: 0.4741 - 301ms/epoch - 23ms/step\n",
            "Epoch 149/300\n",
            "13/13 - 0s - loss: 0.8523 - accuracy: 0.7088 - val_loss: 1.8078 - val_accuracy: 0.4914 - 306ms/epoch - 24ms/step\n",
            "Epoch 150/300\n",
            "13/13 - 0s - loss: 0.9428 - accuracy: 0.6879 - val_loss: 1.6222 - val_accuracy: 0.4957 - 310ms/epoch - 24ms/step\n",
            "Epoch 151/300\n",
            "13/13 - 0s - loss: 0.8881 - accuracy: 0.6914 - val_loss: 1.6589 - val_accuracy: 0.4885 - 306ms/epoch - 24ms/step\n",
            "Epoch 152/300\n",
            "13/13 - 0s - loss: 0.8344 - accuracy: 0.7055 - val_loss: 1.8401 - val_accuracy: 0.4914 - 303ms/epoch - 23ms/step\n",
            "Epoch 153/300\n",
            "13/13 - 0s - loss: 0.8616 - accuracy: 0.7007 - val_loss: 1.6881 - val_accuracy: 0.4870 - 299ms/epoch - 23ms/step\n",
            "Epoch 154/300\n",
            "13/13 - 0s - loss: 0.8593 - accuracy: 0.7060 - val_loss: 1.7939 - val_accuracy: 0.4986 - 305ms/epoch - 23ms/step\n",
            "Epoch 155/300\n",
            "13/13 - 0s - loss: 0.8305 - accuracy: 0.7173 - val_loss: 2.1009 - val_accuracy: 0.4438 - 302ms/epoch - 23ms/step\n",
            "Epoch 156/300\n",
            "13/13 - 0s - loss: 0.8780 - accuracy: 0.7044 - val_loss: 1.9085 - val_accuracy: 0.4784 - 303ms/epoch - 23ms/step\n",
            "Epoch 157/300\n",
            "13/13 - 0s - loss: 0.8933 - accuracy: 0.6980 - val_loss: 2.4322 - val_accuracy: 0.4380 - 310ms/epoch - 24ms/step\n",
            "Epoch 158/300\n",
            "13/13 - 0s - loss: 1.0115 - accuracy: 0.6702 - val_loss: 1.9506 - val_accuracy: 0.4352 - 306ms/epoch - 24ms/step\n",
            "Epoch 159/300\n",
            "13/13 - 0s - loss: 0.9934 - accuracy: 0.6773 - val_loss: 1.5889 - val_accuracy: 0.5173 - 304ms/epoch - 23ms/step\n",
            "Epoch 160/300\n",
            "13/13 - 0s - loss: 0.9312 - accuracy: 0.7023 - val_loss: 1.7130 - val_accuracy: 0.4899 - 300ms/epoch - 23ms/step\n",
            "Epoch 161/300\n",
            "13/13 - 0s - loss: 0.9506 - accuracy: 0.7012 - val_loss: 1.7488 - val_accuracy: 0.4769 - 304ms/epoch - 23ms/step\n",
            "Epoch 162/300\n",
            "13/13 - 0s - loss: 0.8735 - accuracy: 0.7103 - val_loss: 1.6742 - val_accuracy: 0.5058 - 302ms/epoch - 23ms/step\n",
            "Epoch 163/300\n",
            "13/13 - 0s - loss: 0.8786 - accuracy: 0.7015 - val_loss: 1.6895 - val_accuracy: 0.5072 - 299ms/epoch - 23ms/step\n",
            "Epoch 164/300\n",
            "13/13 - 0s - loss: 0.8735 - accuracy: 0.6988 - val_loss: 1.6709 - val_accuracy: 0.4986 - 306ms/epoch - 24ms/step\n",
            "Epoch 165/300\n",
            "13/13 - 0s - loss: 0.8433 - accuracy: 0.7076 - val_loss: 1.7978 - val_accuracy: 0.4712 - 304ms/epoch - 23ms/step\n",
            "Epoch 166/300\n",
            "13/13 - 0s - loss: 0.8439 - accuracy: 0.7114 - val_loss: 1.7484 - val_accuracy: 0.4769 - 300ms/epoch - 23ms/step\n",
            "Epoch 167/300\n",
            "13/13 - 0s - loss: 0.9008 - accuracy: 0.6989 - val_loss: 1.8389 - val_accuracy: 0.4942 - 305ms/epoch - 23ms/step\n",
            "Epoch 168/300\n",
            "13/13 - 0s - loss: 1.0315 - accuracy: 0.6877 - val_loss: 1.9015 - val_accuracy: 0.4697 - 302ms/epoch - 23ms/step\n",
            "Epoch 169/300\n",
            "13/13 - 0s - loss: 0.9695 - accuracy: 0.6770 - val_loss: 1.8196 - val_accuracy: 0.4438 - 301ms/epoch - 23ms/step\n",
            "Epoch 170/300\n",
            "13/13 - 0s - loss: 1.0272 - accuracy: 0.6552 - val_loss: 1.6501 - val_accuracy: 0.4899 - 306ms/epoch - 24ms/step\n",
            "Epoch 171/300\n",
            "13/13 - 0s - loss: 0.9231 - accuracy: 0.6856 - val_loss: 1.9321 - val_accuracy: 0.4798 - 302ms/epoch - 23ms/step\n",
            "Epoch 172/300\n",
            "13/13 - 0s - loss: 0.9075 - accuracy: 0.6941 - val_loss: 1.7800 - val_accuracy: 0.4971 - 304ms/epoch - 23ms/step\n",
            "Epoch 173/300\n",
            "13/13 - 0s - loss: 0.8616 - accuracy: 0.7053 - val_loss: 2.0099 - val_accuracy: 0.4914 - 301ms/epoch - 23ms/step\n",
            "Epoch 174/300\n",
            "13/13 - 0s - loss: 0.8422 - accuracy: 0.7068 - val_loss: 1.9299 - val_accuracy: 0.4683 - 305ms/epoch - 23ms/step\n",
            "Epoch 175/300\n",
            "13/13 - 0s - loss: 0.8159 - accuracy: 0.7229 - val_loss: 1.9672 - val_accuracy: 0.5000 - 302ms/epoch - 23ms/step\n",
            "Epoch 176/300\n",
            "13/13 - 0s - loss: 0.7865 - accuracy: 0.7175 - val_loss: 1.9141 - val_accuracy: 0.4942 - 301ms/epoch - 23ms/step\n",
            "Epoch 177/300\n",
            "13/13 - 0s - loss: 0.7549 - accuracy: 0.7394 - val_loss: 2.0576 - val_accuracy: 0.5072 - 301ms/epoch - 23ms/step\n",
            "Epoch 178/300\n",
            "13/13 - 0s - loss: 0.7679 - accuracy: 0.7377 - val_loss: 1.8095 - val_accuracy: 0.4971 - 308ms/epoch - 24ms/step\n",
            "Epoch 179/300\n",
            "13/13 - 0s - loss: 0.8387 - accuracy: 0.7133 - val_loss: 1.8557 - val_accuracy: 0.5000 - 303ms/epoch - 23ms/step\n",
            "Epoch 180/300\n",
            "13/13 - 0s - loss: 0.8329 - accuracy: 0.7164 - val_loss: 1.9143 - val_accuracy: 0.5144 - 300ms/epoch - 23ms/step\n",
            "Epoch 181/300\n",
            "13/13 - 0s - loss: 0.7747 - accuracy: 0.7258 - val_loss: 2.0252 - val_accuracy: 0.5086 - 301ms/epoch - 23ms/step\n",
            "Epoch 182/300\n",
            "13/13 - 0s - loss: 0.7839 - accuracy: 0.7226 - val_loss: 2.2386 - val_accuracy: 0.4957 - 304ms/epoch - 23ms/step\n",
            "Epoch 183/300\n",
            "13/13 - 0s - loss: 0.8008 - accuracy: 0.7282 - val_loss: 2.0311 - val_accuracy: 0.5548 - 304ms/epoch - 23ms/step\n",
            "Epoch 184/300\n",
            "13/13 - 0s - loss: 0.8013 - accuracy: 0.7252 - val_loss: 2.1926 - val_accuracy: 0.4928 - 308ms/epoch - 24ms/step\n",
            "Epoch 185/300\n",
            "13/13 - 0s - loss: 0.7923 - accuracy: 0.7306 - val_loss: 2.1498 - val_accuracy: 0.4928 - 294ms/epoch - 23ms/step\n",
            "Epoch 186/300\n",
            "13/13 - 0s - loss: 0.9831 - accuracy: 0.6786 - val_loss: 1.8298 - val_accuracy: 0.4726 - 301ms/epoch - 23ms/step\n",
            "Epoch 187/300\n",
            "13/13 - 0s - loss: 1.0047 - accuracy: 0.6638 - val_loss: 1.9257 - val_accuracy: 0.4640 - 304ms/epoch - 23ms/step\n",
            "Epoch 188/300\n",
            "13/13 - 0s - loss: 0.9272 - accuracy: 0.6813 - val_loss: 1.8974 - val_accuracy: 0.4798 - 300ms/epoch - 23ms/step\n",
            "Epoch 189/300\n",
            "13/13 - 0s - loss: 0.9368 - accuracy: 0.6983 - val_loss: 2.0816 - val_accuracy: 0.4597 - 302ms/epoch - 23ms/step\n",
            "Epoch 190/300\n",
            "13/13 - 0s - loss: 0.9909 - accuracy: 0.6755 - val_loss: 2.2894 - val_accuracy: 0.4438 - 305ms/epoch - 23ms/step\n",
            "Epoch 191/300\n",
            "13/13 - 0s - loss: 0.9389 - accuracy: 0.6907 - val_loss: 2.0373 - val_accuracy: 0.4914 - 308ms/epoch - 24ms/step\n",
            "Epoch 192/300\n",
            "13/13 - 0s - loss: 0.9448 - accuracy: 0.6855 - val_loss: 1.8767 - val_accuracy: 0.4784 - 308ms/epoch - 24ms/step\n",
            "Epoch 193/300\n",
            "13/13 - 0s - loss: 0.9996 - accuracy: 0.6744 - val_loss: 2.0087 - val_accuracy: 0.4452 - 311ms/epoch - 24ms/step\n",
            "Epoch 194/300\n",
            "13/13 - 0s - loss: 0.9471 - accuracy: 0.6794 - val_loss: 1.9733 - val_accuracy: 0.4366 - 304ms/epoch - 23ms/step\n",
            "Epoch 195/300\n",
            "13/13 - 0s - loss: 0.9099 - accuracy: 0.6871 - val_loss: 1.8296 - val_accuracy: 0.4798 - 297ms/epoch - 23ms/step\n",
            "Epoch 196/300\n",
            "13/13 - 0s - loss: 0.8341 - accuracy: 0.7080 - val_loss: 1.8590 - val_accuracy: 0.4914 - 301ms/epoch - 23ms/step\n",
            "Epoch 197/300\n",
            "13/13 - 0s - loss: 0.8360 - accuracy: 0.7079 - val_loss: 2.0193 - val_accuracy: 0.4798 - 310ms/epoch - 24ms/step\n",
            "Epoch 198/300\n",
            "13/13 - 0s - loss: 0.8448 - accuracy: 0.7095 - val_loss: 1.8155 - val_accuracy: 0.4856 - 304ms/epoch - 23ms/step\n",
            "Epoch 199/300\n",
            "13/13 - 0s - loss: 0.8653 - accuracy: 0.7167 - val_loss: 2.3151 - val_accuracy: 0.4337 - 296ms/epoch - 23ms/step\n",
            "Epoch 200/300\n",
            "13/13 - 0s - loss: 1.0512 - accuracy: 0.6762 - val_loss: 1.8100 - val_accuracy: 0.4582 - 300ms/epoch - 23ms/step\n",
            "Epoch 201/300\n",
            "13/13 - 0s - loss: 1.1308 - accuracy: 0.6397 - val_loss: 1.8375 - val_accuracy: 0.4654 - 299ms/epoch - 23ms/step\n",
            "Epoch 202/300\n",
            "13/13 - 0s - loss: 1.0091 - accuracy: 0.6653 - val_loss: 2.0030 - val_accuracy: 0.4265 - 307ms/epoch - 24ms/step\n",
            "Epoch 203/300\n",
            "13/13 - 0s - loss: 0.9896 - accuracy: 0.6683 - val_loss: 2.1255 - val_accuracy: 0.4553 - 305ms/epoch - 23ms/step\n",
            "Epoch 204/300\n",
            "13/13 - 0s - loss: 0.9575 - accuracy: 0.6808 - val_loss: 1.7523 - val_accuracy: 0.4841 - 307ms/epoch - 24ms/step\n",
            "Epoch 205/300\n",
            "13/13 - 0s - loss: 0.9997 - accuracy: 0.6807 - val_loss: 1.8271 - val_accuracy: 0.4726 - 305ms/epoch - 23ms/step\n",
            "Epoch 206/300\n",
            "13/13 - 0s - loss: 0.9833 - accuracy: 0.6755 - val_loss: 1.8044 - val_accuracy: 0.4337 - 298ms/epoch - 23ms/step\n",
            "Epoch 207/300\n",
            "13/13 - 0s - loss: 0.9512 - accuracy: 0.6720 - val_loss: 1.6446 - val_accuracy: 0.4885 - 301ms/epoch - 23ms/step\n",
            "Epoch 208/300\n",
            "13/13 - 0s - loss: 0.9671 - accuracy: 0.6837 - val_loss: 1.8862 - val_accuracy: 0.4510 - 296ms/epoch - 23ms/step\n",
            "Epoch 209/300\n",
            "13/13 - 0s - loss: 0.9204 - accuracy: 0.6855 - val_loss: 1.8257 - val_accuracy: 0.5058 - 299ms/epoch - 23ms/step\n",
            "Epoch 210/300\n",
            "13/13 - 0s - loss: 0.8885 - accuracy: 0.7026 - val_loss: 1.7419 - val_accuracy: 0.4741 - 304ms/epoch - 23ms/step\n",
            "Epoch 211/300\n",
            "13/13 - 0s - loss: 0.8245 - accuracy: 0.7103 - val_loss: 1.7499 - val_accuracy: 0.4957 - 300ms/epoch - 23ms/step\n",
            "Epoch 212/300\n",
            "13/13 - 0s - loss: 0.8210 - accuracy: 0.7197 - val_loss: 1.8364 - val_accuracy: 0.5014 - 304ms/epoch - 23ms/step\n",
            "Epoch 213/300\n",
            "13/13 - 0s - loss: 0.7973 - accuracy: 0.7188 - val_loss: 1.7124 - val_accuracy: 0.4942 - 306ms/epoch - 24ms/step\n",
            "Epoch 214/300\n",
            "13/13 - 0s - loss: 0.7626 - accuracy: 0.7298 - val_loss: 1.7469 - val_accuracy: 0.5072 - 309ms/epoch - 24ms/step\n",
            "Epoch 215/300\n",
            "13/13 - 0s - loss: 0.7610 - accuracy: 0.7284 - val_loss: 1.9596 - val_accuracy: 0.5130 - 304ms/epoch - 23ms/step\n",
            "Epoch 216/300\n",
            "13/13 - 0s - loss: 0.7641 - accuracy: 0.7316 - val_loss: 1.9617 - val_accuracy: 0.5144 - 304ms/epoch - 23ms/step\n",
            "Epoch 217/300\n",
            "13/13 - 0s - loss: 0.8294 - accuracy: 0.7316 - val_loss: 1.9971 - val_accuracy: 0.5303 - 300ms/epoch - 23ms/step\n",
            "Epoch 218/300\n",
            "13/13 - 0s - loss: 0.7973 - accuracy: 0.7204 - val_loss: 1.9046 - val_accuracy: 0.4841 - 300ms/epoch - 23ms/step\n",
            "Epoch 219/300\n",
            "13/13 - 0s - loss: 0.7741 - accuracy: 0.7293 - val_loss: 1.9624 - val_accuracy: 0.4986 - 306ms/epoch - 24ms/step\n",
            "Epoch 220/300\n",
            "13/13 - 0s - loss: 0.7981 - accuracy: 0.7298 - val_loss: 2.0673 - val_accuracy: 0.4986 - 307ms/epoch - 24ms/step\n",
            "Epoch 221/300\n",
            "13/13 - 0s - loss: 0.8716 - accuracy: 0.7193 - val_loss: 2.2139 - val_accuracy: 0.4856 - 302ms/epoch - 23ms/step\n",
            "Epoch 222/300\n",
            "13/13 - 0s - loss: 0.8223 - accuracy: 0.7156 - val_loss: 1.9804 - val_accuracy: 0.4914 - 303ms/epoch - 23ms/step\n",
            "Epoch 223/300\n",
            "13/13 - 0s - loss: 0.7896 - accuracy: 0.7212 - val_loss: 2.1231 - val_accuracy: 0.4856 - 303ms/epoch - 23ms/step\n",
            "Epoch 224/300\n",
            "13/13 - 0s - loss: 0.7776 - accuracy: 0.7237 - val_loss: 2.0571 - val_accuracy: 0.4798 - 302ms/epoch - 23ms/step\n",
            "Epoch 225/300\n",
            "13/13 - 0s - loss: 0.7967 - accuracy: 0.7255 - val_loss: 2.1126 - val_accuracy: 0.4885 - 307ms/epoch - 24ms/step\n",
            "Epoch 226/300\n",
            "13/13 - 0s - loss: 0.7574 - accuracy: 0.7373 - val_loss: 1.9872 - val_accuracy: 0.4827 - 309ms/epoch - 24ms/step\n",
            "Epoch 227/300\n",
            "13/13 - 0s - loss: 0.7962 - accuracy: 0.7271 - val_loss: 2.1717 - val_accuracy: 0.4986 - 303ms/epoch - 23ms/step\n",
            "Epoch 228/300\n",
            "13/13 - 0s - loss: 0.7657 - accuracy: 0.7404 - val_loss: 2.3552 - val_accuracy: 0.4957 - 301ms/epoch - 23ms/step\n",
            "Epoch 229/300\n",
            "13/13 - 0s - loss: 0.7722 - accuracy: 0.7277 - val_loss: 1.9536 - val_accuracy: 0.4798 - 299ms/epoch - 23ms/step\n",
            "Epoch 230/300\n",
            "13/13 - 0s - loss: 0.7454 - accuracy: 0.7349 - val_loss: 2.0468 - val_accuracy: 0.4798 - 306ms/epoch - 24ms/step\n",
            "Epoch 231/300\n",
            "13/13 - 0s - loss: 0.7652 - accuracy: 0.7409 - val_loss: 2.1722 - val_accuracy: 0.4827 - 309ms/epoch - 24ms/step\n",
            "Epoch 232/300\n",
            "13/13 - 0s - loss: 0.7647 - accuracy: 0.7386 - val_loss: 2.3742 - val_accuracy: 0.4827 - 308ms/epoch - 24ms/step\n",
            "Epoch 233/300\n",
            "13/13 - 0s - loss: 0.7609 - accuracy: 0.7338 - val_loss: 2.0721 - val_accuracy: 0.4769 - 326ms/epoch - 25ms/step\n",
            "Epoch 234/300\n",
            "13/13 - 0s - loss: 0.7821 - accuracy: 0.7237 - val_loss: 1.9717 - val_accuracy: 0.4856 - 321ms/epoch - 25ms/step\n",
            "Epoch 235/300\n",
            "13/13 - 0s - loss: 0.7821 - accuracy: 0.7282 - val_loss: 2.1955 - val_accuracy: 0.4870 - 321ms/epoch - 25ms/step\n",
            "Epoch 236/300\n",
            "13/13 - 0s - loss: 0.7398 - accuracy: 0.7385 - val_loss: 2.4486 - val_accuracy: 0.4942 - 322ms/epoch - 25ms/step\n",
            "Epoch 237/300\n",
            "13/13 - 0s - loss: 0.7428 - accuracy: 0.7380 - val_loss: 2.1332 - val_accuracy: 0.5000 - 324ms/epoch - 25ms/step\n",
            "Epoch 238/300\n",
            "13/13 - 0s - loss: 0.7399 - accuracy: 0.7389 - val_loss: 1.8619 - val_accuracy: 0.5029 - 319ms/epoch - 25ms/step\n",
            "Epoch 239/300\n",
            "13/13 - 0s - loss: 0.7663 - accuracy: 0.7394 - val_loss: 1.8742 - val_accuracy: 0.5072 - 328ms/epoch - 25ms/step\n",
            "Epoch 240/300\n",
            "13/13 - 0s - loss: 0.7921 - accuracy: 0.7303 - val_loss: 2.1312 - val_accuracy: 0.5029 - 306ms/epoch - 24ms/step\n",
            "Epoch 241/300\n",
            "13/13 - 0s - loss: 0.7664 - accuracy: 0.7356 - val_loss: 2.3494 - val_accuracy: 0.5043 - 299ms/epoch - 23ms/step\n",
            "Epoch 242/300\n",
            "13/13 - 0s - loss: 0.7703 - accuracy: 0.7418 - val_loss: 2.8408 - val_accuracy: 0.4928 - 298ms/epoch - 23ms/step\n",
            "Epoch 243/300\n",
            "13/13 - 0s - loss: 0.8692 - accuracy: 0.7322 - val_loss: 2.8939 - val_accuracy: 0.4769 - 313ms/epoch - 24ms/step\n",
            "Epoch 244/300\n",
            "13/13 - 0s - loss: 0.8623 - accuracy: 0.7284 - val_loss: 2.3204 - val_accuracy: 0.5058 - 303ms/epoch - 23ms/step\n",
            "Epoch 245/300\n",
            "13/13 - 0s - loss: 0.9058 - accuracy: 0.7116 - val_loss: 2.1755 - val_accuracy: 0.4669 - 306ms/epoch - 24ms/step\n",
            "Epoch 246/300\n",
            "13/13 - 0s - loss: 0.9527 - accuracy: 0.6925 - val_loss: 2.0265 - val_accuracy: 0.5014 - 304ms/epoch - 23ms/step\n",
            "Epoch 247/300\n",
            "13/13 - 0s - loss: 1.0840 - accuracy: 0.6683 - val_loss: 2.1308 - val_accuracy: 0.4697 - 297ms/epoch - 23ms/step\n",
            "Epoch 248/300\n",
            "13/13 - 0s - loss: 1.0214 - accuracy: 0.6597 - val_loss: 2.5927 - val_accuracy: 0.4640 - 302ms/epoch - 23ms/step\n",
            "Epoch 249/300\n",
            "13/13 - 0s - loss: 0.9244 - accuracy: 0.6861 - val_loss: 2.0720 - val_accuracy: 0.4971 - 313ms/epoch - 24ms/step\n",
            "Epoch 250/300\n",
            "13/13 - 0s - loss: 0.8970 - accuracy: 0.6903 - val_loss: 1.9580 - val_accuracy: 0.4971 - 304ms/epoch - 23ms/step\n",
            "Epoch 251/300\n",
            "13/13 - 0s - loss: 0.9298 - accuracy: 0.6824 - val_loss: 1.9223 - val_accuracy: 0.4885 - 300ms/epoch - 23ms/step\n",
            "Epoch 252/300\n",
            "13/13 - 0s - loss: 0.8547 - accuracy: 0.7066 - val_loss: 1.8360 - val_accuracy: 0.5014 - 307ms/epoch - 24ms/step\n",
            "Epoch 253/300\n",
            "13/13 - 0s - loss: 0.8910 - accuracy: 0.6983 - val_loss: 1.7727 - val_accuracy: 0.4986 - 307ms/epoch - 24ms/step\n",
            "Epoch 254/300\n",
            "13/13 - 0s - loss: 0.8281 - accuracy: 0.7144 - val_loss: 1.9048 - val_accuracy: 0.4957 - 307ms/epoch - 24ms/step\n",
            "Epoch 255/300\n",
            "13/13 - 0s - loss: 0.8799 - accuracy: 0.7074 - val_loss: 1.9212 - val_accuracy: 0.4827 - 303ms/epoch - 23ms/step\n",
            "Epoch 256/300\n",
            "13/13 - 0s - loss: 0.8285 - accuracy: 0.7104 - val_loss: 1.9645 - val_accuracy: 0.5058 - 303ms/epoch - 23ms/step\n",
            "Epoch 257/300\n",
            "13/13 - 0s - loss: 0.7821 - accuracy: 0.7345 - val_loss: 2.2080 - val_accuracy: 0.4899 - 309ms/epoch - 24ms/step\n",
            "Epoch 258/300\n",
            "13/13 - 0s - loss: 0.9193 - accuracy: 0.7082 - val_loss: 1.8810 - val_accuracy: 0.4928 - 307ms/epoch - 24ms/step\n",
            "Epoch 259/300\n",
            "13/13 - 0s - loss: 0.8193 - accuracy: 0.7160 - val_loss: 2.0183 - val_accuracy: 0.5159 - 301ms/epoch - 23ms/step\n",
            "Epoch 260/300\n",
            "13/13 - 0s - loss: 0.7981 - accuracy: 0.7301 - val_loss: 1.9421 - val_accuracy: 0.5115 - 303ms/epoch - 23ms/step\n",
            "Epoch 261/300\n",
            "13/13 - 0s - loss: 0.8326 - accuracy: 0.7133 - val_loss: 1.9793 - val_accuracy: 0.4885 - 304ms/epoch - 23ms/step\n",
            "Epoch 262/300\n",
            "13/13 - 0s - loss: 0.7863 - accuracy: 0.7311 - val_loss: 2.2242 - val_accuracy: 0.4784 - 302ms/epoch - 23ms/step\n",
            "Epoch 263/300\n",
            "13/13 - 0s - loss: 0.7949 - accuracy: 0.7364 - val_loss: 2.0613 - val_accuracy: 0.4769 - 297ms/epoch - 23ms/step\n",
            "Epoch 264/300\n",
            "13/13 - 0s - loss: 0.7883 - accuracy: 0.7313 - val_loss: 1.9403 - val_accuracy: 0.5000 - 300ms/epoch - 23ms/step\n",
            "Epoch 265/300\n",
            "13/13 - 0s - loss: 0.7969 - accuracy: 0.7340 - val_loss: 1.8455 - val_accuracy: 0.4885 - 304ms/epoch - 23ms/step\n",
            "Epoch 266/300\n",
            "13/13 - 0s - loss: 0.8978 - accuracy: 0.7088 - val_loss: 2.5727 - val_accuracy: 0.4712 - 309ms/epoch - 24ms/step\n",
            "Epoch 267/300\n",
            "13/13 - 0s - loss: 0.9013 - accuracy: 0.7040 - val_loss: 2.2325 - val_accuracy: 0.4885 - 311ms/epoch - 24ms/step\n",
            "Epoch 268/300\n",
            "13/13 - 0s - loss: 0.8345 - accuracy: 0.7149 - val_loss: 2.3338 - val_accuracy: 0.5130 - 306ms/epoch - 24ms/step\n",
            "Epoch 269/300\n",
            "13/13 - 0s - loss: 0.8036 - accuracy: 0.7351 - val_loss: 2.2418 - val_accuracy: 0.5130 - 304ms/epoch - 23ms/step\n",
            "Epoch 270/300\n",
            "13/13 - 0s - loss: 0.7851 - accuracy: 0.7217 - val_loss: 2.4313 - val_accuracy: 0.4914 - 302ms/epoch - 23ms/step\n",
            "Epoch 271/300\n",
            "13/13 - 0s - loss: 0.7579 - accuracy: 0.7281 - val_loss: 2.2234 - val_accuracy: 0.4827 - 309ms/epoch - 24ms/step\n",
            "Epoch 272/300\n",
            "13/13 - 0s - loss: 0.7388 - accuracy: 0.7380 - val_loss: 2.2864 - val_accuracy: 0.5115 - 303ms/epoch - 23ms/step\n",
            "Epoch 273/300\n",
            "13/13 - 0s - loss: 0.7250 - accuracy: 0.7487 - val_loss: 2.6472 - val_accuracy: 0.4885 - 301ms/epoch - 23ms/step\n",
            "Epoch 274/300\n",
            "13/13 - 0s - loss: 0.7049 - accuracy: 0.7506 - val_loss: 2.6812 - val_accuracy: 0.4914 - 301ms/epoch - 23ms/step\n",
            "Epoch 275/300\n",
            "13/13 - 0s - loss: 0.7377 - accuracy: 0.7414 - val_loss: 2.5740 - val_accuracy: 0.5043 - 302ms/epoch - 23ms/step\n",
            "Epoch 276/300\n",
            "13/13 - 0s - loss: 0.7010 - accuracy: 0.7545 - val_loss: 2.3434 - val_accuracy: 0.4957 - 307ms/epoch - 24ms/step\n",
            "Epoch 277/300\n",
            "13/13 - 0s - loss: 0.7858 - accuracy: 0.7537 - val_loss: 2.5411 - val_accuracy: 0.5346 - 305ms/epoch - 23ms/step\n",
            "Epoch 278/300\n",
            "13/13 - 0s - loss: 1.3888 - accuracy: 0.7460 - val_loss: 2.3372 - val_accuracy: 0.4914 - 303ms/epoch - 23ms/step\n",
            "Epoch 279/300\n",
            "13/13 - 0s - loss: 1.1488 - accuracy: 0.6718 - val_loss: 2.7052 - val_accuracy: 0.4222 - 301ms/epoch - 23ms/step\n",
            "Epoch 280/300\n",
            "13/13 - 0s - loss: 1.0277 - accuracy: 0.6702 - val_loss: 1.8757 - val_accuracy: 0.4856 - 300ms/epoch - 23ms/step\n",
            "Epoch 281/300\n",
            "13/13 - 0s - loss: 1.1272 - accuracy: 0.6528 - val_loss: 1.6568 - val_accuracy: 0.4784 - 307ms/epoch - 24ms/step\n",
            "Epoch 282/300\n",
            "13/13 - 0s - loss: 1.0512 - accuracy: 0.6397 - val_loss: 1.7519 - val_accuracy: 0.4827 - 305ms/epoch - 23ms/step\n",
            "Epoch 283/300\n",
            "13/13 - 0s - loss: 1.0812 - accuracy: 0.6518 - val_loss: 1.5961 - val_accuracy: 0.5043 - 308ms/epoch - 24ms/step\n",
            "Epoch 284/300\n",
            "13/13 - 0s - loss: 1.0064 - accuracy: 0.6622 - val_loss: 1.6919 - val_accuracy: 0.4870 - 303ms/epoch - 23ms/step\n",
            "Epoch 285/300\n",
            "13/13 - 0s - loss: 1.1046 - accuracy: 0.6750 - val_loss: 1.9956 - val_accuracy: 0.4741 - 311ms/epoch - 24ms/step\n",
            "Epoch 286/300\n",
            "13/13 - 0s - loss: 1.3351 - accuracy: 0.6525 - val_loss: 1.7100 - val_accuracy: 0.4438 - 315ms/epoch - 24ms/step\n",
            "Epoch 287/300\n",
            "13/13 - 0s - loss: 1.1333 - accuracy: 0.6278 - val_loss: 1.9893 - val_accuracy: 0.4496 - 309ms/epoch - 24ms/step\n",
            "Epoch 288/300\n",
            "13/13 - 0s - loss: 1.0468 - accuracy: 0.6603 - val_loss: 1.7791 - val_accuracy: 0.4697 - 307ms/epoch - 24ms/step\n",
            "Epoch 289/300\n",
            "13/13 - 0s - loss: 1.0778 - accuracy: 0.6382 - val_loss: 2.0158 - val_accuracy: 0.4625 - 306ms/epoch - 24ms/step\n",
            "Epoch 290/300\n",
            "13/13 - 0s - loss: 1.0755 - accuracy: 0.6324 - val_loss: 1.8491 - val_accuracy: 0.4553 - 311ms/epoch - 24ms/step\n",
            "Epoch 291/300\n",
            "13/13 - 0s - loss: 1.0400 - accuracy: 0.6445 - val_loss: 1.8176 - val_accuracy: 0.4597 - 306ms/epoch - 24ms/step\n",
            "Epoch 292/300\n",
            "13/13 - 0s - loss: 0.9814 - accuracy: 0.6595 - val_loss: 2.0531 - val_accuracy: 0.4697 - 302ms/epoch - 23ms/step\n",
            "Epoch 293/300\n",
            "13/13 - 0s - loss: 1.0227 - accuracy: 0.6605 - val_loss: 2.2409 - val_accuracy: 0.4568 - 307ms/epoch - 24ms/step\n",
            "Epoch 294/300\n",
            "13/13 - 0s - loss: 1.0277 - accuracy: 0.6571 - val_loss: 1.7305 - val_accuracy: 0.4424 - 306ms/epoch - 24ms/step\n",
            "Epoch 295/300\n",
            "13/13 - 0s - loss: 1.0010 - accuracy: 0.6531 - val_loss: 1.8528 - val_accuracy: 0.4957 - 299ms/epoch - 23ms/step\n",
            "Epoch 296/300\n",
            "13/13 - 0s - loss: 0.9719 - accuracy: 0.6763 - val_loss: 1.7569 - val_accuracy: 0.4769 - 304ms/epoch - 23ms/step\n",
            "Epoch 297/300\n",
            "13/13 - 0s - loss: 0.9569 - accuracy: 0.6970 - val_loss: 1.6703 - val_accuracy: 0.4841 - 308ms/epoch - 24ms/step\n",
            "Epoch 298/300\n",
            "13/13 - 0s - loss: 0.9482 - accuracy: 0.6888 - val_loss: 1.6773 - val_accuracy: 0.4928 - 307ms/epoch - 24ms/step\n",
            "Epoch 299/300\n",
            "13/13 - 0s - loss: 0.9814 - accuracy: 0.6871 - val_loss: 2.0442 - val_accuracy: 0.4712 - 304ms/epoch - 23ms/step\n",
            "Epoch 300/300\n",
            "13/13 - 0s - loss: 1.0107 - accuracy: 0.6683 - val_loss: 2.0877 - val_accuracy: 0.4942 - 306ms/epoch - 24ms/step\n",
            "Model: \"sequential_103\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_206 (Conv2D)         (None, 4, 36, 80)         27440     \n",
            "                                                                 \n",
            " max_pooling2d_206 (MaxPooli  (None, 1, 12, 80)        0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_103 (Ba  (None, 1, 12, 80)        320       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " conv2d_207 (Conv2D)         (None, 1, 10, 80)         19280     \n",
            "                                                                 \n",
            " max_pooling2d_207 (MaxPooli  (None, 1, 3, 80)         0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " flatten_103 (Flatten)       (None, 240)               0         \n",
            "                                                                 \n",
            " dense_309 (Dense)           (None, 5000)              1205000   \n",
            "                                                                 \n",
            " dropout_206 (Dropout)       (None, 5000)              0         \n",
            "                                                                 \n",
            " dense_310 (Dense)           (None, 5000)              25005000  \n",
            "                                                                 \n",
            " dropout_207 (Dropout)       (None, 5000)              0         \n",
            "                                                                 \n",
            " dense_311 (Dense)           (None, 10)                50010     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 26,307,050\n",
            "Trainable params: 26,306,890\n",
            "Non-trainable params: 160\n",
            "_________________________________________________________________\n",
            "None\n",
            "Result of fold:9\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 40.3691 - accuracy: 0.4905\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 90%|█████████ | 9/10 [15:00<01:43, 103.40s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(6928, 60, 41)\n",
            "Epoch 1/300\n",
            "13/13 - 1s - loss: 4.4261 - accuracy: 0.1514 - val_loss: 2.8809 - val_accuracy: 0.2626 - 1s/epoch - 88ms/step\n",
            "Epoch 2/300\n",
            "13/13 - 0s - loss: 2.1267 - accuracy: 0.2253 - val_loss: 2.1496 - val_accuracy: 0.2698 - 299ms/epoch - 23ms/step\n",
            "Epoch 3/300\n",
            "13/13 - 0s - loss: 2.0028 - accuracy: 0.2565 - val_loss: 2.0306 - val_accuracy: 0.2222 - 300ms/epoch - 23ms/step\n",
            "Epoch 4/300\n",
            "13/13 - 0s - loss: 1.9615 - accuracy: 0.2860 - val_loss: 1.9106 - val_accuracy: 0.2698 - 302ms/epoch - 23ms/step\n",
            "Epoch 5/300\n",
            "13/13 - 0s - loss: 1.9174 - accuracy: 0.3100 - val_loss: 1.9477 - val_accuracy: 0.2727 - 299ms/epoch - 23ms/step\n",
            "Epoch 6/300\n",
            "13/13 - 0s - loss: 1.8326 - accuracy: 0.3286 - val_loss: 1.7481 - val_accuracy: 0.3276 - 297ms/epoch - 23ms/step\n",
            "Epoch 7/300\n",
            "13/13 - 0s - loss: 1.7659 - accuracy: 0.3596 - val_loss: 1.7001 - val_accuracy: 0.3593 - 301ms/epoch - 23ms/step\n",
            "Epoch 8/300\n",
            "13/13 - 0s - loss: 1.7102 - accuracy: 0.3787 - val_loss: 1.6299 - val_accuracy: 0.3752 - 301ms/epoch - 23ms/step\n",
            "Epoch 9/300\n",
            "13/13 - 0s - loss: 1.6316 - accuracy: 0.3957 - val_loss: 1.6299 - val_accuracy: 0.4141 - 308ms/epoch - 24ms/step\n",
            "Epoch 10/300\n",
            "13/13 - 0s - loss: 1.6111 - accuracy: 0.4122 - val_loss: 1.6732 - val_accuracy: 0.3867 - 304ms/epoch - 23ms/step\n",
            "Epoch 11/300\n",
            "13/13 - 0s - loss: 1.5913 - accuracy: 0.4225 - val_loss: 1.7184 - val_accuracy: 0.4430 - 303ms/epoch - 23ms/step\n",
            "Epoch 12/300\n",
            "13/13 - 0s - loss: 1.6092 - accuracy: 0.4151 - val_loss: 1.6013 - val_accuracy: 0.4762 - 301ms/epoch - 23ms/step\n",
            "Epoch 13/300\n",
            "13/13 - 0s - loss: 1.5024 - accuracy: 0.4598 - val_loss: 1.5353 - val_accuracy: 0.4863 - 305ms/epoch - 23ms/step\n",
            "Epoch 14/300\n",
            "13/13 - 0s - loss: 1.4398 - accuracy: 0.4823 - val_loss: 1.5575 - val_accuracy: 0.5022 - 307ms/epoch - 24ms/step\n",
            "Epoch 15/300\n",
            "13/13 - 0s - loss: 1.4542 - accuracy: 0.4765 - val_loss: 1.6350 - val_accuracy: 0.5137 - 307ms/epoch - 24ms/step\n",
            "Epoch 16/300\n",
            "13/13 - 0s - loss: 1.4314 - accuracy: 0.4921 - val_loss: 1.6059 - val_accuracy: 0.4502 - 303ms/epoch - 23ms/step\n",
            "Epoch 17/300\n",
            "13/13 - 0s - loss: 1.3472 - accuracy: 0.5116 - val_loss: 1.6760 - val_accuracy: 0.4978 - 299ms/epoch - 23ms/step\n",
            "Epoch 18/300\n",
            "13/13 - 0s - loss: 1.3316 - accuracy: 0.5291 - val_loss: 1.5906 - val_accuracy: 0.4444 - 301ms/epoch - 23ms/step\n",
            "Epoch 19/300\n",
            "13/13 - 0s - loss: 1.3889 - accuracy: 0.4996 - val_loss: 1.5119 - val_accuracy: 0.5195 - 304ms/epoch - 23ms/step\n",
            "Epoch 20/300\n",
            "13/13 - 0s - loss: 1.3010 - accuracy: 0.5469 - val_loss: 1.4974 - val_accuracy: 0.5584 - 305ms/epoch - 23ms/step\n",
            "Epoch 21/300\n",
            "13/13 - 0s - loss: 1.2482 - accuracy: 0.5591 - val_loss: 1.6549 - val_accuracy: 0.4776 - 305ms/epoch - 23ms/step\n",
            "Epoch 22/300\n",
            "13/13 - 0s - loss: 1.2695 - accuracy: 0.5504 - val_loss: 1.6750 - val_accuracy: 0.4416 - 303ms/epoch - 23ms/step\n",
            "Epoch 23/300\n",
            "13/13 - 0s - loss: 1.3005 - accuracy: 0.5352 - val_loss: 1.5931 - val_accuracy: 0.5253 - 297ms/epoch - 23ms/step\n",
            "Epoch 24/300\n",
            "13/13 - 0s - loss: 1.2427 - accuracy: 0.5554 - val_loss: 1.9315 - val_accuracy: 0.4646 - 299ms/epoch - 23ms/step\n",
            "Epoch 25/300\n",
            "13/13 - 0s - loss: 1.2863 - accuracy: 0.5455 - val_loss: 1.5682 - val_accuracy: 0.4574 - 299ms/epoch - 23ms/step\n",
            "Epoch 26/300\n",
            "13/13 - 0s - loss: 1.2625 - accuracy: 0.5617 - val_loss: 1.6079 - val_accuracy: 0.5137 - 301ms/epoch - 23ms/step\n",
            "Epoch 27/300\n",
            "13/13 - 0s - loss: 1.1807 - accuracy: 0.5742 - val_loss: 1.6892 - val_accuracy: 0.5296 - 300ms/epoch - 23ms/step\n",
            "Epoch 28/300\n",
            "13/13 - 0s - loss: 1.1777 - accuracy: 0.5812 - val_loss: 1.6625 - val_accuracy: 0.5209 - 307ms/epoch - 24ms/step\n",
            "Epoch 29/300\n",
            "13/13 - 0s - loss: 1.2872 - accuracy: 0.5458 - val_loss: 1.5883 - val_accuracy: 0.4921 - 310ms/epoch - 24ms/step\n",
            "Epoch 30/300\n",
            "13/13 - 0s - loss: 1.2099 - accuracy: 0.5618 - val_loss: 1.7099 - val_accuracy: 0.5382 - 309ms/epoch - 24ms/step\n",
            "Epoch 31/300\n",
            "13/13 - 0s - loss: 1.1384 - accuracy: 0.6035 - val_loss: 1.9046 - val_accuracy: 0.5137 - 313ms/epoch - 24ms/step\n",
            "Epoch 32/300\n",
            "13/13 - 0s - loss: 1.0882 - accuracy: 0.6143 - val_loss: 1.9000 - val_accuracy: 0.4906 - 304ms/epoch - 23ms/step\n",
            "Epoch 33/300\n",
            "13/13 - 0s - loss: 1.0988 - accuracy: 0.6037 - val_loss: 1.8842 - val_accuracy: 0.4791 - 308ms/epoch - 24ms/step\n",
            "Epoch 34/300\n",
            "13/13 - 0s - loss: 1.1151 - accuracy: 0.6072 - val_loss: 1.7144 - val_accuracy: 0.5743 - 313ms/epoch - 24ms/step\n",
            "Epoch 35/300\n",
            "13/13 - 0s - loss: 1.1048 - accuracy: 0.6133 - val_loss: 1.6654 - val_accuracy: 0.5830 - 309ms/epoch - 24ms/step\n",
            "Epoch 36/300\n",
            "13/13 - 0s - loss: 1.1398 - accuracy: 0.5912 - val_loss: 1.9915 - val_accuracy: 0.5007 - 307ms/epoch - 24ms/step\n",
            "Epoch 37/300\n",
            "13/13 - 0s - loss: 1.1343 - accuracy: 0.5949 - val_loss: 1.7399 - val_accuracy: 0.5007 - 303ms/epoch - 23ms/step\n",
            "Epoch 38/300\n",
            "13/13 - 0s - loss: 1.0631 - accuracy: 0.6148 - val_loss: 1.7345 - val_accuracy: 0.5051 - 302ms/epoch - 23ms/step\n",
            "Epoch 39/300\n",
            "13/13 - 0s - loss: 1.1034 - accuracy: 0.6056 - val_loss: 1.7172 - val_accuracy: 0.5036 - 296ms/epoch - 23ms/step\n",
            "Epoch 40/300\n",
            "13/13 - 0s - loss: 1.1120 - accuracy: 0.6087 - val_loss: 2.1269 - val_accuracy: 0.4545 - 303ms/epoch - 23ms/step\n",
            "Epoch 41/300\n",
            "13/13 - 0s - loss: 1.0919 - accuracy: 0.6165 - val_loss: 1.7313 - val_accuracy: 0.5022 - 306ms/epoch - 24ms/step\n",
            "Epoch 42/300\n",
            "13/13 - 0s - loss: 1.1282 - accuracy: 0.6083 - val_loss: 2.0392 - val_accuracy: 0.4935 - 304ms/epoch - 23ms/step\n",
            "Epoch 43/300\n",
            "13/13 - 0s - loss: 1.1730 - accuracy: 0.5966 - val_loss: 1.5799 - val_accuracy: 0.4791 - 299ms/epoch - 23ms/step\n",
            "Epoch 44/300\n",
            "13/13 - 0s - loss: 1.1650 - accuracy: 0.5953 - val_loss: 1.7367 - val_accuracy: 0.4993 - 308ms/epoch - 24ms/step\n",
            "Epoch 45/300\n",
            "13/13 - 0s - loss: 1.1106 - accuracy: 0.6059 - val_loss: 1.7861 - val_accuracy: 0.4762 - 307ms/epoch - 24ms/step\n",
            "Epoch 46/300\n",
            "13/13 - 0s - loss: 1.1044 - accuracy: 0.6112 - val_loss: 1.6481 - val_accuracy: 0.4776 - 305ms/epoch - 23ms/step\n",
            "Epoch 47/300\n",
            "13/13 - 0s - loss: 1.1284 - accuracy: 0.6077 - val_loss: 2.0518 - val_accuracy: 0.4877 - 296ms/epoch - 23ms/step\n",
            "Epoch 48/300\n",
            "13/13 - 0s - loss: 1.0681 - accuracy: 0.6196 - val_loss: 1.7010 - val_accuracy: 0.4949 - 297ms/epoch - 23ms/step\n",
            "Epoch 49/300\n",
            "13/13 - 0s - loss: 1.0266 - accuracy: 0.6366 - val_loss: 2.3429 - val_accuracy: 0.5382 - 302ms/epoch - 23ms/step\n",
            "Epoch 50/300\n",
            "13/13 - 0s - loss: 1.0955 - accuracy: 0.6202 - val_loss: 1.7686 - val_accuracy: 0.4993 - 307ms/epoch - 24ms/step\n",
            "Epoch 51/300\n",
            "13/13 - 0s - loss: 1.0720 - accuracy: 0.6192 - val_loss: 1.9447 - val_accuracy: 0.4603 - 305ms/epoch - 23ms/step\n",
            "Epoch 52/300\n",
            "13/13 - 0s - loss: 1.0695 - accuracy: 0.6128 - val_loss: 1.8013 - val_accuracy: 0.5671 - 300ms/epoch - 23ms/step\n",
            "Epoch 53/300\n",
            "13/13 - 0s - loss: 1.0744 - accuracy: 0.6236 - val_loss: 2.1008 - val_accuracy: 0.5397 - 298ms/epoch - 23ms/step\n",
            "Epoch 54/300\n",
            "13/13 - 0s - loss: 1.1098 - accuracy: 0.6170 - val_loss: 2.1571 - val_accuracy: 0.5570 - 300ms/epoch - 23ms/step\n",
            "Epoch 55/300\n",
            "13/13 - 0s - loss: 1.0579 - accuracy: 0.6353 - val_loss: 2.0158 - val_accuracy: 0.5628 - 310ms/epoch - 24ms/step\n",
            "Epoch 56/300\n",
            "13/13 - 0s - loss: 1.1104 - accuracy: 0.6202 - val_loss: 1.7884 - val_accuracy: 0.5368 - 301ms/epoch - 23ms/step\n",
            "Epoch 57/300\n",
            "13/13 - 0s - loss: 1.1174 - accuracy: 0.6048 - val_loss: 1.7429 - val_accuracy: 0.5440 - 297ms/epoch - 23ms/step\n",
            "Epoch 58/300\n",
            "13/13 - 0s - loss: 1.1091 - accuracy: 0.6144 - val_loss: 1.8988 - val_accuracy: 0.5613 - 300ms/epoch - 23ms/step\n",
            "Epoch 59/300\n",
            "13/13 - 0s - loss: 1.0611 - accuracy: 0.6403 - val_loss: 2.1700 - val_accuracy: 0.4863 - 302ms/epoch - 23ms/step\n",
            "Epoch 60/300\n",
            "13/13 - 0s - loss: 1.0107 - accuracy: 0.6587 - val_loss: 2.1690 - val_accuracy: 0.5397 - 299ms/epoch - 23ms/step\n",
            "Epoch 61/300\n",
            "13/13 - 0s - loss: 1.0806 - accuracy: 0.6362 - val_loss: 1.6836 - val_accuracy: 0.5613 - 296ms/epoch - 23ms/step\n",
            "Epoch 62/300\n",
            "13/13 - 0s - loss: 1.1091 - accuracy: 0.6244 - val_loss: 2.0064 - val_accuracy: 0.4834 - 308ms/epoch - 24ms/step\n",
            "Epoch 63/300\n",
            "13/13 - 0s - loss: 1.1335 - accuracy: 0.6285 - val_loss: 2.2551 - val_accuracy: 0.5844 - 301ms/epoch - 23ms/step\n",
            "Epoch 64/300\n",
            "13/13 - 0s - loss: 1.0751 - accuracy: 0.6348 - val_loss: 2.2215 - val_accuracy: 0.4978 - 308ms/epoch - 24ms/step\n",
            "Epoch 65/300\n",
            "13/13 - 0s - loss: 1.1196 - accuracy: 0.6233 - val_loss: 2.4590 - val_accuracy: 0.5238 - 299ms/epoch - 23ms/step\n",
            "Epoch 66/300\n",
            "13/13 - 0s - loss: 1.1282 - accuracy: 0.6197 - val_loss: 3.6963 - val_accuracy: 0.4343 - 301ms/epoch - 23ms/step\n",
            "Epoch 67/300\n",
            "13/13 - 0s - loss: 1.2517 - accuracy: 0.5937 - val_loss: 1.7231 - val_accuracy: 0.5051 - 305ms/epoch - 23ms/step\n",
            "Epoch 68/300\n",
            "13/13 - 0s - loss: 1.2133 - accuracy: 0.5929 - val_loss: 2.0491 - val_accuracy: 0.5368 - 307ms/epoch - 24ms/step\n",
            "Epoch 69/300\n",
            "13/13 - 0s - loss: 1.1661 - accuracy: 0.6236 - val_loss: 1.9433 - val_accuracy: 0.4964 - 309ms/epoch - 24ms/step\n",
            "Epoch 70/300\n",
            "13/13 - 0s - loss: 1.1936 - accuracy: 0.6010 - val_loss: 2.0469 - val_accuracy: 0.4704 - 302ms/epoch - 23ms/step\n",
            "Epoch 71/300\n",
            "13/13 - 0s - loss: 1.1505 - accuracy: 0.6156 - val_loss: 2.8220 - val_accuracy: 0.4603 - 304ms/epoch - 23ms/step\n",
            "Epoch 72/300\n",
            "13/13 - 0s - loss: 1.1701 - accuracy: 0.6111 - val_loss: 2.0650 - val_accuracy: 0.5022 - 310ms/epoch - 24ms/step\n",
            "Epoch 73/300\n",
            "13/13 - 0s - loss: 1.1511 - accuracy: 0.6132 - val_loss: 2.0528 - val_accuracy: 0.5296 - 301ms/epoch - 23ms/step\n",
            "Epoch 74/300\n",
            "13/13 - 0s - loss: 1.0495 - accuracy: 0.6327 - val_loss: 2.0650 - val_accuracy: 0.5931 - 303ms/epoch - 23ms/step\n",
            "Epoch 75/300\n",
            "13/13 - 0s - loss: 1.0495 - accuracy: 0.6520 - val_loss: 2.2193 - val_accuracy: 0.5339 - 298ms/epoch - 23ms/step\n",
            "Epoch 76/300\n",
            "13/13 - 0s - loss: 1.1134 - accuracy: 0.6430 - val_loss: 2.7224 - val_accuracy: 0.4863 - 307ms/epoch - 24ms/step\n",
            "Epoch 77/300\n",
            "13/13 - 0s - loss: 1.1304 - accuracy: 0.6354 - val_loss: 2.2734 - val_accuracy: 0.5137 - 304ms/epoch - 23ms/step\n",
            "Epoch 78/300\n",
            "13/13 - 0s - loss: 1.2019 - accuracy: 0.6380 - val_loss: 3.9434 - val_accuracy: 0.4545 - 306ms/epoch - 24ms/step\n",
            "Epoch 79/300\n",
            "13/13 - 0s - loss: 1.3036 - accuracy: 0.6010 - val_loss: 2.4636 - val_accuracy: 0.4589 - 305ms/epoch - 23ms/step\n",
            "Epoch 80/300\n",
            "13/13 - 0s - loss: 1.3230 - accuracy: 0.5955 - val_loss: 3.1680 - val_accuracy: 0.4834 - 306ms/epoch - 24ms/step\n",
            "Epoch 81/300\n",
            "13/13 - 0s - loss: 1.2810 - accuracy: 0.6112 - val_loss: 3.1301 - val_accuracy: 0.4805 - 303ms/epoch - 23ms/step\n",
            "Epoch 82/300\n",
            "13/13 - 0s - loss: 1.3168 - accuracy: 0.6080 - val_loss: 2.4730 - val_accuracy: 0.5253 - 300ms/epoch - 23ms/step\n",
            "Epoch 83/300\n",
            "13/13 - 0s - loss: 1.3932 - accuracy: 0.5715 - val_loss: 2.4226 - val_accuracy: 0.4531 - 300ms/epoch - 23ms/step\n",
            "Epoch 84/300\n",
            "13/13 - 0s - loss: 1.2047 - accuracy: 0.6083 - val_loss: 2.5942 - val_accuracy: 0.5483 - 299ms/epoch - 23ms/step\n",
            "Epoch 85/300\n",
            "13/13 - 0s - loss: 1.1344 - accuracy: 0.6143 - val_loss: 2.5831 - val_accuracy: 0.4661 - 306ms/epoch - 24ms/step\n",
            "Epoch 86/300\n",
            "13/13 - 0s - loss: 1.0800 - accuracy: 0.6295 - val_loss: 1.9858 - val_accuracy: 0.5281 - 296ms/epoch - 23ms/step\n",
            "Epoch 87/300\n",
            "13/13 - 0s - loss: 1.0983 - accuracy: 0.6346 - val_loss: 2.4288 - val_accuracy: 0.5527 - 300ms/epoch - 23ms/step\n",
            "Epoch 88/300\n",
            "13/13 - 0s - loss: 1.0634 - accuracy: 0.6435 - val_loss: 1.9252 - val_accuracy: 0.5166 - 305ms/epoch - 23ms/step\n",
            "Epoch 89/300\n",
            "13/13 - 0s - loss: 1.1263 - accuracy: 0.6210 - val_loss: 3.0017 - val_accuracy: 0.4502 - 309ms/epoch - 24ms/step\n",
            "Epoch 90/300\n",
            "13/13 - 0s - loss: 1.1245 - accuracy: 0.6295 - val_loss: 1.7900 - val_accuracy: 0.4762 - 300ms/epoch - 23ms/step\n",
            "Epoch 91/300\n",
            "13/13 - 0s - loss: 1.0856 - accuracy: 0.6218 - val_loss: 1.9244 - val_accuracy: 0.5022 - 301ms/epoch - 23ms/step\n",
            "Epoch 92/300\n",
            "13/13 - 0s - loss: 0.9553 - accuracy: 0.6651 - val_loss: 2.1592 - val_accuracy: 0.5714 - 306ms/epoch - 24ms/step\n",
            "Epoch 93/300\n",
            "13/13 - 0s - loss: 0.9997 - accuracy: 0.6544 - val_loss: 2.9957 - val_accuracy: 0.5339 - 303ms/epoch - 23ms/step\n",
            "Epoch 94/300\n",
            "13/13 - 0s - loss: 0.9895 - accuracy: 0.6516 - val_loss: 2.1388 - val_accuracy: 0.5801 - 299ms/epoch - 23ms/step\n",
            "Epoch 95/300\n",
            "13/13 - 0s - loss: 1.0139 - accuracy: 0.6544 - val_loss: 2.3100 - val_accuracy: 0.5079 - 302ms/epoch - 23ms/step\n",
            "Epoch 96/300\n",
            "13/13 - 0s - loss: 0.9576 - accuracy: 0.6584 - val_loss: 2.5440 - val_accuracy: 0.5195 - 303ms/epoch - 23ms/step\n",
            "Epoch 97/300\n",
            "13/13 - 0s - loss: 0.9681 - accuracy: 0.6711 - val_loss: 2.1922 - val_accuracy: 0.5209 - 302ms/epoch - 23ms/step\n",
            "Epoch 98/300\n",
            "13/13 - 0s - loss: 1.0454 - accuracy: 0.6524 - val_loss: 2.3103 - val_accuracy: 0.4949 - 297ms/epoch - 23ms/step\n",
            "Epoch 99/300\n",
            "13/13 - 0s - loss: 0.9933 - accuracy: 0.6632 - val_loss: 2.2479 - val_accuracy: 0.5354 - 299ms/epoch - 23ms/step\n",
            "Epoch 100/300\n",
            "13/13 - 0s - loss: 0.9380 - accuracy: 0.6686 - val_loss: 2.3920 - val_accuracy: 0.4921 - 303ms/epoch - 23ms/step\n",
            "Epoch 101/300\n",
            "13/13 - 0s - loss: 0.9710 - accuracy: 0.6667 - val_loss: 2.1643 - val_accuracy: 0.5671 - 305ms/epoch - 23ms/step\n",
            "Epoch 102/300\n",
            "13/13 - 0s - loss: 1.0237 - accuracy: 0.6678 - val_loss: 2.3735 - val_accuracy: 0.5325 - 301ms/epoch - 23ms/step\n",
            "Epoch 103/300\n",
            "13/13 - 0s - loss: 0.9640 - accuracy: 0.6642 - val_loss: 2.8208 - val_accuracy: 0.5758 - 305ms/epoch - 23ms/step\n",
            "Epoch 104/300\n",
            "13/13 - 0s - loss: 0.9767 - accuracy: 0.6677 - val_loss: 2.4205 - val_accuracy: 0.4949 - 304ms/epoch - 23ms/step\n",
            "Epoch 105/300\n",
            "13/13 - 0s - loss: 0.9250 - accuracy: 0.6776 - val_loss: 2.3965 - val_accuracy: 0.4921 - 300ms/epoch - 23ms/step\n",
            "Epoch 106/300\n",
            "13/13 - 0s - loss: 0.9143 - accuracy: 0.6723 - val_loss: 2.1596 - val_accuracy: 0.5368 - 302ms/epoch - 23ms/step\n",
            "Epoch 107/300\n",
            "13/13 - 0s - loss: 0.8786 - accuracy: 0.6792 - val_loss: 2.4448 - val_accuracy: 0.5599 - 301ms/epoch - 23ms/step\n",
            "Epoch 108/300\n",
            "13/13 - 0s - loss: 0.9108 - accuracy: 0.6868 - val_loss: 2.2059 - val_accuracy: 0.5411 - 298ms/epoch - 23ms/step\n",
            "Epoch 109/300\n",
            "13/13 - 0s - loss: 0.9377 - accuracy: 0.6707 - val_loss: 1.8768 - val_accuracy: 0.5007 - 303ms/epoch - 23ms/step\n",
            "Epoch 110/300\n",
            "13/13 - 0s - loss: 0.9646 - accuracy: 0.6675 - val_loss: 2.0544 - val_accuracy: 0.5108 - 304ms/epoch - 23ms/step\n",
            "Epoch 111/300\n",
            "13/13 - 0s - loss: 1.0056 - accuracy: 0.6656 - val_loss: 2.1366 - val_accuracy: 0.4675 - 308ms/epoch - 24ms/step\n",
            "Epoch 112/300\n",
            "13/13 - 0s - loss: 1.0974 - accuracy: 0.6265 - val_loss: 2.5568 - val_accuracy: 0.5382 - 303ms/epoch - 23ms/step\n",
            "Epoch 113/300\n",
            "13/13 - 0s - loss: 1.0317 - accuracy: 0.6393 - val_loss: 2.4916 - val_accuracy: 0.4820 - 307ms/epoch - 24ms/step\n",
            "Epoch 114/300\n",
            "13/13 - 0s - loss: 1.0283 - accuracy: 0.6460 - val_loss: 3.0489 - val_accuracy: 0.5310 - 306ms/epoch - 24ms/step\n",
            "Epoch 115/300\n",
            "13/13 - 0s - loss: 0.9475 - accuracy: 0.6712 - val_loss: 2.1332 - val_accuracy: 0.4964 - 306ms/epoch - 24ms/step\n",
            "Epoch 116/300\n",
            "13/13 - 0s - loss: 0.9376 - accuracy: 0.6754 - val_loss: 1.8169 - val_accuracy: 0.5238 - 296ms/epoch - 23ms/step\n",
            "Epoch 117/300\n",
            "13/13 - 0s - loss: 0.9158 - accuracy: 0.6889 - val_loss: 2.1116 - val_accuracy: 0.5729 - 308ms/epoch - 24ms/step\n",
            "Epoch 118/300\n",
            "13/13 - 0s - loss: 0.9336 - accuracy: 0.6786 - val_loss: 2.0458 - val_accuracy: 0.5108 - 299ms/epoch - 23ms/step\n",
            "Epoch 119/300\n",
            "13/13 - 0s - loss: 0.9188 - accuracy: 0.6690 - val_loss: 2.2432 - val_accuracy: 0.5411 - 302ms/epoch - 23ms/step\n",
            "Epoch 120/300\n",
            "13/13 - 0s - loss: 0.9380 - accuracy: 0.6850 - val_loss: 3.1526 - val_accuracy: 0.5873 - 299ms/epoch - 23ms/step\n",
            "Epoch 121/300\n",
            "13/13 - 0s - loss: 0.9467 - accuracy: 0.6820 - val_loss: 2.9172 - val_accuracy: 0.5483 - 304ms/epoch - 23ms/step\n",
            "Epoch 122/300\n",
            "13/13 - 0s - loss: 0.9870 - accuracy: 0.6741 - val_loss: 2.2267 - val_accuracy: 0.5354 - 309ms/epoch - 24ms/step\n",
            "Epoch 123/300\n",
            "13/13 - 0s - loss: 0.9987 - accuracy: 0.6683 - val_loss: 2.6507 - val_accuracy: 0.5036 - 306ms/epoch - 24ms/step\n",
            "Epoch 124/300\n",
            "13/13 - 0s - loss: 1.0117 - accuracy: 0.6762 - val_loss: 1.9733 - val_accuracy: 0.5267 - 305ms/epoch - 23ms/step\n",
            "Epoch 125/300\n",
            "13/13 - 0s - loss: 1.0687 - accuracy: 0.6496 - val_loss: 2.5597 - val_accuracy: 0.5051 - 303ms/epoch - 23ms/step\n",
            "Epoch 126/300\n",
            "13/13 - 0s - loss: 1.0738 - accuracy: 0.6513 - val_loss: 2.3401 - val_accuracy: 0.5325 - 303ms/epoch - 23ms/step\n",
            "Epoch 127/300\n",
            "13/13 - 0s - loss: 1.1371 - accuracy: 0.6098 - val_loss: 2.1175 - val_accuracy: 0.5094 - 304ms/epoch - 23ms/step\n",
            "Epoch 128/300\n",
            "13/13 - 0s - loss: 1.1054 - accuracy: 0.6308 - val_loss: 2.3269 - val_accuracy: 0.4805 - 307ms/epoch - 24ms/step\n",
            "Epoch 129/300\n",
            "13/13 - 0s - loss: 1.1040 - accuracy: 0.6221 - val_loss: 2.2191 - val_accuracy: 0.4921 - 303ms/epoch - 23ms/step\n",
            "Epoch 130/300\n",
            "13/13 - 0s - loss: 1.0530 - accuracy: 0.6217 - val_loss: 2.8804 - val_accuracy: 0.5325 - 302ms/epoch - 23ms/step\n",
            "Epoch 131/300\n",
            "13/13 - 0s - loss: 1.1246 - accuracy: 0.6327 - val_loss: 2.7272 - val_accuracy: 0.4921 - 302ms/epoch - 23ms/step\n",
            "Epoch 132/300\n",
            "13/13 - 0s - loss: 1.0307 - accuracy: 0.6329 - val_loss: 2.3561 - val_accuracy: 0.5440 - 308ms/epoch - 24ms/step\n",
            "Epoch 133/300\n",
            "13/13 - 0s - loss: 1.0369 - accuracy: 0.6524 - val_loss: 1.9761 - val_accuracy: 0.5368 - 303ms/epoch - 23ms/step\n",
            "Epoch 134/300\n",
            "13/13 - 0s - loss: 1.0068 - accuracy: 0.6475 - val_loss: 2.0845 - val_accuracy: 0.4430 - 306ms/epoch - 24ms/step\n",
            "Epoch 135/300\n",
            "13/13 - 0s - loss: 0.9903 - accuracy: 0.6459 - val_loss: 2.3723 - val_accuracy: 0.5310 - 302ms/epoch - 23ms/step\n",
            "Epoch 136/300\n",
            "13/13 - 0s - loss: 0.9280 - accuracy: 0.6680 - val_loss: 2.6698 - val_accuracy: 0.4964 - 303ms/epoch - 23ms/step\n",
            "Epoch 137/300\n",
            "13/13 - 0s - loss: 0.9047 - accuracy: 0.6767 - val_loss: 2.2540 - val_accuracy: 0.5036 - 305ms/epoch - 23ms/step\n",
            "Epoch 138/300\n",
            "13/13 - 0s - loss: 0.8829 - accuracy: 0.6879 - val_loss: 2.6981 - val_accuracy: 0.5094 - 304ms/epoch - 23ms/step\n",
            "Epoch 139/300\n",
            "13/13 - 0s - loss: 1.0470 - accuracy: 0.6507 - val_loss: 3.9887 - val_accuracy: 0.4531 - 295ms/epoch - 23ms/step\n",
            "Epoch 140/300\n",
            "13/13 - 0s - loss: 1.1186 - accuracy: 0.6459 - val_loss: 2.0315 - val_accuracy: 0.4978 - 310ms/epoch - 24ms/step\n",
            "Epoch 141/300\n",
            "13/13 - 0s - loss: 1.0592 - accuracy: 0.6353 - val_loss: 2.3607 - val_accuracy: 0.5094 - 301ms/epoch - 23ms/step\n",
            "Epoch 142/300\n",
            "13/13 - 0s - loss: 0.9471 - accuracy: 0.6712 - val_loss: 2.1657 - val_accuracy: 0.5469 - 301ms/epoch - 23ms/step\n",
            "Epoch 143/300\n",
            "13/13 - 0s - loss: 0.9416 - accuracy: 0.6690 - val_loss: 2.2708 - val_accuracy: 0.5382 - 297ms/epoch - 23ms/step\n",
            "Epoch 144/300\n",
            "13/13 - 0s - loss: 0.9787 - accuracy: 0.6642 - val_loss: 2.2499 - val_accuracy: 0.4978 - 302ms/epoch - 23ms/step\n",
            "Epoch 145/300\n",
            "13/13 - 0s - loss: 1.0039 - accuracy: 0.6592 - val_loss: 2.2405 - val_accuracy: 0.4560 - 301ms/epoch - 23ms/step\n",
            "Epoch 146/300\n",
            "13/13 - 0s - loss: 1.0616 - accuracy: 0.6351 - val_loss: 2.0971 - val_accuracy: 0.4675 - 303ms/epoch - 23ms/step\n",
            "Epoch 147/300\n",
            "13/13 - 0s - loss: 1.0975 - accuracy: 0.6266 - val_loss: 2.0858 - val_accuracy: 0.4848 - 302ms/epoch - 23ms/step\n",
            "Epoch 148/300\n",
            "13/13 - 0s - loss: 1.1076 - accuracy: 0.6388 - val_loss: 2.1160 - val_accuracy: 0.5152 - 300ms/epoch - 23ms/step\n",
            "Epoch 149/300\n",
            "13/13 - 0s - loss: 1.0919 - accuracy: 0.6170 - val_loss: 2.1451 - val_accuracy: 0.5123 - 303ms/epoch - 23ms/step\n",
            "Epoch 150/300\n",
            "13/13 - 0s - loss: 1.0208 - accuracy: 0.6449 - val_loss: 2.0939 - val_accuracy: 0.4545 - 306ms/epoch - 24ms/step\n",
            "Epoch 151/300\n",
            "13/13 - 0s - loss: 0.9692 - accuracy: 0.6472 - val_loss: 2.5067 - val_accuracy: 0.5296 - 302ms/epoch - 23ms/step\n",
            "Epoch 152/300\n",
            "13/13 - 0s - loss: 0.9644 - accuracy: 0.6826 - val_loss: 2.8154 - val_accuracy: 0.5411 - 301ms/epoch - 23ms/step\n",
            "Epoch 153/300\n",
            "13/13 - 0s - loss: 0.9107 - accuracy: 0.6781 - val_loss: 2.9076 - val_accuracy: 0.5685 - 300ms/epoch - 23ms/step\n",
            "Epoch 154/300\n",
            "13/13 - 0s - loss: 0.9955 - accuracy: 0.6629 - val_loss: 2.6614 - val_accuracy: 0.5556 - 306ms/epoch - 24ms/step\n",
            "Epoch 155/300\n",
            "13/13 - 0s - loss: 1.0000 - accuracy: 0.6516 - val_loss: 2.9583 - val_accuracy: 0.4848 - 299ms/epoch - 23ms/step\n",
            "Epoch 156/300\n",
            "13/13 - 0s - loss: 0.9169 - accuracy: 0.6751 - val_loss: 2.7482 - val_accuracy: 0.5209 - 309ms/epoch - 24ms/step\n",
            "Epoch 157/300\n",
            "13/13 - 0s - loss: 0.9404 - accuracy: 0.6787 - val_loss: 3.1159 - val_accuracy: 0.4906 - 307ms/epoch - 24ms/step\n",
            "Epoch 158/300\n",
            "13/13 - 0s - loss: 0.9358 - accuracy: 0.6813 - val_loss: 3.1204 - val_accuracy: 0.5051 - 305ms/epoch - 23ms/step\n",
            "Epoch 159/300\n",
            "13/13 - 0s - loss: 0.9206 - accuracy: 0.6800 - val_loss: 2.5555 - val_accuracy: 0.5440 - 308ms/epoch - 24ms/step\n",
            "Epoch 160/300\n",
            "13/13 - 0s - loss: 1.1062 - accuracy: 0.6582 - val_loss: 2.6543 - val_accuracy: 0.4964 - 310ms/epoch - 24ms/step\n",
            "Epoch 161/300\n",
            "13/13 - 0s - loss: 1.2478 - accuracy: 0.6268 - val_loss: 2.6011 - val_accuracy: 0.4762 - 298ms/epoch - 23ms/step\n",
            "Epoch 162/300\n",
            "13/13 - 0s - loss: 1.1381 - accuracy: 0.6337 - val_loss: 2.2355 - val_accuracy: 0.5152 - 303ms/epoch - 23ms/step\n",
            "Epoch 163/300\n",
            "13/13 - 0s - loss: 1.1023 - accuracy: 0.6261 - val_loss: 2.5163 - val_accuracy: 0.5310 - 309ms/epoch - 24ms/step\n",
            "Epoch 164/300\n",
            "13/13 - 0s - loss: 1.1083 - accuracy: 0.6279 - val_loss: 3.2222 - val_accuracy: 0.4646 - 311ms/epoch - 24ms/step\n",
            "Epoch 165/300\n",
            "13/13 - 0s - loss: 1.0397 - accuracy: 0.6496 - val_loss: 2.7838 - val_accuracy: 0.5253 - 307ms/epoch - 24ms/step\n",
            "Epoch 166/300\n",
            "13/13 - 0s - loss: 0.9793 - accuracy: 0.6540 - val_loss: 3.5964 - val_accuracy: 0.5123 - 302ms/epoch - 23ms/step\n",
            "Epoch 167/300\n",
            "13/13 - 0s - loss: 0.9039 - accuracy: 0.6754 - val_loss: 3.0760 - val_accuracy: 0.5065 - 299ms/epoch - 23ms/step\n",
            "Epoch 168/300\n",
            "13/13 - 0s - loss: 0.9997 - accuracy: 0.6515 - val_loss: 3.3137 - val_accuracy: 0.5022 - 303ms/epoch - 23ms/step\n",
            "Epoch 169/300\n",
            "13/13 - 0s - loss: 0.9212 - accuracy: 0.6807 - val_loss: 3.5827 - val_accuracy: 0.5642 - 303ms/epoch - 23ms/step\n",
            "Epoch 170/300\n",
            "13/13 - 0s - loss: 1.0424 - accuracy: 0.6513 - val_loss: 3.1374 - val_accuracy: 0.4964 - 307ms/epoch - 24ms/step\n",
            "Epoch 171/300\n",
            "13/13 - 0s - loss: 1.1317 - accuracy: 0.6412 - val_loss: 3.0626 - val_accuracy: 0.5411 - 307ms/epoch - 24ms/step\n",
            "Epoch 172/300\n",
            "13/13 - 0s - loss: 1.0276 - accuracy: 0.6520 - val_loss: 2.6254 - val_accuracy: 0.5397 - 303ms/epoch - 23ms/step\n",
            "Epoch 173/300\n",
            "13/13 - 0s - loss: 1.0660 - accuracy: 0.6370 - val_loss: 2.5971 - val_accuracy: 0.5281 - 306ms/epoch - 24ms/step\n",
            "Epoch 174/300\n",
            "13/13 - 0s - loss: 0.9791 - accuracy: 0.6563 - val_loss: 2.8041 - val_accuracy: 0.5108 - 301ms/epoch - 23ms/step\n",
            "Epoch 175/300\n",
            "13/13 - 0s - loss: 1.0319 - accuracy: 0.6497 - val_loss: 2.5014 - val_accuracy: 0.5498 - 304ms/epoch - 23ms/step\n",
            "Epoch 176/300\n",
            "13/13 - 0s - loss: 0.9622 - accuracy: 0.6642 - val_loss: 2.6597 - val_accuracy: 0.5253 - 306ms/epoch - 24ms/step\n",
            "Epoch 177/300\n",
            "13/13 - 0s - loss: 1.0085 - accuracy: 0.6481 - val_loss: 2.1051 - val_accuracy: 0.5036 - 301ms/epoch - 23ms/step\n",
            "Epoch 178/300\n",
            "13/13 - 0s - loss: 0.9469 - accuracy: 0.6624 - val_loss: 2.4159 - val_accuracy: 0.5079 - 311ms/epoch - 24ms/step\n",
            "Epoch 179/300\n",
            "13/13 - 0s - loss: 0.8986 - accuracy: 0.6848 - val_loss: 3.3013 - val_accuracy: 0.5354 - 306ms/epoch - 24ms/step\n",
            "Epoch 180/300\n",
            "13/13 - 0s - loss: 0.9829 - accuracy: 0.6674 - val_loss: 3.1614 - val_accuracy: 0.5166 - 299ms/epoch - 23ms/step\n",
            "Epoch 181/300\n",
            "13/13 - 0s - loss: 0.9411 - accuracy: 0.6749 - val_loss: 2.0890 - val_accuracy: 0.5382 - 304ms/epoch - 23ms/step\n",
            "Epoch 182/300\n",
            "13/13 - 0s - loss: 0.9333 - accuracy: 0.6807 - val_loss: 2.5749 - val_accuracy: 0.5123 - 304ms/epoch - 23ms/step\n",
            "Epoch 183/300\n",
            "13/13 - 0s - loss: 1.0972 - accuracy: 0.6504 - val_loss: 1.7703 - val_accuracy: 0.5281 - 308ms/epoch - 24ms/step\n",
            "Epoch 184/300\n",
            "13/13 - 0s - loss: 1.0724 - accuracy: 0.6303 - val_loss: 1.8718 - val_accuracy: 0.5743 - 307ms/epoch - 24ms/step\n",
            "Epoch 185/300\n",
            "13/13 - 0s - loss: 1.0188 - accuracy: 0.6504 - val_loss: 4.6785 - val_accuracy: 0.4661 - 301ms/epoch - 23ms/step\n",
            "Epoch 186/300\n",
            "13/13 - 0s - loss: 0.9892 - accuracy: 0.6534 - val_loss: 2.3921 - val_accuracy: 0.5094 - 302ms/epoch - 23ms/step\n",
            "Epoch 187/300\n",
            "13/13 - 0s - loss: 1.0578 - accuracy: 0.6605 - val_loss: 2.1926 - val_accuracy: 0.4747 - 304ms/epoch - 23ms/step\n",
            "Epoch 188/300\n",
            "13/13 - 0s - loss: 1.0741 - accuracy: 0.6486 - val_loss: 3.1984 - val_accuracy: 0.4906 - 305ms/epoch - 23ms/step\n",
            "Epoch 189/300\n",
            "13/13 - 0s - loss: 1.1642 - accuracy: 0.6468 - val_loss: 2.4412 - val_accuracy: 0.4733 - 305ms/epoch - 23ms/step\n",
            "Epoch 190/300\n",
            "13/13 - 0s - loss: 1.2783 - accuracy: 0.6277 - val_loss: 2.3573 - val_accuracy: 0.5166 - 301ms/epoch - 23ms/step\n",
            "Epoch 191/300\n",
            "13/13 - 0s - loss: 1.0804 - accuracy: 0.6274 - val_loss: 2.1122 - val_accuracy: 0.4935 - 304ms/epoch - 23ms/step\n",
            "Epoch 192/300\n",
            "13/13 - 0s - loss: 1.0005 - accuracy: 0.6508 - val_loss: 2.2387 - val_accuracy: 0.5022 - 305ms/epoch - 23ms/step\n",
            "Epoch 193/300\n",
            "13/13 - 0s - loss: 0.9942 - accuracy: 0.6569 - val_loss: 1.9631 - val_accuracy: 0.4906 - 304ms/epoch - 23ms/step\n",
            "Epoch 194/300\n",
            "13/13 - 0s - loss: 1.1637 - accuracy: 0.6010 - val_loss: 2.1017 - val_accuracy: 0.5238 - 305ms/epoch - 23ms/step\n",
            "Epoch 195/300\n",
            "13/13 - 0s - loss: 1.0528 - accuracy: 0.6295 - val_loss: 2.8040 - val_accuracy: 0.4805 - 306ms/epoch - 24ms/step\n",
            "Epoch 196/300\n",
            "13/13 - 0s - loss: 1.0169 - accuracy: 0.6342 - val_loss: 2.4261 - val_accuracy: 0.5137 - 302ms/epoch - 23ms/step\n",
            "Epoch 197/300\n",
            "13/13 - 0s - loss: 0.9841 - accuracy: 0.6473 - val_loss: 2.6908 - val_accuracy: 0.5137 - 304ms/epoch - 23ms/step\n",
            "Epoch 198/300\n",
            "13/13 - 0s - loss: 0.9159 - accuracy: 0.6701 - val_loss: 2.9524 - val_accuracy: 0.5137 - 305ms/epoch - 23ms/step\n",
            "Epoch 199/300\n",
            "13/13 - 0s - loss: 0.9252 - accuracy: 0.6664 - val_loss: 2.6278 - val_accuracy: 0.5209 - 307ms/epoch - 24ms/step\n",
            "Epoch 200/300\n",
            "13/13 - 0s - loss: 0.9283 - accuracy: 0.6656 - val_loss: 3.3463 - val_accuracy: 0.5267 - 301ms/epoch - 23ms/step\n",
            "Epoch 201/300\n",
            "13/13 - 0s - loss: 0.8817 - accuracy: 0.6834 - val_loss: 7.1715 - val_accuracy: 0.4618 - 305ms/epoch - 23ms/step\n",
            "Epoch 202/300\n",
            "13/13 - 0s - loss: 0.9133 - accuracy: 0.6736 - val_loss: 3.7227 - val_accuracy: 0.5657 - 301ms/epoch - 23ms/step\n",
            "Epoch 203/300\n",
            "13/13 - 0s - loss: 0.9061 - accuracy: 0.6784 - val_loss: 3.4659 - val_accuracy: 0.5065 - 309ms/epoch - 24ms/step\n",
            "Epoch 204/300\n",
            "13/13 - 0s - loss: 0.8906 - accuracy: 0.6831 - val_loss: 3.4852 - val_accuracy: 0.4978 - 305ms/epoch - 23ms/step\n",
            "Epoch 205/300\n",
            "13/13 - 0s - loss: 0.8904 - accuracy: 0.6876 - val_loss: 3.3907 - val_accuracy: 0.5296 - 302ms/epoch - 23ms/step\n",
            "Epoch 206/300\n",
            "13/13 - 0s - loss: 0.9092 - accuracy: 0.6805 - val_loss: 6.7543 - val_accuracy: 0.4762 - 308ms/epoch - 24ms/step\n",
            "Epoch 207/300\n",
            "13/13 - 0s - loss: 0.9030 - accuracy: 0.6940 - val_loss: 3.1506 - val_accuracy: 0.5267 - 305ms/epoch - 23ms/step\n",
            "Epoch 208/300\n",
            "13/13 - 0s - loss: 0.8387 - accuracy: 0.7031 - val_loss: 3.2074 - val_accuracy: 0.5426 - 306ms/epoch - 24ms/step\n",
            "Epoch 209/300\n",
            "13/13 - 0s - loss: 0.8842 - accuracy: 0.7010 - val_loss: 3.3160 - val_accuracy: 0.5296 - 303ms/epoch - 23ms/step\n",
            "Epoch 210/300\n",
            "13/13 - 0s - loss: 0.9908 - accuracy: 0.6810 - val_loss: 2.6322 - val_accuracy: 0.4949 - 309ms/epoch - 24ms/step\n",
            "Epoch 211/300\n",
            "13/13 - 0s - loss: 0.9340 - accuracy: 0.6760 - val_loss: 4.0224 - val_accuracy: 0.4921 - 314ms/epoch - 24ms/step\n",
            "Epoch 212/300\n",
            "13/13 - 0s - loss: 0.9181 - accuracy: 0.6823 - val_loss: 2.7553 - val_accuracy: 0.5498 - 304ms/epoch - 23ms/step\n",
            "Epoch 213/300\n",
            "13/13 - 0s - loss: 0.8966 - accuracy: 0.6821 - val_loss: 3.0740 - val_accuracy: 0.5584 - 302ms/epoch - 23ms/step\n",
            "Epoch 214/300\n",
            "13/13 - 0s - loss: 1.0945 - accuracy: 0.6624 - val_loss: 2.5200 - val_accuracy: 0.5844 - 298ms/epoch - 23ms/step\n",
            "Epoch 215/300\n",
            "13/13 - 0s - loss: 1.0081 - accuracy: 0.6557 - val_loss: 2.9343 - val_accuracy: 0.5887 - 303ms/epoch - 23ms/step\n",
            "Epoch 216/300\n",
            "13/13 - 0s - loss: 1.0704 - accuracy: 0.6707 - val_loss: 2.7078 - val_accuracy: 0.4863 - 310ms/epoch - 24ms/step\n",
            "Epoch 217/300\n",
            "13/13 - 0s - loss: 1.2847 - accuracy: 0.5888 - val_loss: 2.1717 - val_accuracy: 0.4459 - 298ms/epoch - 23ms/step\n",
            "Epoch 218/300\n",
            "13/13 - 0s - loss: 1.2716 - accuracy: 0.5915 - val_loss: 2.5305 - val_accuracy: 0.5065 - 308ms/epoch - 24ms/step\n",
            "Epoch 219/300\n",
            "13/13 - 0s - loss: 1.1169 - accuracy: 0.6217 - val_loss: 2.1261 - val_accuracy: 0.5527 - 306ms/epoch - 24ms/step\n",
            "Epoch 220/300\n",
            "13/13 - 0s - loss: 1.0377 - accuracy: 0.6308 - val_loss: 2.2469 - val_accuracy: 0.5613 - 302ms/epoch - 23ms/step\n",
            "Epoch 221/300\n",
            "13/13 - 0s - loss: 1.0872 - accuracy: 0.6385 - val_loss: 2.3378 - val_accuracy: 0.5137 - 307ms/epoch - 24ms/step\n",
            "Epoch 222/300\n",
            "13/13 - 0s - loss: 1.0783 - accuracy: 0.6279 - val_loss: 2.1873 - val_accuracy: 0.5267 - 306ms/epoch - 24ms/step\n",
            "Epoch 223/300\n",
            "13/13 - 0s - loss: 0.9905 - accuracy: 0.6483 - val_loss: 2.1932 - val_accuracy: 0.5267 - 298ms/epoch - 23ms/step\n",
            "Epoch 224/300\n",
            "13/13 - 0s - loss: 1.0526 - accuracy: 0.6464 - val_loss: 1.9471 - val_accuracy: 0.4805 - 305ms/epoch - 23ms/step\n",
            "Epoch 225/300\n",
            "13/13 - 0s - loss: 0.9893 - accuracy: 0.6451 - val_loss: 2.0476 - val_accuracy: 0.5123 - 300ms/epoch - 23ms/step\n",
            "Epoch 226/300\n",
            "13/13 - 0s - loss: 0.9523 - accuracy: 0.6587 - val_loss: 2.0820 - val_accuracy: 0.5397 - 307ms/epoch - 24ms/step\n",
            "Epoch 227/300\n",
            "13/13 - 0s - loss: 1.0112 - accuracy: 0.6532 - val_loss: 2.0717 - val_accuracy: 0.5382 - 306ms/epoch - 24ms/step\n",
            "Epoch 228/300\n",
            "13/13 - 0s - loss: 0.9774 - accuracy: 0.6532 - val_loss: 1.9753 - val_accuracy: 0.5238 - 300ms/epoch - 23ms/step\n",
            "Epoch 229/300\n",
            "13/13 - 0s - loss: 0.9790 - accuracy: 0.6539 - val_loss: 2.0912 - val_accuracy: 0.5411 - 298ms/epoch - 23ms/step\n",
            "Epoch 230/300\n",
            "13/13 - 0s - loss: 0.9499 - accuracy: 0.6659 - val_loss: 2.2835 - val_accuracy: 0.5022 - 303ms/epoch - 23ms/step\n",
            "Epoch 231/300\n",
            "13/13 - 0s - loss: 0.9481 - accuracy: 0.6664 - val_loss: 2.3450 - val_accuracy: 0.5801 - 311ms/epoch - 24ms/step\n",
            "Epoch 232/300\n",
            "13/13 - 0s - loss: 0.9035 - accuracy: 0.6836 - val_loss: 2.5014 - val_accuracy: 0.5916 - 303ms/epoch - 23ms/step\n",
            "Epoch 233/300\n",
            "13/13 - 0s - loss: 0.9111 - accuracy: 0.6839 - val_loss: 2.4674 - val_accuracy: 0.5195 - 299ms/epoch - 23ms/step\n",
            "Epoch 234/300\n",
            "13/13 - 0s - loss: 0.8759 - accuracy: 0.6847 - val_loss: 3.0658 - val_accuracy: 0.5469 - 295ms/epoch - 23ms/step\n",
            "Epoch 235/300\n",
            "13/13 - 0s - loss: 0.8570 - accuracy: 0.6929 - val_loss: 2.9192 - val_accuracy: 0.5281 - 302ms/epoch - 23ms/step\n",
            "Epoch 236/300\n",
            "13/13 - 0s - loss: 0.8696 - accuracy: 0.6892 - val_loss: 3.3608 - val_accuracy: 0.5325 - 309ms/epoch - 24ms/step\n",
            "Epoch 237/300\n",
            "13/13 - 0s - loss: 0.9124 - accuracy: 0.6815 - val_loss: 2.8967 - val_accuracy: 0.5714 - 304ms/epoch - 23ms/step\n",
            "Epoch 238/300\n",
            "13/13 - 0s - loss: 0.8806 - accuracy: 0.6945 - val_loss: 2.8156 - val_accuracy: 0.5556 - 311ms/epoch - 24ms/step\n",
            "Epoch 239/300\n",
            "13/13 - 0s - loss: 0.8628 - accuracy: 0.6949 - val_loss: 2.9648 - val_accuracy: 0.5108 - 300ms/epoch - 23ms/step\n",
            "Epoch 240/300\n",
            "13/13 - 0s - loss: 0.9281 - accuracy: 0.6842 - val_loss: 2.8987 - val_accuracy: 0.5498 - 303ms/epoch - 23ms/step\n",
            "Epoch 241/300\n",
            "13/13 - 0s - loss: 1.1101 - accuracy: 0.6829 - val_loss: 2.4673 - val_accuracy: 0.4545 - 302ms/epoch - 23ms/step\n",
            "Epoch 242/300\n",
            "13/13 - 0s - loss: 1.0904 - accuracy: 0.6452 - val_loss: 2.9192 - val_accuracy: 0.4949 - 297ms/epoch - 23ms/step\n",
            "Epoch 243/300\n",
            "13/13 - 0s - loss: 1.0104 - accuracy: 0.6693 - val_loss: 2.7518 - val_accuracy: 0.5556 - 301ms/epoch - 23ms/step\n",
            "Epoch 244/300\n",
            "13/13 - 0s - loss: 1.0368 - accuracy: 0.6549 - val_loss: 3.0637 - val_accuracy: 0.5267 - 299ms/epoch - 23ms/step\n",
            "Epoch 245/300\n",
            "13/13 - 0s - loss: 1.1972 - accuracy: 0.6160 - val_loss: 3.2209 - val_accuracy: 0.5310 - 313ms/epoch - 24ms/step\n",
            "Epoch 246/300\n",
            "13/13 - 0s - loss: 1.0821 - accuracy: 0.6375 - val_loss: 2.9166 - val_accuracy: 0.5411 - 303ms/epoch - 23ms/step\n",
            "Epoch 247/300\n",
            "13/13 - 0s - loss: 1.0416 - accuracy: 0.6553 - val_loss: 3.1874 - val_accuracy: 0.4589 - 304ms/epoch - 23ms/step\n",
            "Epoch 248/300\n",
            "13/13 - 0s - loss: 1.0519 - accuracy: 0.6455 - val_loss: 3.3993 - val_accuracy: 0.4906 - 306ms/epoch - 24ms/step\n",
            "Epoch 249/300\n",
            "13/13 - 0s - loss: 0.9845 - accuracy: 0.6590 - val_loss: 3.1586 - val_accuracy: 0.5123 - 302ms/epoch - 23ms/step\n",
            "Epoch 250/300\n",
            "13/13 - 0s - loss: 0.9602 - accuracy: 0.6709 - val_loss: 3.2439 - val_accuracy: 0.5137 - 304ms/epoch - 23ms/step\n",
            "Epoch 251/300\n",
            "13/13 - 0s - loss: 0.9340 - accuracy: 0.6768 - val_loss: 3.9222 - val_accuracy: 0.5108 - 301ms/epoch - 23ms/step\n",
            "Epoch 252/300\n",
            "13/13 - 0s - loss: 0.8698 - accuracy: 0.6898 - val_loss: 3.6576 - val_accuracy: 0.5527 - 298ms/epoch - 23ms/step\n",
            "Epoch 253/300\n",
            "13/13 - 0s - loss: 0.9276 - accuracy: 0.6717 - val_loss: 3.5620 - val_accuracy: 0.5137 - 300ms/epoch - 23ms/step\n",
            "Epoch 254/300\n",
            "13/13 - 0s - loss: 0.9435 - accuracy: 0.6720 - val_loss: 3.7280 - val_accuracy: 0.5469 - 299ms/epoch - 23ms/step\n",
            "Epoch 255/300\n",
            "13/13 - 0s - loss: 0.8703 - accuracy: 0.6908 - val_loss: 3.2638 - val_accuracy: 0.5527 - 310ms/epoch - 24ms/step\n",
            "Epoch 256/300\n",
            "13/13 - 0s - loss: 0.8661 - accuracy: 0.6988 - val_loss: 5.0704 - val_accuracy: 0.5556 - 311ms/epoch - 24ms/step\n",
            "Epoch 257/300\n",
            "13/13 - 0s - loss: 0.8318 - accuracy: 0.7006 - val_loss: 4.4049 - val_accuracy: 0.5426 - 303ms/epoch - 23ms/step\n",
            "Epoch 258/300\n",
            "13/13 - 0s - loss: 0.8395 - accuracy: 0.7014 - val_loss: 4.1652 - val_accuracy: 0.5570 - 301ms/epoch - 23ms/step\n",
            "Epoch 259/300\n",
            "13/13 - 0s - loss: 0.8649 - accuracy: 0.6906 - val_loss: 7.1613 - val_accuracy: 0.4906 - 304ms/epoch - 23ms/step\n",
            "Epoch 260/300\n",
            "13/13 - 0s - loss: 0.8718 - accuracy: 0.6890 - val_loss: 3.6927 - val_accuracy: 0.5570 - 306ms/epoch - 24ms/step\n",
            "Epoch 261/300\n",
            "13/13 - 0s - loss: 0.8136 - accuracy: 0.7020 - val_loss: 3.9875 - val_accuracy: 0.5354 - 304ms/epoch - 23ms/step\n",
            "Epoch 262/300\n",
            "13/13 - 0s - loss: 0.8306 - accuracy: 0.6954 - val_loss: 4.0402 - val_accuracy: 0.5022 - 304ms/epoch - 23ms/step\n",
            "Epoch 263/300\n",
            "13/13 - 0s - loss: 0.8183 - accuracy: 0.7126 - val_loss: 4.0730 - val_accuracy: 0.5440 - 306ms/epoch - 24ms/step\n",
            "Epoch 264/300\n",
            "13/13 - 0s - loss: 0.7848 - accuracy: 0.7128 - val_loss: 3.5676 - val_accuracy: 0.5859 - 306ms/epoch - 24ms/step\n",
            "Epoch 265/300\n",
            "13/13 - 0s - loss: 0.8429 - accuracy: 0.7017 - val_loss: 3.1202 - val_accuracy: 0.5859 - 308ms/epoch - 24ms/step\n",
            "Epoch 266/300\n",
            "13/13 - 0s - loss: 0.8236 - accuracy: 0.7075 - val_loss: 3.7040 - val_accuracy: 0.5368 - 306ms/epoch - 24ms/step\n",
            "Epoch 267/300\n",
            "13/13 - 0s - loss: 0.8608 - accuracy: 0.6890 - val_loss: 6.5286 - val_accuracy: 0.5310 - 304ms/epoch - 23ms/step\n",
            "Epoch 268/300\n",
            "13/13 - 0s - loss: 0.8673 - accuracy: 0.6906 - val_loss: 5.3665 - val_accuracy: 0.5094 - 307ms/epoch - 24ms/step\n",
            "Epoch 269/300\n",
            "13/13 - 0s - loss: 0.8596 - accuracy: 0.6978 - val_loss: 3.6494 - val_accuracy: 0.5758 - 298ms/epoch - 23ms/step\n",
            "Epoch 270/300\n",
            "13/13 - 0s - loss: 0.8662 - accuracy: 0.7001 - val_loss: 4.1522 - val_accuracy: 0.5310 - 303ms/epoch - 23ms/step\n",
            "Epoch 271/300\n",
            "13/13 - 0s - loss: 0.8037 - accuracy: 0.7097 - val_loss: 3.6003 - val_accuracy: 0.5152 - 306ms/epoch - 24ms/step\n",
            "Epoch 272/300\n",
            "13/13 - 0s - loss: 0.8957 - accuracy: 0.6786 - val_loss: 3.4255 - val_accuracy: 0.5743 - 309ms/epoch - 24ms/step\n",
            "Epoch 273/300\n",
            "13/13 - 0s - loss: 0.8343 - accuracy: 0.6986 - val_loss: 3.6221 - val_accuracy: 0.5310 - 304ms/epoch - 23ms/step\n",
            "Epoch 274/300\n",
            "13/13 - 0s - loss: 0.8033 - accuracy: 0.7111 - val_loss: 3.3740 - val_accuracy: 0.5613 - 301ms/epoch - 23ms/step\n",
            "Epoch 275/300\n",
            "13/13 - 0s - loss: 0.7695 - accuracy: 0.7200 - val_loss: 2.8095 - val_accuracy: 0.5382 - 301ms/epoch - 23ms/step\n",
            "Epoch 276/300\n",
            "13/13 - 0s - loss: 0.7608 - accuracy: 0.7241 - val_loss: 3.3101 - val_accuracy: 0.5065 - 294ms/epoch - 23ms/step\n",
            "Epoch 277/300\n",
            "13/13 - 0s - loss: 0.7960 - accuracy: 0.7214 - val_loss: 3.4840 - val_accuracy: 0.5253 - 300ms/epoch - 23ms/step\n",
            "Epoch 278/300\n",
            "13/13 - 0s - loss: 0.7882 - accuracy: 0.7171 - val_loss: 3.8535 - val_accuracy: 0.5152 - 302ms/epoch - 23ms/step\n",
            "Epoch 279/300\n",
            "13/13 - 0s - loss: 0.8616 - accuracy: 0.7076 - val_loss: 3.5185 - val_accuracy: 0.5296 - 301ms/epoch - 23ms/step\n",
            "Epoch 280/300\n",
            "13/13 - 0s - loss: 0.8033 - accuracy: 0.7145 - val_loss: 3.9411 - val_accuracy: 0.5267 - 305ms/epoch - 23ms/step\n",
            "Epoch 281/300\n",
            "13/13 - 0s - loss: 0.7912 - accuracy: 0.7209 - val_loss: 3.8140 - val_accuracy: 0.5570 - 302ms/epoch - 23ms/step\n",
            "Epoch 282/300\n",
            "13/13 - 0s - loss: 0.7925 - accuracy: 0.7137 - val_loss: 3.9257 - val_accuracy: 0.5469 - 306ms/epoch - 24ms/step\n",
            "Epoch 283/300\n",
            "13/13 - 0s - loss: 0.7824 - accuracy: 0.7198 - val_loss: 3.6737 - val_accuracy: 0.5281 - 304ms/epoch - 23ms/step\n",
            "Epoch 284/300\n",
            "13/13 - 0s - loss: 0.8280 - accuracy: 0.7139 - val_loss: 3.6295 - val_accuracy: 0.4791 - 305ms/epoch - 23ms/step\n",
            "Epoch 285/300\n",
            "13/13 - 0s - loss: 0.9322 - accuracy: 0.6962 - val_loss: 3.4868 - val_accuracy: 0.5339 - 307ms/epoch - 24ms/step\n",
            "Epoch 286/300\n",
            "13/13 - 0s - loss: 0.8511 - accuracy: 0.6961 - val_loss: 3.4989 - val_accuracy: 0.5281 - 303ms/epoch - 23ms/step\n",
            "Epoch 287/300\n",
            "13/13 - 0s - loss: 0.8453 - accuracy: 0.6962 - val_loss: 3.5233 - val_accuracy: 0.5512 - 295ms/epoch - 23ms/step\n",
            "Epoch 288/300\n",
            "13/13 - 0s - loss: 0.8418 - accuracy: 0.6982 - val_loss: 3.1560 - val_accuracy: 0.5267 - 308ms/epoch - 24ms/step\n",
            "Epoch 289/300\n",
            "13/13 - 0s - loss: 0.8246 - accuracy: 0.7139 - val_loss: 3.8653 - val_accuracy: 0.5541 - 308ms/epoch - 24ms/step\n",
            "Epoch 290/300\n",
            "13/13 - 0s - loss: 0.8345 - accuracy: 0.7084 - val_loss: 4.0850 - val_accuracy: 0.5325 - 308ms/epoch - 24ms/step\n",
            "Epoch 291/300\n",
            "13/13 - 0s - loss: 0.7962 - accuracy: 0.7079 - val_loss: 4.5151 - val_accuracy: 0.5354 - 309ms/epoch - 24ms/step\n",
            "Epoch 292/300\n",
            "13/13 - 0s - loss: 0.8117 - accuracy: 0.7161 - val_loss: 3.4142 - val_accuracy: 0.5628 - 297ms/epoch - 23ms/step\n",
            "Epoch 293/300\n",
            "13/13 - 0s - loss: 0.7541 - accuracy: 0.7322 - val_loss: 3.6343 - val_accuracy: 0.5123 - 295ms/epoch - 23ms/step\n",
            "Epoch 294/300\n",
            "13/13 - 0s - loss: 0.7751 - accuracy: 0.7176 - val_loss: 3.5467 - val_accuracy: 0.5079 - 300ms/epoch - 23ms/step\n",
            "Epoch 295/300\n",
            "13/13 - 0s - loss: 0.8255 - accuracy: 0.7014 - val_loss: 3.1844 - val_accuracy: 0.4949 - 301ms/epoch - 23ms/step\n",
            "Epoch 296/300\n",
            "13/13 - 0s - loss: 0.7844 - accuracy: 0.7116 - val_loss: 4.0305 - val_accuracy: 0.5123 - 303ms/epoch - 23ms/step\n",
            "Epoch 297/300\n",
            "13/13 - 0s - loss: 0.8056 - accuracy: 0.7179 - val_loss: 3.6842 - val_accuracy: 0.5281 - 306ms/epoch - 24ms/step\n",
            "Epoch 298/300\n",
            "13/13 - 0s - loss: 0.8345 - accuracy: 0.7075 - val_loss: 3.4169 - val_accuracy: 0.5354 - 303ms/epoch - 23ms/step\n",
            "Epoch 299/300\n",
            "13/13 - 0s - loss: 0.8349 - accuracy: 0.7063 - val_loss: 3.8461 - val_accuracy: 0.5224 - 302ms/epoch - 23ms/step\n",
            "Epoch 300/300\n",
            "13/13 - 0s - loss: 0.8448 - accuracy: 0.7062 - val_loss: 3.7435 - val_accuracy: 0.5253 - 302ms/epoch - 23ms/step\n",
            "Model: \"sequential_105\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_210 (Conv2D)         (None, 4, 36, 80)         27440     \n",
            "                                                                 \n",
            " max_pooling2d_210 (MaxPooli  (None, 1, 12, 80)        0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " batch_normalization_105 (Ba  (None, 1, 12, 80)        320       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " conv2d_211 (Conv2D)         (None, 1, 10, 80)         19280     \n",
            "                                                                 \n",
            " max_pooling2d_211 (MaxPooli  (None, 1, 3, 80)         0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " flatten_105 (Flatten)       (None, 240)               0         \n",
            "                                                                 \n",
            " dense_315 (Dense)           (None, 5000)              1205000   \n",
            "                                                                 \n",
            " dropout_210 (Dropout)       (None, 5000)              0         \n",
            "                                                                 \n",
            " dense_316 (Dense)           (None, 5000)              25005000  \n",
            "                                                                 \n",
            " dropout_211 (Dropout)       (None, 5000)              0         \n",
            "                                                                 \n",
            " dense_317 (Dense)           (None, 10)                50010     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 26,307,050\n",
            "Trainable params: 26,306,890\n",
            "Non-trainable params: 160\n",
            "_________________________________________________________________\n",
            "None\n",
            "Result of fold:10\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 2.2931 - accuracy: 0.5027\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [16:37<00:00, 99.73s/it] \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**You do not need to run following code again. They are not 10-fold.**"
      ],
      "metadata": {
        "id": "A01zgOU95RNt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Preprocessing: Spectrogram"
      ],
      "metadata": {
        "id": "WPvUKRDOsiVI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import pandas as pd\n",
        "# import numpy as np\n",
        "\n",
        "# pd.plotting.register_matplotlib_converters()\n",
        "# import matplotlib.pyplot as plt\n",
        "# %matplotlib inline\n",
        "# import seaborn as sns\n",
        "\n",
        "# from sklearn.model_selection import train_test_split\n",
        "# from sklearn.metrics import classification_report\n",
        "# from sklearn.model_selection import GridSearchCV\n",
        "# from sklearn.preprocessing import MinMaxScaler\n",
        "# from tensorflow.keras.models import Sequential\n",
        "# from tensorflow.keras.layers import Conv2D, Flatten, Dense, MaxPool2D, Dropout\n",
        "# from tensorflow.keras.utils import to_categorical \n",
        "# import os,glob,skimage,librosa\n",
        "# import librosa.display\n",
        "\n",
        "# import warnings\n",
        "# warnings.filterwarnings(\"ignore\")    \n",
        "# root=\"/content/drive/MyDrive/Thesis_Keras/\"         #忽略警告信息\n",
        "# csvPth = '/content/drive/MyDrive/Thesis_Keras/UrbanSound8K/metadata/UrbanSound8K.csv'\n",
        "# examplePath = '/content/drive/MyDrive/Thesis_Keras/UrbanSound8K/audio/fold6/85249-2-0-79.wav'"
      ],
      "metadata": {
        "id": "jCqmewnpBd8q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kxV7SanMx24e",
        "outputId": "919ec2b9-4313-4622-e8a0-4f5b4377484c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# df = pd.read_csv(csvPth)\n",
        "\n",
        "# df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "fXoRw0fnBe0Q",
        "outputId": "e284fb36-c7de-457a-d145-7c0a47575e91"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      slice_file_name    fsID  start        end  salience  fold  classID  \\\n",
              "0    100032-3-0-0.wav  100032    0.0   0.317551         1     5        3   \n",
              "1  100263-2-0-117.wav  100263   58.5  62.500000         1     5        2   \n",
              "2  100263-2-0-121.wav  100263   60.5  64.500000         1     5        2   \n",
              "3  100263-2-0-126.wav  100263   63.0  67.000000         1     5        2   \n",
              "4  100263-2-0-137.wav  100263   68.5  72.500000         1     5        2   \n",
              "\n",
              "              class  \n",
              "0          dog_bark  \n",
              "1  children_playing  \n",
              "2  children_playing  \n",
              "3  children_playing  \n",
              "4  children_playing  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-391bf9b2-ab9d-443a-a01a-f94065f53655\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>slice_file_name</th>\n",
              "      <th>fsID</th>\n",
              "      <th>start</th>\n",
              "      <th>end</th>\n",
              "      <th>salience</th>\n",
              "      <th>fold</th>\n",
              "      <th>classID</th>\n",
              "      <th>class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>100032-3-0-0.wav</td>\n",
              "      <td>100032</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.317551</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>dog_bark</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>100263-2-0-117.wav</td>\n",
              "      <td>100263</td>\n",
              "      <td>58.5</td>\n",
              "      <td>62.500000</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>children_playing</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>100263-2-0-121.wav</td>\n",
              "      <td>100263</td>\n",
              "      <td>60.5</td>\n",
              "      <td>64.500000</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>children_playing</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>100263-2-0-126.wav</td>\n",
              "      <td>100263</td>\n",
              "      <td>63.0</td>\n",
              "      <td>67.000000</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>children_playing</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>100263-2-0-137.wav</td>\n",
              "      <td>100263</td>\n",
              "      <td>68.5</td>\n",
              "      <td>72.500000</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>children_playing</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-391bf9b2-ab9d-443a-a01a-f94065f53655')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-391bf9b2-ab9d-443a-a01a-f94065f53655 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-391bf9b2-ab9d-443a-a01a-f94065f53655');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from psutil import virtual_memory\n",
        "# ram_gb = virtual_memory().total / 1e9\n",
        "# print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
        "\n",
        "# if ram_gb < 20:\n",
        "#   print('Not using a high-RAM runtime')\n",
        "# else:\n",
        "#   print('You are using a high-RAM runtime!')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ar1HSW5ex5vm",
        "outputId": "490473ec-78e8-49ba-9068-e91f46ed3f9f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Your runtime has 27.3 gigabytes of available RAM\n",
            "\n",
            "You are using a high-RAM runtime!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# D=[]\n",
        "# for i in range(8732):\n",
        "#   try:\n",
        "#     file_name = '/content/drive/MyDrive/Thesis_Keras/UrbanSound8K/audio/fold' + str(df[\"fold\"][i]) + '/' + df[\"slice_file_name\"][i]\n",
        "#     class_id = df[\"classID\"][i]\n",
        "\n",
        "#     X, sample_rate = librosa.load(file_name, res_type='kaiser_fast')\n",
        "#     print(f\"{i}out of 8732\")\n",
        "#     if i == 4803 or i==6246:\n",
        "#       continue\n",
        "#     x = np.pad(X,(0,88200-X.shape[0]) if (0,88200-X.shape[0]>0) else (0,-88200+X.shape[0]),'constant')\n",
        "#     print(f\"{i}out of 8732\")\n",
        "\n",
        "#     mels = librosa.feature.melspectrogram(x, sr=sample_rate,\n",
        "#                          n_mels=60,\n",
        "#                          n_fft=2048,\n",
        "#                          hop_length=1024,\n",
        "#                          )\n",
        "#     print('shape: ',mels.shape)\n",
        "#     feature = mels\n",
        "#     label = class_id\n",
        "#     D.append((feature,label)) \n",
        "#   except Exception:\n",
        "#     print(\"Error encountered while parsing file: \", file_name)\n",
        "#     mfccs,class_id = None, None\n",
        "  \n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EGfA4vnddqOa",
        "outputId": "6e8202f1-c3ca-47da-dc97-cd45818bf1d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43m流式输出内容被截断，只能显示最后 5000 行内容。\u001b[0m\n",
            "7065out of 8732\n",
            "shape:  (60, 87)\n",
            "7066out of 8732\n",
            "7066out of 8732\n",
            "shape:  (60, 87)\n",
            "7067out of 8732\n",
            "7067out of 8732\n",
            "shape:  (60, 87)\n",
            "7068out of 8732\n",
            "7068out of 8732\n",
            "shape:  (60, 87)\n",
            "7069out of 8732\n",
            "7069out of 8732\n",
            "shape:  (60, 87)\n",
            "7070out of 8732\n",
            "7070out of 8732\n",
            "shape:  (60, 87)\n",
            "7071out of 8732\n",
            "7071out of 8732\n",
            "shape:  (60, 87)\n",
            "7072out of 8732\n",
            "7072out of 8732\n",
            "shape:  (60, 87)\n",
            "7073out of 8732\n",
            "7073out of 8732\n",
            "shape:  (60, 87)\n",
            "7074out of 8732\n",
            "7074out of 8732\n",
            "shape:  (60, 87)\n",
            "7075out of 8732\n",
            "7075out of 8732\n",
            "shape:  (60, 87)\n",
            "7076out of 8732\n",
            "7076out of 8732\n",
            "shape:  (60, 87)\n",
            "7077out of 8732\n",
            "7077out of 8732\n",
            "shape:  (60, 87)\n",
            "7078out of 8732\n",
            "7078out of 8732\n",
            "shape:  (60, 87)\n",
            "7079out of 8732\n",
            "7079out of 8732\n",
            "shape:  (60, 87)\n",
            "7080out of 8732\n",
            "7080out of 8732\n",
            "shape:  (60, 87)\n",
            "7081out of 8732\n",
            "7081out of 8732\n",
            "shape:  (60, 87)\n",
            "7082out of 8732\n",
            "7082out of 8732\n",
            "shape:  (60, 87)\n",
            "7083out of 8732\n",
            "7083out of 8732\n",
            "shape:  (60, 87)\n",
            "7084out of 8732\n",
            "7084out of 8732\n",
            "shape:  (60, 87)\n",
            "7085out of 8732\n",
            "7085out of 8732\n",
            "shape:  (60, 87)\n",
            "7086out of 8732\n",
            "7086out of 8732\n",
            "shape:  (60, 87)\n",
            "7087out of 8732\n",
            "7087out of 8732\n",
            "shape:  (60, 87)\n",
            "7088out of 8732\n",
            "7088out of 8732\n",
            "shape:  (60, 87)\n",
            "7089out of 8732\n",
            "7089out of 8732\n",
            "shape:  (60, 87)\n",
            "7090out of 8732\n",
            "7090out of 8732\n",
            "shape:  (60, 87)\n",
            "7091out of 8732\n",
            "7091out of 8732\n",
            "shape:  (60, 87)\n",
            "7092out of 8732\n",
            "7092out of 8732\n",
            "shape:  (60, 87)\n",
            "7093out of 8732\n",
            "7093out of 8732\n",
            "shape:  (60, 87)\n",
            "7094out of 8732\n",
            "7094out of 8732\n",
            "shape:  (60, 87)\n",
            "7095out of 8732\n",
            "7095out of 8732\n",
            "shape:  (60, 87)\n",
            "7096out of 8732\n",
            "7096out of 8732\n",
            "shape:  (60, 87)\n",
            "7097out of 8732\n",
            "7097out of 8732\n",
            "shape:  (60, 87)\n",
            "7098out of 8732\n",
            "7098out of 8732\n",
            "shape:  (60, 87)\n",
            "7099out of 8732\n",
            "7099out of 8732\n",
            "shape:  (60, 87)\n",
            "7100out of 8732\n",
            "7100out of 8732\n",
            "shape:  (60, 87)\n",
            "7101out of 8732\n",
            "7101out of 8732\n",
            "shape:  (60, 87)\n",
            "7102out of 8732\n",
            "7102out of 8732\n",
            "shape:  (60, 87)\n",
            "7103out of 8732\n",
            "7103out of 8732\n",
            "shape:  (60, 87)\n",
            "7104out of 8732\n",
            "7104out of 8732\n",
            "shape:  (60, 87)\n",
            "7105out of 8732\n",
            "7105out of 8732\n",
            "shape:  (60, 87)\n",
            "7106out of 8732\n",
            "7106out of 8732\n",
            "shape:  (60, 87)\n",
            "7107out of 8732\n",
            "7107out of 8732\n",
            "shape:  (60, 87)\n",
            "7108out of 8732\n",
            "7108out of 8732\n",
            "shape:  (60, 87)\n",
            "7109out of 8732\n",
            "7109out of 8732\n",
            "shape:  (60, 87)\n",
            "7110out of 8732\n",
            "7110out of 8732\n",
            "shape:  (60, 87)\n",
            "7111out of 8732\n",
            "7111out of 8732\n",
            "shape:  (60, 87)\n",
            "7112out of 8732\n",
            "7112out of 8732\n",
            "shape:  (60, 87)\n",
            "7113out of 8732\n",
            "7113out of 8732\n",
            "shape:  (60, 87)\n",
            "7114out of 8732\n",
            "7114out of 8732\n",
            "shape:  (60, 87)\n",
            "7115out of 8732\n",
            "7115out of 8732\n",
            "shape:  (60, 87)\n",
            "7116out of 8732\n",
            "7116out of 8732\n",
            "shape:  (60, 87)\n",
            "7117out of 8732\n",
            "7117out of 8732\n",
            "shape:  (60, 87)\n",
            "7118out of 8732\n",
            "7118out of 8732\n",
            "shape:  (60, 87)\n",
            "7119out of 8732\n",
            "7119out of 8732\n",
            "shape:  (60, 87)\n",
            "7120out of 8732\n",
            "7120out of 8732\n",
            "shape:  (60, 87)\n",
            "7121out of 8732\n",
            "7121out of 8732\n",
            "shape:  (60, 87)\n",
            "7122out of 8732\n",
            "7122out of 8732\n",
            "shape:  (60, 87)\n",
            "7123out of 8732\n",
            "7123out of 8732\n",
            "shape:  (60, 87)\n",
            "7124out of 8732\n",
            "7124out of 8732\n",
            "shape:  (60, 87)\n",
            "7125out of 8732\n",
            "7125out of 8732\n",
            "shape:  (60, 87)\n",
            "7126out of 8732\n",
            "7126out of 8732\n",
            "shape:  (60, 87)\n",
            "7127out of 8732\n",
            "7127out of 8732\n",
            "shape:  (60, 87)\n",
            "7128out of 8732\n",
            "7128out of 8732\n",
            "shape:  (60, 87)\n",
            "7129out of 8732\n",
            "7129out of 8732\n",
            "shape:  (60, 87)\n",
            "7130out of 8732\n",
            "7130out of 8732\n",
            "shape:  (60, 87)\n",
            "7131out of 8732\n",
            "7131out of 8732\n",
            "shape:  (60, 87)\n",
            "7132out of 8732\n",
            "7132out of 8732\n",
            "shape:  (60, 87)\n",
            "7133out of 8732\n",
            "7133out of 8732\n",
            "shape:  (60, 87)\n",
            "7134out of 8732\n",
            "7134out of 8732\n",
            "shape:  (60, 87)\n",
            "7135out of 8732\n",
            "7135out of 8732\n",
            "shape:  (60, 87)\n",
            "7136out of 8732\n",
            "7136out of 8732\n",
            "shape:  (60, 87)\n",
            "7137out of 8732\n",
            "7137out of 8732\n",
            "shape:  (60, 87)\n",
            "7138out of 8732\n",
            "7138out of 8732\n",
            "shape:  (60, 87)\n",
            "7139out of 8732\n",
            "7139out of 8732\n",
            "shape:  (60, 87)\n",
            "7140out of 8732\n",
            "7140out of 8732\n",
            "shape:  (60, 87)\n",
            "7141out of 8732\n",
            "7141out of 8732\n",
            "shape:  (60, 87)\n",
            "7142out of 8732\n",
            "7142out of 8732\n",
            "shape:  (60, 87)\n",
            "7143out of 8732\n",
            "7143out of 8732\n",
            "shape:  (60, 87)\n",
            "7144out of 8732\n",
            "7144out of 8732\n",
            "shape:  (60, 87)\n",
            "7145out of 8732\n",
            "7145out of 8732\n",
            "shape:  (60, 87)\n",
            "7146out of 8732\n",
            "7146out of 8732\n",
            "shape:  (60, 87)\n",
            "7147out of 8732\n",
            "7147out of 8732\n",
            "shape:  (60, 87)\n",
            "7148out of 8732\n",
            "7148out of 8732\n",
            "shape:  (60, 87)\n",
            "7149out of 8732\n",
            "7149out of 8732\n",
            "shape:  (60, 87)\n",
            "7150out of 8732\n",
            "7150out of 8732\n",
            "shape:  (60, 87)\n",
            "7151out of 8732\n",
            "7151out of 8732\n",
            "shape:  (60, 87)\n",
            "7152out of 8732\n",
            "7152out of 8732\n",
            "shape:  (60, 87)\n",
            "7153out of 8732\n",
            "7153out of 8732\n",
            "shape:  (60, 87)\n",
            "7154out of 8732\n",
            "7154out of 8732\n",
            "shape:  (60, 87)\n",
            "7155out of 8732\n",
            "7155out of 8732\n",
            "shape:  (60, 87)\n",
            "7156out of 8732\n",
            "7156out of 8732\n",
            "shape:  (60, 87)\n",
            "7157out of 8732\n",
            "7157out of 8732\n",
            "shape:  (60, 87)\n",
            "7158out of 8732\n",
            "7158out of 8732\n",
            "shape:  (60, 87)\n",
            "7159out of 8732\n",
            "7159out of 8732\n",
            "shape:  (60, 87)\n",
            "7160out of 8732\n",
            "7160out of 8732\n",
            "shape:  (60, 87)\n",
            "7161out of 8732\n",
            "7161out of 8732\n",
            "shape:  (60, 87)\n",
            "7162out of 8732\n",
            "7162out of 8732\n",
            "shape:  (60, 87)\n",
            "7163out of 8732\n",
            "7163out of 8732\n",
            "shape:  (60, 87)\n",
            "7164out of 8732\n",
            "7164out of 8732\n",
            "shape:  (60, 87)\n",
            "7165out of 8732\n",
            "7165out of 8732\n",
            "shape:  (60, 87)\n",
            "7166out of 8732\n",
            "7166out of 8732\n",
            "shape:  (60, 87)\n",
            "7167out of 8732\n",
            "7167out of 8732\n",
            "shape:  (60, 87)\n",
            "7168out of 8732\n",
            "7168out of 8732\n",
            "shape:  (60, 87)\n",
            "7169out of 8732\n",
            "7169out of 8732\n",
            "shape:  (60, 87)\n",
            "7170out of 8732\n",
            "7170out of 8732\n",
            "shape:  (60, 87)\n",
            "7171out of 8732\n",
            "7171out of 8732\n",
            "shape:  (60, 87)\n",
            "7172out of 8732\n",
            "7172out of 8732\n",
            "shape:  (60, 87)\n",
            "7173out of 8732\n",
            "7173out of 8732\n",
            "shape:  (60, 87)\n",
            "7174out of 8732\n",
            "7174out of 8732\n",
            "shape:  (60, 87)\n",
            "7175out of 8732\n",
            "7175out of 8732\n",
            "shape:  (60, 87)\n",
            "7176out of 8732\n",
            "7176out of 8732\n",
            "shape:  (60, 87)\n",
            "7177out of 8732\n",
            "7177out of 8732\n",
            "shape:  (60, 87)\n",
            "7178out of 8732\n",
            "7178out of 8732\n",
            "shape:  (60, 87)\n",
            "7179out of 8732\n",
            "7179out of 8732\n",
            "shape:  (60, 87)\n",
            "7180out of 8732\n",
            "7180out of 8732\n",
            "shape:  (60, 87)\n",
            "7181out of 8732\n",
            "7181out of 8732\n",
            "shape:  (60, 87)\n",
            "7182out of 8732\n",
            "7182out of 8732\n",
            "shape:  (60, 87)\n",
            "7183out of 8732\n",
            "7183out of 8732\n",
            "shape:  (60, 87)\n",
            "7184out of 8732\n",
            "7184out of 8732\n",
            "shape:  (60, 87)\n",
            "7185out of 8732\n",
            "7185out of 8732\n",
            "shape:  (60, 87)\n",
            "7186out of 8732\n",
            "7186out of 8732\n",
            "shape:  (60, 87)\n",
            "7187out of 8732\n",
            "7187out of 8732\n",
            "shape:  (60, 87)\n",
            "7188out of 8732\n",
            "7188out of 8732\n",
            "shape:  (60, 87)\n",
            "7189out of 8732\n",
            "7189out of 8732\n",
            "shape:  (60, 87)\n",
            "7190out of 8732\n",
            "7190out of 8732\n",
            "shape:  (60, 87)\n",
            "7191out of 8732\n",
            "7191out of 8732\n",
            "shape:  (60, 87)\n",
            "7192out of 8732\n",
            "7192out of 8732\n",
            "shape:  (60, 87)\n",
            "7193out of 8732\n",
            "7193out of 8732\n",
            "shape:  (60, 87)\n",
            "7194out of 8732\n",
            "7194out of 8732\n",
            "shape:  (60, 87)\n",
            "7195out of 8732\n",
            "7195out of 8732\n",
            "shape:  (60, 87)\n",
            "7196out of 8732\n",
            "7196out of 8732\n",
            "shape:  (60, 87)\n",
            "7197out of 8732\n",
            "7197out of 8732\n",
            "shape:  (60, 87)\n",
            "7198out of 8732\n",
            "7198out of 8732\n",
            "shape:  (60, 87)\n",
            "7199out of 8732\n",
            "7199out of 8732\n",
            "shape:  (60, 87)\n",
            "7200out of 8732\n",
            "7200out of 8732\n",
            "shape:  (60, 87)\n",
            "7201out of 8732\n",
            "7201out of 8732\n",
            "shape:  (60, 87)\n",
            "7202out of 8732\n",
            "7202out of 8732\n",
            "shape:  (60, 87)\n",
            "7203out of 8732\n",
            "7203out of 8732\n",
            "shape:  (60, 87)\n",
            "7204out of 8732\n",
            "7204out of 8732\n",
            "shape:  (60, 87)\n",
            "7205out of 8732\n",
            "7205out of 8732\n",
            "shape:  (60, 87)\n",
            "7206out of 8732\n",
            "7206out of 8732\n",
            "shape:  (60, 87)\n",
            "7207out of 8732\n",
            "7207out of 8732\n",
            "shape:  (60, 87)\n",
            "7208out of 8732\n",
            "7208out of 8732\n",
            "shape:  (60, 87)\n",
            "7209out of 8732\n",
            "7209out of 8732\n",
            "shape:  (60, 87)\n",
            "7210out of 8732\n",
            "7210out of 8732\n",
            "shape:  (60, 87)\n",
            "7211out of 8732\n",
            "7211out of 8732\n",
            "shape:  (60, 87)\n",
            "7212out of 8732\n",
            "7212out of 8732\n",
            "shape:  (60, 87)\n",
            "7213out of 8732\n",
            "7213out of 8732\n",
            "shape:  (60, 87)\n",
            "7214out of 8732\n",
            "7214out of 8732\n",
            "shape:  (60, 87)\n",
            "7215out of 8732\n",
            "7215out of 8732\n",
            "shape:  (60, 87)\n",
            "7216out of 8732\n",
            "7216out of 8732\n",
            "shape:  (60, 87)\n",
            "7217out of 8732\n",
            "7217out of 8732\n",
            "shape:  (60, 87)\n",
            "7218out of 8732\n",
            "7218out of 8732\n",
            "shape:  (60, 87)\n",
            "7219out of 8732\n",
            "7219out of 8732\n",
            "shape:  (60, 87)\n",
            "7220out of 8732\n",
            "7220out of 8732\n",
            "shape:  (60, 87)\n",
            "7221out of 8732\n",
            "7221out of 8732\n",
            "shape:  (60, 87)\n",
            "7222out of 8732\n",
            "7222out of 8732\n",
            "shape:  (60, 87)\n",
            "7223out of 8732\n",
            "7223out of 8732\n",
            "shape:  (60, 87)\n",
            "7224out of 8732\n",
            "7224out of 8732\n",
            "shape:  (60, 87)\n",
            "7225out of 8732\n",
            "7225out of 8732\n",
            "shape:  (60, 87)\n",
            "7226out of 8732\n",
            "7226out of 8732\n",
            "shape:  (60, 87)\n",
            "7227out of 8732\n",
            "7227out of 8732\n",
            "shape:  (60, 87)\n",
            "7228out of 8732\n",
            "7228out of 8732\n",
            "shape:  (60, 87)\n",
            "7229out of 8732\n",
            "7229out of 8732\n",
            "shape:  (60, 87)\n",
            "7230out of 8732\n",
            "7230out of 8732\n",
            "shape:  (60, 87)\n",
            "7231out of 8732\n",
            "7231out of 8732\n",
            "shape:  (60, 87)\n",
            "7232out of 8732\n",
            "7232out of 8732\n",
            "shape:  (60, 87)\n",
            "7233out of 8732\n",
            "7233out of 8732\n",
            "shape:  (60, 87)\n",
            "7234out of 8732\n",
            "7234out of 8732\n",
            "shape:  (60, 87)\n",
            "7235out of 8732\n",
            "7235out of 8732\n",
            "shape:  (60, 87)\n",
            "7236out of 8732\n",
            "7236out of 8732\n",
            "shape:  (60, 87)\n",
            "7237out of 8732\n",
            "7237out of 8732\n",
            "shape:  (60, 87)\n",
            "7238out of 8732\n",
            "7238out of 8732\n",
            "shape:  (60, 87)\n",
            "7239out of 8732\n",
            "7239out of 8732\n",
            "shape:  (60, 87)\n",
            "7240out of 8732\n",
            "7240out of 8732\n",
            "shape:  (60, 87)\n",
            "7241out of 8732\n",
            "7241out of 8732\n",
            "shape:  (60, 87)\n",
            "7242out of 8732\n",
            "7242out of 8732\n",
            "shape:  (60, 87)\n",
            "7243out of 8732\n",
            "7243out of 8732\n",
            "shape:  (60, 87)\n",
            "7244out of 8732\n",
            "7244out of 8732\n",
            "shape:  (60, 87)\n",
            "7245out of 8732\n",
            "7245out of 8732\n",
            "shape:  (60, 87)\n",
            "7246out of 8732\n",
            "7246out of 8732\n",
            "shape:  (60, 87)\n",
            "7247out of 8732\n",
            "7247out of 8732\n",
            "shape:  (60, 87)\n",
            "7248out of 8732\n",
            "7248out of 8732\n",
            "shape:  (60, 87)\n",
            "7249out of 8732\n",
            "7249out of 8732\n",
            "shape:  (60, 87)\n",
            "7250out of 8732\n",
            "7250out of 8732\n",
            "shape:  (60, 87)\n",
            "7251out of 8732\n",
            "7251out of 8732\n",
            "shape:  (60, 87)\n",
            "7252out of 8732\n",
            "7252out of 8732\n",
            "shape:  (60, 87)\n",
            "7253out of 8732\n",
            "7253out of 8732\n",
            "shape:  (60, 87)\n",
            "7254out of 8732\n",
            "7254out of 8732\n",
            "shape:  (60, 87)\n",
            "7255out of 8732\n",
            "7255out of 8732\n",
            "shape:  (60, 87)\n",
            "7256out of 8732\n",
            "7256out of 8732\n",
            "shape:  (60, 87)\n",
            "7257out of 8732\n",
            "7257out of 8732\n",
            "shape:  (60, 87)\n",
            "7258out of 8732\n",
            "7258out of 8732\n",
            "shape:  (60, 87)\n",
            "7259out of 8732\n",
            "7259out of 8732\n",
            "shape:  (60, 87)\n",
            "7260out of 8732\n",
            "7260out of 8732\n",
            "shape:  (60, 87)\n",
            "7261out of 8732\n",
            "7261out of 8732\n",
            "shape:  (60, 87)\n",
            "7262out of 8732\n",
            "7262out of 8732\n",
            "shape:  (60, 87)\n",
            "7263out of 8732\n",
            "7263out of 8732\n",
            "shape:  (60, 87)\n",
            "7264out of 8732\n",
            "7264out of 8732\n",
            "shape:  (60, 87)\n",
            "7265out of 8732\n",
            "7265out of 8732\n",
            "shape:  (60, 87)\n",
            "7266out of 8732\n",
            "7266out of 8732\n",
            "shape:  (60, 87)\n",
            "7267out of 8732\n",
            "7267out of 8732\n",
            "shape:  (60, 87)\n",
            "7268out of 8732\n",
            "7268out of 8732\n",
            "shape:  (60, 87)\n",
            "7269out of 8732\n",
            "7269out of 8732\n",
            "shape:  (60, 87)\n",
            "7270out of 8732\n",
            "7270out of 8732\n",
            "shape:  (60, 87)\n",
            "7271out of 8732\n",
            "7271out of 8732\n",
            "shape:  (60, 87)\n",
            "7272out of 8732\n",
            "7272out of 8732\n",
            "shape:  (60, 87)\n",
            "7273out of 8732\n",
            "7273out of 8732\n",
            "shape:  (60, 87)\n",
            "7274out of 8732\n",
            "7274out of 8732\n",
            "shape:  (60, 87)\n",
            "7275out of 8732\n",
            "7275out of 8732\n",
            "shape:  (60, 87)\n",
            "7276out of 8732\n",
            "7276out of 8732\n",
            "shape:  (60, 87)\n",
            "7277out of 8732\n",
            "7277out of 8732\n",
            "shape:  (60, 87)\n",
            "7278out of 8732\n",
            "7278out of 8732\n",
            "shape:  (60, 87)\n",
            "7279out of 8732\n",
            "7279out of 8732\n",
            "shape:  (60, 87)\n",
            "7280out of 8732\n",
            "7280out of 8732\n",
            "shape:  (60, 87)\n",
            "7281out of 8732\n",
            "7281out of 8732\n",
            "shape:  (60, 87)\n",
            "7282out of 8732\n",
            "7282out of 8732\n",
            "shape:  (60, 87)\n",
            "7283out of 8732\n",
            "7283out of 8732\n",
            "shape:  (60, 87)\n",
            "7284out of 8732\n",
            "7284out of 8732\n",
            "shape:  (60, 87)\n",
            "7285out of 8732\n",
            "7285out of 8732\n",
            "shape:  (60, 87)\n",
            "7286out of 8732\n",
            "7286out of 8732\n",
            "shape:  (60, 87)\n",
            "7287out of 8732\n",
            "7287out of 8732\n",
            "shape:  (60, 87)\n",
            "7288out of 8732\n",
            "7288out of 8732\n",
            "shape:  (60, 87)\n",
            "7289out of 8732\n",
            "7289out of 8732\n",
            "shape:  (60, 87)\n",
            "7290out of 8732\n",
            "7290out of 8732\n",
            "shape:  (60, 87)\n",
            "7291out of 8732\n",
            "7291out of 8732\n",
            "shape:  (60, 87)\n",
            "7292out of 8732\n",
            "7292out of 8732\n",
            "shape:  (60, 87)\n",
            "7293out of 8732\n",
            "7293out of 8732\n",
            "shape:  (60, 87)\n",
            "7294out of 8732\n",
            "7294out of 8732\n",
            "shape:  (60, 87)\n",
            "7295out of 8732\n",
            "7295out of 8732\n",
            "shape:  (60, 87)\n",
            "7296out of 8732\n",
            "7296out of 8732\n",
            "shape:  (60, 87)\n",
            "7297out of 8732\n",
            "7297out of 8732\n",
            "shape:  (60, 87)\n",
            "7298out of 8732\n",
            "7298out of 8732\n",
            "shape:  (60, 87)\n",
            "7299out of 8732\n",
            "7299out of 8732\n",
            "shape:  (60, 87)\n",
            "7300out of 8732\n",
            "7300out of 8732\n",
            "shape:  (60, 87)\n",
            "7301out of 8732\n",
            "7301out of 8732\n",
            "shape:  (60, 87)\n",
            "7302out of 8732\n",
            "7302out of 8732\n",
            "shape:  (60, 87)\n",
            "7303out of 8732\n",
            "7303out of 8732\n",
            "shape:  (60, 87)\n",
            "7304out of 8732\n",
            "7304out of 8732\n",
            "shape:  (60, 87)\n",
            "7305out of 8732\n",
            "7305out of 8732\n",
            "shape:  (60, 87)\n",
            "7306out of 8732\n",
            "7306out of 8732\n",
            "shape:  (60, 87)\n",
            "7307out of 8732\n",
            "7307out of 8732\n",
            "shape:  (60, 87)\n",
            "7308out of 8732\n",
            "7308out of 8732\n",
            "shape:  (60, 87)\n",
            "7309out of 8732\n",
            "7309out of 8732\n",
            "shape:  (60, 87)\n",
            "7310out of 8732\n",
            "7310out of 8732\n",
            "shape:  (60, 87)\n",
            "7311out of 8732\n",
            "7311out of 8732\n",
            "shape:  (60, 87)\n",
            "7312out of 8732\n",
            "7312out of 8732\n",
            "shape:  (60, 87)\n",
            "7313out of 8732\n",
            "7313out of 8732\n",
            "shape:  (60, 87)\n",
            "7314out of 8732\n",
            "7314out of 8732\n",
            "shape:  (60, 87)\n",
            "7315out of 8732\n",
            "7315out of 8732\n",
            "shape:  (60, 87)\n",
            "7316out of 8732\n",
            "7316out of 8732\n",
            "shape:  (60, 87)\n",
            "7317out of 8732\n",
            "7317out of 8732\n",
            "shape:  (60, 87)\n",
            "7318out of 8732\n",
            "7318out of 8732\n",
            "shape:  (60, 87)\n",
            "7319out of 8732\n",
            "7319out of 8732\n",
            "shape:  (60, 87)\n",
            "7320out of 8732\n",
            "7320out of 8732\n",
            "shape:  (60, 87)\n",
            "7321out of 8732\n",
            "7321out of 8732\n",
            "shape:  (60, 87)\n",
            "7322out of 8732\n",
            "7322out of 8732\n",
            "shape:  (60, 87)\n",
            "7323out of 8732\n",
            "7323out of 8732\n",
            "shape:  (60, 87)\n",
            "7324out of 8732\n",
            "7324out of 8732\n",
            "shape:  (60, 87)\n",
            "7325out of 8732\n",
            "7325out of 8732\n",
            "shape:  (60, 87)\n",
            "7326out of 8732\n",
            "7326out of 8732\n",
            "shape:  (60, 87)\n",
            "7327out of 8732\n",
            "7327out of 8732\n",
            "shape:  (60, 87)\n",
            "7328out of 8732\n",
            "7328out of 8732\n",
            "shape:  (60, 87)\n",
            "7329out of 8732\n",
            "7329out of 8732\n",
            "shape:  (60, 87)\n",
            "7330out of 8732\n",
            "7330out of 8732\n",
            "shape:  (60, 87)\n",
            "7331out of 8732\n",
            "7331out of 8732\n",
            "shape:  (60, 87)\n",
            "7332out of 8732\n",
            "7332out of 8732\n",
            "shape:  (60, 87)\n",
            "7333out of 8732\n",
            "7333out of 8732\n",
            "shape:  (60, 87)\n",
            "7334out of 8732\n",
            "7334out of 8732\n",
            "shape:  (60, 87)\n",
            "7335out of 8732\n",
            "7335out of 8732\n",
            "shape:  (60, 87)\n",
            "7336out of 8732\n",
            "7336out of 8732\n",
            "shape:  (60, 87)\n",
            "7337out of 8732\n",
            "7337out of 8732\n",
            "shape:  (60, 87)\n",
            "7338out of 8732\n",
            "7338out of 8732\n",
            "shape:  (60, 87)\n",
            "7339out of 8732\n",
            "7339out of 8732\n",
            "shape:  (60, 87)\n",
            "7340out of 8732\n",
            "7340out of 8732\n",
            "shape:  (60, 87)\n",
            "7341out of 8732\n",
            "7341out of 8732\n",
            "shape:  (60, 87)\n",
            "7342out of 8732\n",
            "7342out of 8732\n",
            "shape:  (60, 87)\n",
            "7343out of 8732\n",
            "7343out of 8732\n",
            "shape:  (60, 87)\n",
            "7344out of 8732\n",
            "7344out of 8732\n",
            "shape:  (60, 87)\n",
            "7345out of 8732\n",
            "7345out of 8732\n",
            "shape:  (60, 87)\n",
            "7346out of 8732\n",
            "7346out of 8732\n",
            "shape:  (60, 87)\n",
            "7347out of 8732\n",
            "7347out of 8732\n",
            "shape:  (60, 87)\n",
            "7348out of 8732\n",
            "7348out of 8732\n",
            "shape:  (60, 87)\n",
            "7349out of 8732\n",
            "7349out of 8732\n",
            "shape:  (60, 87)\n",
            "7350out of 8732\n",
            "7350out of 8732\n",
            "shape:  (60, 87)\n",
            "7351out of 8732\n",
            "7351out of 8732\n",
            "shape:  (60, 87)\n",
            "7352out of 8732\n",
            "7352out of 8732\n",
            "shape:  (60, 87)\n",
            "7353out of 8732\n",
            "7353out of 8732\n",
            "shape:  (60, 87)\n",
            "7354out of 8732\n",
            "7354out of 8732\n",
            "shape:  (60, 87)\n",
            "7355out of 8732\n",
            "7355out of 8732\n",
            "shape:  (60, 87)\n",
            "7356out of 8732\n",
            "7356out of 8732\n",
            "shape:  (60, 87)\n",
            "7357out of 8732\n",
            "7357out of 8732\n",
            "shape:  (60, 87)\n",
            "7358out of 8732\n",
            "7358out of 8732\n",
            "shape:  (60, 87)\n",
            "7359out of 8732\n",
            "7359out of 8732\n",
            "shape:  (60, 87)\n",
            "7360out of 8732\n",
            "7360out of 8732\n",
            "shape:  (60, 87)\n",
            "7361out of 8732\n",
            "7361out of 8732\n",
            "shape:  (60, 87)\n",
            "7362out of 8732\n",
            "7362out of 8732\n",
            "shape:  (60, 87)\n",
            "7363out of 8732\n",
            "7363out of 8732\n",
            "shape:  (60, 87)\n",
            "7364out of 8732\n",
            "7364out of 8732\n",
            "shape:  (60, 87)\n",
            "7365out of 8732\n",
            "7365out of 8732\n",
            "shape:  (60, 87)\n",
            "7366out of 8732\n",
            "7366out of 8732\n",
            "shape:  (60, 87)\n",
            "7367out of 8732\n",
            "7367out of 8732\n",
            "shape:  (60, 87)\n",
            "7368out of 8732\n",
            "7368out of 8732\n",
            "shape:  (60, 87)\n",
            "7369out of 8732\n",
            "7369out of 8732\n",
            "shape:  (60, 87)\n",
            "7370out of 8732\n",
            "7370out of 8732\n",
            "shape:  (60, 87)\n",
            "7371out of 8732\n",
            "7371out of 8732\n",
            "shape:  (60, 87)\n",
            "7372out of 8732\n",
            "7372out of 8732\n",
            "shape:  (60, 87)\n",
            "7373out of 8732\n",
            "7373out of 8732\n",
            "shape:  (60, 87)\n",
            "7374out of 8732\n",
            "7374out of 8732\n",
            "shape:  (60, 87)\n",
            "7375out of 8732\n",
            "7375out of 8732\n",
            "shape:  (60, 87)\n",
            "7376out of 8732\n",
            "7376out of 8732\n",
            "shape:  (60, 87)\n",
            "7377out of 8732\n",
            "7377out of 8732\n",
            "shape:  (60, 87)\n",
            "7378out of 8732\n",
            "7378out of 8732\n",
            "shape:  (60, 87)\n",
            "7379out of 8732\n",
            "7379out of 8732\n",
            "shape:  (60, 87)\n",
            "7380out of 8732\n",
            "7380out of 8732\n",
            "shape:  (60, 87)\n",
            "7381out of 8732\n",
            "7381out of 8732\n",
            "shape:  (60, 87)\n",
            "7382out of 8732\n",
            "7382out of 8732\n",
            "shape:  (60, 87)\n",
            "7383out of 8732\n",
            "7383out of 8732\n",
            "shape:  (60, 87)\n",
            "7384out of 8732\n",
            "7384out of 8732\n",
            "shape:  (60, 87)\n",
            "7385out of 8732\n",
            "7385out of 8732\n",
            "shape:  (60, 87)\n",
            "7386out of 8732\n",
            "7386out of 8732\n",
            "shape:  (60, 87)\n",
            "7387out of 8732\n",
            "7387out of 8732\n",
            "shape:  (60, 87)\n",
            "7388out of 8732\n",
            "7388out of 8732\n",
            "shape:  (60, 87)\n",
            "7389out of 8732\n",
            "7389out of 8732\n",
            "shape:  (60, 87)\n",
            "7390out of 8732\n",
            "7390out of 8732\n",
            "shape:  (60, 87)\n",
            "7391out of 8732\n",
            "7391out of 8732\n",
            "shape:  (60, 87)\n",
            "7392out of 8732\n",
            "7392out of 8732\n",
            "shape:  (60, 87)\n",
            "7393out of 8732\n",
            "7393out of 8732\n",
            "shape:  (60, 87)\n",
            "7394out of 8732\n",
            "7394out of 8732\n",
            "shape:  (60, 87)\n",
            "7395out of 8732\n",
            "7395out of 8732\n",
            "shape:  (60, 87)\n",
            "7396out of 8732\n",
            "7396out of 8732\n",
            "shape:  (60, 87)\n",
            "7397out of 8732\n",
            "7397out of 8732\n",
            "shape:  (60, 87)\n",
            "7398out of 8732\n",
            "7398out of 8732\n",
            "shape:  (60, 87)\n",
            "7399out of 8732\n",
            "7399out of 8732\n",
            "shape:  (60, 87)\n",
            "7400out of 8732\n",
            "7400out of 8732\n",
            "shape:  (60, 87)\n",
            "7401out of 8732\n",
            "7401out of 8732\n",
            "shape:  (60, 87)\n",
            "7402out of 8732\n",
            "7402out of 8732\n",
            "shape:  (60, 87)\n",
            "7403out of 8732\n",
            "7403out of 8732\n",
            "shape:  (60, 87)\n",
            "7404out of 8732\n",
            "7404out of 8732\n",
            "shape:  (60, 87)\n",
            "7405out of 8732\n",
            "7405out of 8732\n",
            "shape:  (60, 87)\n",
            "7406out of 8732\n",
            "7406out of 8732\n",
            "shape:  (60, 87)\n",
            "7407out of 8732\n",
            "7407out of 8732\n",
            "shape:  (60, 87)\n",
            "7408out of 8732\n",
            "7408out of 8732\n",
            "shape:  (60, 87)\n",
            "7409out of 8732\n",
            "7409out of 8732\n",
            "shape:  (60, 87)\n",
            "7410out of 8732\n",
            "7410out of 8732\n",
            "shape:  (60, 87)\n",
            "7411out of 8732\n",
            "7411out of 8732\n",
            "shape:  (60, 87)\n",
            "7412out of 8732\n",
            "7412out of 8732\n",
            "shape:  (60, 87)\n",
            "7413out of 8732\n",
            "7413out of 8732\n",
            "shape:  (60, 87)\n",
            "7414out of 8732\n",
            "7414out of 8732\n",
            "shape:  (60, 87)\n",
            "7415out of 8732\n",
            "7415out of 8732\n",
            "shape:  (60, 87)\n",
            "7416out of 8732\n",
            "7416out of 8732\n",
            "shape:  (60, 87)\n",
            "7417out of 8732\n",
            "7417out of 8732\n",
            "shape:  (60, 87)\n",
            "7418out of 8732\n",
            "7418out of 8732\n",
            "shape:  (60, 87)\n",
            "7419out of 8732\n",
            "7419out of 8732\n",
            "shape:  (60, 87)\n",
            "7420out of 8732\n",
            "7420out of 8732\n",
            "shape:  (60, 87)\n",
            "7421out of 8732\n",
            "7421out of 8732\n",
            "shape:  (60, 87)\n",
            "7422out of 8732\n",
            "7422out of 8732\n",
            "shape:  (60, 87)\n",
            "7423out of 8732\n",
            "7423out of 8732\n",
            "shape:  (60, 87)\n",
            "7424out of 8732\n",
            "7424out of 8732\n",
            "shape:  (60, 87)\n",
            "7425out of 8732\n",
            "7425out of 8732\n",
            "shape:  (60, 87)\n",
            "7426out of 8732\n",
            "7426out of 8732\n",
            "shape:  (60, 87)\n",
            "7427out of 8732\n",
            "7427out of 8732\n",
            "shape:  (60, 87)\n",
            "7428out of 8732\n",
            "7428out of 8732\n",
            "shape:  (60, 87)\n",
            "7429out of 8732\n",
            "7429out of 8732\n",
            "shape:  (60, 87)\n",
            "7430out of 8732\n",
            "7430out of 8732\n",
            "shape:  (60, 87)\n",
            "7431out of 8732\n",
            "7431out of 8732\n",
            "shape:  (60, 87)\n",
            "7432out of 8732\n",
            "7432out of 8732\n",
            "shape:  (60, 87)\n",
            "7433out of 8732\n",
            "7433out of 8732\n",
            "shape:  (60, 87)\n",
            "7434out of 8732\n",
            "7434out of 8732\n",
            "shape:  (60, 87)\n",
            "7435out of 8732\n",
            "7435out of 8732\n",
            "shape:  (60, 87)\n",
            "7436out of 8732\n",
            "7436out of 8732\n",
            "shape:  (60, 87)\n",
            "7437out of 8732\n",
            "7437out of 8732\n",
            "shape:  (60, 87)\n",
            "7438out of 8732\n",
            "7438out of 8732\n",
            "shape:  (60, 87)\n",
            "7439out of 8732\n",
            "7439out of 8732\n",
            "shape:  (60, 87)\n",
            "7440out of 8732\n",
            "7440out of 8732\n",
            "shape:  (60, 87)\n",
            "7441out of 8732\n",
            "7441out of 8732\n",
            "shape:  (60, 87)\n",
            "7442out of 8732\n",
            "7442out of 8732\n",
            "shape:  (60, 87)\n",
            "7443out of 8732\n",
            "7443out of 8732\n",
            "shape:  (60, 87)\n",
            "7444out of 8732\n",
            "7444out of 8732\n",
            "shape:  (60, 87)\n",
            "7445out of 8732\n",
            "7445out of 8732\n",
            "shape:  (60, 87)\n",
            "7446out of 8732\n",
            "7446out of 8732\n",
            "shape:  (60, 87)\n",
            "7447out of 8732\n",
            "7447out of 8732\n",
            "shape:  (60, 87)\n",
            "7448out of 8732\n",
            "7448out of 8732\n",
            "shape:  (60, 87)\n",
            "7449out of 8732\n",
            "7449out of 8732\n",
            "shape:  (60, 87)\n",
            "7450out of 8732\n",
            "7450out of 8732\n",
            "shape:  (60, 87)\n",
            "7451out of 8732\n",
            "7451out of 8732\n",
            "shape:  (60, 87)\n",
            "7452out of 8732\n",
            "7452out of 8732\n",
            "shape:  (60, 87)\n",
            "7453out of 8732\n",
            "7453out of 8732\n",
            "shape:  (60, 87)\n",
            "7454out of 8732\n",
            "7454out of 8732\n",
            "shape:  (60, 87)\n",
            "7455out of 8732\n",
            "7455out of 8732\n",
            "shape:  (60, 87)\n",
            "7456out of 8732\n",
            "7456out of 8732\n",
            "shape:  (60, 87)\n",
            "7457out of 8732\n",
            "7457out of 8732\n",
            "shape:  (60, 87)\n",
            "7458out of 8732\n",
            "7458out of 8732\n",
            "shape:  (60, 87)\n",
            "7459out of 8732\n",
            "7459out of 8732\n",
            "shape:  (60, 87)\n",
            "7460out of 8732\n",
            "7460out of 8732\n",
            "shape:  (60, 87)\n",
            "7461out of 8732\n",
            "7461out of 8732\n",
            "shape:  (60, 87)\n",
            "7462out of 8732\n",
            "7462out of 8732\n",
            "shape:  (60, 87)\n",
            "7463out of 8732\n",
            "7463out of 8732\n",
            "shape:  (60, 87)\n",
            "7464out of 8732\n",
            "7464out of 8732\n",
            "shape:  (60, 87)\n",
            "7465out of 8732\n",
            "7465out of 8732\n",
            "shape:  (60, 87)\n",
            "7466out of 8732\n",
            "7466out of 8732\n",
            "shape:  (60, 87)\n",
            "7467out of 8732\n",
            "7467out of 8732\n",
            "shape:  (60, 87)\n",
            "7468out of 8732\n",
            "7468out of 8732\n",
            "shape:  (60, 87)\n",
            "7469out of 8732\n",
            "7469out of 8732\n",
            "shape:  (60, 87)\n",
            "7470out of 8732\n",
            "7470out of 8732\n",
            "shape:  (60, 87)\n",
            "7471out of 8732\n",
            "7471out of 8732\n",
            "shape:  (60, 87)\n",
            "7472out of 8732\n",
            "7472out of 8732\n",
            "shape:  (60, 87)\n",
            "7473out of 8732\n",
            "7473out of 8732\n",
            "shape:  (60, 87)\n",
            "7474out of 8732\n",
            "7474out of 8732\n",
            "shape:  (60, 87)\n",
            "7475out of 8732\n",
            "7475out of 8732\n",
            "shape:  (60, 87)\n",
            "7476out of 8732\n",
            "7476out of 8732\n",
            "shape:  (60, 87)\n",
            "7477out of 8732\n",
            "7477out of 8732\n",
            "shape:  (60, 87)\n",
            "7478out of 8732\n",
            "7478out of 8732\n",
            "shape:  (60, 87)\n",
            "7479out of 8732\n",
            "7479out of 8732\n",
            "shape:  (60, 87)\n",
            "7480out of 8732\n",
            "7480out of 8732\n",
            "shape:  (60, 87)\n",
            "7481out of 8732\n",
            "7481out of 8732\n",
            "shape:  (60, 87)\n",
            "7482out of 8732\n",
            "7482out of 8732\n",
            "shape:  (60, 87)\n",
            "7483out of 8732\n",
            "7483out of 8732\n",
            "shape:  (60, 87)\n",
            "7484out of 8732\n",
            "7484out of 8732\n",
            "shape:  (60, 87)\n",
            "7485out of 8732\n",
            "7485out of 8732\n",
            "shape:  (60, 87)\n",
            "7486out of 8732\n",
            "7486out of 8732\n",
            "shape:  (60, 87)\n",
            "7487out of 8732\n",
            "7487out of 8732\n",
            "shape:  (60, 87)\n",
            "7488out of 8732\n",
            "7488out of 8732\n",
            "shape:  (60, 87)\n",
            "7489out of 8732\n",
            "7489out of 8732\n",
            "shape:  (60, 87)\n",
            "7490out of 8732\n",
            "7490out of 8732\n",
            "shape:  (60, 87)\n",
            "7491out of 8732\n",
            "7491out of 8732\n",
            "shape:  (60, 87)\n",
            "7492out of 8732\n",
            "7492out of 8732\n",
            "shape:  (60, 87)\n",
            "7493out of 8732\n",
            "7493out of 8732\n",
            "shape:  (60, 87)\n",
            "7494out of 8732\n",
            "7494out of 8732\n",
            "shape:  (60, 87)\n",
            "7495out of 8732\n",
            "7495out of 8732\n",
            "shape:  (60, 87)\n",
            "7496out of 8732\n",
            "7496out of 8732\n",
            "shape:  (60, 87)\n",
            "7497out of 8732\n",
            "7497out of 8732\n",
            "shape:  (60, 87)\n",
            "7498out of 8732\n",
            "7498out of 8732\n",
            "shape:  (60, 87)\n",
            "7499out of 8732\n",
            "7499out of 8732\n",
            "shape:  (60, 87)\n",
            "7500out of 8732\n",
            "7500out of 8732\n",
            "shape:  (60, 87)\n",
            "7501out of 8732\n",
            "7501out of 8732\n",
            "shape:  (60, 87)\n",
            "7502out of 8732\n",
            "7502out of 8732\n",
            "shape:  (60, 87)\n",
            "7503out of 8732\n",
            "7503out of 8732\n",
            "shape:  (60, 87)\n",
            "7504out of 8732\n",
            "7504out of 8732\n",
            "shape:  (60, 87)\n",
            "7505out of 8732\n",
            "7505out of 8732\n",
            "shape:  (60, 87)\n",
            "7506out of 8732\n",
            "7506out of 8732\n",
            "shape:  (60, 87)\n",
            "7507out of 8732\n",
            "7507out of 8732\n",
            "shape:  (60, 87)\n",
            "7508out of 8732\n",
            "7508out of 8732\n",
            "shape:  (60, 87)\n",
            "7509out of 8732\n",
            "7509out of 8732\n",
            "shape:  (60, 87)\n",
            "7510out of 8732\n",
            "7510out of 8732\n",
            "shape:  (60, 87)\n",
            "7511out of 8732\n",
            "7511out of 8732\n",
            "shape:  (60, 87)\n",
            "7512out of 8732\n",
            "7512out of 8732\n",
            "shape:  (60, 87)\n",
            "7513out of 8732\n",
            "7513out of 8732\n",
            "shape:  (60, 87)\n",
            "7514out of 8732\n",
            "7514out of 8732\n",
            "shape:  (60, 87)\n",
            "7515out of 8732\n",
            "7515out of 8732\n",
            "shape:  (60, 87)\n",
            "7516out of 8732\n",
            "7516out of 8732\n",
            "shape:  (60, 87)\n",
            "7517out of 8732\n",
            "7517out of 8732\n",
            "shape:  (60, 87)\n",
            "7518out of 8732\n",
            "7518out of 8732\n",
            "shape:  (60, 87)\n",
            "7519out of 8732\n",
            "7519out of 8732\n",
            "shape:  (60, 87)\n",
            "7520out of 8732\n",
            "7520out of 8732\n",
            "shape:  (60, 87)\n",
            "7521out of 8732\n",
            "7521out of 8732\n",
            "shape:  (60, 87)\n",
            "7522out of 8732\n",
            "7522out of 8732\n",
            "shape:  (60, 87)\n",
            "7523out of 8732\n",
            "7523out of 8732\n",
            "shape:  (60, 87)\n",
            "7524out of 8732\n",
            "7524out of 8732\n",
            "shape:  (60, 87)\n",
            "7525out of 8732\n",
            "7525out of 8732\n",
            "shape:  (60, 87)\n",
            "7526out of 8732\n",
            "7526out of 8732\n",
            "shape:  (60, 87)\n",
            "7527out of 8732\n",
            "7527out of 8732\n",
            "shape:  (60, 87)\n",
            "7528out of 8732\n",
            "7528out of 8732\n",
            "shape:  (60, 87)\n",
            "7529out of 8732\n",
            "7529out of 8732\n",
            "shape:  (60, 87)\n",
            "7530out of 8732\n",
            "7530out of 8732\n",
            "shape:  (60, 87)\n",
            "7531out of 8732\n",
            "7531out of 8732\n",
            "shape:  (60, 87)\n",
            "7532out of 8732\n",
            "7532out of 8732\n",
            "shape:  (60, 87)\n",
            "7533out of 8732\n",
            "7533out of 8732\n",
            "shape:  (60, 87)\n",
            "7534out of 8732\n",
            "7534out of 8732\n",
            "shape:  (60, 87)\n",
            "7535out of 8732\n",
            "7535out of 8732\n",
            "shape:  (60, 87)\n",
            "7536out of 8732\n",
            "7536out of 8732\n",
            "shape:  (60, 87)\n",
            "7537out of 8732\n",
            "7537out of 8732\n",
            "shape:  (60, 87)\n",
            "7538out of 8732\n",
            "7538out of 8732\n",
            "shape:  (60, 87)\n",
            "7539out of 8732\n",
            "7539out of 8732\n",
            "shape:  (60, 87)\n",
            "7540out of 8732\n",
            "7540out of 8732\n",
            "shape:  (60, 87)\n",
            "7541out of 8732\n",
            "7541out of 8732\n",
            "shape:  (60, 87)\n",
            "7542out of 8732\n",
            "7542out of 8732\n",
            "shape:  (60, 87)\n",
            "7543out of 8732\n",
            "7543out of 8732\n",
            "shape:  (60, 87)\n",
            "7544out of 8732\n",
            "7544out of 8732\n",
            "shape:  (60, 87)\n",
            "7545out of 8732\n",
            "7545out of 8732\n",
            "shape:  (60, 87)\n",
            "7546out of 8732\n",
            "7546out of 8732\n",
            "shape:  (60, 87)\n",
            "7547out of 8732\n",
            "7547out of 8732\n",
            "shape:  (60, 87)\n",
            "7548out of 8732\n",
            "7548out of 8732\n",
            "shape:  (60, 87)\n",
            "7549out of 8732\n",
            "7549out of 8732\n",
            "shape:  (60, 87)\n",
            "7550out of 8732\n",
            "7550out of 8732\n",
            "shape:  (60, 87)\n",
            "7551out of 8732\n",
            "7551out of 8732\n",
            "shape:  (60, 87)\n",
            "7552out of 8732\n",
            "7552out of 8732\n",
            "shape:  (60, 87)\n",
            "7553out of 8732\n",
            "7553out of 8732\n",
            "shape:  (60, 87)\n",
            "7554out of 8732\n",
            "7554out of 8732\n",
            "shape:  (60, 87)\n",
            "7555out of 8732\n",
            "7555out of 8732\n",
            "shape:  (60, 87)\n",
            "7556out of 8732\n",
            "7556out of 8732\n",
            "shape:  (60, 87)\n",
            "7557out of 8732\n",
            "7557out of 8732\n",
            "shape:  (60, 87)\n",
            "7558out of 8732\n",
            "7558out of 8732\n",
            "shape:  (60, 87)\n",
            "7559out of 8732\n",
            "7559out of 8732\n",
            "shape:  (60, 87)\n",
            "7560out of 8732\n",
            "7560out of 8732\n",
            "shape:  (60, 87)\n",
            "7561out of 8732\n",
            "7561out of 8732\n",
            "shape:  (60, 87)\n",
            "7562out of 8732\n",
            "7562out of 8732\n",
            "shape:  (60, 87)\n",
            "7563out of 8732\n",
            "7563out of 8732\n",
            "shape:  (60, 87)\n",
            "7564out of 8732\n",
            "7564out of 8732\n",
            "shape:  (60, 87)\n",
            "7565out of 8732\n",
            "7565out of 8732\n",
            "shape:  (60, 87)\n",
            "7566out of 8732\n",
            "7566out of 8732\n",
            "shape:  (60, 87)\n",
            "7567out of 8732\n",
            "7567out of 8732\n",
            "shape:  (60, 87)\n",
            "7568out of 8732\n",
            "7568out of 8732\n",
            "shape:  (60, 87)\n",
            "7569out of 8732\n",
            "7569out of 8732\n",
            "shape:  (60, 87)\n",
            "7570out of 8732\n",
            "7570out of 8732\n",
            "shape:  (60, 87)\n",
            "7571out of 8732\n",
            "7571out of 8732\n",
            "shape:  (60, 87)\n",
            "7572out of 8732\n",
            "7572out of 8732\n",
            "shape:  (60, 87)\n",
            "7573out of 8732\n",
            "7573out of 8732\n",
            "shape:  (60, 87)\n",
            "7574out of 8732\n",
            "7574out of 8732\n",
            "shape:  (60, 87)\n",
            "7575out of 8732\n",
            "7575out of 8732\n",
            "shape:  (60, 87)\n",
            "7576out of 8732\n",
            "7576out of 8732\n",
            "shape:  (60, 87)\n",
            "7577out of 8732\n",
            "7577out of 8732\n",
            "shape:  (60, 87)\n",
            "7578out of 8732\n",
            "7578out of 8732\n",
            "shape:  (60, 87)\n",
            "7579out of 8732\n",
            "7579out of 8732\n",
            "shape:  (60, 87)\n",
            "7580out of 8732\n",
            "7580out of 8732\n",
            "shape:  (60, 87)\n",
            "7581out of 8732\n",
            "7581out of 8732\n",
            "shape:  (60, 87)\n",
            "7582out of 8732\n",
            "7582out of 8732\n",
            "shape:  (60, 87)\n",
            "7583out of 8732\n",
            "7583out of 8732\n",
            "shape:  (60, 87)\n",
            "7584out of 8732\n",
            "7584out of 8732\n",
            "shape:  (60, 87)\n",
            "7585out of 8732\n",
            "7585out of 8732\n",
            "shape:  (60, 87)\n",
            "7586out of 8732\n",
            "7586out of 8732\n",
            "shape:  (60, 87)\n",
            "7587out of 8732\n",
            "7587out of 8732\n",
            "shape:  (60, 87)\n",
            "7588out of 8732\n",
            "7588out of 8732\n",
            "shape:  (60, 87)\n",
            "7589out of 8732\n",
            "7589out of 8732\n",
            "shape:  (60, 87)\n",
            "7590out of 8732\n",
            "7590out of 8732\n",
            "shape:  (60, 87)\n",
            "7591out of 8732\n",
            "7591out of 8732\n",
            "shape:  (60, 87)\n",
            "7592out of 8732\n",
            "7592out of 8732\n",
            "shape:  (60, 87)\n",
            "7593out of 8732\n",
            "7593out of 8732\n",
            "shape:  (60, 87)\n",
            "7594out of 8732\n",
            "7594out of 8732\n",
            "shape:  (60, 87)\n",
            "7595out of 8732\n",
            "7595out of 8732\n",
            "shape:  (60, 87)\n",
            "7596out of 8732\n",
            "7596out of 8732\n",
            "shape:  (60, 87)\n",
            "7597out of 8732\n",
            "7597out of 8732\n",
            "shape:  (60, 87)\n",
            "7598out of 8732\n",
            "7598out of 8732\n",
            "shape:  (60, 87)\n",
            "7599out of 8732\n",
            "7599out of 8732\n",
            "shape:  (60, 87)\n",
            "7600out of 8732\n",
            "7600out of 8732\n",
            "shape:  (60, 87)\n",
            "7601out of 8732\n",
            "7601out of 8732\n",
            "shape:  (60, 87)\n",
            "7602out of 8732\n",
            "7602out of 8732\n",
            "shape:  (60, 87)\n",
            "7603out of 8732\n",
            "7603out of 8732\n",
            "shape:  (60, 87)\n",
            "7604out of 8732\n",
            "7604out of 8732\n",
            "shape:  (60, 87)\n",
            "7605out of 8732\n",
            "7605out of 8732\n",
            "shape:  (60, 87)\n",
            "7606out of 8732\n",
            "7606out of 8732\n",
            "shape:  (60, 87)\n",
            "7607out of 8732\n",
            "7607out of 8732\n",
            "shape:  (60, 87)\n",
            "7608out of 8732\n",
            "7608out of 8732\n",
            "shape:  (60, 87)\n",
            "7609out of 8732\n",
            "7609out of 8732\n",
            "shape:  (60, 87)\n",
            "7610out of 8732\n",
            "7610out of 8732\n",
            "shape:  (60, 87)\n",
            "7611out of 8732\n",
            "7611out of 8732\n",
            "shape:  (60, 87)\n",
            "7612out of 8732\n",
            "7612out of 8732\n",
            "shape:  (60, 87)\n",
            "7613out of 8732\n",
            "7613out of 8732\n",
            "shape:  (60, 87)\n",
            "7614out of 8732\n",
            "7614out of 8732\n",
            "shape:  (60, 87)\n",
            "7615out of 8732\n",
            "7615out of 8732\n",
            "shape:  (60, 87)\n",
            "7616out of 8732\n",
            "7616out of 8732\n",
            "shape:  (60, 87)\n",
            "7617out of 8732\n",
            "7617out of 8732\n",
            "shape:  (60, 87)\n",
            "7618out of 8732\n",
            "7618out of 8732\n",
            "shape:  (60, 87)\n",
            "7619out of 8732\n",
            "7619out of 8732\n",
            "shape:  (60, 87)\n",
            "7620out of 8732\n",
            "7620out of 8732\n",
            "shape:  (60, 87)\n",
            "7621out of 8732\n",
            "7621out of 8732\n",
            "shape:  (60, 87)\n",
            "7622out of 8732\n",
            "7622out of 8732\n",
            "shape:  (60, 87)\n",
            "7623out of 8732\n",
            "7623out of 8732\n",
            "shape:  (60, 87)\n",
            "7624out of 8732\n",
            "7624out of 8732\n",
            "shape:  (60, 87)\n",
            "7625out of 8732\n",
            "7625out of 8732\n",
            "shape:  (60, 87)\n",
            "7626out of 8732\n",
            "7626out of 8732\n",
            "shape:  (60, 87)\n",
            "7627out of 8732\n",
            "7627out of 8732\n",
            "shape:  (60, 87)\n",
            "7628out of 8732\n",
            "7628out of 8732\n",
            "shape:  (60, 87)\n",
            "7629out of 8732\n",
            "7629out of 8732\n",
            "shape:  (60, 87)\n",
            "7630out of 8732\n",
            "7630out of 8732\n",
            "shape:  (60, 87)\n",
            "7631out of 8732\n",
            "7631out of 8732\n",
            "shape:  (60, 87)\n",
            "7632out of 8732\n",
            "7632out of 8732\n",
            "shape:  (60, 87)\n",
            "7633out of 8732\n",
            "7633out of 8732\n",
            "shape:  (60, 87)\n",
            "7634out of 8732\n",
            "7634out of 8732\n",
            "shape:  (60, 87)\n",
            "7635out of 8732\n",
            "7635out of 8732\n",
            "shape:  (60, 87)\n",
            "7636out of 8732\n",
            "7636out of 8732\n",
            "shape:  (60, 87)\n",
            "7637out of 8732\n",
            "7637out of 8732\n",
            "shape:  (60, 87)\n",
            "7638out of 8732\n",
            "7638out of 8732\n",
            "shape:  (60, 87)\n",
            "7639out of 8732\n",
            "7639out of 8732\n",
            "shape:  (60, 87)\n",
            "7640out of 8732\n",
            "7640out of 8732\n",
            "shape:  (60, 87)\n",
            "7641out of 8732\n",
            "7641out of 8732\n",
            "shape:  (60, 87)\n",
            "7642out of 8732\n",
            "7642out of 8732\n",
            "shape:  (60, 87)\n",
            "7643out of 8732\n",
            "7643out of 8732\n",
            "shape:  (60, 87)\n",
            "7644out of 8732\n",
            "7644out of 8732\n",
            "shape:  (60, 87)\n",
            "7645out of 8732\n",
            "7645out of 8732\n",
            "shape:  (60, 87)\n",
            "7646out of 8732\n",
            "7646out of 8732\n",
            "shape:  (60, 87)\n",
            "7647out of 8732\n",
            "7647out of 8732\n",
            "shape:  (60, 87)\n",
            "7648out of 8732\n",
            "7648out of 8732\n",
            "shape:  (60, 87)\n",
            "7649out of 8732\n",
            "7649out of 8732\n",
            "shape:  (60, 87)\n",
            "7650out of 8732\n",
            "7650out of 8732\n",
            "shape:  (60, 87)\n",
            "7651out of 8732\n",
            "7651out of 8732\n",
            "shape:  (60, 87)\n",
            "7652out of 8732\n",
            "7652out of 8732\n",
            "shape:  (60, 87)\n",
            "7653out of 8732\n",
            "7653out of 8732\n",
            "shape:  (60, 87)\n",
            "7654out of 8732\n",
            "7654out of 8732\n",
            "shape:  (60, 87)\n",
            "7655out of 8732\n",
            "7655out of 8732\n",
            "shape:  (60, 87)\n",
            "7656out of 8732\n",
            "7656out of 8732\n",
            "shape:  (60, 87)\n",
            "7657out of 8732\n",
            "7657out of 8732\n",
            "shape:  (60, 87)\n",
            "7658out of 8732\n",
            "7658out of 8732\n",
            "shape:  (60, 87)\n",
            "7659out of 8732\n",
            "7659out of 8732\n",
            "shape:  (60, 87)\n",
            "7660out of 8732\n",
            "7660out of 8732\n",
            "shape:  (60, 87)\n",
            "7661out of 8732\n",
            "7661out of 8732\n",
            "shape:  (60, 87)\n",
            "7662out of 8732\n",
            "7662out of 8732\n",
            "shape:  (60, 87)\n",
            "7663out of 8732\n",
            "7663out of 8732\n",
            "shape:  (60, 87)\n",
            "7664out of 8732\n",
            "7664out of 8732\n",
            "shape:  (60, 87)\n",
            "7665out of 8732\n",
            "7665out of 8732\n",
            "shape:  (60, 87)\n",
            "7666out of 8732\n",
            "7666out of 8732\n",
            "shape:  (60, 87)\n",
            "7667out of 8732\n",
            "7667out of 8732\n",
            "shape:  (60, 87)\n",
            "7668out of 8732\n",
            "7668out of 8732\n",
            "shape:  (60, 87)\n",
            "7669out of 8732\n",
            "7669out of 8732\n",
            "shape:  (60, 87)\n",
            "7670out of 8732\n",
            "7670out of 8732\n",
            "shape:  (60, 87)\n",
            "7671out of 8732\n",
            "7671out of 8732\n",
            "shape:  (60, 87)\n",
            "7672out of 8732\n",
            "7672out of 8732\n",
            "shape:  (60, 87)\n",
            "7673out of 8732\n",
            "7673out of 8732\n",
            "shape:  (60, 87)\n",
            "7674out of 8732\n",
            "7674out of 8732\n",
            "shape:  (60, 87)\n",
            "7675out of 8732\n",
            "7675out of 8732\n",
            "shape:  (60, 87)\n",
            "7676out of 8732\n",
            "7676out of 8732\n",
            "shape:  (60, 87)\n",
            "7677out of 8732\n",
            "7677out of 8732\n",
            "shape:  (60, 87)\n",
            "7678out of 8732\n",
            "7678out of 8732\n",
            "shape:  (60, 87)\n",
            "7679out of 8732\n",
            "7679out of 8732\n",
            "shape:  (60, 87)\n",
            "7680out of 8732\n",
            "7680out of 8732\n",
            "shape:  (60, 87)\n",
            "7681out of 8732\n",
            "7681out of 8732\n",
            "shape:  (60, 87)\n",
            "7682out of 8732\n",
            "7682out of 8732\n",
            "shape:  (60, 87)\n",
            "7683out of 8732\n",
            "7683out of 8732\n",
            "shape:  (60, 87)\n",
            "7684out of 8732\n",
            "7684out of 8732\n",
            "shape:  (60, 87)\n",
            "7685out of 8732\n",
            "7685out of 8732\n",
            "shape:  (60, 87)\n",
            "7686out of 8732\n",
            "7686out of 8732\n",
            "shape:  (60, 87)\n",
            "7687out of 8732\n",
            "7687out of 8732\n",
            "shape:  (60, 87)\n",
            "7688out of 8732\n",
            "7688out of 8732\n",
            "shape:  (60, 87)\n",
            "7689out of 8732\n",
            "7689out of 8732\n",
            "shape:  (60, 87)\n",
            "7690out of 8732\n",
            "7690out of 8732\n",
            "shape:  (60, 87)\n",
            "7691out of 8732\n",
            "7691out of 8732\n",
            "shape:  (60, 87)\n",
            "7692out of 8732\n",
            "7692out of 8732\n",
            "shape:  (60, 87)\n",
            "7693out of 8732\n",
            "7693out of 8732\n",
            "shape:  (60, 87)\n",
            "7694out of 8732\n",
            "7694out of 8732\n",
            "shape:  (60, 87)\n",
            "7695out of 8732\n",
            "7695out of 8732\n",
            "shape:  (60, 87)\n",
            "7696out of 8732\n",
            "7696out of 8732\n",
            "shape:  (60, 87)\n",
            "7697out of 8732\n",
            "7697out of 8732\n",
            "shape:  (60, 87)\n",
            "7698out of 8732\n",
            "7698out of 8732\n",
            "shape:  (60, 87)\n",
            "7699out of 8732\n",
            "7699out of 8732\n",
            "shape:  (60, 87)\n",
            "7700out of 8732\n",
            "7700out of 8732\n",
            "shape:  (60, 87)\n",
            "7701out of 8732\n",
            "7701out of 8732\n",
            "shape:  (60, 87)\n",
            "7702out of 8732\n",
            "7702out of 8732\n",
            "shape:  (60, 87)\n",
            "7703out of 8732\n",
            "7703out of 8732\n",
            "shape:  (60, 87)\n",
            "7704out of 8732\n",
            "7704out of 8732\n",
            "shape:  (60, 87)\n",
            "7705out of 8732\n",
            "7705out of 8732\n",
            "shape:  (60, 87)\n",
            "7706out of 8732\n",
            "7706out of 8732\n",
            "shape:  (60, 87)\n",
            "7707out of 8732\n",
            "7707out of 8732\n",
            "shape:  (60, 87)\n",
            "7708out of 8732\n",
            "7708out of 8732\n",
            "shape:  (60, 87)\n",
            "7709out of 8732\n",
            "7709out of 8732\n",
            "shape:  (60, 87)\n",
            "7710out of 8732\n",
            "7710out of 8732\n",
            "shape:  (60, 87)\n",
            "7711out of 8732\n",
            "7711out of 8732\n",
            "shape:  (60, 87)\n",
            "7712out of 8732\n",
            "7712out of 8732\n",
            "shape:  (60, 87)\n",
            "7713out of 8732\n",
            "7713out of 8732\n",
            "shape:  (60, 87)\n",
            "7714out of 8732\n",
            "7714out of 8732\n",
            "shape:  (60, 87)\n",
            "7715out of 8732\n",
            "7715out of 8732\n",
            "shape:  (60, 87)\n",
            "7716out of 8732\n",
            "7716out of 8732\n",
            "shape:  (60, 87)\n",
            "7717out of 8732\n",
            "7717out of 8732\n",
            "shape:  (60, 87)\n",
            "7718out of 8732\n",
            "7718out of 8732\n",
            "shape:  (60, 87)\n",
            "7719out of 8732\n",
            "7719out of 8732\n",
            "shape:  (60, 87)\n",
            "7720out of 8732\n",
            "7720out of 8732\n",
            "shape:  (60, 87)\n",
            "7721out of 8732\n",
            "7721out of 8732\n",
            "shape:  (60, 87)\n",
            "7722out of 8732\n",
            "7722out of 8732\n",
            "shape:  (60, 87)\n",
            "7723out of 8732\n",
            "7723out of 8732\n",
            "shape:  (60, 87)\n",
            "7724out of 8732\n",
            "7724out of 8732\n",
            "shape:  (60, 87)\n",
            "7725out of 8732\n",
            "7725out of 8732\n",
            "shape:  (60, 87)\n",
            "7726out of 8732\n",
            "7726out of 8732\n",
            "shape:  (60, 87)\n",
            "7727out of 8732\n",
            "7727out of 8732\n",
            "shape:  (60, 87)\n",
            "7728out of 8732\n",
            "7728out of 8732\n",
            "shape:  (60, 87)\n",
            "7729out of 8732\n",
            "7729out of 8732\n",
            "shape:  (60, 87)\n",
            "7730out of 8732\n",
            "7730out of 8732\n",
            "shape:  (60, 87)\n",
            "7731out of 8732\n",
            "7731out of 8732\n",
            "shape:  (60, 87)\n",
            "7732out of 8732\n",
            "7732out of 8732\n",
            "shape:  (60, 87)\n",
            "7733out of 8732\n",
            "7733out of 8732\n",
            "shape:  (60, 87)\n",
            "7734out of 8732\n",
            "7734out of 8732\n",
            "shape:  (60, 87)\n",
            "7735out of 8732\n",
            "7735out of 8732\n",
            "shape:  (60, 87)\n",
            "7736out of 8732\n",
            "7736out of 8732\n",
            "shape:  (60, 87)\n",
            "7737out of 8732\n",
            "7737out of 8732\n",
            "shape:  (60, 87)\n",
            "7738out of 8732\n",
            "7738out of 8732\n",
            "shape:  (60, 87)\n",
            "7739out of 8732\n",
            "7739out of 8732\n",
            "shape:  (60, 87)\n",
            "7740out of 8732\n",
            "7740out of 8732\n",
            "shape:  (60, 87)\n",
            "7741out of 8732\n",
            "7741out of 8732\n",
            "shape:  (60, 87)\n",
            "7742out of 8732\n",
            "7742out of 8732\n",
            "shape:  (60, 87)\n",
            "7743out of 8732\n",
            "7743out of 8732\n",
            "shape:  (60, 87)\n",
            "7744out of 8732\n",
            "7744out of 8732\n",
            "shape:  (60, 87)\n",
            "7745out of 8732\n",
            "7745out of 8732\n",
            "shape:  (60, 87)\n",
            "7746out of 8732\n",
            "7746out of 8732\n",
            "shape:  (60, 87)\n",
            "7747out of 8732\n",
            "7747out of 8732\n",
            "shape:  (60, 87)\n",
            "7748out of 8732\n",
            "7748out of 8732\n",
            "shape:  (60, 87)\n",
            "7749out of 8732\n",
            "7749out of 8732\n",
            "shape:  (60, 87)\n",
            "7750out of 8732\n",
            "7750out of 8732\n",
            "shape:  (60, 87)\n",
            "7751out of 8732\n",
            "7751out of 8732\n",
            "shape:  (60, 87)\n",
            "7752out of 8732\n",
            "7752out of 8732\n",
            "shape:  (60, 87)\n",
            "7753out of 8732\n",
            "7753out of 8732\n",
            "shape:  (60, 87)\n",
            "7754out of 8732\n",
            "7754out of 8732\n",
            "shape:  (60, 87)\n",
            "7755out of 8732\n",
            "7755out of 8732\n",
            "shape:  (60, 87)\n",
            "7756out of 8732\n",
            "7756out of 8732\n",
            "shape:  (60, 87)\n",
            "7757out of 8732\n",
            "7757out of 8732\n",
            "shape:  (60, 87)\n",
            "7758out of 8732\n",
            "7758out of 8732\n",
            "shape:  (60, 87)\n",
            "7759out of 8732\n",
            "7759out of 8732\n",
            "shape:  (60, 87)\n",
            "7760out of 8732\n",
            "7760out of 8732\n",
            "shape:  (60, 87)\n",
            "7761out of 8732\n",
            "7761out of 8732\n",
            "shape:  (60, 87)\n",
            "7762out of 8732\n",
            "7762out of 8732\n",
            "shape:  (60, 87)\n",
            "7763out of 8732\n",
            "7763out of 8732\n",
            "shape:  (60, 87)\n",
            "7764out of 8732\n",
            "7764out of 8732\n",
            "shape:  (60, 87)\n",
            "7765out of 8732\n",
            "7765out of 8732\n",
            "shape:  (60, 87)\n",
            "7766out of 8732\n",
            "7766out of 8732\n",
            "shape:  (60, 87)\n",
            "7767out of 8732\n",
            "7767out of 8732\n",
            "shape:  (60, 87)\n",
            "7768out of 8732\n",
            "7768out of 8732\n",
            "shape:  (60, 87)\n",
            "7769out of 8732\n",
            "7769out of 8732\n",
            "shape:  (60, 87)\n",
            "7770out of 8732\n",
            "7770out of 8732\n",
            "shape:  (60, 87)\n",
            "7771out of 8732\n",
            "7771out of 8732\n",
            "shape:  (60, 87)\n",
            "7772out of 8732\n",
            "7772out of 8732\n",
            "shape:  (60, 87)\n",
            "7773out of 8732\n",
            "7773out of 8732\n",
            "shape:  (60, 87)\n",
            "7774out of 8732\n",
            "7774out of 8732\n",
            "shape:  (60, 87)\n",
            "7775out of 8732\n",
            "7775out of 8732\n",
            "shape:  (60, 87)\n",
            "7776out of 8732\n",
            "7776out of 8732\n",
            "shape:  (60, 87)\n",
            "7777out of 8732\n",
            "7777out of 8732\n",
            "shape:  (60, 87)\n",
            "7778out of 8732\n",
            "7778out of 8732\n",
            "shape:  (60, 87)\n",
            "7779out of 8732\n",
            "7779out of 8732\n",
            "shape:  (60, 87)\n",
            "7780out of 8732\n",
            "7780out of 8732\n",
            "shape:  (60, 87)\n",
            "7781out of 8732\n",
            "7781out of 8732\n",
            "shape:  (60, 87)\n",
            "7782out of 8732\n",
            "7782out of 8732\n",
            "shape:  (60, 87)\n",
            "7783out of 8732\n",
            "7783out of 8732\n",
            "shape:  (60, 87)\n",
            "7784out of 8732\n",
            "7784out of 8732\n",
            "shape:  (60, 87)\n",
            "7785out of 8732\n",
            "7785out of 8732\n",
            "shape:  (60, 87)\n",
            "7786out of 8732\n",
            "7786out of 8732\n",
            "shape:  (60, 87)\n",
            "7787out of 8732\n",
            "7787out of 8732\n",
            "shape:  (60, 87)\n",
            "7788out of 8732\n",
            "7788out of 8732\n",
            "shape:  (60, 87)\n",
            "7789out of 8732\n",
            "7789out of 8732\n",
            "shape:  (60, 87)\n",
            "7790out of 8732\n",
            "7790out of 8732\n",
            "shape:  (60, 87)\n",
            "7791out of 8732\n",
            "7791out of 8732\n",
            "shape:  (60, 87)\n",
            "7792out of 8732\n",
            "7792out of 8732\n",
            "shape:  (60, 87)\n",
            "7793out of 8732\n",
            "7793out of 8732\n",
            "shape:  (60, 87)\n",
            "7794out of 8732\n",
            "7794out of 8732\n",
            "shape:  (60, 87)\n",
            "7795out of 8732\n",
            "7795out of 8732\n",
            "shape:  (60, 87)\n",
            "7796out of 8732\n",
            "7796out of 8732\n",
            "shape:  (60, 87)\n",
            "7797out of 8732\n",
            "7797out of 8732\n",
            "shape:  (60, 87)\n",
            "7798out of 8732\n",
            "7798out of 8732\n",
            "shape:  (60, 87)\n",
            "7799out of 8732\n",
            "7799out of 8732\n",
            "shape:  (60, 87)\n",
            "7800out of 8732\n",
            "7800out of 8732\n",
            "shape:  (60, 87)\n",
            "7801out of 8732\n",
            "7801out of 8732\n",
            "shape:  (60, 87)\n",
            "7802out of 8732\n",
            "7802out of 8732\n",
            "shape:  (60, 87)\n",
            "7803out of 8732\n",
            "7803out of 8732\n",
            "shape:  (60, 87)\n",
            "7804out of 8732\n",
            "7804out of 8732\n",
            "shape:  (60, 87)\n",
            "7805out of 8732\n",
            "7805out of 8732\n",
            "shape:  (60, 87)\n",
            "7806out of 8732\n",
            "7806out of 8732\n",
            "shape:  (60, 87)\n",
            "7807out of 8732\n",
            "7807out of 8732\n",
            "shape:  (60, 87)\n",
            "7808out of 8732\n",
            "7808out of 8732\n",
            "shape:  (60, 87)\n",
            "7809out of 8732\n",
            "7809out of 8732\n",
            "shape:  (60, 87)\n",
            "7810out of 8732\n",
            "7810out of 8732\n",
            "shape:  (60, 87)\n",
            "7811out of 8732\n",
            "7811out of 8732\n",
            "shape:  (60, 87)\n",
            "7812out of 8732\n",
            "7812out of 8732\n",
            "shape:  (60, 87)\n",
            "7813out of 8732\n",
            "7813out of 8732\n",
            "shape:  (60, 87)\n",
            "7814out of 8732\n",
            "7814out of 8732\n",
            "shape:  (60, 87)\n",
            "7815out of 8732\n",
            "7815out of 8732\n",
            "shape:  (60, 87)\n",
            "7816out of 8732\n",
            "7816out of 8732\n",
            "shape:  (60, 87)\n",
            "7817out of 8732\n",
            "7817out of 8732\n",
            "shape:  (60, 87)\n",
            "7818out of 8732\n",
            "7818out of 8732\n",
            "shape:  (60, 87)\n",
            "7819out of 8732\n",
            "7819out of 8732\n",
            "shape:  (60, 87)\n",
            "7820out of 8732\n",
            "7820out of 8732\n",
            "shape:  (60, 87)\n",
            "7821out of 8732\n",
            "7821out of 8732\n",
            "shape:  (60, 87)\n",
            "7822out of 8732\n",
            "7822out of 8732\n",
            "shape:  (60, 87)\n",
            "7823out of 8732\n",
            "7823out of 8732\n",
            "shape:  (60, 87)\n",
            "7824out of 8732\n",
            "7824out of 8732\n",
            "shape:  (60, 87)\n",
            "7825out of 8732\n",
            "7825out of 8732\n",
            "shape:  (60, 87)\n",
            "7826out of 8732\n",
            "7826out of 8732\n",
            "shape:  (60, 87)\n",
            "7827out of 8732\n",
            "7827out of 8732\n",
            "shape:  (60, 87)\n",
            "7828out of 8732\n",
            "7828out of 8732\n",
            "shape:  (60, 87)\n",
            "7829out of 8732\n",
            "7829out of 8732\n",
            "shape:  (60, 87)\n",
            "7830out of 8732\n",
            "7830out of 8732\n",
            "shape:  (60, 87)\n",
            "7831out of 8732\n",
            "7831out of 8732\n",
            "shape:  (60, 87)\n",
            "7832out of 8732\n",
            "7832out of 8732\n",
            "shape:  (60, 87)\n",
            "7833out of 8732\n",
            "7833out of 8732\n",
            "shape:  (60, 87)\n",
            "7834out of 8732\n",
            "7834out of 8732\n",
            "shape:  (60, 87)\n",
            "7835out of 8732\n",
            "7835out of 8732\n",
            "shape:  (60, 87)\n",
            "7836out of 8732\n",
            "7836out of 8732\n",
            "shape:  (60, 87)\n",
            "7837out of 8732\n",
            "7837out of 8732\n",
            "shape:  (60, 87)\n",
            "7838out of 8732\n",
            "7838out of 8732\n",
            "shape:  (60, 87)\n",
            "7839out of 8732\n",
            "7839out of 8732\n",
            "shape:  (60, 87)\n",
            "7840out of 8732\n",
            "7840out of 8732\n",
            "shape:  (60, 87)\n",
            "7841out of 8732\n",
            "7841out of 8732\n",
            "shape:  (60, 87)\n",
            "7842out of 8732\n",
            "7842out of 8732\n",
            "shape:  (60, 87)\n",
            "7843out of 8732\n",
            "7843out of 8732\n",
            "shape:  (60, 87)\n",
            "7844out of 8732\n",
            "7844out of 8732\n",
            "shape:  (60, 87)\n",
            "7845out of 8732\n",
            "7845out of 8732\n",
            "shape:  (60, 87)\n",
            "7846out of 8732\n",
            "7846out of 8732\n",
            "shape:  (60, 87)\n",
            "7847out of 8732\n",
            "7847out of 8732\n",
            "shape:  (60, 87)\n",
            "7848out of 8732\n",
            "7848out of 8732\n",
            "shape:  (60, 87)\n",
            "7849out of 8732\n",
            "7849out of 8732\n",
            "shape:  (60, 87)\n",
            "7850out of 8732\n",
            "7850out of 8732\n",
            "shape:  (60, 87)\n",
            "7851out of 8732\n",
            "7851out of 8732\n",
            "shape:  (60, 87)\n",
            "7852out of 8732\n",
            "7852out of 8732\n",
            "shape:  (60, 87)\n",
            "7853out of 8732\n",
            "7853out of 8732\n",
            "shape:  (60, 87)\n",
            "7854out of 8732\n",
            "7854out of 8732\n",
            "shape:  (60, 87)\n",
            "7855out of 8732\n",
            "7855out of 8732\n",
            "shape:  (60, 87)\n",
            "7856out of 8732\n",
            "7856out of 8732\n",
            "shape:  (60, 87)\n",
            "7857out of 8732\n",
            "7857out of 8732\n",
            "shape:  (60, 87)\n",
            "7858out of 8732\n",
            "7858out of 8732\n",
            "shape:  (60, 87)\n",
            "7859out of 8732\n",
            "7859out of 8732\n",
            "shape:  (60, 87)\n",
            "7860out of 8732\n",
            "7860out of 8732\n",
            "shape:  (60, 87)\n",
            "7861out of 8732\n",
            "7861out of 8732\n",
            "shape:  (60, 87)\n",
            "7862out of 8732\n",
            "7862out of 8732\n",
            "shape:  (60, 87)\n",
            "7863out of 8732\n",
            "7863out of 8732\n",
            "shape:  (60, 87)\n",
            "7864out of 8732\n",
            "7864out of 8732\n",
            "shape:  (60, 87)\n",
            "7865out of 8732\n",
            "7865out of 8732\n",
            "shape:  (60, 87)\n",
            "7866out of 8732\n",
            "7866out of 8732\n",
            "shape:  (60, 87)\n",
            "7867out of 8732\n",
            "7867out of 8732\n",
            "shape:  (60, 87)\n",
            "7868out of 8732\n",
            "7868out of 8732\n",
            "shape:  (60, 87)\n",
            "7869out of 8732\n",
            "7869out of 8732\n",
            "shape:  (60, 87)\n",
            "7870out of 8732\n",
            "7870out of 8732\n",
            "shape:  (60, 87)\n",
            "7871out of 8732\n",
            "7871out of 8732\n",
            "shape:  (60, 87)\n",
            "7872out of 8732\n",
            "7872out of 8732\n",
            "shape:  (60, 87)\n",
            "7873out of 8732\n",
            "7873out of 8732\n",
            "shape:  (60, 87)\n",
            "7874out of 8732\n",
            "7874out of 8732\n",
            "shape:  (60, 87)\n",
            "7875out of 8732\n",
            "7875out of 8732\n",
            "shape:  (60, 87)\n",
            "7876out of 8732\n",
            "7876out of 8732\n",
            "shape:  (60, 87)\n",
            "7877out of 8732\n",
            "7877out of 8732\n",
            "shape:  (60, 87)\n",
            "7878out of 8732\n",
            "7878out of 8732\n",
            "shape:  (60, 87)\n",
            "7879out of 8732\n",
            "7879out of 8732\n",
            "shape:  (60, 87)\n",
            "7880out of 8732\n",
            "7880out of 8732\n",
            "shape:  (60, 87)\n",
            "7881out of 8732\n",
            "7881out of 8732\n",
            "shape:  (60, 87)\n",
            "7882out of 8732\n",
            "7882out of 8732\n",
            "shape:  (60, 87)\n",
            "7883out of 8732\n",
            "7883out of 8732\n",
            "shape:  (60, 87)\n",
            "7884out of 8732\n",
            "7884out of 8732\n",
            "shape:  (60, 87)\n",
            "7885out of 8732\n",
            "7885out of 8732\n",
            "shape:  (60, 87)\n",
            "7886out of 8732\n",
            "7886out of 8732\n",
            "shape:  (60, 87)\n",
            "7887out of 8732\n",
            "7887out of 8732\n",
            "shape:  (60, 87)\n",
            "7888out of 8732\n",
            "7888out of 8732\n",
            "shape:  (60, 87)\n",
            "7889out of 8732\n",
            "7889out of 8732\n",
            "shape:  (60, 87)\n",
            "7890out of 8732\n",
            "7890out of 8732\n",
            "shape:  (60, 87)\n",
            "7891out of 8732\n",
            "7891out of 8732\n",
            "shape:  (60, 87)\n",
            "7892out of 8732\n",
            "7892out of 8732\n",
            "shape:  (60, 87)\n",
            "7893out of 8732\n",
            "7893out of 8732\n",
            "shape:  (60, 87)\n",
            "7894out of 8732\n",
            "7894out of 8732\n",
            "shape:  (60, 87)\n",
            "7895out of 8732\n",
            "7895out of 8732\n",
            "shape:  (60, 87)\n",
            "7896out of 8732\n",
            "7896out of 8732\n",
            "shape:  (60, 87)\n",
            "7897out of 8732\n",
            "7897out of 8732\n",
            "shape:  (60, 87)\n",
            "7898out of 8732\n",
            "7898out of 8732\n",
            "shape:  (60, 87)\n",
            "7899out of 8732\n",
            "7899out of 8732\n",
            "shape:  (60, 87)\n",
            "7900out of 8732\n",
            "7900out of 8732\n",
            "shape:  (60, 87)\n",
            "7901out of 8732\n",
            "7901out of 8732\n",
            "shape:  (60, 87)\n",
            "7902out of 8732\n",
            "7902out of 8732\n",
            "shape:  (60, 87)\n",
            "7903out of 8732\n",
            "7903out of 8732\n",
            "shape:  (60, 87)\n",
            "7904out of 8732\n",
            "7904out of 8732\n",
            "shape:  (60, 87)\n",
            "7905out of 8732\n",
            "7905out of 8732\n",
            "shape:  (60, 87)\n",
            "7906out of 8732\n",
            "7906out of 8732\n",
            "shape:  (60, 87)\n",
            "7907out of 8732\n",
            "7907out of 8732\n",
            "shape:  (60, 87)\n",
            "7908out of 8732\n",
            "7908out of 8732\n",
            "shape:  (60, 87)\n",
            "7909out of 8732\n",
            "7909out of 8732\n",
            "shape:  (60, 87)\n",
            "7910out of 8732\n",
            "7910out of 8732\n",
            "shape:  (60, 87)\n",
            "7911out of 8732\n",
            "7911out of 8732\n",
            "shape:  (60, 87)\n",
            "7912out of 8732\n",
            "7912out of 8732\n",
            "shape:  (60, 87)\n",
            "7913out of 8732\n",
            "7913out of 8732\n",
            "shape:  (60, 87)\n",
            "7914out of 8732\n",
            "7914out of 8732\n",
            "shape:  (60, 87)\n",
            "7915out of 8732\n",
            "7915out of 8732\n",
            "shape:  (60, 87)\n",
            "7916out of 8732\n",
            "7916out of 8732\n",
            "shape:  (60, 87)\n",
            "7917out of 8732\n",
            "7917out of 8732\n",
            "shape:  (60, 87)\n",
            "7918out of 8732\n",
            "7918out of 8732\n",
            "shape:  (60, 87)\n",
            "7919out of 8732\n",
            "7919out of 8732\n",
            "shape:  (60, 87)\n",
            "7920out of 8732\n",
            "7920out of 8732\n",
            "shape:  (60, 87)\n",
            "7921out of 8732\n",
            "7921out of 8732\n",
            "shape:  (60, 87)\n",
            "7922out of 8732\n",
            "7922out of 8732\n",
            "shape:  (60, 87)\n",
            "7923out of 8732\n",
            "7923out of 8732\n",
            "shape:  (60, 87)\n",
            "7924out of 8732\n",
            "7924out of 8732\n",
            "shape:  (60, 87)\n",
            "7925out of 8732\n",
            "7925out of 8732\n",
            "shape:  (60, 87)\n",
            "7926out of 8732\n",
            "7926out of 8732\n",
            "shape:  (60, 87)\n",
            "7927out of 8732\n",
            "7927out of 8732\n",
            "shape:  (60, 87)\n",
            "7928out of 8732\n",
            "7928out of 8732\n",
            "shape:  (60, 87)\n",
            "7929out of 8732\n",
            "7929out of 8732\n",
            "shape:  (60, 87)\n",
            "7930out of 8732\n",
            "7930out of 8732\n",
            "shape:  (60, 87)\n",
            "7931out of 8732\n",
            "7931out of 8732\n",
            "shape:  (60, 87)\n",
            "7932out of 8732\n",
            "7932out of 8732\n",
            "shape:  (60, 87)\n",
            "7933out of 8732\n",
            "7933out of 8732\n",
            "shape:  (60, 87)\n",
            "7934out of 8732\n",
            "7934out of 8732\n",
            "shape:  (60, 87)\n",
            "7935out of 8732\n",
            "7935out of 8732\n",
            "shape:  (60, 87)\n",
            "7936out of 8732\n",
            "7936out of 8732\n",
            "shape:  (60, 87)\n",
            "7937out of 8732\n",
            "7937out of 8732\n",
            "shape:  (60, 87)\n",
            "7938out of 8732\n",
            "7938out of 8732\n",
            "shape:  (60, 87)\n",
            "7939out of 8732\n",
            "7939out of 8732\n",
            "shape:  (60, 87)\n",
            "7940out of 8732\n",
            "7940out of 8732\n",
            "shape:  (60, 87)\n",
            "7941out of 8732\n",
            "7941out of 8732\n",
            "shape:  (60, 87)\n",
            "7942out of 8732\n",
            "7942out of 8732\n",
            "shape:  (60, 87)\n",
            "7943out of 8732\n",
            "7943out of 8732\n",
            "shape:  (60, 87)\n",
            "7944out of 8732\n",
            "7944out of 8732\n",
            "shape:  (60, 87)\n",
            "7945out of 8732\n",
            "7945out of 8732\n",
            "shape:  (60, 87)\n",
            "7946out of 8732\n",
            "7946out of 8732\n",
            "shape:  (60, 87)\n",
            "7947out of 8732\n",
            "7947out of 8732\n",
            "shape:  (60, 87)\n",
            "7948out of 8732\n",
            "7948out of 8732\n",
            "shape:  (60, 87)\n",
            "7949out of 8732\n",
            "7949out of 8732\n",
            "shape:  (60, 87)\n",
            "7950out of 8732\n",
            "7950out of 8732\n",
            "shape:  (60, 87)\n",
            "7951out of 8732\n",
            "7951out of 8732\n",
            "shape:  (60, 87)\n",
            "7952out of 8732\n",
            "7952out of 8732\n",
            "shape:  (60, 87)\n",
            "7953out of 8732\n",
            "7953out of 8732\n",
            "shape:  (60, 87)\n",
            "7954out of 8732\n",
            "7954out of 8732\n",
            "shape:  (60, 87)\n",
            "7955out of 8732\n",
            "7955out of 8732\n",
            "shape:  (60, 87)\n",
            "7956out of 8732\n",
            "7956out of 8732\n",
            "shape:  (60, 87)\n",
            "7957out of 8732\n",
            "7957out of 8732\n",
            "shape:  (60, 87)\n",
            "7958out of 8732\n",
            "7958out of 8732\n",
            "shape:  (60, 87)\n",
            "7959out of 8732\n",
            "7959out of 8732\n",
            "shape:  (60, 87)\n",
            "7960out of 8732\n",
            "7960out of 8732\n",
            "shape:  (60, 87)\n",
            "7961out of 8732\n",
            "7961out of 8732\n",
            "shape:  (60, 87)\n",
            "7962out of 8732\n",
            "7962out of 8732\n",
            "shape:  (60, 87)\n",
            "7963out of 8732\n",
            "7963out of 8732\n",
            "shape:  (60, 87)\n",
            "7964out of 8732\n",
            "7964out of 8732\n",
            "shape:  (60, 87)\n",
            "7965out of 8732\n",
            "7965out of 8732\n",
            "shape:  (60, 87)\n",
            "7966out of 8732\n",
            "7966out of 8732\n",
            "shape:  (60, 87)\n",
            "7967out of 8732\n",
            "7967out of 8732\n",
            "shape:  (60, 87)\n",
            "7968out of 8732\n",
            "7968out of 8732\n",
            "shape:  (60, 87)\n",
            "7969out of 8732\n",
            "7969out of 8732\n",
            "shape:  (60, 87)\n",
            "7970out of 8732\n",
            "7970out of 8732\n",
            "shape:  (60, 87)\n",
            "7971out of 8732\n",
            "7971out of 8732\n",
            "shape:  (60, 87)\n",
            "7972out of 8732\n",
            "7972out of 8732\n",
            "shape:  (60, 87)\n",
            "7973out of 8732\n",
            "7973out of 8732\n",
            "shape:  (60, 87)\n",
            "7974out of 8732\n",
            "7974out of 8732\n",
            "shape:  (60, 87)\n",
            "7975out of 8732\n",
            "7975out of 8732\n",
            "shape:  (60, 87)\n",
            "7976out of 8732\n",
            "7976out of 8732\n",
            "shape:  (60, 87)\n",
            "7977out of 8732\n",
            "7977out of 8732\n",
            "shape:  (60, 87)\n",
            "7978out of 8732\n",
            "7978out of 8732\n",
            "shape:  (60, 87)\n",
            "7979out of 8732\n",
            "7979out of 8732\n",
            "shape:  (60, 87)\n",
            "7980out of 8732\n",
            "7980out of 8732\n",
            "shape:  (60, 87)\n",
            "7981out of 8732\n",
            "7981out of 8732\n",
            "shape:  (60, 87)\n",
            "7982out of 8732\n",
            "7982out of 8732\n",
            "shape:  (60, 87)\n",
            "7983out of 8732\n",
            "7983out of 8732\n",
            "shape:  (60, 87)\n",
            "7984out of 8732\n",
            "7984out of 8732\n",
            "shape:  (60, 87)\n",
            "7985out of 8732\n",
            "7985out of 8732\n",
            "shape:  (60, 87)\n",
            "7986out of 8732\n",
            "7986out of 8732\n",
            "shape:  (60, 87)\n",
            "7987out of 8732\n",
            "7987out of 8732\n",
            "shape:  (60, 87)\n",
            "7988out of 8732\n",
            "7988out of 8732\n",
            "shape:  (60, 87)\n",
            "7989out of 8732\n",
            "7989out of 8732\n",
            "shape:  (60, 87)\n",
            "7990out of 8732\n",
            "7990out of 8732\n",
            "shape:  (60, 87)\n",
            "7991out of 8732\n",
            "7991out of 8732\n",
            "shape:  (60, 87)\n",
            "7992out of 8732\n",
            "7992out of 8732\n",
            "shape:  (60, 87)\n",
            "7993out of 8732\n",
            "7993out of 8732\n",
            "shape:  (60, 87)\n",
            "7994out of 8732\n",
            "7994out of 8732\n",
            "shape:  (60, 87)\n",
            "7995out of 8732\n",
            "7995out of 8732\n",
            "shape:  (60, 87)\n",
            "7996out of 8732\n",
            "7996out of 8732\n",
            "shape:  (60, 87)\n",
            "7997out of 8732\n",
            "7997out of 8732\n",
            "shape:  (60, 87)\n",
            "7998out of 8732\n",
            "7998out of 8732\n",
            "shape:  (60, 87)\n",
            "7999out of 8732\n",
            "7999out of 8732\n",
            "shape:  (60, 87)\n",
            "8000out of 8732\n",
            "8000out of 8732\n",
            "shape:  (60, 87)\n",
            "8001out of 8732\n",
            "8001out of 8732\n",
            "shape:  (60, 87)\n",
            "8002out of 8732\n",
            "8002out of 8732\n",
            "shape:  (60, 87)\n",
            "8003out of 8732\n",
            "8003out of 8732\n",
            "shape:  (60, 87)\n",
            "8004out of 8732\n",
            "8004out of 8732\n",
            "shape:  (60, 87)\n",
            "8005out of 8732\n",
            "8005out of 8732\n",
            "shape:  (60, 87)\n",
            "8006out of 8732\n",
            "8006out of 8732\n",
            "shape:  (60, 87)\n",
            "8007out of 8732\n",
            "8007out of 8732\n",
            "shape:  (60, 87)\n",
            "8008out of 8732\n",
            "8008out of 8732\n",
            "shape:  (60, 87)\n",
            "8009out of 8732\n",
            "8009out of 8732\n",
            "shape:  (60, 87)\n",
            "8010out of 8732\n",
            "8010out of 8732\n",
            "shape:  (60, 87)\n",
            "8011out of 8732\n",
            "8011out of 8732\n",
            "shape:  (60, 87)\n",
            "8012out of 8732\n",
            "8012out of 8732\n",
            "shape:  (60, 87)\n",
            "8013out of 8732\n",
            "8013out of 8732\n",
            "shape:  (60, 87)\n",
            "8014out of 8732\n",
            "8014out of 8732\n",
            "shape:  (60, 87)\n",
            "8015out of 8732\n",
            "8015out of 8732\n",
            "shape:  (60, 87)\n",
            "8016out of 8732\n",
            "8016out of 8732\n",
            "shape:  (60, 87)\n",
            "8017out of 8732\n",
            "8017out of 8732\n",
            "shape:  (60, 87)\n",
            "8018out of 8732\n",
            "8018out of 8732\n",
            "shape:  (60, 87)\n",
            "8019out of 8732\n",
            "8019out of 8732\n",
            "shape:  (60, 87)\n",
            "8020out of 8732\n",
            "8020out of 8732\n",
            "shape:  (60, 87)\n",
            "8021out of 8732\n",
            "8021out of 8732\n",
            "shape:  (60, 87)\n",
            "8022out of 8732\n",
            "8022out of 8732\n",
            "shape:  (60, 87)\n",
            "8023out of 8732\n",
            "8023out of 8732\n",
            "shape:  (60, 87)\n",
            "8024out of 8732\n",
            "8024out of 8732\n",
            "shape:  (60, 87)\n",
            "8025out of 8732\n",
            "8025out of 8732\n",
            "shape:  (60, 87)\n",
            "8026out of 8732\n",
            "8026out of 8732\n",
            "shape:  (60, 87)\n",
            "8027out of 8732\n",
            "8027out of 8732\n",
            "shape:  (60, 87)\n",
            "8028out of 8732\n",
            "8028out of 8732\n",
            "shape:  (60, 87)\n",
            "8029out of 8732\n",
            "8029out of 8732\n",
            "shape:  (60, 87)\n",
            "8030out of 8732\n",
            "8030out of 8732\n",
            "shape:  (60, 87)\n",
            "8031out of 8732\n",
            "8031out of 8732\n",
            "shape:  (60, 87)\n",
            "8032out of 8732\n",
            "8032out of 8732\n",
            "shape:  (60, 87)\n",
            "8033out of 8732\n",
            "8033out of 8732\n",
            "shape:  (60, 87)\n",
            "8034out of 8732\n",
            "8034out of 8732\n",
            "shape:  (60, 87)\n",
            "8035out of 8732\n",
            "8035out of 8732\n",
            "shape:  (60, 87)\n",
            "8036out of 8732\n",
            "8036out of 8732\n",
            "shape:  (60, 87)\n",
            "8037out of 8732\n",
            "8037out of 8732\n",
            "shape:  (60, 87)\n",
            "8038out of 8732\n",
            "8038out of 8732\n",
            "shape:  (60, 87)\n",
            "8039out of 8732\n",
            "8039out of 8732\n",
            "shape:  (60, 87)\n",
            "8040out of 8732\n",
            "8040out of 8732\n",
            "shape:  (60, 87)\n",
            "8041out of 8732\n",
            "8041out of 8732\n",
            "shape:  (60, 87)\n",
            "8042out of 8732\n",
            "8042out of 8732\n",
            "shape:  (60, 87)\n",
            "8043out of 8732\n",
            "8043out of 8732\n",
            "shape:  (60, 87)\n",
            "8044out of 8732\n",
            "8044out of 8732\n",
            "shape:  (60, 87)\n",
            "8045out of 8732\n",
            "8045out of 8732\n",
            "shape:  (60, 87)\n",
            "8046out of 8732\n",
            "8046out of 8732\n",
            "shape:  (60, 87)\n",
            "8047out of 8732\n",
            "8047out of 8732\n",
            "shape:  (60, 87)\n",
            "8048out of 8732\n",
            "8048out of 8732\n",
            "shape:  (60, 87)\n",
            "8049out of 8732\n",
            "8049out of 8732\n",
            "shape:  (60, 87)\n",
            "8050out of 8732\n",
            "8050out of 8732\n",
            "shape:  (60, 87)\n",
            "8051out of 8732\n",
            "8051out of 8732\n",
            "shape:  (60, 87)\n",
            "8052out of 8732\n",
            "8052out of 8732\n",
            "shape:  (60, 87)\n",
            "8053out of 8732\n",
            "8053out of 8732\n",
            "shape:  (60, 87)\n",
            "8054out of 8732\n",
            "8054out of 8732\n",
            "shape:  (60, 87)\n",
            "8055out of 8732\n",
            "8055out of 8732\n",
            "shape:  (60, 87)\n",
            "8056out of 8732\n",
            "8056out of 8732\n",
            "shape:  (60, 87)\n",
            "8057out of 8732\n",
            "8057out of 8732\n",
            "shape:  (60, 87)\n",
            "8058out of 8732\n",
            "8058out of 8732\n",
            "shape:  (60, 87)\n",
            "8059out of 8732\n",
            "8059out of 8732\n",
            "shape:  (60, 87)\n",
            "8060out of 8732\n",
            "8060out of 8732\n",
            "shape:  (60, 87)\n",
            "8061out of 8732\n",
            "8061out of 8732\n",
            "shape:  (60, 87)\n",
            "8062out of 8732\n",
            "8062out of 8732\n",
            "shape:  (60, 87)\n",
            "8063out of 8732\n",
            "8063out of 8732\n",
            "shape:  (60, 87)\n",
            "8064out of 8732\n",
            "8064out of 8732\n",
            "shape:  (60, 87)\n",
            "8065out of 8732\n",
            "8065out of 8732\n",
            "shape:  (60, 87)\n",
            "8066out of 8732\n",
            "8066out of 8732\n",
            "shape:  (60, 87)\n",
            "8067out of 8732\n",
            "8067out of 8732\n",
            "shape:  (60, 87)\n",
            "8068out of 8732\n",
            "8068out of 8732\n",
            "shape:  (60, 87)\n",
            "8069out of 8732\n",
            "8069out of 8732\n",
            "shape:  (60, 87)\n",
            "8070out of 8732\n",
            "8070out of 8732\n",
            "shape:  (60, 87)\n",
            "8071out of 8732\n",
            "8071out of 8732\n",
            "shape:  (60, 87)\n",
            "8072out of 8732\n",
            "8072out of 8732\n",
            "shape:  (60, 87)\n",
            "8073out of 8732\n",
            "8073out of 8732\n",
            "shape:  (60, 87)\n",
            "8074out of 8732\n",
            "8074out of 8732\n",
            "shape:  (60, 87)\n",
            "8075out of 8732\n",
            "8075out of 8732\n",
            "shape:  (60, 87)\n",
            "8076out of 8732\n",
            "8076out of 8732\n",
            "shape:  (60, 87)\n",
            "8077out of 8732\n",
            "8077out of 8732\n",
            "shape:  (60, 87)\n",
            "8078out of 8732\n",
            "8078out of 8732\n",
            "shape:  (60, 87)\n",
            "8079out of 8732\n",
            "8079out of 8732\n",
            "shape:  (60, 87)\n",
            "8080out of 8732\n",
            "8080out of 8732\n",
            "shape:  (60, 87)\n",
            "8081out of 8732\n",
            "8081out of 8732\n",
            "shape:  (60, 87)\n",
            "8082out of 8732\n",
            "8082out of 8732\n",
            "shape:  (60, 87)\n",
            "8083out of 8732\n",
            "8083out of 8732\n",
            "shape:  (60, 87)\n",
            "8084out of 8732\n",
            "8084out of 8732\n",
            "shape:  (60, 87)\n",
            "8085out of 8732\n",
            "8085out of 8732\n",
            "shape:  (60, 87)\n",
            "8086out of 8732\n",
            "8086out of 8732\n",
            "shape:  (60, 87)\n",
            "8087out of 8732\n",
            "8087out of 8732\n",
            "shape:  (60, 87)\n",
            "8088out of 8732\n",
            "8088out of 8732\n",
            "shape:  (60, 87)\n",
            "8089out of 8732\n",
            "8089out of 8732\n",
            "shape:  (60, 87)\n",
            "8090out of 8732\n",
            "8090out of 8732\n",
            "shape:  (60, 87)\n",
            "8091out of 8732\n",
            "8091out of 8732\n",
            "shape:  (60, 87)\n",
            "8092out of 8732\n",
            "8092out of 8732\n",
            "shape:  (60, 87)\n",
            "8093out of 8732\n",
            "8093out of 8732\n",
            "shape:  (60, 87)\n",
            "8094out of 8732\n",
            "8094out of 8732\n",
            "shape:  (60, 87)\n",
            "8095out of 8732\n",
            "8095out of 8732\n",
            "shape:  (60, 87)\n",
            "8096out of 8732\n",
            "8096out of 8732\n",
            "shape:  (60, 87)\n",
            "8097out of 8732\n",
            "8097out of 8732\n",
            "shape:  (60, 87)\n",
            "8098out of 8732\n",
            "8098out of 8732\n",
            "shape:  (60, 87)\n",
            "8099out of 8732\n",
            "8099out of 8732\n",
            "shape:  (60, 87)\n",
            "8100out of 8732\n",
            "8100out of 8732\n",
            "shape:  (60, 87)\n",
            "8101out of 8732\n",
            "8101out of 8732\n",
            "shape:  (60, 87)\n",
            "8102out of 8732\n",
            "8102out of 8732\n",
            "shape:  (60, 87)\n",
            "8103out of 8732\n",
            "8103out of 8732\n",
            "shape:  (60, 87)\n",
            "8104out of 8732\n",
            "8104out of 8732\n",
            "shape:  (60, 87)\n",
            "8105out of 8732\n",
            "8105out of 8732\n",
            "shape:  (60, 87)\n",
            "8106out of 8732\n",
            "8106out of 8732\n",
            "shape:  (60, 87)\n",
            "8107out of 8732\n",
            "8107out of 8732\n",
            "shape:  (60, 87)\n",
            "8108out of 8732\n",
            "8108out of 8732\n",
            "shape:  (60, 87)\n",
            "8109out of 8732\n",
            "8109out of 8732\n",
            "shape:  (60, 87)\n",
            "8110out of 8732\n",
            "8110out of 8732\n",
            "shape:  (60, 87)\n",
            "8111out of 8732\n",
            "8111out of 8732\n",
            "shape:  (60, 87)\n",
            "8112out of 8732\n",
            "8112out of 8732\n",
            "shape:  (60, 87)\n",
            "8113out of 8732\n",
            "8113out of 8732\n",
            "shape:  (60, 87)\n",
            "8114out of 8732\n",
            "8114out of 8732\n",
            "shape:  (60, 87)\n",
            "8115out of 8732\n",
            "8115out of 8732\n",
            "shape:  (60, 87)\n",
            "8116out of 8732\n",
            "8116out of 8732\n",
            "shape:  (60, 87)\n",
            "8117out of 8732\n",
            "8117out of 8732\n",
            "shape:  (60, 87)\n",
            "8118out of 8732\n",
            "8118out of 8732\n",
            "shape:  (60, 87)\n",
            "8119out of 8732\n",
            "8119out of 8732\n",
            "shape:  (60, 87)\n",
            "8120out of 8732\n",
            "8120out of 8732\n",
            "shape:  (60, 87)\n",
            "8121out of 8732\n",
            "8121out of 8732\n",
            "shape:  (60, 87)\n",
            "8122out of 8732\n",
            "8122out of 8732\n",
            "shape:  (60, 87)\n",
            "8123out of 8732\n",
            "8123out of 8732\n",
            "shape:  (60, 87)\n",
            "8124out of 8732\n",
            "8124out of 8732\n",
            "shape:  (60, 87)\n",
            "8125out of 8732\n",
            "8125out of 8732\n",
            "shape:  (60, 87)\n",
            "8126out of 8732\n",
            "8126out of 8732\n",
            "shape:  (60, 87)\n",
            "8127out of 8732\n",
            "8127out of 8732\n",
            "shape:  (60, 87)\n",
            "8128out of 8732\n",
            "8128out of 8732\n",
            "shape:  (60, 87)\n",
            "8129out of 8732\n",
            "8129out of 8732\n",
            "shape:  (60, 87)\n",
            "8130out of 8732\n",
            "8130out of 8732\n",
            "shape:  (60, 87)\n",
            "8131out of 8732\n",
            "8131out of 8732\n",
            "shape:  (60, 87)\n",
            "8132out of 8732\n",
            "8132out of 8732\n",
            "shape:  (60, 87)\n",
            "8133out of 8732\n",
            "8133out of 8732\n",
            "shape:  (60, 87)\n",
            "8134out of 8732\n",
            "8134out of 8732\n",
            "shape:  (60, 87)\n",
            "8135out of 8732\n",
            "8135out of 8732\n",
            "shape:  (60, 87)\n",
            "8136out of 8732\n",
            "8136out of 8732\n",
            "shape:  (60, 87)\n",
            "8137out of 8732\n",
            "8137out of 8732\n",
            "shape:  (60, 87)\n",
            "8138out of 8732\n",
            "8138out of 8732\n",
            "shape:  (60, 87)\n",
            "8139out of 8732\n",
            "8139out of 8732\n",
            "shape:  (60, 87)\n",
            "8140out of 8732\n",
            "8140out of 8732\n",
            "shape:  (60, 87)\n",
            "8141out of 8732\n",
            "8141out of 8732\n",
            "shape:  (60, 87)\n",
            "8142out of 8732\n",
            "8142out of 8732\n",
            "shape:  (60, 87)\n",
            "8143out of 8732\n",
            "8143out of 8732\n",
            "shape:  (60, 87)\n",
            "8144out of 8732\n",
            "8144out of 8732\n",
            "shape:  (60, 87)\n",
            "8145out of 8732\n",
            "8145out of 8732\n",
            "shape:  (60, 87)\n",
            "8146out of 8732\n",
            "8146out of 8732\n",
            "shape:  (60, 87)\n",
            "8147out of 8732\n",
            "8147out of 8732\n",
            "shape:  (60, 87)\n",
            "8148out of 8732\n",
            "8148out of 8732\n",
            "shape:  (60, 87)\n",
            "8149out of 8732\n",
            "8149out of 8732\n",
            "shape:  (60, 87)\n",
            "8150out of 8732\n",
            "8150out of 8732\n",
            "shape:  (60, 87)\n",
            "8151out of 8732\n",
            "8151out of 8732\n",
            "shape:  (60, 87)\n",
            "8152out of 8732\n",
            "8152out of 8732\n",
            "shape:  (60, 87)\n",
            "8153out of 8732\n",
            "8153out of 8732\n",
            "shape:  (60, 87)\n",
            "8154out of 8732\n",
            "8154out of 8732\n",
            "shape:  (60, 87)\n",
            "8155out of 8732\n",
            "8155out of 8732\n",
            "shape:  (60, 87)\n",
            "8156out of 8732\n",
            "8156out of 8732\n",
            "shape:  (60, 87)\n",
            "8157out of 8732\n",
            "8157out of 8732\n",
            "shape:  (60, 87)\n",
            "8158out of 8732\n",
            "8158out of 8732\n",
            "shape:  (60, 87)\n",
            "8159out of 8732\n",
            "8159out of 8732\n",
            "shape:  (60, 87)\n",
            "8160out of 8732\n",
            "8160out of 8732\n",
            "shape:  (60, 87)\n",
            "8161out of 8732\n",
            "8161out of 8732\n",
            "shape:  (60, 87)\n",
            "8162out of 8732\n",
            "8162out of 8732\n",
            "shape:  (60, 87)\n",
            "8163out of 8732\n",
            "8163out of 8732\n",
            "shape:  (60, 87)\n",
            "8164out of 8732\n",
            "8164out of 8732\n",
            "shape:  (60, 87)\n",
            "8165out of 8732\n",
            "8165out of 8732\n",
            "shape:  (60, 87)\n",
            "8166out of 8732\n",
            "8166out of 8732\n",
            "shape:  (60, 87)\n",
            "8167out of 8732\n",
            "8167out of 8732\n",
            "shape:  (60, 87)\n",
            "8168out of 8732\n",
            "8168out of 8732\n",
            "shape:  (60, 87)\n",
            "8169out of 8732\n",
            "8169out of 8732\n",
            "shape:  (60, 87)\n",
            "8170out of 8732\n",
            "8170out of 8732\n",
            "shape:  (60, 87)\n",
            "8171out of 8732\n",
            "8171out of 8732\n",
            "shape:  (60, 87)\n",
            "8172out of 8732\n",
            "8172out of 8732\n",
            "shape:  (60, 87)\n",
            "8173out of 8732\n",
            "8173out of 8732\n",
            "shape:  (60, 87)\n",
            "8174out of 8732\n",
            "8174out of 8732\n",
            "shape:  (60, 87)\n",
            "8175out of 8732\n",
            "8175out of 8732\n",
            "shape:  (60, 87)\n",
            "8176out of 8732\n",
            "8176out of 8732\n",
            "shape:  (60, 87)\n",
            "8177out of 8732\n",
            "8177out of 8732\n",
            "shape:  (60, 87)\n",
            "8178out of 8732\n",
            "8178out of 8732\n",
            "shape:  (60, 87)\n",
            "8179out of 8732\n",
            "8179out of 8732\n",
            "shape:  (60, 87)\n",
            "8180out of 8732\n",
            "8180out of 8732\n",
            "shape:  (60, 87)\n",
            "8181out of 8732\n",
            "8181out of 8732\n",
            "shape:  (60, 87)\n",
            "8182out of 8732\n",
            "8182out of 8732\n",
            "shape:  (60, 87)\n",
            "8183out of 8732\n",
            "8183out of 8732\n",
            "shape:  (60, 87)\n",
            "8184out of 8732\n",
            "8184out of 8732\n",
            "shape:  (60, 87)\n",
            "8185out of 8732\n",
            "8185out of 8732\n",
            "shape:  (60, 87)\n",
            "8186out of 8732\n",
            "8186out of 8732\n",
            "shape:  (60, 87)\n",
            "8187out of 8732\n",
            "8187out of 8732\n",
            "shape:  (60, 87)\n",
            "8188out of 8732\n",
            "8188out of 8732\n",
            "shape:  (60, 87)\n",
            "8189out of 8732\n",
            "8189out of 8732\n",
            "shape:  (60, 87)\n",
            "8190out of 8732\n",
            "8190out of 8732\n",
            "shape:  (60, 87)\n",
            "8191out of 8732\n",
            "8191out of 8732\n",
            "shape:  (60, 87)\n",
            "8192out of 8732\n",
            "8192out of 8732\n",
            "shape:  (60, 87)\n",
            "8193out of 8732\n",
            "8193out of 8732\n",
            "shape:  (60, 87)\n",
            "8194out of 8732\n",
            "8194out of 8732\n",
            "shape:  (60, 87)\n",
            "8195out of 8732\n",
            "8195out of 8732\n",
            "shape:  (60, 87)\n",
            "8196out of 8732\n",
            "8196out of 8732\n",
            "shape:  (60, 87)\n",
            "8197out of 8732\n",
            "8197out of 8732\n",
            "shape:  (60, 87)\n",
            "8198out of 8732\n",
            "8198out of 8732\n",
            "shape:  (60, 87)\n",
            "8199out of 8732\n",
            "8199out of 8732\n",
            "shape:  (60, 87)\n",
            "8200out of 8732\n",
            "8200out of 8732\n",
            "shape:  (60, 87)\n",
            "8201out of 8732\n",
            "8201out of 8732\n",
            "shape:  (60, 87)\n",
            "8202out of 8732\n",
            "8202out of 8732\n",
            "shape:  (60, 87)\n",
            "8203out of 8732\n",
            "8203out of 8732\n",
            "shape:  (60, 87)\n",
            "8204out of 8732\n",
            "8204out of 8732\n",
            "shape:  (60, 87)\n",
            "8205out of 8732\n",
            "8205out of 8732\n",
            "shape:  (60, 87)\n",
            "8206out of 8732\n",
            "8206out of 8732\n",
            "shape:  (60, 87)\n",
            "8207out of 8732\n",
            "8207out of 8732\n",
            "shape:  (60, 87)\n",
            "8208out of 8732\n",
            "8208out of 8732\n",
            "shape:  (60, 87)\n",
            "8209out of 8732\n",
            "8209out of 8732\n",
            "shape:  (60, 87)\n",
            "8210out of 8732\n",
            "8210out of 8732\n",
            "shape:  (60, 87)\n",
            "8211out of 8732\n",
            "8211out of 8732\n",
            "shape:  (60, 87)\n",
            "8212out of 8732\n",
            "8212out of 8732\n",
            "shape:  (60, 87)\n",
            "8213out of 8732\n",
            "8213out of 8732\n",
            "shape:  (60, 87)\n",
            "8214out of 8732\n",
            "8214out of 8732\n",
            "shape:  (60, 87)\n",
            "8215out of 8732\n",
            "8215out of 8732\n",
            "shape:  (60, 87)\n",
            "8216out of 8732\n",
            "8216out of 8732\n",
            "shape:  (60, 87)\n",
            "8217out of 8732\n",
            "8217out of 8732\n",
            "shape:  (60, 87)\n",
            "8218out of 8732\n",
            "8218out of 8732\n",
            "shape:  (60, 87)\n",
            "8219out of 8732\n",
            "8219out of 8732\n",
            "shape:  (60, 87)\n",
            "8220out of 8732\n",
            "8220out of 8732\n",
            "shape:  (60, 87)\n",
            "8221out of 8732\n",
            "8221out of 8732\n",
            "shape:  (60, 87)\n",
            "8222out of 8732\n",
            "8222out of 8732\n",
            "shape:  (60, 87)\n",
            "8223out of 8732\n",
            "8223out of 8732\n",
            "shape:  (60, 87)\n",
            "8224out of 8732\n",
            "8224out of 8732\n",
            "shape:  (60, 87)\n",
            "8225out of 8732\n",
            "8225out of 8732\n",
            "shape:  (60, 87)\n",
            "8226out of 8732\n",
            "8226out of 8732\n",
            "shape:  (60, 87)\n",
            "8227out of 8732\n",
            "8227out of 8732\n",
            "shape:  (60, 87)\n",
            "8228out of 8732\n",
            "8228out of 8732\n",
            "shape:  (60, 87)\n",
            "8229out of 8732\n",
            "8229out of 8732\n",
            "shape:  (60, 87)\n",
            "8230out of 8732\n",
            "8230out of 8732\n",
            "shape:  (60, 87)\n",
            "8231out of 8732\n",
            "8231out of 8732\n",
            "shape:  (60, 87)\n",
            "8232out of 8732\n",
            "8232out of 8732\n",
            "shape:  (60, 87)\n",
            "8233out of 8732\n",
            "8233out of 8732\n",
            "shape:  (60, 87)\n",
            "8234out of 8732\n",
            "8234out of 8732\n",
            "shape:  (60, 87)\n",
            "8235out of 8732\n",
            "8235out of 8732\n",
            "shape:  (60, 87)\n",
            "8236out of 8732\n",
            "8236out of 8732\n",
            "shape:  (60, 87)\n",
            "8237out of 8732\n",
            "8237out of 8732\n",
            "shape:  (60, 87)\n",
            "8238out of 8732\n",
            "8238out of 8732\n",
            "shape:  (60, 87)\n",
            "8239out of 8732\n",
            "8239out of 8732\n",
            "shape:  (60, 87)\n",
            "8240out of 8732\n",
            "8240out of 8732\n",
            "shape:  (60, 87)\n",
            "8241out of 8732\n",
            "8241out of 8732\n",
            "shape:  (60, 87)\n",
            "8242out of 8732\n",
            "8242out of 8732\n",
            "shape:  (60, 87)\n",
            "8243out of 8732\n",
            "8243out of 8732\n",
            "shape:  (60, 87)\n",
            "8244out of 8732\n",
            "8244out of 8732\n",
            "shape:  (60, 87)\n",
            "8245out of 8732\n",
            "8245out of 8732\n",
            "shape:  (60, 87)\n",
            "8246out of 8732\n",
            "8246out of 8732\n",
            "shape:  (60, 87)\n",
            "8247out of 8732\n",
            "8247out of 8732\n",
            "shape:  (60, 87)\n",
            "8248out of 8732\n",
            "8248out of 8732\n",
            "shape:  (60, 87)\n",
            "8249out of 8732\n",
            "8249out of 8732\n",
            "shape:  (60, 87)\n",
            "8250out of 8732\n",
            "8250out of 8732\n",
            "shape:  (60, 87)\n",
            "8251out of 8732\n",
            "8251out of 8732\n",
            "shape:  (60, 87)\n",
            "8252out of 8732\n",
            "8252out of 8732\n",
            "shape:  (60, 87)\n",
            "8253out of 8732\n",
            "8253out of 8732\n",
            "shape:  (60, 87)\n",
            "8254out of 8732\n",
            "8254out of 8732\n",
            "shape:  (60, 87)\n",
            "8255out of 8732\n",
            "8255out of 8732\n",
            "shape:  (60, 87)\n",
            "8256out of 8732\n",
            "8256out of 8732\n",
            "shape:  (60, 87)\n",
            "8257out of 8732\n",
            "8257out of 8732\n",
            "shape:  (60, 87)\n",
            "8258out of 8732\n",
            "8258out of 8732\n",
            "shape:  (60, 87)\n",
            "8259out of 8732\n",
            "8259out of 8732\n",
            "shape:  (60, 87)\n",
            "8260out of 8732\n",
            "8260out of 8732\n",
            "shape:  (60, 87)\n",
            "8261out of 8732\n",
            "8261out of 8732\n",
            "shape:  (60, 87)\n",
            "8262out of 8732\n",
            "8262out of 8732\n",
            "shape:  (60, 87)\n",
            "8263out of 8732\n",
            "8263out of 8732\n",
            "shape:  (60, 87)\n",
            "8264out of 8732\n",
            "8264out of 8732\n",
            "shape:  (60, 87)\n",
            "8265out of 8732\n",
            "8265out of 8732\n",
            "shape:  (60, 87)\n",
            "8266out of 8732\n",
            "8266out of 8732\n",
            "shape:  (60, 87)\n",
            "8267out of 8732\n",
            "8267out of 8732\n",
            "shape:  (60, 87)\n",
            "8268out of 8732\n",
            "8268out of 8732\n",
            "shape:  (60, 87)\n",
            "8269out of 8732\n",
            "8269out of 8732\n",
            "shape:  (60, 87)\n",
            "8270out of 8732\n",
            "8270out of 8732\n",
            "shape:  (60, 87)\n",
            "8271out of 8732\n",
            "8271out of 8732\n",
            "shape:  (60, 87)\n",
            "8272out of 8732\n",
            "8272out of 8732\n",
            "shape:  (60, 87)\n",
            "8273out of 8732\n",
            "8273out of 8732\n",
            "shape:  (60, 87)\n",
            "8274out of 8732\n",
            "8274out of 8732\n",
            "shape:  (60, 87)\n",
            "8275out of 8732\n",
            "8275out of 8732\n",
            "shape:  (60, 87)\n",
            "8276out of 8732\n",
            "8276out of 8732\n",
            "shape:  (60, 87)\n",
            "8277out of 8732\n",
            "8277out of 8732\n",
            "shape:  (60, 87)\n",
            "8278out of 8732\n",
            "8278out of 8732\n",
            "shape:  (60, 87)\n",
            "8279out of 8732\n",
            "8279out of 8732\n",
            "shape:  (60, 87)\n",
            "8280out of 8732\n",
            "8280out of 8732\n",
            "shape:  (60, 87)\n",
            "8281out of 8732\n",
            "8281out of 8732\n",
            "shape:  (60, 87)\n",
            "8282out of 8732\n",
            "8282out of 8732\n",
            "shape:  (60, 87)\n",
            "8283out of 8732\n",
            "8283out of 8732\n",
            "shape:  (60, 87)\n",
            "8284out of 8732\n",
            "8284out of 8732\n",
            "shape:  (60, 87)\n",
            "8285out of 8732\n",
            "8285out of 8732\n",
            "shape:  (60, 87)\n",
            "8286out of 8732\n",
            "8286out of 8732\n",
            "shape:  (60, 87)\n",
            "8287out of 8732\n",
            "8287out of 8732\n",
            "shape:  (60, 87)\n",
            "8288out of 8732\n",
            "8288out of 8732\n",
            "shape:  (60, 87)\n",
            "8289out of 8732\n",
            "8289out of 8732\n",
            "shape:  (60, 87)\n",
            "8290out of 8732\n",
            "8290out of 8732\n",
            "shape:  (60, 87)\n",
            "8291out of 8732\n",
            "8291out of 8732\n",
            "shape:  (60, 87)\n",
            "8292out of 8732\n",
            "8292out of 8732\n",
            "shape:  (60, 87)\n",
            "8293out of 8732\n",
            "8293out of 8732\n",
            "shape:  (60, 87)\n",
            "8294out of 8732\n",
            "8294out of 8732\n",
            "shape:  (60, 87)\n",
            "8295out of 8732\n",
            "8295out of 8732\n",
            "shape:  (60, 87)\n",
            "8296out of 8732\n",
            "8296out of 8732\n",
            "shape:  (60, 87)\n",
            "8297out of 8732\n",
            "8297out of 8732\n",
            "shape:  (60, 87)\n",
            "8298out of 8732\n",
            "8298out of 8732\n",
            "shape:  (60, 87)\n",
            "8299out of 8732\n",
            "8299out of 8732\n",
            "shape:  (60, 87)\n",
            "8300out of 8732\n",
            "8300out of 8732\n",
            "shape:  (60, 87)\n",
            "8301out of 8732\n",
            "8301out of 8732\n",
            "shape:  (60, 87)\n",
            "8302out of 8732\n",
            "8302out of 8732\n",
            "shape:  (60, 87)\n",
            "8303out of 8732\n",
            "8303out of 8732\n",
            "shape:  (60, 87)\n",
            "8304out of 8732\n",
            "8304out of 8732\n",
            "shape:  (60, 87)\n",
            "8305out of 8732\n",
            "8305out of 8732\n",
            "shape:  (60, 87)\n",
            "8306out of 8732\n",
            "8306out of 8732\n",
            "shape:  (60, 87)\n",
            "8307out of 8732\n",
            "8307out of 8732\n",
            "shape:  (60, 87)\n",
            "8308out of 8732\n",
            "8308out of 8732\n",
            "shape:  (60, 87)\n",
            "8309out of 8732\n",
            "8309out of 8732\n",
            "shape:  (60, 87)\n",
            "8310out of 8732\n",
            "8310out of 8732\n",
            "shape:  (60, 87)\n",
            "8311out of 8732\n",
            "8311out of 8732\n",
            "shape:  (60, 87)\n",
            "8312out of 8732\n",
            "8312out of 8732\n",
            "shape:  (60, 87)\n",
            "8313out of 8732\n",
            "8313out of 8732\n",
            "shape:  (60, 87)\n",
            "8314out of 8732\n",
            "8314out of 8732\n",
            "shape:  (60, 87)\n",
            "8315out of 8732\n",
            "8315out of 8732\n",
            "shape:  (60, 87)\n",
            "8316out of 8732\n",
            "8316out of 8732\n",
            "shape:  (60, 87)\n",
            "8317out of 8732\n",
            "8317out of 8732\n",
            "shape:  (60, 87)\n",
            "8318out of 8732\n",
            "8318out of 8732\n",
            "shape:  (60, 87)\n",
            "8319out of 8732\n",
            "8319out of 8732\n",
            "shape:  (60, 87)\n",
            "8320out of 8732\n",
            "8320out of 8732\n",
            "shape:  (60, 87)\n",
            "8321out of 8732\n",
            "8321out of 8732\n",
            "shape:  (60, 87)\n",
            "8322out of 8732\n",
            "8322out of 8732\n",
            "shape:  (60, 87)\n",
            "8323out of 8732\n",
            "8323out of 8732\n",
            "shape:  (60, 87)\n",
            "8324out of 8732\n",
            "8324out of 8732\n",
            "shape:  (60, 87)\n",
            "8325out of 8732\n",
            "8325out of 8732\n",
            "shape:  (60, 87)\n",
            "8326out of 8732\n",
            "8326out of 8732\n",
            "shape:  (60, 87)\n",
            "8327out of 8732\n",
            "8327out of 8732\n",
            "shape:  (60, 87)\n",
            "8328out of 8732\n",
            "8328out of 8732\n",
            "shape:  (60, 87)\n",
            "8329out of 8732\n",
            "8329out of 8732\n",
            "shape:  (60, 87)\n",
            "8330out of 8732\n",
            "8330out of 8732\n",
            "shape:  (60, 87)\n",
            "8331out of 8732\n",
            "8331out of 8732\n",
            "shape:  (60, 87)\n",
            "8332out of 8732\n",
            "8332out of 8732\n",
            "shape:  (60, 87)\n",
            "8333out of 8732\n",
            "8333out of 8732\n",
            "shape:  (60, 87)\n",
            "8334out of 8732\n",
            "8334out of 8732\n",
            "shape:  (60, 87)\n",
            "8335out of 8732\n",
            "8335out of 8732\n",
            "shape:  (60, 87)\n",
            "8336out of 8732\n",
            "8336out of 8732\n",
            "shape:  (60, 87)\n",
            "8337out of 8732\n",
            "8337out of 8732\n",
            "shape:  (60, 87)\n",
            "8338out of 8732\n",
            "8338out of 8732\n",
            "shape:  (60, 87)\n",
            "8339out of 8732\n",
            "8339out of 8732\n",
            "shape:  (60, 87)\n",
            "8340out of 8732\n",
            "8340out of 8732\n",
            "shape:  (60, 87)\n",
            "8341out of 8732\n",
            "8341out of 8732\n",
            "shape:  (60, 87)\n",
            "8342out of 8732\n",
            "8342out of 8732\n",
            "shape:  (60, 87)\n",
            "8343out of 8732\n",
            "8343out of 8732\n",
            "shape:  (60, 87)\n",
            "8344out of 8732\n",
            "8344out of 8732\n",
            "shape:  (60, 87)\n",
            "8345out of 8732\n",
            "8345out of 8732\n",
            "shape:  (60, 87)\n",
            "8346out of 8732\n",
            "8346out of 8732\n",
            "shape:  (60, 87)\n",
            "8347out of 8732\n",
            "8347out of 8732\n",
            "shape:  (60, 87)\n",
            "8348out of 8732\n",
            "8348out of 8732\n",
            "shape:  (60, 87)\n",
            "8349out of 8732\n",
            "8349out of 8732\n",
            "shape:  (60, 87)\n",
            "8350out of 8732\n",
            "8350out of 8732\n",
            "shape:  (60, 87)\n",
            "8351out of 8732\n",
            "8351out of 8732\n",
            "shape:  (60, 87)\n",
            "8352out of 8732\n",
            "8352out of 8732\n",
            "shape:  (60, 87)\n",
            "8353out of 8732\n",
            "8353out of 8732\n",
            "shape:  (60, 87)\n",
            "8354out of 8732\n",
            "8354out of 8732\n",
            "shape:  (60, 87)\n",
            "8355out of 8732\n",
            "8355out of 8732\n",
            "shape:  (60, 87)\n",
            "8356out of 8732\n",
            "8356out of 8732\n",
            "shape:  (60, 87)\n",
            "8357out of 8732\n",
            "8357out of 8732\n",
            "shape:  (60, 87)\n",
            "8358out of 8732\n",
            "8358out of 8732\n",
            "shape:  (60, 87)\n",
            "8359out of 8732\n",
            "8359out of 8732\n",
            "shape:  (60, 87)\n",
            "8360out of 8732\n",
            "8360out of 8732\n",
            "shape:  (60, 87)\n",
            "8361out of 8732\n",
            "8361out of 8732\n",
            "shape:  (60, 87)\n",
            "8362out of 8732\n",
            "8362out of 8732\n",
            "shape:  (60, 87)\n",
            "8363out of 8732\n",
            "8363out of 8732\n",
            "shape:  (60, 87)\n",
            "8364out of 8732\n",
            "8364out of 8732\n",
            "shape:  (60, 87)\n",
            "8365out of 8732\n",
            "8365out of 8732\n",
            "shape:  (60, 87)\n",
            "8366out of 8732\n",
            "8366out of 8732\n",
            "shape:  (60, 87)\n",
            "8367out of 8732\n",
            "8367out of 8732\n",
            "shape:  (60, 87)\n",
            "8368out of 8732\n",
            "8368out of 8732\n",
            "shape:  (60, 87)\n",
            "8369out of 8732\n",
            "8369out of 8732\n",
            "shape:  (60, 87)\n",
            "8370out of 8732\n",
            "8370out of 8732\n",
            "shape:  (60, 87)\n",
            "8371out of 8732\n",
            "8371out of 8732\n",
            "shape:  (60, 87)\n",
            "8372out of 8732\n",
            "8372out of 8732\n",
            "shape:  (60, 87)\n",
            "8373out of 8732\n",
            "8373out of 8732\n",
            "shape:  (60, 87)\n",
            "8374out of 8732\n",
            "8374out of 8732\n",
            "shape:  (60, 87)\n",
            "8375out of 8732\n",
            "8375out of 8732\n",
            "shape:  (60, 87)\n",
            "8376out of 8732\n",
            "8376out of 8732\n",
            "shape:  (60, 87)\n",
            "8377out of 8732\n",
            "8377out of 8732\n",
            "shape:  (60, 87)\n",
            "8378out of 8732\n",
            "8378out of 8732\n",
            "shape:  (60, 87)\n",
            "8379out of 8732\n",
            "8379out of 8732\n",
            "shape:  (60, 87)\n",
            "8380out of 8732\n",
            "8380out of 8732\n",
            "shape:  (60, 87)\n",
            "8381out of 8732\n",
            "8381out of 8732\n",
            "shape:  (60, 87)\n",
            "8382out of 8732\n",
            "8382out of 8732\n",
            "shape:  (60, 87)\n",
            "8383out of 8732\n",
            "8383out of 8732\n",
            "shape:  (60, 87)\n",
            "8384out of 8732\n",
            "8384out of 8732\n",
            "shape:  (60, 87)\n",
            "8385out of 8732\n",
            "8385out of 8732\n",
            "shape:  (60, 87)\n",
            "8386out of 8732\n",
            "8386out of 8732\n",
            "shape:  (60, 87)\n",
            "8387out of 8732\n",
            "8387out of 8732\n",
            "shape:  (60, 87)\n",
            "8388out of 8732\n",
            "8388out of 8732\n",
            "shape:  (60, 87)\n",
            "8389out of 8732\n",
            "8389out of 8732\n",
            "shape:  (60, 87)\n",
            "8390out of 8732\n",
            "8390out of 8732\n",
            "shape:  (60, 87)\n",
            "8391out of 8732\n",
            "8391out of 8732\n",
            "shape:  (60, 87)\n",
            "8392out of 8732\n",
            "8392out of 8732\n",
            "shape:  (60, 87)\n",
            "8393out of 8732\n",
            "8393out of 8732\n",
            "shape:  (60, 87)\n",
            "8394out of 8732\n",
            "8394out of 8732\n",
            "shape:  (60, 87)\n",
            "8395out of 8732\n",
            "8395out of 8732\n",
            "shape:  (60, 87)\n",
            "8396out of 8732\n",
            "8396out of 8732\n",
            "shape:  (60, 87)\n",
            "8397out of 8732\n",
            "8397out of 8732\n",
            "shape:  (60, 87)\n",
            "8398out of 8732\n",
            "8398out of 8732\n",
            "shape:  (60, 87)\n",
            "8399out of 8732\n",
            "8399out of 8732\n",
            "shape:  (60, 87)\n",
            "8400out of 8732\n",
            "8400out of 8732\n",
            "shape:  (60, 87)\n",
            "8401out of 8732\n",
            "8401out of 8732\n",
            "shape:  (60, 87)\n",
            "8402out of 8732\n",
            "8402out of 8732\n",
            "shape:  (60, 87)\n",
            "8403out of 8732\n",
            "8403out of 8732\n",
            "shape:  (60, 87)\n",
            "8404out of 8732\n",
            "8404out of 8732\n",
            "shape:  (60, 87)\n",
            "8405out of 8732\n",
            "8405out of 8732\n",
            "shape:  (60, 87)\n",
            "8406out of 8732\n",
            "8406out of 8732\n",
            "shape:  (60, 87)\n",
            "8407out of 8732\n",
            "8407out of 8732\n",
            "shape:  (60, 87)\n",
            "8408out of 8732\n",
            "8408out of 8732\n",
            "shape:  (60, 87)\n",
            "8409out of 8732\n",
            "8409out of 8732\n",
            "shape:  (60, 87)\n",
            "8410out of 8732\n",
            "8410out of 8732\n",
            "shape:  (60, 87)\n",
            "8411out of 8732\n",
            "8411out of 8732\n",
            "shape:  (60, 87)\n",
            "8412out of 8732\n",
            "8412out of 8732\n",
            "shape:  (60, 87)\n",
            "8413out of 8732\n",
            "8413out of 8732\n",
            "shape:  (60, 87)\n",
            "8414out of 8732\n",
            "8414out of 8732\n",
            "shape:  (60, 87)\n",
            "8415out of 8732\n",
            "8415out of 8732\n",
            "shape:  (60, 87)\n",
            "8416out of 8732\n",
            "8416out of 8732\n",
            "shape:  (60, 87)\n",
            "8417out of 8732\n",
            "8417out of 8732\n",
            "shape:  (60, 87)\n",
            "8418out of 8732\n",
            "8418out of 8732\n",
            "shape:  (60, 87)\n",
            "8419out of 8732\n",
            "8419out of 8732\n",
            "shape:  (60, 87)\n",
            "8420out of 8732\n",
            "8420out of 8732\n",
            "shape:  (60, 87)\n",
            "8421out of 8732\n",
            "8421out of 8732\n",
            "shape:  (60, 87)\n",
            "8422out of 8732\n",
            "8422out of 8732\n",
            "shape:  (60, 87)\n",
            "8423out of 8732\n",
            "8423out of 8732\n",
            "shape:  (60, 87)\n",
            "8424out of 8732\n",
            "8424out of 8732\n",
            "shape:  (60, 87)\n",
            "8425out of 8732\n",
            "8425out of 8732\n",
            "shape:  (60, 87)\n",
            "8426out of 8732\n",
            "8426out of 8732\n",
            "shape:  (60, 87)\n",
            "8427out of 8732\n",
            "8427out of 8732\n",
            "shape:  (60, 87)\n",
            "8428out of 8732\n",
            "8428out of 8732\n",
            "shape:  (60, 87)\n",
            "8429out of 8732\n",
            "8429out of 8732\n",
            "shape:  (60, 87)\n",
            "8430out of 8732\n",
            "8430out of 8732\n",
            "shape:  (60, 87)\n",
            "8431out of 8732\n",
            "8431out of 8732\n",
            "shape:  (60, 87)\n",
            "8432out of 8732\n",
            "8432out of 8732\n",
            "shape:  (60, 87)\n",
            "8433out of 8732\n",
            "8433out of 8732\n",
            "shape:  (60, 87)\n",
            "8434out of 8732\n",
            "8434out of 8732\n",
            "shape:  (60, 87)\n",
            "8435out of 8732\n",
            "8435out of 8732\n",
            "shape:  (60, 87)\n",
            "8436out of 8732\n",
            "8436out of 8732\n",
            "shape:  (60, 87)\n",
            "8437out of 8732\n",
            "8437out of 8732\n",
            "shape:  (60, 87)\n",
            "8438out of 8732\n",
            "8438out of 8732\n",
            "shape:  (60, 87)\n",
            "8439out of 8732\n",
            "8439out of 8732\n",
            "shape:  (60, 87)\n",
            "8440out of 8732\n",
            "8440out of 8732\n",
            "shape:  (60, 87)\n",
            "8441out of 8732\n",
            "8441out of 8732\n",
            "shape:  (60, 87)\n",
            "8442out of 8732\n",
            "8442out of 8732\n",
            "shape:  (60, 87)\n",
            "8443out of 8732\n",
            "8443out of 8732\n",
            "shape:  (60, 87)\n",
            "8444out of 8732\n",
            "8444out of 8732\n",
            "shape:  (60, 87)\n",
            "8445out of 8732\n",
            "8445out of 8732\n",
            "shape:  (60, 87)\n",
            "8446out of 8732\n",
            "8446out of 8732\n",
            "shape:  (60, 87)\n",
            "8447out of 8732\n",
            "8447out of 8732\n",
            "shape:  (60, 87)\n",
            "8448out of 8732\n",
            "8448out of 8732\n",
            "shape:  (60, 87)\n",
            "8449out of 8732\n",
            "8449out of 8732\n",
            "shape:  (60, 87)\n",
            "8450out of 8732\n",
            "8450out of 8732\n",
            "shape:  (60, 87)\n",
            "8451out of 8732\n",
            "8451out of 8732\n",
            "shape:  (60, 87)\n",
            "8452out of 8732\n",
            "8452out of 8732\n",
            "shape:  (60, 87)\n",
            "8453out of 8732\n",
            "8453out of 8732\n",
            "shape:  (60, 87)\n",
            "8454out of 8732\n",
            "8454out of 8732\n",
            "shape:  (60, 87)\n",
            "8455out of 8732\n",
            "8455out of 8732\n",
            "shape:  (60, 87)\n",
            "8456out of 8732\n",
            "8456out of 8732\n",
            "shape:  (60, 87)\n",
            "8457out of 8732\n",
            "8457out of 8732\n",
            "shape:  (60, 87)\n",
            "8458out of 8732\n",
            "8458out of 8732\n",
            "shape:  (60, 87)\n",
            "8459out of 8732\n",
            "8459out of 8732\n",
            "shape:  (60, 87)\n",
            "8460out of 8732\n",
            "8460out of 8732\n",
            "shape:  (60, 87)\n",
            "8461out of 8732\n",
            "8461out of 8732\n",
            "shape:  (60, 87)\n",
            "8462out of 8732\n",
            "8462out of 8732\n",
            "shape:  (60, 87)\n",
            "8463out of 8732\n",
            "8463out of 8732\n",
            "shape:  (60, 87)\n",
            "8464out of 8732\n",
            "8464out of 8732\n",
            "shape:  (60, 87)\n",
            "8465out of 8732\n",
            "8465out of 8732\n",
            "shape:  (60, 87)\n",
            "8466out of 8732\n",
            "8466out of 8732\n",
            "shape:  (60, 87)\n",
            "8467out of 8732\n",
            "8467out of 8732\n",
            "shape:  (60, 87)\n",
            "8468out of 8732\n",
            "8468out of 8732\n",
            "shape:  (60, 87)\n",
            "8469out of 8732\n",
            "8469out of 8732\n",
            "shape:  (60, 87)\n",
            "8470out of 8732\n",
            "8470out of 8732\n",
            "shape:  (60, 87)\n",
            "8471out of 8732\n",
            "8471out of 8732\n",
            "shape:  (60, 87)\n",
            "8472out of 8732\n",
            "8472out of 8732\n",
            "shape:  (60, 87)\n",
            "8473out of 8732\n",
            "8473out of 8732\n",
            "shape:  (60, 87)\n",
            "8474out of 8732\n",
            "8474out of 8732\n",
            "shape:  (60, 87)\n",
            "8475out of 8732\n",
            "8475out of 8732\n",
            "shape:  (60, 87)\n",
            "8476out of 8732\n",
            "8476out of 8732\n",
            "shape:  (60, 87)\n",
            "8477out of 8732\n",
            "8477out of 8732\n",
            "shape:  (60, 87)\n",
            "8478out of 8732\n",
            "8478out of 8732\n",
            "shape:  (60, 87)\n",
            "8479out of 8732\n",
            "8479out of 8732\n",
            "shape:  (60, 87)\n",
            "8480out of 8732\n",
            "8480out of 8732\n",
            "shape:  (60, 87)\n",
            "8481out of 8732\n",
            "8481out of 8732\n",
            "shape:  (60, 87)\n",
            "8482out of 8732\n",
            "8482out of 8732\n",
            "shape:  (60, 87)\n",
            "8483out of 8732\n",
            "8483out of 8732\n",
            "shape:  (60, 87)\n",
            "8484out of 8732\n",
            "8484out of 8732\n",
            "shape:  (60, 87)\n",
            "8485out of 8732\n",
            "8485out of 8732\n",
            "shape:  (60, 87)\n",
            "8486out of 8732\n",
            "8486out of 8732\n",
            "shape:  (60, 87)\n",
            "8487out of 8732\n",
            "8487out of 8732\n",
            "shape:  (60, 87)\n",
            "8488out of 8732\n",
            "8488out of 8732\n",
            "shape:  (60, 87)\n",
            "8489out of 8732\n",
            "8489out of 8732\n",
            "shape:  (60, 87)\n",
            "8490out of 8732\n",
            "8490out of 8732\n",
            "shape:  (60, 87)\n",
            "8491out of 8732\n",
            "8491out of 8732\n",
            "shape:  (60, 87)\n",
            "8492out of 8732\n",
            "8492out of 8732\n",
            "shape:  (60, 87)\n",
            "8493out of 8732\n",
            "8493out of 8732\n",
            "shape:  (60, 87)\n",
            "8494out of 8732\n",
            "8494out of 8732\n",
            "shape:  (60, 87)\n",
            "8495out of 8732\n",
            "8495out of 8732\n",
            "shape:  (60, 87)\n",
            "8496out of 8732\n",
            "8496out of 8732\n",
            "shape:  (60, 87)\n",
            "8497out of 8732\n",
            "8497out of 8732\n",
            "shape:  (60, 87)\n",
            "8498out of 8732\n",
            "8498out of 8732\n",
            "shape:  (60, 87)\n",
            "8499out of 8732\n",
            "8499out of 8732\n",
            "shape:  (60, 87)\n",
            "8500out of 8732\n",
            "8500out of 8732\n",
            "shape:  (60, 87)\n",
            "8501out of 8732\n",
            "8501out of 8732\n",
            "shape:  (60, 87)\n",
            "8502out of 8732\n",
            "8502out of 8732\n",
            "shape:  (60, 87)\n",
            "8503out of 8732\n",
            "8503out of 8732\n",
            "shape:  (60, 87)\n",
            "8504out of 8732\n",
            "8504out of 8732\n",
            "shape:  (60, 87)\n",
            "8505out of 8732\n",
            "8505out of 8732\n",
            "shape:  (60, 87)\n",
            "8506out of 8732\n",
            "8506out of 8732\n",
            "shape:  (60, 87)\n",
            "8507out of 8732\n",
            "8507out of 8732\n",
            "shape:  (60, 87)\n",
            "8508out of 8732\n",
            "8508out of 8732\n",
            "shape:  (60, 87)\n",
            "8509out of 8732\n",
            "8509out of 8732\n",
            "shape:  (60, 87)\n",
            "8510out of 8732\n",
            "8510out of 8732\n",
            "shape:  (60, 87)\n",
            "8511out of 8732\n",
            "8511out of 8732\n",
            "shape:  (60, 87)\n",
            "8512out of 8732\n",
            "8512out of 8732\n",
            "shape:  (60, 87)\n",
            "8513out of 8732\n",
            "8513out of 8732\n",
            "shape:  (60, 87)\n",
            "8514out of 8732\n",
            "8514out of 8732\n",
            "shape:  (60, 87)\n",
            "8515out of 8732\n",
            "8515out of 8732\n",
            "shape:  (60, 87)\n",
            "8516out of 8732\n",
            "8516out of 8732\n",
            "shape:  (60, 87)\n",
            "8517out of 8732\n",
            "8517out of 8732\n",
            "shape:  (60, 87)\n",
            "8518out of 8732\n",
            "8518out of 8732\n",
            "shape:  (60, 87)\n",
            "8519out of 8732\n",
            "8519out of 8732\n",
            "shape:  (60, 87)\n",
            "8520out of 8732\n",
            "8520out of 8732\n",
            "shape:  (60, 87)\n",
            "8521out of 8732\n",
            "8521out of 8732\n",
            "shape:  (60, 87)\n",
            "8522out of 8732\n",
            "8522out of 8732\n",
            "shape:  (60, 87)\n",
            "8523out of 8732\n",
            "8523out of 8732\n",
            "shape:  (60, 87)\n",
            "8524out of 8732\n",
            "8524out of 8732\n",
            "shape:  (60, 87)\n",
            "8525out of 8732\n",
            "8525out of 8732\n",
            "shape:  (60, 87)\n",
            "8526out of 8732\n",
            "8526out of 8732\n",
            "shape:  (60, 87)\n",
            "8527out of 8732\n",
            "8527out of 8732\n",
            "shape:  (60, 87)\n",
            "8528out of 8732\n",
            "8528out of 8732\n",
            "shape:  (60, 87)\n",
            "8529out of 8732\n",
            "8529out of 8732\n",
            "shape:  (60, 87)\n",
            "8530out of 8732\n",
            "8530out of 8732\n",
            "shape:  (60, 87)\n",
            "8531out of 8732\n",
            "8531out of 8732\n",
            "shape:  (60, 87)\n",
            "8532out of 8732\n",
            "8532out of 8732\n",
            "shape:  (60, 87)\n",
            "8533out of 8732\n",
            "8533out of 8732\n",
            "shape:  (60, 87)\n",
            "8534out of 8732\n",
            "8534out of 8732\n",
            "shape:  (60, 87)\n",
            "8535out of 8732\n",
            "8535out of 8732\n",
            "shape:  (60, 87)\n",
            "8536out of 8732\n",
            "8536out of 8732\n",
            "shape:  (60, 87)\n",
            "8537out of 8732\n",
            "8537out of 8732\n",
            "shape:  (60, 87)\n",
            "8538out of 8732\n",
            "8538out of 8732\n",
            "shape:  (60, 87)\n",
            "8539out of 8732\n",
            "8539out of 8732\n",
            "shape:  (60, 87)\n",
            "8540out of 8732\n",
            "8540out of 8732\n",
            "shape:  (60, 87)\n",
            "8541out of 8732\n",
            "8541out of 8732\n",
            "shape:  (60, 87)\n",
            "8542out of 8732\n",
            "8542out of 8732\n",
            "shape:  (60, 87)\n",
            "8543out of 8732\n",
            "8543out of 8732\n",
            "shape:  (60, 87)\n",
            "8544out of 8732\n",
            "8544out of 8732\n",
            "shape:  (60, 87)\n",
            "8545out of 8732\n",
            "8545out of 8732\n",
            "shape:  (60, 87)\n",
            "8546out of 8732\n",
            "8546out of 8732\n",
            "shape:  (60, 87)\n",
            "8547out of 8732\n",
            "8547out of 8732\n",
            "shape:  (60, 87)\n",
            "8548out of 8732\n",
            "8548out of 8732\n",
            "shape:  (60, 87)\n",
            "8549out of 8732\n",
            "8549out of 8732\n",
            "shape:  (60, 87)\n",
            "8550out of 8732\n",
            "8550out of 8732\n",
            "shape:  (60, 87)\n",
            "8551out of 8732\n",
            "8551out of 8732\n",
            "shape:  (60, 87)\n",
            "8552out of 8732\n",
            "8552out of 8732\n",
            "shape:  (60, 87)\n",
            "8553out of 8732\n",
            "8553out of 8732\n",
            "shape:  (60, 87)\n",
            "8554out of 8732\n",
            "8554out of 8732\n",
            "shape:  (60, 87)\n",
            "8555out of 8732\n",
            "8555out of 8732\n",
            "shape:  (60, 87)\n",
            "8556out of 8732\n",
            "8556out of 8732\n",
            "shape:  (60, 87)\n",
            "8557out of 8732\n",
            "8557out of 8732\n",
            "shape:  (60, 87)\n",
            "8558out of 8732\n",
            "8558out of 8732\n",
            "shape:  (60, 87)\n",
            "8559out of 8732\n",
            "8559out of 8732\n",
            "shape:  (60, 87)\n",
            "8560out of 8732\n",
            "8560out of 8732\n",
            "shape:  (60, 87)\n",
            "8561out of 8732\n",
            "8561out of 8732\n",
            "shape:  (60, 87)\n",
            "8562out of 8732\n",
            "8562out of 8732\n",
            "shape:  (60, 87)\n",
            "8563out of 8732\n",
            "8563out of 8732\n",
            "shape:  (60, 87)\n",
            "8564out of 8732\n",
            "8564out of 8732\n",
            "shape:  (60, 87)\n",
            "8565out of 8732\n",
            "8565out of 8732\n",
            "shape:  (60, 87)\n",
            "8566out of 8732\n",
            "8566out of 8732\n",
            "shape:  (60, 87)\n",
            "8567out of 8732\n",
            "8567out of 8732\n",
            "shape:  (60, 87)\n",
            "8568out of 8732\n",
            "8568out of 8732\n",
            "shape:  (60, 87)\n",
            "8569out of 8732\n",
            "8569out of 8732\n",
            "shape:  (60, 87)\n",
            "8570out of 8732\n",
            "8570out of 8732\n",
            "shape:  (60, 87)\n",
            "8571out of 8732\n",
            "8571out of 8732\n",
            "shape:  (60, 87)\n",
            "8572out of 8732\n",
            "8572out of 8732\n",
            "shape:  (60, 87)\n",
            "8573out of 8732\n",
            "8573out of 8732\n",
            "shape:  (60, 87)\n",
            "8574out of 8732\n",
            "8574out of 8732\n",
            "shape:  (60, 87)\n",
            "8575out of 8732\n",
            "8575out of 8732\n",
            "shape:  (60, 87)\n",
            "8576out of 8732\n",
            "8576out of 8732\n",
            "shape:  (60, 87)\n",
            "8577out of 8732\n",
            "8577out of 8732\n",
            "shape:  (60, 87)\n",
            "8578out of 8732\n",
            "8578out of 8732\n",
            "shape:  (60, 87)\n",
            "8579out of 8732\n",
            "8579out of 8732\n",
            "shape:  (60, 87)\n",
            "8580out of 8732\n",
            "8580out of 8732\n",
            "shape:  (60, 87)\n",
            "8581out of 8732\n",
            "8581out of 8732\n",
            "shape:  (60, 87)\n",
            "8582out of 8732\n",
            "8582out of 8732\n",
            "shape:  (60, 87)\n",
            "8583out of 8732\n",
            "8583out of 8732\n",
            "shape:  (60, 87)\n",
            "8584out of 8732\n",
            "8584out of 8732\n",
            "shape:  (60, 87)\n",
            "8585out of 8732\n",
            "8585out of 8732\n",
            "shape:  (60, 87)\n",
            "8586out of 8732\n",
            "8586out of 8732\n",
            "shape:  (60, 87)\n",
            "8587out of 8732\n",
            "8587out of 8732\n",
            "shape:  (60, 87)\n",
            "8588out of 8732\n",
            "8588out of 8732\n",
            "shape:  (60, 87)\n",
            "8589out of 8732\n",
            "8589out of 8732\n",
            "shape:  (60, 87)\n",
            "8590out of 8732\n",
            "8590out of 8732\n",
            "shape:  (60, 87)\n",
            "8591out of 8732\n",
            "8591out of 8732\n",
            "shape:  (60, 87)\n",
            "8592out of 8732\n",
            "8592out of 8732\n",
            "shape:  (60, 87)\n",
            "8593out of 8732\n",
            "8593out of 8732\n",
            "shape:  (60, 87)\n",
            "8594out of 8732\n",
            "8594out of 8732\n",
            "shape:  (60, 87)\n",
            "8595out of 8732\n",
            "8595out of 8732\n",
            "shape:  (60, 87)\n",
            "8596out of 8732\n",
            "8596out of 8732\n",
            "shape:  (60, 87)\n",
            "8597out of 8732\n",
            "8597out of 8732\n",
            "shape:  (60, 87)\n",
            "8598out of 8732\n",
            "8598out of 8732\n",
            "shape:  (60, 87)\n",
            "8599out of 8732\n",
            "8599out of 8732\n",
            "shape:  (60, 87)\n",
            "8600out of 8732\n",
            "8600out of 8732\n",
            "shape:  (60, 87)\n",
            "8601out of 8732\n",
            "8601out of 8732\n",
            "shape:  (60, 87)\n",
            "8602out of 8732\n",
            "8602out of 8732\n",
            "shape:  (60, 87)\n",
            "8603out of 8732\n",
            "8603out of 8732\n",
            "shape:  (60, 87)\n",
            "8604out of 8732\n",
            "8604out of 8732\n",
            "shape:  (60, 87)\n",
            "8605out of 8732\n",
            "8605out of 8732\n",
            "shape:  (60, 87)\n",
            "8606out of 8732\n",
            "8606out of 8732\n",
            "shape:  (60, 87)\n",
            "8607out of 8732\n",
            "8607out of 8732\n",
            "shape:  (60, 87)\n",
            "8608out of 8732\n",
            "8608out of 8732\n",
            "shape:  (60, 87)\n",
            "8609out of 8732\n",
            "8609out of 8732\n",
            "shape:  (60, 87)\n",
            "8610out of 8732\n",
            "8610out of 8732\n",
            "shape:  (60, 87)\n",
            "8611out of 8732\n",
            "8611out of 8732\n",
            "shape:  (60, 87)\n",
            "8612out of 8732\n",
            "8612out of 8732\n",
            "shape:  (60, 87)\n",
            "8613out of 8732\n",
            "8613out of 8732\n",
            "shape:  (60, 87)\n",
            "8614out of 8732\n",
            "8614out of 8732\n",
            "shape:  (60, 87)\n",
            "8615out of 8732\n",
            "8615out of 8732\n",
            "shape:  (60, 87)\n",
            "8616out of 8732\n",
            "8616out of 8732\n",
            "shape:  (60, 87)\n",
            "8617out of 8732\n",
            "8617out of 8732\n",
            "shape:  (60, 87)\n",
            "8618out of 8732\n",
            "8618out of 8732\n",
            "shape:  (60, 87)\n",
            "8619out of 8732\n",
            "8619out of 8732\n",
            "shape:  (60, 87)\n",
            "8620out of 8732\n",
            "8620out of 8732\n",
            "shape:  (60, 87)\n",
            "8621out of 8732\n",
            "8621out of 8732\n",
            "shape:  (60, 87)\n",
            "8622out of 8732\n",
            "8622out of 8732\n",
            "shape:  (60, 87)\n",
            "8623out of 8732\n",
            "8623out of 8732\n",
            "shape:  (60, 87)\n",
            "8624out of 8732\n",
            "8624out of 8732\n",
            "shape:  (60, 87)\n",
            "8625out of 8732\n",
            "8625out of 8732\n",
            "shape:  (60, 87)\n",
            "8626out of 8732\n",
            "8626out of 8732\n",
            "shape:  (60, 87)\n",
            "8627out of 8732\n",
            "8627out of 8732\n",
            "shape:  (60, 87)\n",
            "8628out of 8732\n",
            "8628out of 8732\n",
            "shape:  (60, 87)\n",
            "8629out of 8732\n",
            "8629out of 8732\n",
            "shape:  (60, 87)\n",
            "8630out of 8732\n",
            "8630out of 8732\n",
            "shape:  (60, 87)\n",
            "8631out of 8732\n",
            "8631out of 8732\n",
            "shape:  (60, 87)\n",
            "8632out of 8732\n",
            "8632out of 8732\n",
            "shape:  (60, 87)\n",
            "8633out of 8732\n",
            "8633out of 8732\n",
            "shape:  (60, 87)\n",
            "8634out of 8732\n",
            "8634out of 8732\n",
            "shape:  (60, 87)\n",
            "8635out of 8732\n",
            "8635out of 8732\n",
            "shape:  (60, 87)\n",
            "8636out of 8732\n",
            "8636out of 8732\n",
            "shape:  (60, 87)\n",
            "8637out of 8732\n",
            "8637out of 8732\n",
            "shape:  (60, 87)\n",
            "8638out of 8732\n",
            "8638out of 8732\n",
            "shape:  (60, 87)\n",
            "8639out of 8732\n",
            "8639out of 8732\n",
            "shape:  (60, 87)\n",
            "8640out of 8732\n",
            "8640out of 8732\n",
            "shape:  (60, 87)\n",
            "8641out of 8732\n",
            "8641out of 8732\n",
            "shape:  (60, 87)\n",
            "8642out of 8732\n",
            "8642out of 8732\n",
            "shape:  (60, 87)\n",
            "8643out of 8732\n",
            "8643out of 8732\n",
            "shape:  (60, 87)\n",
            "8644out of 8732\n",
            "8644out of 8732\n",
            "shape:  (60, 87)\n",
            "8645out of 8732\n",
            "8645out of 8732\n",
            "shape:  (60, 87)\n",
            "8646out of 8732\n",
            "8646out of 8732\n",
            "shape:  (60, 87)\n",
            "8647out of 8732\n",
            "8647out of 8732\n",
            "shape:  (60, 87)\n",
            "8648out of 8732\n",
            "8648out of 8732\n",
            "shape:  (60, 87)\n",
            "8649out of 8732\n",
            "8649out of 8732\n",
            "shape:  (60, 87)\n",
            "8650out of 8732\n",
            "8650out of 8732\n",
            "shape:  (60, 87)\n",
            "8651out of 8732\n",
            "8651out of 8732\n",
            "shape:  (60, 87)\n",
            "8652out of 8732\n",
            "8652out of 8732\n",
            "shape:  (60, 87)\n",
            "8653out of 8732\n",
            "8653out of 8732\n",
            "shape:  (60, 87)\n",
            "8654out of 8732\n",
            "8654out of 8732\n",
            "shape:  (60, 87)\n",
            "8655out of 8732\n",
            "8655out of 8732\n",
            "shape:  (60, 87)\n",
            "8656out of 8732\n",
            "8656out of 8732\n",
            "shape:  (60, 87)\n",
            "8657out of 8732\n",
            "8657out of 8732\n",
            "shape:  (60, 87)\n",
            "8658out of 8732\n",
            "8658out of 8732\n",
            "shape:  (60, 87)\n",
            "8659out of 8732\n",
            "8659out of 8732\n",
            "shape:  (60, 87)\n",
            "8660out of 8732\n",
            "8660out of 8732\n",
            "shape:  (60, 87)\n",
            "8661out of 8732\n",
            "8661out of 8732\n",
            "shape:  (60, 87)\n",
            "8662out of 8732\n",
            "8662out of 8732\n",
            "shape:  (60, 87)\n",
            "8663out of 8732\n",
            "8663out of 8732\n",
            "shape:  (60, 87)\n",
            "8664out of 8732\n",
            "8664out of 8732\n",
            "shape:  (60, 87)\n",
            "8665out of 8732\n",
            "8665out of 8732\n",
            "shape:  (60, 87)\n",
            "8666out of 8732\n",
            "8666out of 8732\n",
            "shape:  (60, 87)\n",
            "8667out of 8732\n",
            "8667out of 8732\n",
            "shape:  (60, 87)\n",
            "8668out of 8732\n",
            "8668out of 8732\n",
            "shape:  (60, 87)\n",
            "8669out of 8732\n",
            "8669out of 8732\n",
            "shape:  (60, 87)\n",
            "8670out of 8732\n",
            "8670out of 8732\n",
            "shape:  (60, 87)\n",
            "8671out of 8732\n",
            "8671out of 8732\n",
            "shape:  (60, 87)\n",
            "8672out of 8732\n",
            "8672out of 8732\n",
            "shape:  (60, 87)\n",
            "8673out of 8732\n",
            "8673out of 8732\n",
            "shape:  (60, 87)\n",
            "8674out of 8732\n",
            "8674out of 8732\n",
            "shape:  (60, 87)\n",
            "8675out of 8732\n",
            "8675out of 8732\n",
            "shape:  (60, 87)\n",
            "8676out of 8732\n",
            "8676out of 8732\n",
            "shape:  (60, 87)\n",
            "8677out of 8732\n",
            "8677out of 8732\n",
            "shape:  (60, 87)\n",
            "8678out of 8732\n",
            "8678out of 8732\n",
            "shape:  (60, 87)\n",
            "8679out of 8732\n",
            "8679out of 8732\n",
            "shape:  (60, 87)\n",
            "8680out of 8732\n",
            "8680out of 8732\n",
            "shape:  (60, 87)\n",
            "8681out of 8732\n",
            "8681out of 8732\n",
            "shape:  (60, 87)\n",
            "8682out of 8732\n",
            "8682out of 8732\n",
            "shape:  (60, 87)\n",
            "8683out of 8732\n",
            "8683out of 8732\n",
            "shape:  (60, 87)\n",
            "8684out of 8732\n",
            "8684out of 8732\n",
            "shape:  (60, 87)\n",
            "8685out of 8732\n",
            "8685out of 8732\n",
            "shape:  (60, 87)\n",
            "8686out of 8732\n",
            "8686out of 8732\n",
            "shape:  (60, 87)\n",
            "8687out of 8732\n",
            "8687out of 8732\n",
            "shape:  (60, 87)\n",
            "8688out of 8732\n",
            "8688out of 8732\n",
            "shape:  (60, 87)\n",
            "8689out of 8732\n",
            "8689out of 8732\n",
            "shape:  (60, 87)\n",
            "8690out of 8732\n",
            "8690out of 8732\n",
            "shape:  (60, 87)\n",
            "8691out of 8732\n",
            "8691out of 8732\n",
            "shape:  (60, 87)\n",
            "8692out of 8732\n",
            "8692out of 8732\n",
            "shape:  (60, 87)\n",
            "8693out of 8732\n",
            "8693out of 8732\n",
            "shape:  (60, 87)\n",
            "8694out of 8732\n",
            "8694out of 8732\n",
            "shape:  (60, 87)\n",
            "8695out of 8732\n",
            "8695out of 8732\n",
            "shape:  (60, 87)\n",
            "8696out of 8732\n",
            "8696out of 8732\n",
            "shape:  (60, 87)\n",
            "8697out of 8732\n",
            "8697out of 8732\n",
            "shape:  (60, 87)\n",
            "8698out of 8732\n",
            "8698out of 8732\n",
            "shape:  (60, 87)\n",
            "8699out of 8732\n",
            "8699out of 8732\n",
            "shape:  (60, 87)\n",
            "8700out of 8732\n",
            "8700out of 8732\n",
            "shape:  (60, 87)\n",
            "8701out of 8732\n",
            "8701out of 8732\n",
            "shape:  (60, 87)\n",
            "8702out of 8732\n",
            "8702out of 8732\n",
            "shape:  (60, 87)\n",
            "8703out of 8732\n",
            "8703out of 8732\n",
            "shape:  (60, 87)\n",
            "8704out of 8732\n",
            "8704out of 8732\n",
            "shape:  (60, 87)\n",
            "8705out of 8732\n",
            "8705out of 8732\n",
            "shape:  (60, 87)\n",
            "8706out of 8732\n",
            "8706out of 8732\n",
            "shape:  (60, 87)\n",
            "8707out of 8732\n",
            "8707out of 8732\n",
            "shape:  (60, 87)\n",
            "8708out of 8732\n",
            "8708out of 8732\n",
            "shape:  (60, 87)\n",
            "8709out of 8732\n",
            "8709out of 8732\n",
            "shape:  (60, 87)\n",
            "8710out of 8732\n",
            "8710out of 8732\n",
            "shape:  (60, 87)\n",
            "8711out of 8732\n",
            "8711out of 8732\n",
            "shape:  (60, 87)\n",
            "8712out of 8732\n",
            "8712out of 8732\n",
            "shape:  (60, 87)\n",
            "8713out of 8732\n",
            "8713out of 8732\n",
            "shape:  (60, 87)\n",
            "8714out of 8732\n",
            "8714out of 8732\n",
            "shape:  (60, 87)\n",
            "8715out of 8732\n",
            "8715out of 8732\n",
            "shape:  (60, 87)\n",
            "8716out of 8732\n",
            "8716out of 8732\n",
            "shape:  (60, 87)\n",
            "8717out of 8732\n",
            "8717out of 8732\n",
            "shape:  (60, 87)\n",
            "8718out of 8732\n",
            "8718out of 8732\n",
            "shape:  (60, 87)\n",
            "8719out of 8732\n",
            "8719out of 8732\n",
            "shape:  (60, 87)\n",
            "8720out of 8732\n",
            "8720out of 8732\n",
            "shape:  (60, 87)\n",
            "8721out of 8732\n",
            "8721out of 8732\n",
            "shape:  (60, 87)\n",
            "8722out of 8732\n",
            "8722out of 8732\n",
            "shape:  (60, 87)\n",
            "8723out of 8732\n",
            "8723out of 8732\n",
            "shape:  (60, 87)\n",
            "8724out of 8732\n",
            "8724out of 8732\n",
            "shape:  (60, 87)\n",
            "8725out of 8732\n",
            "8725out of 8732\n",
            "shape:  (60, 87)\n",
            "8726out of 8732\n",
            "8726out of 8732\n",
            "shape:  (60, 87)\n",
            "8727out of 8732\n",
            "8727out of 8732\n",
            "shape:  (60, 87)\n",
            "8728out of 8732\n",
            "8728out of 8732\n",
            "shape:  (60, 87)\n",
            "8729out of 8732\n",
            "8729out of 8732\n",
            "shape:  (60, 87)\n",
            "8730out of 8732\n",
            "8730out of 8732\n",
            "shape:  (60, 87)\n",
            "8731out of 8732\n",
            "8731out of 8732\n",
            "shape:  (60, 87)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# X,Y=zip(*D)\n",
        "# x_train, x_test, y_train, y_test = train_test_split(X, Y,test_size = 0.2, random_state = 114514)\n"
      ],
      "metadata": {
        "id": "_dfncTfQd-UU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print(len(X))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0cmia9NzrlZR",
        "outputId": "67f6202d-e618-4006-a0e7-c0afef521f65"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8724\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# def Interp(x, shape):\n",
        "#   new_height, new_width = shape\n",
        "#   resized = tf.image.resize(x, [new_height, new_width,1])\n",
        "#   return resized\n"
      ],
      "metadata": {
        "id": "84qzZackTzCT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import tensorflow as tf\n",
        "\n",
        "# X_train = np.array([x.reshape((60, 87, 1)) for x in x_train])\n",
        "# X_test = np.array([x.reshape((60, 87, 1)) for x in x_test])\n",
        "\n",
        "# Y_train = np.array(tf.keras.utils.to_categorical(y_train, 10))\n",
        "# Y_test = np.array(tf.keras.utils.to_categorical(y_test, 10))\n",
        "\n"
      ],
      "metadata": {
        "id": "Ji5f61mMzGlG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# X_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size=0.2, random_state=114514)\n"
      ],
      "metadata": {
        "id": "45ZbMj8cd-aX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print(X_train[1145])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uU7xLFRSzLOk",
        "outputId": "b7ba1d85-b9f2-47a1-d76f-cad214406746"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[[1.0455314e-03]\n",
            "  [5.1709678e-04]\n",
            "  [2.5263586e-04]\n",
            "  ...\n",
            "  [3.9997429e-04]\n",
            "  [3.0722126e-04]\n",
            "  [4.2975880e-04]]\n",
            "\n",
            " [[7.7875389e-04]\n",
            "  [4.2112573e-04]\n",
            "  [4.0374883e-04]\n",
            "  ...\n",
            "  [4.8511961e-04]\n",
            "  [4.6588332e-04]\n",
            "  [6.7806157e-04]]\n",
            "\n",
            " [[2.0950861e-04]\n",
            "  [4.2175088e-04]\n",
            "  [3.9619423e-04]\n",
            "  ...\n",
            "  [3.7220604e-04]\n",
            "  [6.7442143e-04]\n",
            "  [7.1041432e-04]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[5.4765726e-04]\n",
            "  [8.1522152e-04]\n",
            "  [4.6818389e-04]\n",
            "  ...\n",
            "  [6.1661046e-04]\n",
            "  [4.8344114e-04]\n",
            "  [4.4885612e-04]]\n",
            "\n",
            " [[7.6826524e-05]\n",
            "  [6.9950140e-05]\n",
            "  [5.9073627e-05]\n",
            "  ...\n",
            "  [5.8440040e-05]\n",
            "  [7.2749463e-05]\n",
            "  [9.7659518e-05]]\n",
            "\n",
            " [[1.3309325e-05]\n",
            "  [1.0258907e-06]\n",
            "  [7.6925448e-07]\n",
            "  ...\n",
            "  [1.2543660e-06]\n",
            "  [1.5422303e-06]\n",
            "  [4.2171991e-06]]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# def save_npy(nparr,folder,featureName,subDataset):\n",
        "#     import os\n",
        "#     dirs = root+folder+\"/data/datasetnpy\"+'/'+featureName\n",
        "    \n",
        "#     #Create a directory to place the dataset npy files.\n",
        "#     if not os.path.exists(dirs):\n",
        "#         os.makedirs(dirs)\n",
        "#         print(f\"Created directory:{dirs}\")\n",
        "    \n",
        "#     subDataset+='.npy'\n",
        "#     print(subDataset)\n",
        "#     subsetPth=os.path.join(dirs,subDataset)\n",
        "#     #with open(subsetPth, 'w') as f:\n",
        "#     np.save(subsetPth, nparr)\n",
        "#     print(f\"save {subDataset} done\")\n",
        "#     print(f\"Path:{subsetPth}\")"
      ],
      "metadata": {
        "id": "uvgwlHz9d-cx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# folderName=\"PiczakCNN\"\n",
        "\n",
        "# save_npy(X_train, folderName, 'melspectro_short','x_train')\n",
        "# save_npy(X_test, folderName, 'melspectro_short','x_test')\n",
        "# save_npy(Y_train, folderName, 'melspectro_short','y_train')\n",
        "# save_npy(Y_test, folderName, 'melspectro_short', 'y_test')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fN-FUPaPd-fN",
        "outputId": "3d4b9e9b-3731-4069-80dc-3720771b2366"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x_train.npy\n",
            "save x_train.npy done\n",
            "Path:/content/drive/MyDrive/Thesis_Keras/PiczakCNN/data/datasetnpy/melspectro_short/x_train.npy\n",
            "x_test.npy\n",
            "save x_test.npy done\n",
            "Path:/content/drive/MyDrive/Thesis_Keras/PiczakCNN/data/datasetnpy/melspectro_short/x_test.npy\n",
            "y_train.npy\n",
            "save y_train.npy done\n",
            "Path:/content/drive/MyDrive/Thesis_Keras/PiczakCNN/data/datasetnpy/melspectro_short/y_train.npy\n",
            "y_test.npy\n",
            "save y_test.npy done\n",
            "Path:/content/drive/MyDrive/Thesis_Keras/PiczakCNN/data/datasetnpy/melspectro_short/y_test.npy\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "如果已经完成特征提取"
      ],
      "metadata": {
        "id": "uN_tYk6gzOte"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import pandas as pd\n",
        "# import numpy as np\n",
        "\n",
        "# pd.plotting.register_matplotlib_converters()\n",
        "# import matplotlib.pyplot as plt\n",
        "# %matplotlib inline\n",
        "# import seaborn as sns\n",
        "\n",
        "# from sklearn.model_selection import train_test_split\n",
        "# from sklearn.metrics import classification_report\n",
        "# from sklearn.model_selection import GridSearchCV\n",
        "# from sklearn.preprocessing import MinMaxScaler\n",
        "# from tensorflow.keras.models import Sequential\n",
        "# from tensorflow.keras.layers import Conv2D, Flatten, Dense, MaxPool2D, Dropout\n",
        "# from tensorflow.keras.utils import to_categorical \n",
        "# import os,glob,skimage,librosa\n",
        "# import librosa.display\n",
        "\n",
        "# import warnings\n",
        "# warnings.filterwarnings(\"ignore\")  "
      ],
      "metadata": {
        "id": "izaNAb8-zRQ3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I2WlOelTzUJN",
        "outputId": "cbf14457-358a-4075-f33b-86a45233bfba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import sys, os, random\n",
        "# import tensorflow as tf\n",
        "# X = np.load('/content/drive/MyDrive/Thesis_Keras/PiczakCNN/data/datasetnpy/melspectro_short/x_train.npy')\n",
        "# Y = np.load('/content/drive/MyDrive/Thesis_Keras/PiczakCNN/data/datasetnpy/melspectro_short/y_train.npy')\n",
        "\n",
        "# x_train, x_val, Y_train, Y_val = train_test_split(X, Y, test_size=0.2, random_state=1)\n",
        "# input_length = x_train[0].shape[0]\n"
      ],
      "metadata": {
        "id": "6_mrZWgwd-hI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# x_test=np.load('/content/drive/MyDrive/Thesis_Keras/PiczakCNN/data/datasetnpy/melspectro_short/x_test.npy',allow_pickle=True)\n",
        "# Y_test = np.load('/content/drive/MyDrive/Thesis_Keras/PiczakCNN/data/datasetnpy/melspectro_short/y_test.npy')\n",
        "\n",
        "# # X_train = np.array([tf.image.resize(x, [60,41]) for x in x_train])\n",
        "# # X_test = np.array([tf.image.resize(x,[60,41]) for x in x_test])\n",
        "# # X_val = np.array([tf.image.resize(x,[60,41]) for x in x_val])\n",
        "\n",
        "# X_train = x_train\n",
        "# X_test = x_test\n",
        "# X_val = x_val\n",
        "# print(X_train.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L1BL9kEbMciI",
        "outputId": "05f4424f-87b8-42e1-b02e-a70781c86ae9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(4466, 60, 87, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# print(X_train.shape)\n",
        "# print(X_train[1145])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GC8sKAC6ouqq",
        "outputId": "2b8f51cf-54ab-4e31-f8fa-e3d8d98a79cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(4466, 60, 41, 1)\n",
            "[[[2.6936624e-02]\n",
            "  [2.2600148e-02]\n",
            "  [2.2361010e-02]\n",
            "  ...\n",
            "  [2.4613027e-02]\n",
            "  [2.3752892e-02]\n",
            "  [1.9524679e-02]]\n",
            "\n",
            " [[5.7118297e-02]\n",
            "  [6.0621031e-02]\n",
            "  [3.7980061e-02]\n",
            "  ...\n",
            "  [4.5247633e-02]\n",
            "  [6.3172713e-02]\n",
            "  [3.6731903e-02]]\n",
            "\n",
            " [[8.3568946e-02]\n",
            "  [1.5924920e-01]\n",
            "  [6.8076044e-02]\n",
            "  ...\n",
            "  [1.5682268e-01]\n",
            "  [2.0437901e-01]\n",
            "  [7.9768844e-02]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[2.0901161e-05]\n",
            "  [3.4801975e-05]\n",
            "  [2.3741095e-05]\n",
            "  ...\n",
            "  [4.9242943e-05]\n",
            "  [3.4047302e-05]\n",
            "  [2.8230799e-05]]\n",
            "\n",
            " [[3.2157996e-06]\n",
            "  [4.6190335e-06]\n",
            "  [4.2177653e-06]\n",
            "  ...\n",
            "  [2.4315918e-06]\n",
            "  [3.5402850e-06]\n",
            "  [3.5141654e-06]]\n",
            "\n",
            " [[3.3999100e-07]\n",
            "  [2.4270665e-07]\n",
            "  [1.2811400e-07]\n",
            "  ...\n",
            "  [1.8791073e-07]\n",
            "  [1.3390083e-07]\n",
            "  [3.5269511e-07]]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "但是你还得弄个模型出来。——鲁迅"
      ],
      "metadata": {
        "id": "HAX6EisdlI__"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import tensorflow as tf\n",
        "# from tensorflow.keras.models import Sequential\n",
        "# from tensorflow.keras.layers import Dense, InputLayer, Dropout, Conv1D, Conv2D, Flatten, Reshape, MaxPooling1D, MaxPooling2D, BatchNormalization, TimeDistributed,LeakyReLU,SpatialDropout2D,GlobalAveragePooling2D\n",
        "# from tensorflow.keras.optimizers import Adam,SGD\n",
        "# from tensorflow.keras import regularizers\n",
        "# EPOCHS = 300\n",
        "# # this controls the batch size, or you can manipulate the tf.data.Dataset objects yourself\n",
        "# BATCH_SIZE = 32\n",
        "# input_length=len(X_train[0])\n",
        "# callbacks = []"
      ],
      "metadata": {
        "id": "sUTn_42P_TGs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def build_model(bands=60, frames=41, channels=1, n_labels=10,\n",
        "#                 fc=5000, dropout=0.5):\n",
        "\n",
        "#     \"\"\"\n",
        "#     Implements the short-segment CNN from\n",
        "#     ENVIRONMENTAL SOUND CLASSIFICATION WITH CONVOLUTIONAL NEURAL NETWORKS\n",
        "#     Karol J. Piczak, 2015.\n",
        "#     https://karol.piczak.com/papers/Piczak2015-ESC-ConvNet.pdf\n",
        "#     \"\"\"\n",
        "\n",
        "#     from keras.models import Sequential\n",
        "#     from keras.layers import Dense, Dropout, Activation, Flatten\n",
        "#     from keras.layers import Convolution2D, MaxPooling2D\n",
        "#     from keras.regularizers import l2\n",
        "\n",
        "#     input_shape = (bands, frames, channels)\n",
        "\n",
        "#     model = Sequential([\n",
        "#         Convolution2D(80, (bands-3,6), strides=(1,1), input_shape=input_shape, activation='relu'),\n",
        "#         MaxPooling2D((4,3), strides=(1,3)),\n",
        "#         BatchNormalization(),\n",
        "#         Convolution2D(80, (1,3), activation='relu'),\n",
        "#         MaxPooling2D((1,3), strides=(1,3)),\n",
        "#         Flatten(),\n",
        "#         Dense(fc, activation='relu'),\n",
        "#         Dropout(dropout),\n",
        "#         Dense(fc, activation='relu'),\n",
        "#         Dropout(dropout),\n",
        "#         Dense(n_labels, activation='softmax'),\n",
        "#     ])\n",
        "\n",
        "#     return model\n",
        "\n",
        "\n",
        "# # this controls the learning rate\n",
        "# #opt = SGD(learning_rate=0.002, momentum=0.9, nesterov=True)\n",
        "# opt = Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999)\n"
      ],
      "metadata": {
        "id": "UN1Q-i4onwTV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# train the neural network\n",
        "model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
        "print(model.summary())\n",
        "model.fit(train_dataset, epochs=EPOCHS, validation_data=validation_dataset, verbose=2, callbacks=callbacks)\n",
        "\n",
        "# Use this flag to disable per-channel quantization for a model.\n",
        "# This can reduce RAM usage for convolutional models, but may have\n",
        "# an impact on accuracy.\n",
        "disable_per_channel_quantization = False"
      ],
      "metadata": {
        "id": "404twBD9HWDM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# model=build_model(X_train.shape[1],X_train.shape[2],1)\n",
        "# print(model.summary())\n",
        "# # train the neural network\n",
        "\n",
        "# model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
        "\n",
        "# model.fit(X_train,Y_train, batch_size=BATCH_SIZE, epochs=EPOCHS, validation_data=(X_val,Y_val), verbose=2, callbacks=callbacks)\n",
        "\n",
        "# # Use this flag to disable per-channel quantization for a model.\n",
        "# # This can reduce RAM usage for convolutional models, but may have\n",
        "# # an impact on accuracy.\n",
        "# disable_per_channel_quantization = False"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cEAePPkfzllH",
        "outputId": "a995ccc9-c590-4266-d648-5102ba6b6521"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_20\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_40 (Conv2D)          (None, 4, 82, 80)         27440     \n",
            "                                                                 \n",
            " max_pooling2d_40 (MaxPoolin  (None, 1, 27, 80)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " batch_normalization_20 (Bat  (None, 1, 27, 80)        320       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv2d_41 (Conv2D)          (None, 1, 25, 80)         19280     \n",
            "                                                                 \n",
            " max_pooling2d_41 (MaxPoolin  (None, 1, 8, 80)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten_18 (Flatten)        (None, 640)               0         \n",
            "                                                                 \n",
            " dense_60 (Dense)            (None, 5000)              3205000   \n",
            "                                                                 \n",
            " dropout_40 (Dropout)        (None, 5000)              0         \n",
            "                                                                 \n",
            " dense_61 (Dense)            (None, 5000)              25005000  \n",
            "                                                                 \n",
            " dropout_41 (Dropout)        (None, 5000)              0         \n",
            "                                                                 \n",
            " dense_62 (Dense)            (None, 10)                50010     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 28,307,050\n",
            "Trainable params: 28,306,890\n",
            "Non-trainable params: 160\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/300\n",
            "140/140 - 2s - loss: 2.0994 - accuracy: 0.2938 - val_loss: 1.7338 - val_accuracy: 0.3993 - 2s/epoch - 15ms/step\n",
            "Epoch 2/300\n",
            "140/140 - 1s - loss: 1.7616 - accuracy: 0.3876 - val_loss: 1.6298 - val_accuracy: 0.4458 - 1s/epoch - 9ms/step\n",
            "Epoch 3/300\n",
            "140/140 - 1s - loss: 1.6392 - accuracy: 0.4275 - val_loss: 1.5409 - val_accuracy: 0.4548 - 1s/epoch - 9ms/step\n",
            "Epoch 4/300\n",
            "140/140 - 1s - loss: 1.5643 - accuracy: 0.4624 - val_loss: 1.5692 - val_accuracy: 0.4387 - 1s/epoch - 9ms/step\n",
            "Epoch 5/300\n",
            "140/140 - 1s - loss: 1.5080 - accuracy: 0.4678 - val_loss: 1.5551 - val_accuracy: 0.4226 - 1s/epoch - 9ms/step\n",
            "Epoch 6/300\n",
            "140/140 - 1s - loss: 1.4050 - accuracy: 0.5125 - val_loss: 1.6292 - val_accuracy: 0.4100 - 1s/epoch - 9ms/step\n",
            "Epoch 7/300\n",
            "140/140 - 1s - loss: 1.3840 - accuracy: 0.5150 - val_loss: 1.5616 - val_accuracy: 0.4360 - 1s/epoch - 9ms/step\n",
            "Epoch 8/300\n",
            "140/140 - 1s - loss: 1.3163 - accuracy: 0.5439 - val_loss: 1.4221 - val_accuracy: 0.5013 - 1s/epoch - 9ms/step\n",
            "Epoch 9/300\n",
            "140/140 - 1s - loss: 1.2674 - accuracy: 0.5551 - val_loss: 1.4159 - val_accuracy: 0.4960 - 1s/epoch - 9ms/step\n",
            "Epoch 10/300\n",
            "140/140 - 1s - loss: 1.2454 - accuracy: 0.5676 - val_loss: 1.3929 - val_accuracy: 0.5219 - 1s/epoch - 9ms/step\n",
            "Epoch 11/300\n",
            "140/140 - 1s - loss: 1.2097 - accuracy: 0.5701 - val_loss: 1.4145 - val_accuracy: 0.5291 - 1s/epoch - 9ms/step\n",
            "Epoch 12/300\n",
            "140/140 - 1s - loss: 1.2552 - accuracy: 0.5734 - val_loss: 1.4158 - val_accuracy: 0.5309 - 1s/epoch - 9ms/step\n",
            "Epoch 13/300\n",
            "140/140 - 1s - loss: 1.1304 - accuracy: 0.6057 - val_loss: 1.3197 - val_accuracy: 0.5470 - 1s/epoch - 9ms/step\n",
            "Epoch 14/300\n",
            "140/140 - 1s - loss: 1.1322 - accuracy: 0.6084 - val_loss: 1.3522 - val_accuracy: 0.5372 - 1s/epoch - 9ms/step\n",
            "Epoch 15/300\n",
            "140/140 - 1s - loss: 1.1279 - accuracy: 0.6099 - val_loss: 1.2771 - val_accuracy: 0.5434 - 1s/epoch - 9ms/step\n",
            "Epoch 16/300\n",
            "140/140 - 1s - loss: 1.1058 - accuracy: 0.6209 - val_loss: 1.3064 - val_accuracy: 0.5649 - 1s/epoch - 9ms/step\n",
            "Epoch 17/300\n",
            "140/140 - 1s - loss: 1.0788 - accuracy: 0.6314 - val_loss: 1.2949 - val_accuracy: 0.5703 - 1s/epoch - 9ms/step\n",
            "Epoch 18/300\n",
            "140/140 - 1s - loss: 1.0292 - accuracy: 0.6406 - val_loss: 1.3025 - val_accuracy: 0.5452 - 1s/epoch - 9ms/step\n",
            "Epoch 19/300\n",
            "140/140 - 1s - loss: 1.0133 - accuracy: 0.6572 - val_loss: 1.3649 - val_accuracy: 0.5318 - 1s/epoch - 9ms/step\n",
            "Epoch 20/300\n",
            "140/140 - 1s - loss: 1.0910 - accuracy: 0.6438 - val_loss: 1.3008 - val_accuracy: 0.5900 - 1s/epoch - 9ms/step\n",
            "Epoch 21/300\n",
            "140/140 - 1s - loss: 1.0873 - accuracy: 0.6408 - val_loss: 1.3230 - val_accuracy: 0.5560 - 1s/epoch - 9ms/step\n",
            "Epoch 22/300\n",
            "140/140 - 1s - loss: 0.9905 - accuracy: 0.6527 - val_loss: 1.3080 - val_accuracy: 0.5828 - 1s/epoch - 9ms/step\n",
            "Epoch 23/300\n",
            "140/140 - 1s - loss: 0.9975 - accuracy: 0.6558 - val_loss: 1.3839 - val_accuracy: 0.5855 - 1s/epoch - 9ms/step\n",
            "Epoch 24/300\n",
            "140/140 - 1s - loss: 0.9697 - accuracy: 0.6673 - val_loss: 1.5899 - val_accuracy: 0.5031 - 1s/epoch - 9ms/step\n",
            "Epoch 25/300\n",
            "140/140 - 1s - loss: 0.9353 - accuracy: 0.6704 - val_loss: 1.4038 - val_accuracy: 0.5372 - 1s/epoch - 9ms/step\n",
            "Epoch 26/300\n",
            "140/140 - 1s - loss: 0.9634 - accuracy: 0.6805 - val_loss: 1.6125 - val_accuracy: 0.5094 - 1s/epoch - 9ms/step\n",
            "Epoch 27/300\n",
            "140/140 - 1s - loss: 0.9546 - accuracy: 0.6771 - val_loss: 1.6012 - val_accuracy: 0.5461 - 1s/epoch - 9ms/step\n",
            "Epoch 28/300\n",
            "140/140 - 1s - loss: 0.9600 - accuracy: 0.6805 - val_loss: 1.8645 - val_accuracy: 0.5443 - 1s/epoch - 9ms/step\n",
            "Epoch 29/300\n",
            "140/140 - 1s - loss: 0.9768 - accuracy: 0.6845 - val_loss: 1.3658 - val_accuracy: 0.5810 - 1s/epoch - 9ms/step\n",
            "Epoch 30/300\n",
            "140/140 - 1s - loss: 0.9094 - accuracy: 0.6959 - val_loss: 1.4697 - val_accuracy: 0.5434 - 1s/epoch - 9ms/step\n",
            "Epoch 31/300\n",
            "140/140 - 1s - loss: 0.9399 - accuracy: 0.6881 - val_loss: 1.3488 - val_accuracy: 0.5953 - 1s/epoch - 9ms/step\n",
            "Epoch 32/300\n",
            "140/140 - 1s - loss: 0.8927 - accuracy: 0.6944 - val_loss: 1.5716 - val_accuracy: 0.5953 - 1s/epoch - 9ms/step\n",
            "Epoch 33/300\n",
            "140/140 - 1s - loss: 0.8395 - accuracy: 0.7062 - val_loss: 1.5403 - val_accuracy: 0.5622 - 1s/epoch - 9ms/step\n",
            "Epoch 34/300\n",
            "140/140 - 1s - loss: 0.8365 - accuracy: 0.7116 - val_loss: 1.4733 - val_accuracy: 0.5927 - 1s/epoch - 9ms/step\n",
            "Epoch 35/300\n",
            "140/140 - 1s - loss: 0.7912 - accuracy: 0.7259 - val_loss: 1.6956 - val_accuracy: 0.5327 - 1s/epoch - 9ms/step\n",
            "Epoch 36/300\n",
            "140/140 - 1s - loss: 0.8642 - accuracy: 0.7154 - val_loss: 1.6487 - val_accuracy: 0.5273 - 1s/epoch - 9ms/step\n",
            "Epoch 37/300\n",
            "140/140 - 1s - loss: 0.8765 - accuracy: 0.7147 - val_loss: 1.4832 - val_accuracy: 0.5953 - 1s/epoch - 10ms/step\n",
            "Epoch 38/300\n",
            "140/140 - 1s - loss: 0.8726 - accuracy: 0.7091 - val_loss: 1.5322 - val_accuracy: 0.5640 - 1s/epoch - 9ms/step\n",
            "Epoch 39/300\n",
            "140/140 - 1s - loss: 0.8295 - accuracy: 0.7320 - val_loss: 1.5525 - val_accuracy: 0.5927 - 1s/epoch - 9ms/step\n",
            "Epoch 40/300\n",
            "140/140 - 1s - loss: 0.8015 - accuracy: 0.7291 - val_loss: 1.5230 - val_accuracy: 0.5873 - 1s/epoch - 9ms/step\n",
            "Epoch 41/300\n",
            "140/140 - 1s - loss: 0.8000 - accuracy: 0.7382 - val_loss: 1.4150 - val_accuracy: 0.5801 - 1s/epoch - 9ms/step\n",
            "Epoch 42/300\n",
            "140/140 - 1s - loss: 0.7938 - accuracy: 0.7306 - val_loss: 1.6400 - val_accuracy: 0.6007 - 1s/epoch - 9ms/step\n",
            "Epoch 43/300\n",
            "140/140 - 1s - loss: 0.7828 - accuracy: 0.7398 - val_loss: 1.5987 - val_accuracy: 0.5855 - 1s/epoch - 9ms/step\n",
            "Epoch 44/300\n",
            "140/140 - 1s - loss: 0.7789 - accuracy: 0.7445 - val_loss: 1.6283 - val_accuracy: 0.5819 - 1s/epoch - 9ms/step\n",
            "Epoch 45/300\n",
            "140/140 - 1s - loss: 0.8717 - accuracy: 0.7246 - val_loss: 1.7716 - val_accuracy: 0.5649 - 1s/epoch - 9ms/step\n",
            "Epoch 46/300\n",
            "140/140 - 1s - loss: 0.7748 - accuracy: 0.7465 - val_loss: 1.6424 - val_accuracy: 0.6168 - 1s/epoch - 9ms/step\n",
            "Epoch 47/300\n",
            "140/140 - 1s - loss: 0.7629 - accuracy: 0.7468 - val_loss: 1.6474 - val_accuracy: 0.6312 - 1s/epoch - 9ms/step\n",
            "Epoch 48/300\n",
            "140/140 - 1s - loss: 0.8301 - accuracy: 0.7326 - val_loss: 1.6247 - val_accuracy: 0.6034 - 1s/epoch - 9ms/step\n",
            "Epoch 49/300\n",
            "140/140 - 1s - loss: 0.7574 - accuracy: 0.7530 - val_loss: 1.6456 - val_accuracy: 0.5855 - 1s/epoch - 9ms/step\n",
            "Epoch 50/300\n",
            "140/140 - 1s - loss: 0.7392 - accuracy: 0.7553 - val_loss: 1.8861 - val_accuracy: 0.5998 - 1s/epoch - 9ms/step\n",
            "Epoch 51/300\n",
            "140/140 - 1s - loss: 0.7431 - accuracy: 0.7604 - val_loss: 1.5026 - val_accuracy: 0.6115 - 1s/epoch - 9ms/step\n",
            "Epoch 52/300\n",
            "140/140 - 1s - loss: 0.8392 - accuracy: 0.7347 - val_loss: 1.6951 - val_accuracy: 0.6124 - 1s/epoch - 9ms/step\n",
            "Epoch 53/300\n",
            "140/140 - 1s - loss: 0.7111 - accuracy: 0.7544 - val_loss: 1.8773 - val_accuracy: 0.5864 - 1s/epoch - 9ms/step\n",
            "Epoch 54/300\n",
            "140/140 - 1s - loss: 0.7058 - accuracy: 0.7611 - val_loss: 1.7763 - val_accuracy: 0.6025 - 1s/epoch - 9ms/step\n",
            "Epoch 55/300\n",
            "140/140 - 1s - loss: 0.7365 - accuracy: 0.7649 - val_loss: 2.0368 - val_accuracy: 0.5756 - 1s/epoch - 9ms/step\n",
            "Epoch 56/300\n",
            "140/140 - 1s - loss: 0.7972 - accuracy: 0.7526 - val_loss: 1.7685 - val_accuracy: 0.5944 - 1s/epoch - 9ms/step\n",
            "Epoch 57/300\n",
            "140/140 - 1s - loss: 0.7627 - accuracy: 0.7530 - val_loss: 1.7419 - val_accuracy: 0.5488 - 1s/epoch - 9ms/step\n",
            "Epoch 58/300\n",
            "140/140 - 1s - loss: 0.7642 - accuracy: 0.7553 - val_loss: 1.7226 - val_accuracy: 0.5810 - 1s/epoch - 9ms/step\n",
            "Epoch 59/300\n",
            "140/140 - 1s - loss: 0.7075 - accuracy: 0.7734 - val_loss: 2.1251 - val_accuracy: 0.5524 - 1s/epoch - 9ms/step\n",
            "Epoch 60/300\n",
            "140/140 - 1s - loss: 0.8359 - accuracy: 0.7429 - val_loss: 2.0325 - val_accuracy: 0.5998 - 1s/epoch - 10ms/step\n",
            "Epoch 61/300\n",
            "140/140 - 1s - loss: 0.7823 - accuracy: 0.7463 - val_loss: 1.7682 - val_accuracy: 0.5882 - 1s/epoch - 9ms/step\n",
            "Epoch 62/300\n",
            "140/140 - 1s - loss: 0.6754 - accuracy: 0.7680 - val_loss: 1.9936 - val_accuracy: 0.5739 - 1s/epoch - 9ms/step\n",
            "Epoch 63/300\n",
            "140/140 - 1s - loss: 0.6818 - accuracy: 0.7781 - val_loss: 1.7624 - val_accuracy: 0.5846 - 1s/epoch - 9ms/step\n",
            "Epoch 64/300\n",
            "140/140 - 1s - loss: 0.6713 - accuracy: 0.7730 - val_loss: 1.8770 - val_accuracy: 0.5730 - 1s/epoch - 9ms/step\n",
            "Epoch 65/300\n",
            "140/140 - 1s - loss: 0.5978 - accuracy: 0.7924 - val_loss: 1.7635 - val_accuracy: 0.6016 - 1s/epoch - 9ms/step\n",
            "Epoch 66/300\n",
            "140/140 - 1s - loss: 0.7481 - accuracy: 0.7801 - val_loss: 1.9829 - val_accuracy: 0.5900 - 1s/epoch - 9ms/step\n",
            "Epoch 67/300\n",
            "140/140 - 1s - loss: 0.6598 - accuracy: 0.7862 - val_loss: 1.9998 - val_accuracy: 0.6079 - 1s/epoch - 9ms/step\n",
            "Epoch 68/300\n",
            "140/140 - 1s - loss: 0.6697 - accuracy: 0.7833 - val_loss: 2.1321 - val_accuracy: 0.6410 - 1s/epoch - 9ms/step\n",
            "Epoch 69/300\n",
            "140/140 - 1s - loss: 0.6356 - accuracy: 0.7880 - val_loss: 1.8922 - val_accuracy: 0.6088 - 1s/epoch - 9ms/step\n",
            "Epoch 70/300\n",
            "140/140 - 1s - loss: 0.6991 - accuracy: 0.7797 - val_loss: 1.9366 - val_accuracy: 0.5909 - 1s/epoch - 9ms/step\n",
            "Epoch 71/300\n",
            "140/140 - 1s - loss: 0.6782 - accuracy: 0.7891 - val_loss: 1.9312 - val_accuracy: 0.5962 - 1s/epoch - 9ms/step\n",
            "Epoch 72/300\n",
            "140/140 - 1s - loss: 0.7537 - accuracy: 0.7752 - val_loss: 2.3033 - val_accuracy: 0.5989 - 1s/epoch - 9ms/step\n",
            "Epoch 73/300\n",
            "140/140 - 1s - loss: 0.8032 - accuracy: 0.7606 - val_loss: 2.1602 - val_accuracy: 0.5918 - 1s/epoch - 9ms/step\n",
            "Epoch 74/300\n",
            "140/140 - 1s - loss: 0.6644 - accuracy: 0.7857 - val_loss: 2.3548 - val_accuracy: 0.5810 - 1s/epoch - 9ms/step\n",
            "Epoch 75/300\n",
            "140/140 - 1s - loss: 0.6705 - accuracy: 0.7913 - val_loss: 2.0081 - val_accuracy: 0.6079 - 1s/epoch - 9ms/step\n",
            "Epoch 76/300\n",
            "140/140 - 1s - loss: 0.6767 - accuracy: 0.7830 - val_loss: 2.4842 - val_accuracy: 0.5192 - 1s/epoch - 9ms/step\n",
            "Epoch 77/300\n",
            "140/140 - 1s - loss: 0.6640 - accuracy: 0.7844 - val_loss: 2.0418 - val_accuracy: 0.5551 - 1s/epoch - 9ms/step\n",
            "Epoch 78/300\n",
            "140/140 - 1s - loss: 0.7119 - accuracy: 0.7947 - val_loss: 2.0312 - val_accuracy: 0.6106 - 1s/epoch - 9ms/step\n",
            "Epoch 79/300\n",
            "140/140 - 1s - loss: 0.6290 - accuracy: 0.7996 - val_loss: 2.2033 - val_accuracy: 0.6159 - 1s/epoch - 9ms/step\n",
            "Epoch 80/300\n",
            "140/140 - 1s - loss: 0.6414 - accuracy: 0.7947 - val_loss: 2.0002 - val_accuracy: 0.6329 - 1s/epoch - 9ms/step\n",
            "Epoch 81/300\n",
            "140/140 - 1s - loss: 0.6182 - accuracy: 0.8065 - val_loss: 2.3162 - val_accuracy: 0.5936 - 1s/epoch - 9ms/step\n",
            "Epoch 82/300\n",
            "140/140 - 1s - loss: 0.7301 - accuracy: 0.7846 - val_loss: 2.4980 - val_accuracy: 0.5586 - 1s/epoch - 9ms/step\n",
            "Epoch 83/300\n",
            "140/140 - 1s - loss: 0.6540 - accuracy: 0.7987 - val_loss: 2.3224 - val_accuracy: 0.5730 - 1s/epoch - 9ms/step\n",
            "Epoch 84/300\n",
            "140/140 - 1s - loss: 0.6447 - accuracy: 0.8047 - val_loss: 2.2665 - val_accuracy: 0.5936 - 1s/epoch - 9ms/step\n",
            "Epoch 85/300\n",
            "140/140 - 1s - loss: 0.6640 - accuracy: 0.7994 - val_loss: 2.2446 - val_accuracy: 0.6186 - 1s/epoch - 9ms/step\n",
            "Epoch 86/300\n",
            "140/140 - 1s - loss: 0.6354 - accuracy: 0.7978 - val_loss: 2.3371 - val_accuracy: 0.6007 - 1s/epoch - 9ms/step\n",
            "Epoch 87/300\n",
            "140/140 - 1s - loss: 0.6443 - accuracy: 0.7949 - val_loss: 2.6090 - val_accuracy: 0.6025 - 1s/epoch - 9ms/step\n",
            "Epoch 88/300\n",
            "140/140 - 1s - loss: 0.5829 - accuracy: 0.8126 - val_loss: 2.3910 - val_accuracy: 0.6231 - 1s/epoch - 9ms/step\n",
            "Epoch 89/300\n",
            "140/140 - 1s - loss: 0.6227 - accuracy: 0.8144 - val_loss: 2.3738 - val_accuracy: 0.6168 - 1s/epoch - 9ms/step\n",
            "Epoch 90/300\n",
            "140/140 - 1s - loss: 0.6074 - accuracy: 0.7996 - val_loss: 2.5182 - val_accuracy: 0.6159 - 1s/epoch - 9ms/step\n",
            "Epoch 91/300\n",
            "140/140 - 1s - loss: 0.5995 - accuracy: 0.8097 - val_loss: 2.3792 - val_accuracy: 0.6222 - 1s/epoch - 9ms/step\n",
            "Epoch 92/300\n",
            "140/140 - 1s - loss: 0.6242 - accuracy: 0.8056 - val_loss: 3.0966 - val_accuracy: 0.5389 - 1s/epoch - 9ms/step\n",
            "Epoch 93/300\n",
            "140/140 - 1s - loss: 0.7747 - accuracy: 0.7857 - val_loss: 2.2048 - val_accuracy: 0.6052 - 1s/epoch - 9ms/step\n",
            "Epoch 94/300\n",
            "140/140 - 1s - loss: 0.6829 - accuracy: 0.7974 - val_loss: 2.8314 - val_accuracy: 0.6061 - 1s/epoch - 9ms/step\n",
            "Epoch 95/300\n",
            "140/140 - 1s - loss: 0.6334 - accuracy: 0.8003 - val_loss: 2.5564 - val_accuracy: 0.6061 - 1s/epoch - 9ms/step\n",
            "Epoch 96/300\n",
            "140/140 - 1s - loss: 0.5639 - accuracy: 0.8153 - val_loss: 2.6278 - val_accuracy: 0.6294 - 1s/epoch - 9ms/step\n",
            "Epoch 97/300\n",
            "140/140 - 1s - loss: 0.5716 - accuracy: 0.8195 - val_loss: 2.5177 - val_accuracy: 0.6231 - 1s/epoch - 9ms/step\n",
            "Epoch 98/300\n",
            "140/140 - 1s - loss: 0.6145 - accuracy: 0.8070 - val_loss: 4.0264 - val_accuracy: 0.5712 - 1s/epoch - 9ms/step\n",
            "Epoch 99/300\n",
            "140/140 - 1s - loss: 0.6073 - accuracy: 0.8099 - val_loss: 2.5353 - val_accuracy: 0.6097 - 1s/epoch - 9ms/step\n",
            "Epoch 100/300\n",
            "140/140 - 1s - loss: 0.7183 - accuracy: 0.8083 - val_loss: 2.8802 - val_accuracy: 0.5927 - 1s/epoch - 9ms/step\n",
            "Epoch 101/300\n",
            "140/140 - 1s - loss: 0.8211 - accuracy: 0.7866 - val_loss: 2.4437 - val_accuracy: 0.6034 - 1s/epoch - 9ms/step\n",
            "Epoch 102/300\n",
            "140/140 - 1s - loss: 0.5535 - accuracy: 0.8103 - val_loss: 2.2610 - val_accuracy: 0.6195 - 1s/epoch - 9ms/step\n",
            "Epoch 103/300\n",
            "140/140 - 1s - loss: 0.6061 - accuracy: 0.8081 - val_loss: 2.5182 - val_accuracy: 0.5989 - 1s/epoch - 9ms/step\n",
            "Epoch 104/300\n",
            "140/140 - 1s - loss: 0.6344 - accuracy: 0.8222 - val_loss: 3.0951 - val_accuracy: 0.5918 - 1s/epoch - 9ms/step\n",
            "Epoch 105/300\n",
            "140/140 - 1s - loss: 0.5832 - accuracy: 0.8103 - val_loss: 2.6265 - val_accuracy: 0.6249 - 1s/epoch - 9ms/step\n",
            "Epoch 106/300\n",
            "140/140 - 1s - loss: 0.5551 - accuracy: 0.8202 - val_loss: 2.5810 - val_accuracy: 0.6097 - 1s/epoch - 9ms/step\n",
            "Epoch 107/300\n",
            "140/140 - 1s - loss: 0.6020 - accuracy: 0.8135 - val_loss: 2.9605 - val_accuracy: 0.6070 - 1s/epoch - 9ms/step\n",
            "Epoch 108/300\n",
            "140/140 - 1s - loss: 0.5627 - accuracy: 0.8236 - val_loss: 2.9698 - val_accuracy: 0.5891 - 1s/epoch - 9ms/step\n",
            "Epoch 109/300\n",
            "140/140 - 1s - loss: 0.5768 - accuracy: 0.8316 - val_loss: 2.8254 - val_accuracy: 0.5622 - 1s/epoch - 9ms/step\n",
            "Epoch 110/300\n",
            "140/140 - 1s - loss: 0.5603 - accuracy: 0.8231 - val_loss: 2.5885 - val_accuracy: 0.6186 - 1s/epoch - 9ms/step\n",
            "Epoch 111/300\n",
            "140/140 - 1s - loss: 0.6226 - accuracy: 0.8121 - val_loss: 2.8245 - val_accuracy: 0.5873 - 1s/epoch - 9ms/step\n",
            "Epoch 112/300\n",
            "140/140 - 1s - loss: 0.5418 - accuracy: 0.8236 - val_loss: 3.1639 - val_accuracy: 0.6204 - 1s/epoch - 9ms/step\n",
            "Epoch 113/300\n",
            "140/140 - 1s - loss: 0.5694 - accuracy: 0.8265 - val_loss: 3.5618 - val_accuracy: 0.6061 - 1s/epoch - 9ms/step\n",
            "Epoch 114/300\n",
            "140/140 - 1s - loss: 0.5568 - accuracy: 0.8240 - val_loss: 2.6361 - val_accuracy: 0.6034 - 1s/epoch - 9ms/step\n",
            "Epoch 115/300\n",
            "140/140 - 1s - loss: 0.6392 - accuracy: 0.8099 - val_loss: 2.7420 - val_accuracy: 0.5998 - 1s/epoch - 9ms/step\n",
            "Epoch 116/300\n",
            "140/140 - 1s - loss: 0.5357 - accuracy: 0.8287 - val_loss: 2.4546 - val_accuracy: 0.5980 - 1s/epoch - 9ms/step\n",
            "Epoch 117/300\n",
            "140/140 - 1s - loss: 0.6627 - accuracy: 0.8218 - val_loss: 2.6391 - val_accuracy: 0.6052 - 1s/epoch - 9ms/step\n",
            "Epoch 118/300\n",
            "140/140 - 1s - loss: 0.6072 - accuracy: 0.8130 - val_loss: 2.8316 - val_accuracy: 0.6016 - 1s/epoch - 9ms/step\n",
            "Epoch 119/300\n",
            "140/140 - 1s - loss: 0.5464 - accuracy: 0.8307 - val_loss: 2.9750 - val_accuracy: 0.6195 - 1s/epoch - 9ms/step\n",
            "Epoch 120/300\n",
            "140/140 - 1s - loss: 0.5481 - accuracy: 0.8227 - val_loss: 2.7520 - val_accuracy: 0.6043 - 1s/epoch - 9ms/step\n",
            "Epoch 121/300\n",
            "140/140 - 1s - loss: 0.5776 - accuracy: 0.8256 - val_loss: 2.8265 - val_accuracy: 0.5971 - 1s/epoch - 9ms/step\n",
            "Epoch 122/300\n",
            "140/140 - 1s - loss: 0.6158 - accuracy: 0.8191 - val_loss: 2.6409 - val_accuracy: 0.6240 - 1s/epoch - 9ms/step\n",
            "Epoch 123/300\n",
            "140/140 - 1s - loss: 0.5890 - accuracy: 0.8153 - val_loss: 2.7049 - val_accuracy: 0.5918 - 1s/epoch - 9ms/step\n",
            "Epoch 124/300\n",
            "140/140 - 1s - loss: 0.4886 - accuracy: 0.8399 - val_loss: 2.9273 - val_accuracy: 0.6043 - 1s/epoch - 9ms/step\n",
            "Epoch 125/300\n",
            "140/140 - 1s - loss: 0.6681 - accuracy: 0.8211 - val_loss: 3.0172 - val_accuracy: 0.6088 - 1s/epoch - 9ms/step\n",
            "Epoch 126/300\n",
            "140/140 - 1s - loss: 0.5703 - accuracy: 0.8146 - val_loss: 3.2530 - val_accuracy: 0.5667 - 1s/epoch - 9ms/step\n",
            "Epoch 127/300\n",
            "140/140 - 1s - loss: 0.5180 - accuracy: 0.8323 - val_loss: 3.0568 - val_accuracy: 0.5819 - 1s/epoch - 9ms/step\n",
            "Epoch 128/300\n",
            "140/140 - 1s - loss: 0.4969 - accuracy: 0.8383 - val_loss: 3.2298 - val_accuracy: 0.5980 - 1s/epoch - 9ms/step\n",
            "Epoch 129/300\n",
            "140/140 - 1s - loss: 0.6758 - accuracy: 0.8258 - val_loss: 3.2180 - val_accuracy: 0.6124 - 1s/epoch - 9ms/step\n",
            "Epoch 130/300\n",
            "140/140 - 1s - loss: 0.6125 - accuracy: 0.8213 - val_loss: 2.6665 - val_accuracy: 0.6186 - 1s/epoch - 9ms/step\n",
            "Epoch 131/300\n",
            "140/140 - 1s - loss: 0.6461 - accuracy: 0.8209 - val_loss: 2.6421 - val_accuracy: 0.6097 - 1s/epoch - 9ms/step\n",
            "Epoch 132/300\n",
            "140/140 - 1s - loss: 0.6231 - accuracy: 0.8265 - val_loss: 2.5617 - val_accuracy: 0.5962 - 1s/epoch - 9ms/step\n",
            "Epoch 133/300\n",
            "140/140 - 1s - loss: 0.5414 - accuracy: 0.8356 - val_loss: 2.6813 - val_accuracy: 0.6124 - 1s/epoch - 9ms/step\n",
            "Epoch 134/300\n",
            "140/140 - 1s - loss: 0.5426 - accuracy: 0.8300 - val_loss: 2.8977 - val_accuracy: 0.5989 - 1s/epoch - 9ms/step\n",
            "Epoch 135/300\n",
            "140/140 - 1s - loss: 0.5858 - accuracy: 0.8229 - val_loss: 2.8730 - val_accuracy: 0.6070 - 1s/epoch - 9ms/step\n",
            "Epoch 136/300\n",
            "140/140 - 1s - loss: 0.5583 - accuracy: 0.8220 - val_loss: 2.8452 - val_accuracy: 0.6321 - 1s/epoch - 9ms/step\n",
            "Epoch 137/300\n",
            "140/140 - 1s - loss: 0.4808 - accuracy: 0.8417 - val_loss: 3.4563 - val_accuracy: 0.6070 - 1s/epoch - 9ms/step\n",
            "Epoch 138/300\n",
            "140/140 - 1s - loss: 0.6155 - accuracy: 0.8287 - val_loss: 3.0824 - val_accuracy: 0.6132 - 1s/epoch - 9ms/step\n",
            "Epoch 139/300\n",
            "140/140 - 1s - loss: 0.6298 - accuracy: 0.8222 - val_loss: 3.0271 - val_accuracy: 0.6231 - 1s/epoch - 9ms/step\n",
            "Epoch 140/300\n",
            "140/140 - 1s - loss: 0.6774 - accuracy: 0.8115 - val_loss: 2.7292 - val_accuracy: 0.6141 - 1s/epoch - 9ms/step\n",
            "Epoch 141/300\n",
            "140/140 - 1s - loss: 0.5931 - accuracy: 0.8215 - val_loss: 3.0959 - val_accuracy: 0.6294 - 1s/epoch - 9ms/step\n",
            "Epoch 142/300\n",
            "140/140 - 1s - loss: 0.5801 - accuracy: 0.8305 - val_loss: 3.0822 - val_accuracy: 0.6052 - 1s/epoch - 9ms/step\n",
            "Epoch 143/300\n",
            "140/140 - 1s - loss: 0.5134 - accuracy: 0.8430 - val_loss: 3.0778 - val_accuracy: 0.6338 - 1s/epoch - 9ms/step\n",
            "Epoch 144/300\n",
            "140/140 - 1s - loss: 0.6108 - accuracy: 0.8233 - val_loss: 3.1315 - val_accuracy: 0.6088 - 1s/epoch - 9ms/step\n",
            "Epoch 145/300\n",
            "140/140 - 1s - loss: 0.5519 - accuracy: 0.8374 - val_loss: 3.0936 - val_accuracy: 0.6222 - 1s/epoch - 9ms/step\n",
            "Epoch 146/300\n",
            "140/140 - 1s - loss: 0.5201 - accuracy: 0.8372 - val_loss: 3.0664 - val_accuracy: 0.6132 - 1s/epoch - 9ms/step\n",
            "Epoch 147/300\n",
            "140/140 - 1s - loss: 0.5046 - accuracy: 0.8451 - val_loss: 2.8954 - val_accuracy: 0.6168 - 1s/epoch - 9ms/step\n",
            "Epoch 148/300\n",
            "140/140 - 1s - loss: 0.5087 - accuracy: 0.8361 - val_loss: 3.0921 - val_accuracy: 0.6392 - 1s/epoch - 9ms/step\n",
            "Epoch 149/300\n",
            "140/140 - 1s - loss: 0.4510 - accuracy: 0.8502 - val_loss: 3.8479 - val_accuracy: 0.6365 - 1s/epoch - 9ms/step\n",
            "Epoch 150/300\n",
            "140/140 - 1s - loss: 0.5241 - accuracy: 0.8473 - val_loss: 3.6786 - val_accuracy: 0.6025 - 1s/epoch - 9ms/step\n",
            "Epoch 151/300\n",
            "140/140 - 1s - loss: 0.5549 - accuracy: 0.8312 - val_loss: 3.0218 - val_accuracy: 0.6249 - 1s/epoch - 9ms/step\n",
            "Epoch 152/300\n",
            "140/140 - 1s - loss: 0.5352 - accuracy: 0.8439 - val_loss: 3.8372 - val_accuracy: 0.6070 - 1s/epoch - 9ms/step\n",
            "Epoch 153/300\n",
            "140/140 - 1s - loss: 0.5380 - accuracy: 0.8390 - val_loss: 3.2670 - val_accuracy: 0.6356 - 1s/epoch - 9ms/step\n",
            "Epoch 154/300\n",
            "140/140 - 1s - loss: 0.4587 - accuracy: 0.8500 - val_loss: 3.8473 - val_accuracy: 0.6240 - 1s/epoch - 9ms/step\n",
            "Epoch 155/300\n",
            "140/140 - 1s - loss: 0.4371 - accuracy: 0.8571 - val_loss: 3.7238 - val_accuracy: 0.6124 - 1s/epoch - 9ms/step\n",
            "Epoch 156/300\n",
            "140/140 - 1s - loss: 0.5277 - accuracy: 0.8480 - val_loss: 3.9868 - val_accuracy: 0.6276 - 1s/epoch - 9ms/step\n",
            "Epoch 157/300\n",
            "140/140 - 1s - loss: 0.5863 - accuracy: 0.8285 - val_loss: 3.1116 - val_accuracy: 0.6168 - 1s/epoch - 9ms/step\n",
            "Epoch 158/300\n",
            "140/140 - 1s - loss: 0.4765 - accuracy: 0.8482 - val_loss: 3.7280 - val_accuracy: 0.6088 - 1s/epoch - 9ms/step\n",
            "Epoch 159/300\n",
            "140/140 - 1s - loss: 0.5945 - accuracy: 0.8468 - val_loss: 3.2612 - val_accuracy: 0.6097 - 1s/epoch - 9ms/step\n",
            "Epoch 160/300\n",
            "140/140 - 1s - loss: 0.6050 - accuracy: 0.8388 - val_loss: 3.4161 - val_accuracy: 0.5864 - 1s/epoch - 9ms/step\n",
            "Epoch 161/300\n",
            "140/140 - 1s - loss: 0.5386 - accuracy: 0.8323 - val_loss: 2.7963 - val_accuracy: 0.6106 - 1s/epoch - 10ms/step\n",
            "Epoch 162/300\n",
            "140/140 - 1s - loss: 0.4677 - accuracy: 0.8524 - val_loss: 3.5119 - val_accuracy: 0.6150 - 1s/epoch - 9ms/step\n",
            "Epoch 163/300\n",
            "140/140 - 1s - loss: 0.5327 - accuracy: 0.8495 - val_loss: 3.0277 - val_accuracy: 0.6267 - 1s/epoch - 9ms/step\n",
            "Epoch 164/300\n",
            "140/140 - 1s - loss: 0.4880 - accuracy: 0.8495 - val_loss: 3.3563 - val_accuracy: 0.6222 - 1s/epoch - 9ms/step\n",
            "Epoch 165/300\n",
            "140/140 - 1s - loss: 0.4716 - accuracy: 0.8486 - val_loss: 4.2832 - val_accuracy: 0.6383 - 1s/epoch - 9ms/step\n",
            "Epoch 166/300\n",
            "140/140 - 1s - loss: 0.5098 - accuracy: 0.8475 - val_loss: 4.3915 - val_accuracy: 0.6168 - 1s/epoch - 9ms/step\n",
            "Epoch 167/300\n",
            "140/140 - 1s - loss: 0.4673 - accuracy: 0.8515 - val_loss: 3.9406 - val_accuracy: 0.6106 - 1s/epoch - 9ms/step\n",
            "Epoch 168/300\n",
            "140/140 - 1s - loss: 0.7046 - accuracy: 0.8417 - val_loss: 3.8864 - val_accuracy: 0.6132 - 1s/epoch - 9ms/step\n",
            "Epoch 169/300\n",
            "140/140 - 1s - loss: 0.5140 - accuracy: 0.8473 - val_loss: 3.2563 - val_accuracy: 0.6213 - 1s/epoch - 9ms/step\n",
            "Epoch 170/300\n",
            "140/140 - 1s - loss: 0.5124 - accuracy: 0.8379 - val_loss: 3.6435 - val_accuracy: 0.6106 - 1s/epoch - 9ms/step\n",
            "Epoch 171/300\n",
            "140/140 - 1s - loss: 0.4851 - accuracy: 0.8522 - val_loss: 3.1481 - val_accuracy: 0.6285 - 1s/epoch - 9ms/step\n",
            "Epoch 172/300\n",
            "140/140 - 1s - loss: 0.5408 - accuracy: 0.8529 - val_loss: 3.1756 - val_accuracy: 0.6222 - 1s/epoch - 9ms/step\n",
            "Epoch 173/300\n",
            "140/140 - 1s - loss: 0.4571 - accuracy: 0.8576 - val_loss: 3.2774 - val_accuracy: 0.6150 - 1s/epoch - 9ms/step\n",
            "Epoch 174/300\n",
            "140/140 - 1s - loss: 0.4069 - accuracy: 0.8659 - val_loss: 3.2966 - val_accuracy: 0.6159 - 1s/epoch - 9ms/step\n",
            "Epoch 175/300\n",
            "140/140 - 1s - loss: 0.3900 - accuracy: 0.8688 - val_loss: 3.1802 - val_accuracy: 0.6231 - 1s/epoch - 9ms/step\n",
            "Epoch 176/300\n",
            "140/140 - 1s - loss: 0.3941 - accuracy: 0.8744 - val_loss: 3.3919 - val_accuracy: 0.6321 - 1s/epoch - 9ms/step\n",
            "Epoch 177/300\n",
            "140/140 - 1s - loss: 0.4093 - accuracy: 0.8621 - val_loss: 3.5441 - val_accuracy: 0.6168 - 1s/epoch - 9ms/step\n",
            "Epoch 178/300\n",
            "140/140 - 1s - loss: 0.4008 - accuracy: 0.8697 - val_loss: 3.5892 - val_accuracy: 0.5989 - 1s/epoch - 9ms/step\n",
            "Epoch 179/300\n",
            "140/140 - 1s - loss: 0.5398 - accuracy: 0.8527 - val_loss: 3.9938 - val_accuracy: 0.5873 - 1s/epoch - 9ms/step\n",
            "Epoch 180/300\n",
            "140/140 - 1s - loss: 0.6410 - accuracy: 0.8365 - val_loss: 3.4937 - val_accuracy: 0.6213 - 1s/epoch - 9ms/step\n",
            "Epoch 181/300\n",
            "140/140 - 1s - loss: 0.6108 - accuracy: 0.8354 - val_loss: 4.0064 - val_accuracy: 0.5980 - 1s/epoch - 9ms/step\n",
            "Epoch 182/300\n",
            "140/140 - 1s - loss: 0.5550 - accuracy: 0.8444 - val_loss: 3.9013 - val_accuracy: 0.5936 - 1s/epoch - 9ms/step\n",
            "Epoch 183/300\n",
            "140/140 - 1s - loss: 0.5374 - accuracy: 0.8459 - val_loss: 3.5518 - val_accuracy: 0.6195 - 1s/epoch - 9ms/step\n",
            "Epoch 184/300\n",
            "140/140 - 1s - loss: 0.6156 - accuracy: 0.8415 - val_loss: 3.7888 - val_accuracy: 0.6303 - 1s/epoch - 9ms/step\n",
            "Epoch 185/300\n",
            "140/140 - 1s - loss: 0.5227 - accuracy: 0.8383 - val_loss: 4.1397 - val_accuracy: 0.5998 - 1s/epoch - 9ms/step\n",
            "Epoch 186/300\n",
            "140/140 - 1s - loss: 0.5308 - accuracy: 0.8542 - val_loss: 4.7847 - val_accuracy: 0.6016 - 1s/epoch - 9ms/step\n",
            "Epoch 187/300\n",
            "140/140 - 1s - loss: 0.5520 - accuracy: 0.8468 - val_loss: 4.2879 - val_accuracy: 0.6106 - 1s/epoch - 9ms/step\n",
            "Epoch 188/300\n",
            "140/140 - 1s - loss: 0.4808 - accuracy: 0.8560 - val_loss: 4.6644 - val_accuracy: 0.6258 - 1s/epoch - 9ms/step\n",
            "Epoch 189/300\n",
            "140/140 - 1s - loss: 0.4827 - accuracy: 0.8578 - val_loss: 4.2163 - val_accuracy: 0.6124 - 1s/epoch - 9ms/step\n",
            "Epoch 190/300\n",
            "140/140 - 1s - loss: 0.4503 - accuracy: 0.8645 - val_loss: 3.7886 - val_accuracy: 0.6338 - 1s/epoch - 9ms/step\n",
            "Epoch 191/300\n",
            "140/140 - 1s - loss: 0.5620 - accuracy: 0.8524 - val_loss: 3.1672 - val_accuracy: 0.6231 - 1s/epoch - 9ms/step\n",
            "Epoch 192/300\n",
            "140/140 - 1s - loss: 0.7031 - accuracy: 0.8361 - val_loss: 3.0343 - val_accuracy: 0.5980 - 1s/epoch - 9ms/step\n",
            "Epoch 193/300\n",
            "140/140 - 1s - loss: 0.6013 - accuracy: 0.8462 - val_loss: 2.6806 - val_accuracy: 0.6079 - 1s/epoch - 9ms/step\n",
            "Epoch 194/300\n",
            "140/140 - 1s - loss: 0.5780 - accuracy: 0.8466 - val_loss: 3.0137 - val_accuracy: 0.6249 - 1s/epoch - 9ms/step\n",
            "Epoch 195/300\n",
            "140/140 - 1s - loss: 0.5483 - accuracy: 0.8491 - val_loss: 3.8356 - val_accuracy: 0.6052 - 1s/epoch - 9ms/step\n",
            "Epoch 196/300\n",
            "140/140 - 1s - loss: 0.4811 - accuracy: 0.8536 - val_loss: 4.4592 - val_accuracy: 0.6097 - 1s/epoch - 9ms/step\n",
            "Epoch 197/300\n",
            "140/140 - 1s - loss: 0.6396 - accuracy: 0.8466 - val_loss: 4.3506 - val_accuracy: 0.6097 - 1s/epoch - 9ms/step\n",
            "Epoch 198/300\n",
            "140/140 - 1s - loss: 0.5931 - accuracy: 0.8504 - val_loss: 3.4706 - val_accuracy: 0.6150 - 1s/epoch - 9ms/step\n",
            "Epoch 199/300\n",
            "140/140 - 1s - loss: 0.5903 - accuracy: 0.8415 - val_loss: 3.5633 - val_accuracy: 0.5998 - 1s/epoch - 9ms/step\n",
            "Epoch 200/300\n",
            "140/140 - 1s - loss: 0.4853 - accuracy: 0.8542 - val_loss: 3.7062 - val_accuracy: 0.6258 - 1s/epoch - 9ms/step\n",
            "Epoch 201/300\n",
            "140/140 - 1s - loss: 0.4937 - accuracy: 0.8607 - val_loss: 3.9383 - val_accuracy: 0.6240 - 1s/epoch - 9ms/step\n",
            "Epoch 202/300\n",
            "140/140 - 1s - loss: 0.4756 - accuracy: 0.8659 - val_loss: 4.3040 - val_accuracy: 0.6195 - 1s/epoch - 9ms/step\n",
            "Epoch 203/300\n",
            "140/140 - 1s - loss: 0.6133 - accuracy: 0.8645 - val_loss: 3.8351 - val_accuracy: 0.5971 - 1s/epoch - 9ms/step\n",
            "Epoch 204/300\n",
            "140/140 - 1s - loss: 0.6739 - accuracy: 0.8430 - val_loss: 4.1062 - val_accuracy: 0.6249 - 1s/epoch - 9ms/step\n",
            "Epoch 205/300\n",
            "140/140 - 1s - loss: 0.5029 - accuracy: 0.8515 - val_loss: 4.7079 - val_accuracy: 0.6195 - 1s/epoch - 9ms/step\n",
            "Epoch 206/300\n",
            "140/140 - 1s - loss: 0.5084 - accuracy: 0.8587 - val_loss: 4.7068 - val_accuracy: 0.5936 - 1s/epoch - 9ms/step\n",
            "Epoch 207/300\n",
            "140/140 - 1s - loss: 0.5792 - accuracy: 0.8457 - val_loss: 3.8386 - val_accuracy: 0.6132 - 1s/epoch - 9ms/step\n",
            "Epoch 208/300\n",
            "140/140 - 1s - loss: 0.4170 - accuracy: 0.8634 - val_loss: 3.9117 - val_accuracy: 0.5927 - 1s/epoch - 9ms/step\n",
            "Epoch 209/300\n",
            "140/140 - 1s - loss: 0.4525 - accuracy: 0.8643 - val_loss: 3.3135 - val_accuracy: 0.6258 - 1s/epoch - 9ms/step\n",
            "Epoch 210/300\n",
            "140/140 - 1s - loss: 0.4005 - accuracy: 0.8730 - val_loss: 3.2163 - val_accuracy: 0.6213 - 1s/epoch - 9ms/step\n",
            "Epoch 211/300\n",
            "140/140 - 1s - loss: 0.3772 - accuracy: 0.8766 - val_loss: 3.3321 - val_accuracy: 0.6204 - 1s/epoch - 9ms/step\n",
            "Epoch 212/300\n",
            "140/140 - 1s - loss: 0.3963 - accuracy: 0.8739 - val_loss: 4.4401 - val_accuracy: 0.6455 - 1s/epoch - 9ms/step\n",
            "Epoch 213/300\n",
            "140/140 - 1s - loss: 0.4828 - accuracy: 0.8683 - val_loss: 3.2462 - val_accuracy: 0.6294 - 1s/epoch - 9ms/step\n",
            "Epoch 214/300\n",
            "140/140 - 1s - loss: 0.5483 - accuracy: 0.8471 - val_loss: 4.2001 - val_accuracy: 0.6097 - 1s/epoch - 9ms/step\n",
            "Epoch 215/300\n",
            "140/140 - 1s - loss: 0.5636 - accuracy: 0.8567 - val_loss: 3.9507 - val_accuracy: 0.6338 - 1s/epoch - 9ms/step\n",
            "Epoch 216/300\n",
            "140/140 - 1s - loss: 0.6285 - accuracy: 0.8560 - val_loss: 4.1058 - val_accuracy: 0.6150 - 1s/epoch - 9ms/step\n",
            "Epoch 217/300\n",
            "140/140 - 1s - loss: 0.5279 - accuracy: 0.8446 - val_loss: 4.8875 - val_accuracy: 0.5855 - 1s/epoch - 9ms/step\n",
            "Epoch 218/300\n",
            "140/140 - 1s - loss: 0.5010 - accuracy: 0.8565 - val_loss: 4.1826 - val_accuracy: 0.6419 - 1s/epoch - 9ms/step\n",
            "Epoch 219/300\n",
            "140/140 - 1s - loss: 0.5155 - accuracy: 0.8562 - val_loss: 4.4223 - val_accuracy: 0.6159 - 1s/epoch - 9ms/step\n",
            "Epoch 220/300\n",
            "140/140 - 1s - loss: 0.5227 - accuracy: 0.8596 - val_loss: 4.8738 - val_accuracy: 0.6079 - 1s/epoch - 9ms/step\n",
            "Epoch 221/300\n",
            "140/140 - 1s - loss: 0.4772 - accuracy: 0.8567 - val_loss: 5.2102 - val_accuracy: 0.6285 - 1s/epoch - 9ms/step\n",
            "Epoch 222/300\n",
            "140/140 - 1s - loss: 0.5262 - accuracy: 0.8609 - val_loss: 3.9851 - val_accuracy: 0.6106 - 1s/epoch - 9ms/step\n",
            "Epoch 223/300\n",
            "140/140 - 1s - loss: 0.4282 - accuracy: 0.8648 - val_loss: 4.1832 - val_accuracy: 0.6491 - 1s/epoch - 9ms/step\n",
            "Epoch 224/300\n",
            "140/140 - 1s - loss: 0.4481 - accuracy: 0.8704 - val_loss: 4.0972 - val_accuracy: 0.6276 - 1s/epoch - 9ms/step\n",
            "Epoch 225/300\n",
            "140/140 - 1s - loss: 0.4468 - accuracy: 0.8746 - val_loss: 4.3981 - val_accuracy: 0.6186 - 1s/epoch - 9ms/step\n",
            "Epoch 226/300\n",
            "140/140 - 1s - loss: 0.4656 - accuracy: 0.8650 - val_loss: 4.0128 - val_accuracy: 0.6115 - 1s/epoch - 9ms/step\n",
            "Epoch 227/300\n",
            "140/140 - 1s - loss: 0.4736 - accuracy: 0.8746 - val_loss: 3.9902 - val_accuracy: 0.6321 - 1s/epoch - 9ms/step\n",
            "Epoch 228/300\n",
            "140/140 - 1s - loss: 0.5086 - accuracy: 0.8515 - val_loss: 3.4215 - val_accuracy: 0.6267 - 1s/epoch - 9ms/step\n",
            "Epoch 229/300\n",
            "140/140 - 1s - loss: 0.5029 - accuracy: 0.8569 - val_loss: 4.0718 - val_accuracy: 0.6177 - 1s/epoch - 9ms/step\n",
            "Epoch 230/300\n",
            "140/140 - 1s - loss: 0.4446 - accuracy: 0.8645 - val_loss: 3.9951 - val_accuracy: 0.6132 - 1s/epoch - 9ms/step\n",
            "Epoch 231/300\n",
            "140/140 - 1s - loss: 0.5360 - accuracy: 0.8636 - val_loss: 4.5069 - val_accuracy: 0.6141 - 1s/epoch - 9ms/step\n",
            "Epoch 232/300\n",
            "140/140 - 1s - loss: 0.6162 - accuracy: 0.8549 - val_loss: 3.8810 - val_accuracy: 0.6061 - 1s/epoch - 9ms/step\n",
            "Epoch 233/300\n",
            "140/140 - 1s - loss: 0.4351 - accuracy: 0.8674 - val_loss: 4.6266 - val_accuracy: 0.6168 - 1s/epoch - 9ms/step\n",
            "Epoch 234/300\n",
            "140/140 - 1s - loss: 0.4222 - accuracy: 0.8735 - val_loss: 4.7795 - val_accuracy: 0.6177 - 1s/epoch - 9ms/step\n",
            "Epoch 235/300\n",
            "140/140 - 1s - loss: 0.4946 - accuracy: 0.8654 - val_loss: 5.0679 - val_accuracy: 0.6070 - 1s/epoch - 9ms/step\n",
            "Epoch 236/300\n",
            "140/140 - 1s - loss: 0.4598 - accuracy: 0.8735 - val_loss: 4.0157 - val_accuracy: 0.6052 - 1s/epoch - 9ms/step\n",
            "Epoch 237/300\n",
            "140/140 - 1s - loss: 0.4690 - accuracy: 0.8724 - val_loss: 4.1824 - val_accuracy: 0.6159 - 1s/epoch - 9ms/step\n",
            "Epoch 238/300\n",
            "140/140 - 1s - loss: 0.4710 - accuracy: 0.8733 - val_loss: 4.0520 - val_accuracy: 0.6186 - 1s/epoch - 9ms/step\n",
            "Epoch 239/300\n",
            "140/140 - 1s - loss: 0.4160 - accuracy: 0.8733 - val_loss: 4.6752 - val_accuracy: 0.6303 - 1s/epoch - 9ms/step\n",
            "Epoch 240/300\n",
            "140/140 - 1s - loss: 0.4249 - accuracy: 0.8811 - val_loss: 4.9949 - val_accuracy: 0.6097 - 1s/epoch - 9ms/step\n",
            "Epoch 241/300\n",
            "140/140 - 1s - loss: 0.6280 - accuracy: 0.8657 - val_loss: 4.5781 - val_accuracy: 0.6267 - 1s/epoch - 9ms/step\n",
            "Epoch 242/300\n",
            "140/140 - 1s - loss: 0.5564 - accuracy: 0.8596 - val_loss: 4.1931 - val_accuracy: 0.6258 - 1s/epoch - 9ms/step\n",
            "Epoch 243/300\n",
            "140/140 - 1s - loss: 0.4664 - accuracy: 0.8663 - val_loss: 4.6839 - val_accuracy: 0.6043 - 1s/epoch - 9ms/step\n",
            "Epoch 244/300\n",
            "140/140 - 1s - loss: 0.4359 - accuracy: 0.8764 - val_loss: 4.4251 - val_accuracy: 0.5855 - 1s/epoch - 9ms/step\n",
            "Epoch 245/300\n",
            "140/140 - 1s - loss: 0.4041 - accuracy: 0.8760 - val_loss: 4.4654 - val_accuracy: 0.5962 - 1s/epoch - 9ms/step\n",
            "Epoch 246/300\n",
            "140/140 - 1s - loss: 0.4645 - accuracy: 0.8708 - val_loss: 3.6609 - val_accuracy: 0.6204 - 1s/epoch - 9ms/step\n",
            "Epoch 247/300\n",
            "140/140 - 1s - loss: 0.3888 - accuracy: 0.8733 - val_loss: 4.1368 - val_accuracy: 0.6329 - 1s/epoch - 9ms/step\n",
            "Epoch 248/300\n",
            "140/140 - 1s - loss: 0.4449 - accuracy: 0.8746 - val_loss: 4.6617 - val_accuracy: 0.6097 - 1s/epoch - 9ms/step\n",
            "Epoch 249/300\n",
            "140/140 - 1s - loss: 0.5841 - accuracy: 0.8645 - val_loss: 3.3777 - val_accuracy: 0.6204 - 1s/epoch - 9ms/step\n",
            "Epoch 250/300\n",
            "140/140 - 1s - loss: 0.4830 - accuracy: 0.8598 - val_loss: 4.1019 - val_accuracy: 0.6195 - 1s/epoch - 9ms/step\n",
            "Epoch 251/300\n",
            "140/140 - 1s - loss: 0.4226 - accuracy: 0.8715 - val_loss: 4.8041 - val_accuracy: 0.6159 - 1s/epoch - 9ms/step\n",
            "Epoch 252/300\n",
            "140/140 - 1s - loss: 0.3834 - accuracy: 0.8804 - val_loss: 4.9784 - val_accuracy: 0.6222 - 1s/epoch - 9ms/step\n",
            "Epoch 253/300\n",
            "140/140 - 1s - loss: 0.4345 - accuracy: 0.8721 - val_loss: 5.5265 - val_accuracy: 0.6267 - 1s/epoch - 9ms/step\n",
            "Epoch 254/300\n",
            "140/140 - 1s - loss: 0.4904 - accuracy: 0.8708 - val_loss: 4.4935 - val_accuracy: 0.6294 - 1s/epoch - 9ms/step\n",
            "Epoch 255/300\n",
            "140/140 - 1s - loss: 0.4651 - accuracy: 0.8733 - val_loss: 4.8454 - val_accuracy: 0.6204 - 1s/epoch - 9ms/step\n",
            "Epoch 256/300\n",
            "140/140 - 1s - loss: 0.4359 - accuracy: 0.8815 - val_loss: 4.9280 - val_accuracy: 0.6294 - 1s/epoch - 9ms/step\n",
            "Epoch 257/300\n",
            "140/140 - 1s - loss: 0.4671 - accuracy: 0.8782 - val_loss: 4.4086 - val_accuracy: 0.6473 - 1s/epoch - 9ms/step\n",
            "Epoch 258/300\n",
            "140/140 - 1s - loss: 0.6428 - accuracy: 0.8596 - val_loss: 4.1291 - val_accuracy: 0.6321 - 1s/epoch - 9ms/step\n",
            "Epoch 259/300\n",
            "140/140 - 1s - loss: 0.4611 - accuracy: 0.8715 - val_loss: 4.5236 - val_accuracy: 0.6258 - 1s/epoch - 9ms/step\n",
            "Epoch 260/300\n",
            "140/140 - 1s - loss: 0.3553 - accuracy: 0.8889 - val_loss: 4.5470 - val_accuracy: 0.6079 - 1s/epoch - 9ms/step\n",
            "Epoch 261/300\n",
            "140/140 - 1s - loss: 0.3972 - accuracy: 0.8865 - val_loss: 5.4145 - val_accuracy: 0.6150 - 1s/epoch - 9ms/step\n",
            "Epoch 262/300\n",
            "140/140 - 1s - loss: 0.4329 - accuracy: 0.8807 - val_loss: 4.4037 - val_accuracy: 0.6088 - 1s/epoch - 9ms/step\n",
            "Epoch 263/300\n",
            "140/140 - 1s - loss: 0.5186 - accuracy: 0.8623 - val_loss: 5.7540 - val_accuracy: 0.5801 - 1s/epoch - 9ms/step\n",
            "Epoch 264/300\n",
            "140/140 - 1s - loss: 0.4828 - accuracy: 0.8717 - val_loss: 3.7505 - val_accuracy: 0.6240 - 1s/epoch - 9ms/step\n",
            "Epoch 265/300\n",
            "140/140 - 1s - loss: 0.4282 - accuracy: 0.8748 - val_loss: 3.9560 - val_accuracy: 0.6338 - 1s/epoch - 9ms/step\n",
            "Epoch 266/300\n",
            "140/140 - 1s - loss: 0.4380 - accuracy: 0.8746 - val_loss: 5.7158 - val_accuracy: 0.6016 - 1s/epoch - 9ms/step\n",
            "Epoch 267/300\n",
            "140/140 - 1s - loss: 0.4289 - accuracy: 0.8775 - val_loss: 5.7016 - val_accuracy: 0.6070 - 1s/epoch - 9ms/step\n",
            "Epoch 268/300\n",
            "140/140 - 1s - loss: 0.3996 - accuracy: 0.8780 - val_loss: 5.5858 - val_accuracy: 0.6061 - 1s/epoch - 9ms/step\n",
            "Epoch 269/300\n",
            "140/140 - 1s - loss: 0.4178 - accuracy: 0.8795 - val_loss: 5.3292 - val_accuracy: 0.6097 - 1s/epoch - 9ms/step\n",
            "Epoch 270/300\n",
            "140/140 - 1s - loss: 0.4573 - accuracy: 0.8782 - val_loss: 5.1138 - val_accuracy: 0.5873 - 1s/epoch - 9ms/step\n",
            "Epoch 271/300\n",
            "140/140 - 1s - loss: 0.3620 - accuracy: 0.8874 - val_loss: 5.1943 - val_accuracy: 0.6231 - 1s/epoch - 9ms/step\n",
            "Epoch 272/300\n",
            "140/140 - 1s - loss: 0.4915 - accuracy: 0.8773 - val_loss: 6.0326 - val_accuracy: 0.5962 - 1s/epoch - 9ms/step\n",
            "Epoch 273/300\n",
            "140/140 - 1s - loss: 0.6575 - accuracy: 0.8688 - val_loss: 4.8568 - val_accuracy: 0.5891 - 1s/epoch - 9ms/step\n",
            "Epoch 274/300\n",
            "140/140 - 1s - loss: 0.6091 - accuracy: 0.8569 - val_loss: 4.3506 - val_accuracy: 0.6070 - 1s/epoch - 9ms/step\n",
            "Epoch 275/300\n",
            "140/140 - 1s - loss: 0.5033 - accuracy: 0.8627 - val_loss: 5.2869 - val_accuracy: 0.6025 - 1s/epoch - 9ms/step\n",
            "Epoch 276/300\n",
            "140/140 - 1s - loss: 0.4686 - accuracy: 0.8730 - val_loss: 5.3263 - val_accuracy: 0.6070 - 1s/epoch - 9ms/step\n",
            "Epoch 277/300\n",
            "140/140 - 1s - loss: 0.4175 - accuracy: 0.8831 - val_loss: 5.2519 - val_accuracy: 0.6132 - 1s/epoch - 9ms/step\n",
            "Epoch 278/300\n",
            "140/140 - 1s - loss: 0.4695 - accuracy: 0.8786 - val_loss: 5.3129 - val_accuracy: 0.6419 - 1s/epoch - 9ms/step\n",
            "Epoch 279/300\n",
            "140/140 - 1s - loss: 0.6107 - accuracy: 0.8733 - val_loss: 6.1744 - val_accuracy: 0.6132 - 1s/epoch - 9ms/step\n",
            "Epoch 280/300\n",
            "140/140 - 1s - loss: 0.5416 - accuracy: 0.8571 - val_loss: 6.3383 - val_accuracy: 0.6258 - 1s/epoch - 9ms/step\n",
            "Epoch 281/300\n",
            "140/140 - 1s - loss: 0.5953 - accuracy: 0.8657 - val_loss: 4.4128 - val_accuracy: 0.6061 - 1s/epoch - 9ms/step\n",
            "Epoch 282/300\n",
            "140/140 - 1s - loss: 0.4203 - accuracy: 0.8708 - val_loss: 4.8371 - val_accuracy: 0.6195 - 1s/epoch - 9ms/step\n",
            "Epoch 283/300\n",
            "140/140 - 1s - loss: 0.4387 - accuracy: 0.8751 - val_loss: 5.0050 - val_accuracy: 0.6240 - 1s/epoch - 9ms/step\n",
            "Epoch 284/300\n",
            "140/140 - 1s - loss: 0.3390 - accuracy: 0.8918 - val_loss: 4.9581 - val_accuracy: 0.6141 - 1s/epoch - 9ms/step\n",
            "Epoch 285/300\n",
            "140/140 - 1s - loss: 0.3728 - accuracy: 0.8865 - val_loss: 5.0668 - val_accuracy: 0.6097 - 1s/epoch - 9ms/step\n",
            "Epoch 286/300\n",
            "140/140 - 1s - loss: 0.3831 - accuracy: 0.8842 - val_loss: 4.8623 - val_accuracy: 0.6267 - 1s/epoch - 9ms/step\n",
            "Epoch 287/300\n",
            "140/140 - 1s - loss: 0.4118 - accuracy: 0.8818 - val_loss: 4.4838 - val_accuracy: 0.6222 - 1s/epoch - 9ms/step\n",
            "Epoch 288/300\n",
            "140/140 - 1s - loss: 0.4187 - accuracy: 0.8824 - val_loss: 4.2506 - val_accuracy: 0.6338 - 1s/epoch - 9ms/step\n",
            "Epoch 289/300\n",
            "140/140 - 1s - loss: 0.4631 - accuracy: 0.8786 - val_loss: 4.2834 - val_accuracy: 0.6267 - 1s/epoch - 9ms/step\n",
            "Epoch 290/300\n",
            "140/140 - 1s - loss: 0.3544 - accuracy: 0.8925 - val_loss: 4.4086 - val_accuracy: 0.6374 - 1s/epoch - 9ms/step\n",
            "Epoch 291/300\n",
            "140/140 - 1s - loss: 0.3753 - accuracy: 0.8936 - val_loss: 5.1508 - val_accuracy: 0.6258 - 1s/epoch - 9ms/step\n",
            "Epoch 292/300\n",
            "140/140 - 1s - loss: 0.5055 - accuracy: 0.8791 - val_loss: 4.7672 - val_accuracy: 0.6097 - 1s/epoch - 9ms/step\n",
            "Epoch 293/300\n",
            "140/140 - 1s - loss: 0.5774 - accuracy: 0.8645 - val_loss: 6.2464 - val_accuracy: 0.5953 - 1s/epoch - 9ms/step\n",
            "Epoch 294/300\n",
            "140/140 - 1s - loss: 0.7651 - accuracy: 0.8569 - val_loss: 5.2712 - val_accuracy: 0.6079 - 1s/epoch - 9ms/step\n",
            "Epoch 295/300\n",
            "140/140 - 1s - loss: 0.5069 - accuracy: 0.8699 - val_loss: 5.0689 - val_accuracy: 0.6526 - 1s/epoch - 9ms/step\n",
            "Epoch 296/300\n",
            "140/140 - 1s - loss: 0.4728 - accuracy: 0.8804 - val_loss: 4.8397 - val_accuracy: 0.6249 - 1s/epoch - 9ms/step\n",
            "Epoch 297/300\n",
            "140/140 - 1s - loss: 0.4186 - accuracy: 0.8820 - val_loss: 5.6649 - val_accuracy: 0.6428 - 1s/epoch - 9ms/step\n",
            "Epoch 298/300\n",
            "140/140 - 1s - loss: 0.3646 - accuracy: 0.8901 - val_loss: 5.0956 - val_accuracy: 0.6231 - 1s/epoch - 9ms/step\n",
            "Epoch 299/300\n",
            "140/140 - 1s - loss: 0.4370 - accuracy: 0.8880 - val_loss: 5.0447 - val_accuracy: 0.6195 - 1s/epoch - 9ms/step\n",
            "Epoch 300/300\n",
            "140/140 - 1s - loss: 0.6176 - accuracy: 0.8815 - val_loss: 4.6771 - val_accuracy: 0.6356 - 1s/epoch - 9ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # Save the model to disk\n",
        "# model.save('/content/drive/MyDrive/Thesis_Keras/PiczakCNN/data/saved_models/spectro')"
      ],
      "metadata": {
        "id": "Z8jHfvnOnw1G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# score = model.evaluate(\n",
        "#         x=X_test,\n",
        "#         y=Y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ujLL2n-o-bu8",
        "outputId": "c832bfd1-51dc-45fe-b900-4ce475a5b4ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "55/55 [==============================] - 0s 4ms/step - loss: 5.8573 - accuracy: 0.6539\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "模型名称： PiczakCNN\n",
        "\n",
        "准确度： 0.6539"
      ],
      "metadata": {
        "id": "nGuO4KB__puz"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vLAkLFThlOBF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# mfccs = extract_feature(examplePath)\n",
        "# plt.figure(figsize=(20,5))\n",
        "# librosa.display.specshow(mfccs, sr=22050, x_axis='time', cmap='viridis')\n",
        "# plt.colorbar()\n",
        "# plt.show()\n",
        "# print (mfccs.var(axis=1))\n",
        "# print (mfccs.mean(axis=1))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 721
        },
        "id": "yferRfxW1ZSz",
        "outputId": "e3b635d3-efd0-4f6f-e1d8-50199ca4326e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_data.py:236: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
            "  \"Numerical issues were encountered \"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_data.py:255: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
            "  \"Numerical issues were encountered \"\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1440x360 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1.0000001  1.0000001  1.         1.         1.0000001  1.0000001\n",
            " 1.         0.99999994 1.0000001  1.         0.9999998  1.\n",
            " 1.         0.99999994 1.         1.         0.99999994 1.\n",
            " 1.         1.0000001  1.0000001  0.99999994 0.99999994 1.\n",
            " 1.0000001  1.0000001  1.0000001  1.0000001  1.         1.0000001\n",
            " 1.0000001  1.         1.         0.9999998  0.99999994 0.9999998\n",
            " 1.         1.         1.         0.99999994]\n",
            "[-1.1025136e-08  0.0000000e+00  6.8907102e-09  2.7562841e-09\n",
            "  0.0000000e+00  2.2050273e-08  5.5125682e-09  1.1025136e-08\n",
            " -4.1344261e-09  5.5125682e-09 -1.3781420e-09  0.0000000e+00\n",
            " -1.1025136e-08  1.1025136e-08 -1.1025136e-08 -2.2050273e-08\n",
            " -5.5125682e-09 -2.7562841e-09  1.1025136e-08  1.1025136e-08\n",
            "  0.0000000e+00 -5.5125682e-09 -5.5125682e-09  0.0000000e+00\n",
            " -1.1025136e-08 -1.1025136e-08  0.0000000e+00 -2.2050273e-08\n",
            "  0.0000000e+00  0.0000000e+00  0.0000000e+00 -5.5125682e-09\n",
            " -4.1344261e-09  1.1025136e-08 -5.5125682e-09 -5.5125682e-09\n",
            "  7.5797812e-09 -8.2688523e-09  0.0000000e+00  0.0000000e+00]\n"
          ]
        }
      ]
    }
  ]
}