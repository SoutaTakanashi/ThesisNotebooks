{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WPvUKRDOsiVI"
      },
      "source": [
        "##Preprocessing: Mel\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "pd.plotting.register_matplotlib_converters()\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, Flatten, Dense, MaxPool2D, Dropout\n",
        "from tensorflow.keras.utils import to_categorical \n",
        "import os,glob,skimage,librosa\n",
        "import librosa.display\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")    \n",
        "root=\"/content/drive/MyDrive/Thesis_Keras/\"        \n",
        "csvPth = '/content/drive/MyDrive/Thesis_Keras/UrbanSound8K/metadata/UrbanSound8K.csv'\n",
        "examplePath = '/content/drive/MyDrive/Thesis_Keras/UrbanSound8K/audio/fold6/85249-2-0-79.wav'"
      ],
      "metadata": {
        "id": "op1lY4SGE9v0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "r8QjcjeMFxFm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import librosa\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "import keras\n",
        "from scipy import signal\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tqdm import tqdm\n",
        "from tqdm._tqdm import trange\n",
        "from keras.utils import np_utils\n",
        "\n",
        "def readFromCsv(csvpth):\n",
        "    # 生成数据列表\n",
        "    # 读取wav文件函数\n",
        "    #data = pd.read_csv('metadata/UrbanSound8K.csv')\n",
        "    data = pd.read_csv(csvpth)\n",
        "    valid_data = data[['slice_file_name', 'fold', 'classID', 'class']][data['end'] - data['start'] >= 2]\n",
        "    valid_data['path'] = 'fold' + valid_data['fold'].astype('str') + '/' + valid_data['slice_file_name'].astype(\n",
        "        'str')\n",
        "    return valid_data\n",
        "\n",
        "\n",
        "def splitData(current):\n",
        "  \n",
        "  D=[]\n",
        "  i=1\n",
        "\n",
        "  for row in tqdm(current.itertuples(),total=current.shape[0]):\n",
        "        #print(row.path)\n",
        "        #print(row.classID)\n",
        "        #print(f\"{i} out of {len(current)}\")\n",
        "        X, sample_rate = librosa.load(\"/content/drive/MyDrive/Thesis_Keras/UrbanSound8K/audio/\" + row.path, res_type='kaiser_fast', duration=2.97)\n",
        "\n",
        "\n",
        "        mels = librosa.feature.melspectrogram(X, sr=sample_rate,n_mels=40,n_fft=256,\n",
        "                         hop_length=1000)\n",
        "\n",
        "        if mels.shape != (40, 128): \n",
        "          continue\n",
        "        feature = mels\n",
        "        label = row.classID\n",
        "        D.append((feature,label))\n",
        "  dataset = D\n",
        "  X,y=zip(*dataset)\n",
        "  \n",
        "  print(\"type of X is:\",type(X))\n",
        "  y=np.array(y).astype(np.int64)\n",
        "  y = np.array(np_utils.to_categorical(y, 10))\n",
        "\n",
        "  return  X,y\n",
        "\n",
        "\n",
        "def save_npy(nparr,modelName,featureName,subDataset,fold):\n",
        "    import os\n",
        "    dirs = \"drive/MyDrive/Thesis_Keras/TenFoldDataset/datasetnpy\"+'/'+modelName+'/'+featureName+'/'+fold\n",
        "    \n",
        "    #Create a directory to place the dataset npy files.\n",
        "    if not os.path.exists(dirs):\n",
        "        os.makedirs(dirs)\n",
        "        print(f\"Created directory:{dirs}\")\n",
        "    \n",
        "    subDataset+='.npy'\n",
        "    print(subDataset)\n",
        "    subsetPth=os.path.join(dirs,subDataset)\n",
        "    #with open(subsetPth, 'w') as f:\n",
        "    np.save(subsetPth, nparr)\n",
        "    print(f\"save {subDataset} done\")\n",
        "    print(f\"Path:{subsetPth}\")\n",
        "\n",
        "def Ten_fold():\n",
        "    csvPth = '/content/drive/MyDrive/Thesis_Keras/UrbanSound8K/metadata/UrbanSound8K.csv'\n",
        "    #df=pd.read_csv(csvPth)\n",
        "    valid_data=readFromCsv(csvPth)\n",
        "    #valid_data = df[['slice_file_name', 'fold', 'classID', 'class']][df['end'] - df['start']]\n",
        "    # valid_data['path'] = 'fold' + valid_data['fold'].astype('str') + '/' + valid_data['slice_file_name'].astype(\n",
        "    #     'str')\n",
        "    for i in range(10):#Folder : \"fold1\" to \"fold10\"\n",
        "        print(f\"fold:{i+1} out of 10\")\n",
        "        current=valid_data[valid_data['fold'] == i+1]\n",
        "        X,y = splitData(current)\n",
        "        print(\"Dataset split done!\")\n",
        "        print(\"Saving subsets to .npy files!\")\n",
        "        \n",
        "        save_npy(X, 'MelConv1', 'mel', 'X',f\"fold{i+1}\")\n",
        "        save_npy(y, 'MelConv1', 'mel', 'y',f\"fold{i+1}\")"
      ],
      "metadata": {
        "id": "i-DLWDpuFyi5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Ten_fold() # generate 10-fold training and test data packed in .npy files. Easier to be used in later experiments."
      ],
      "metadata": {
        "id": "zwyWiz-CFzwp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "izaNAb8-zRQ3"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "pd.plotting.register_matplotlib_converters()\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, Flatten, Dense, MaxPool2D, Dropout\n",
        "from tensorflow.keras.utils import to_categorical \n",
        "import os,glob,skimage,librosa\n",
        "import librosa.display\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")  "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Then we do 10-fold again..."
      ],
      "metadata": {
        "id": "pWhrFB6JnV9T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ten fold"
      ],
      "metadata": {
        "id": "NWUpoT5axPdo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "def generate_loader(i_val):\n",
        "    train_X = []\n",
        "    train_y=[]\n",
        "    X_test=[]\n",
        "    y_test=[]\n",
        "    for i in range(10):\n",
        "        if i + 1 == i_val:\n",
        "            X_test = np.load(\n",
        "                \"drive/MyDrive/Thesis_Keras/TenFoldDataset/datasetnpy/MelConv1/mel/\"+f\"fold{i + 1}\"+\"/X.npy\"\n",
        "                )\n",
        "            y_test=np.load(\n",
        "                \"drive/MyDrive/Thesis_Keras/TenFoldDataset/datasetnpy/MelConv1/mel/\"+f\"fold{i + 1}\"+\"/y.npy\"\n",
        "            )\n",
        "        else:\n",
        "            X_train = np.load(\n",
        "                \"drive/MyDrive/Thesis_Keras/TenFoldDataset/datasetnpy/MelConv1/mel/\"+f\"fold{i + 1}\"+\"/X.npy\"\n",
        "            )\n",
        "            y_train = np.load(\n",
        "                \"drive/MyDrive/Thesis_Keras/TenFoldDataset/datasetnpy/MelConv1/mel/\"+f\"fold{i + 1}\"+\"/y.npy\"\n",
        "            )\n",
        "\n",
        "            for item in X_train:\n",
        "                train_X.append(item)\n",
        "            for item in y_train:\n",
        "                train_y.append(item)\n",
        "\n",
        "    return np.array(train_X),np.array(train_y),np.array(X_test),np.array(y_test)"
      ],
      "metadata": {
        "id": "0ZdHJrrxxRoD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nsvesYDqz01s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, InputLayer, Dropout, Conv1D, Conv2D, Flatten, Reshape, MaxPooling1D, MaxPooling2D, BatchNormalization, TimeDistributed,AveragePooling1D,AveragePooling2D\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "\n",
        "def build_model(input_length):\n",
        "  model = Sequential()\n",
        "  model.add(Reshape((128,40,1), input_shape=(input_length,128)))\n",
        "  model.add(Conv2D(8, kernel_size=3, activation='relu', kernel_constraint=tf.keras.constraints.MaxNorm(1), padding='same'))\n",
        "  model.add(MaxPooling2D(pool_size=2, strides=2, padding='same'))\n",
        "  model.add(BatchNormalization())\n",
        "  #model.add(Dropout(0.5))\n",
        "  model.add(Conv2D(16, kernel_size=10, activation='relu', kernel_constraint=tf.keras.constraints.MaxNorm(1), padding='same'))\n",
        "  model.add(MaxPooling2D(pool_size=2, strides=2, padding='same'))\n",
        "  model.add(Dropout(0.2))\n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(10, activation='softmax', name='y_pred'))\n",
        "\n",
        "  return model\n",
        "\n",
        "def train_model(model,X_train,Y_train,X_test,Y_test,X_val,Y_val,foldNum):\n",
        "  EPOCHS = 100\n",
        "  # this controls the batch size, or you can manipulate the tf.data.Dataset objects yourself\n",
        "  BATCH_SIZE = 32\n",
        "  callbacks = []\n",
        "  # model architecture\n",
        "  \n",
        "  # this controls the learning rate\n",
        "  opt = Adam(learning_rate=0.005, beta_1=0.9, beta_2=0.999)\n",
        "  #callbacks.append(BatchLoggerCallback(BATCH_SIZE, train_sample_count, epochs=EPOCHS))\n",
        "\n",
        "  # train the neural network\n",
        "  model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
        "\n",
        "  model.fit(X_train,Y_train, batch_size=BATCH_SIZE, epochs=EPOCHS, verbose=2,validation_data=(X_val,Y_val),shuffle=True)\n",
        "  print(model.summary())\n",
        "  # Use this flag to disable per-channel quantization for a model.\n",
        "  # This can reduce RAM usage for convolutional models, but may have\n",
        "  # an impact on accuracy.\n",
        "  disable_per_channel_quantization = False\n",
        "  print(\"Result of fold:\"+f\"{foldNum}\")\n",
        "  score = model.evaluate(\n",
        "        x=X_test,\n",
        "        y=Y_test)"
      ],
      "metadata": {
        "id": "m4zpTkxHxdr8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in tqdm(range(10)):\n",
        "  #from tensorflow.compat.v1.keras import backend as K\n",
        "  import tensorflow as tf\n",
        "\n",
        "  import os\n",
        "  # os.environ[\"TF_FORCE_GPU_ALLOW_GROWTH\"] = \"true\"\n",
        "  # config = tf.compat.v1.ConfigProto()#对session进行参数配置\n",
        "  # config.allow_soft_placement=True #如果你指定的设备不存在，允许TF自动分配设备\n",
        "  # config.gpu_options.per_process_gpu_memory_fraction=0.7#分配百分之七十的显存给程序使用，避免内存溢出，可以自己调整\n",
        "  # config.gpu_options.allow_growth = True#按需分配显存，这个比较重要\n",
        "        \n",
        "  # sess = tf.compat.v1.Session(config=config)\n",
        "  # #tf.compat.v1.keras.backend.set_session(sess)\n",
        "  # #K.set_session(sess)\n",
        "  x_train,y_train,X_test,y_test = generate_loader(i+1)\n",
        "  #print(X_train[1])\n",
        "  #print(y_train[1])\n",
        "  from sklearn.model_selection import train_test_split\n",
        "\n",
        "  X_train, X_val, Y_train, Y_val = train_test_split(x_train,y_train, test_size=0.2)\n",
        "  input_len=len(X_train[0])\n",
        "  print(X_train[0].shape)\n",
        "  model = build_model(input_len)\n",
        "  if not i==0:\n",
        "    model = build_model(input_len)\n",
        "  \n",
        "  train_model(model,X_train,Y_train,X_test,y_test,X_val,Y_val,i+1)\n",
        "  model.save(\"/content/drive/MyDrive/Thesis_Keras/\"+\"model/saved/Trivedi\"+f\"fold{i+1}\"+\".h5\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3zP6n5zixrZV",
        "outputId": "9f3be7a7-c7a1-4e9f-9989-182004765e7a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/10 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(40, 128)\n",
            "Epoch 1/100\n",
            "169/169 - 2s - loss: 2.3121 - accuracy: 0.2493 - val_loss: 2.0423 - val_accuracy: 0.2848 - 2s/epoch - 13ms/step\n",
            "Epoch 2/100\n",
            "169/169 - 1s - loss: 1.9445 - accuracy: 0.3313 - val_loss: 1.9145 - val_accuracy: 0.2974 - 819ms/epoch - 5ms/step\n",
            "Epoch 3/100\n",
            "169/169 - 1s - loss: 1.7648 - accuracy: 0.3858 - val_loss: 1.8435 - val_accuracy: 0.3353 - 812ms/epoch - 5ms/step\n",
            "Epoch 4/100\n",
            "169/169 - 1s - loss: 1.6460 - accuracy: 0.4267 - val_loss: 1.6865 - val_accuracy: 0.4149 - 831ms/epoch - 5ms/step\n",
            "Epoch 5/100\n",
            "169/169 - 1s - loss: 1.5592 - accuracy: 0.4563 - val_loss: 1.7285 - val_accuracy: 0.4119 - 815ms/epoch - 5ms/step\n",
            "Epoch 6/100\n",
            "169/169 - 1s - loss: 1.5569 - accuracy: 0.4593 - val_loss: 1.6022 - val_accuracy: 0.4178 - 820ms/epoch - 5ms/step\n",
            "Epoch 7/100\n",
            "169/169 - 1s - loss: 1.4205 - accuracy: 0.4842 - val_loss: 1.4843 - val_accuracy: 0.4669 - 812ms/epoch - 5ms/step\n",
            "Epoch 8/100\n",
            "169/169 - 1s - loss: 1.3874 - accuracy: 0.5108 - val_loss: 1.4224 - val_accuracy: 0.4967 - 814ms/epoch - 5ms/step\n",
            "Epoch 9/100\n",
            "169/169 - 1s - loss: 1.3274 - accuracy: 0.5281 - val_loss: 1.4091 - val_accuracy: 0.5048 - 811ms/epoch - 5ms/step\n",
            "Epoch 10/100\n",
            "169/169 - 1s - loss: 1.3100 - accuracy: 0.5338 - val_loss: 1.3636 - val_accuracy: 0.5309 - 816ms/epoch - 5ms/step\n",
            "Epoch 11/100\n",
            "169/169 - 1s - loss: 1.2383 - accuracy: 0.5526 - val_loss: 1.4457 - val_accuracy: 0.5033 - 819ms/epoch - 5ms/step\n",
            "Epoch 12/100\n",
            "169/169 - 1s - loss: 1.2258 - accuracy: 0.5759 - val_loss: 1.3382 - val_accuracy: 0.5613 - 809ms/epoch - 5ms/step\n",
            "Epoch 13/100\n",
            "169/169 - 1s - loss: 1.2270 - accuracy: 0.5734 - val_loss: 1.4805 - val_accuracy: 0.5227 - 818ms/epoch - 5ms/step\n",
            "Epoch 14/100\n",
            "169/169 - 1s - loss: 1.2806 - accuracy: 0.5435 - val_loss: 1.3232 - val_accuracy: 0.5465 - 819ms/epoch - 5ms/step\n",
            "Epoch 15/100\n",
            "169/169 - 1s - loss: 1.2006 - accuracy: 0.5720 - val_loss: 1.3375 - val_accuracy: 0.5636 - 815ms/epoch - 5ms/step\n",
            "Epoch 16/100\n",
            "169/169 - 1s - loss: 1.1114 - accuracy: 0.6121 - val_loss: 1.3158 - val_accuracy: 0.5717 - 826ms/epoch - 5ms/step\n",
            "Epoch 17/100\n",
            "169/169 - 1s - loss: 1.1507 - accuracy: 0.5993 - val_loss: 1.3615 - val_accuracy: 0.5480 - 813ms/epoch - 5ms/step\n",
            "Epoch 18/100\n",
            "169/169 - 1s - loss: 1.2505 - accuracy: 0.5584 - val_loss: 1.3826 - val_accuracy: 0.5621 - 817ms/epoch - 5ms/step\n",
            "Epoch 19/100\n",
            "169/169 - 1s - loss: 1.1751 - accuracy: 0.5948 - val_loss: 1.4353 - val_accuracy: 0.5665 - 809ms/epoch - 5ms/step\n",
            "Epoch 20/100\n",
            "169/169 - 1s - loss: 1.2537 - accuracy: 0.5599 - val_loss: 1.3819 - val_accuracy: 0.5375 - 809ms/epoch - 5ms/step\n",
            "Epoch 21/100\n",
            "169/169 - 1s - loss: 1.1474 - accuracy: 0.5926 - val_loss: 1.3652 - val_accuracy: 0.5665 - 812ms/epoch - 5ms/step\n",
            "Epoch 22/100\n",
            "169/169 - 1s - loss: 1.0952 - accuracy: 0.6134 - val_loss: 1.3639 - val_accuracy: 0.5613 - 811ms/epoch - 5ms/step\n",
            "Epoch 23/100\n",
            "169/169 - 1s - loss: 1.2410 - accuracy: 0.5640 - val_loss: 1.5040 - val_accuracy: 0.5494 - 808ms/epoch - 5ms/step\n",
            "Epoch 24/100\n",
            "169/169 - 1s - loss: 1.0801 - accuracy: 0.6177 - val_loss: 1.3934 - val_accuracy: 0.5799 - 804ms/epoch - 5ms/step\n",
            "Epoch 25/100\n",
            "169/169 - 1s - loss: 1.0789 - accuracy: 0.6144 - val_loss: 1.2719 - val_accuracy: 0.5985 - 808ms/epoch - 5ms/step\n",
            "Epoch 26/100\n",
            "169/169 - 1s - loss: 1.0085 - accuracy: 0.6447 - val_loss: 1.3008 - val_accuracy: 0.5963 - 811ms/epoch - 5ms/step\n",
            "Epoch 27/100\n",
            "169/169 - 1s - loss: 0.9465 - accuracy: 0.6653 - val_loss: 1.2313 - val_accuracy: 0.6216 - 811ms/epoch - 5ms/step\n",
            "Epoch 28/100\n",
            "169/169 - 1s - loss: 0.9725 - accuracy: 0.6614 - val_loss: 1.2933 - val_accuracy: 0.6119 - 809ms/epoch - 5ms/step\n",
            "Epoch 29/100\n",
            "169/169 - 1s - loss: 0.9325 - accuracy: 0.6768 - val_loss: 1.1951 - val_accuracy: 0.6253 - 817ms/epoch - 5ms/step\n",
            "Epoch 30/100\n",
            "169/169 - 1s - loss: 0.8575 - accuracy: 0.7027 - val_loss: 1.2902 - val_accuracy: 0.6305 - 818ms/epoch - 5ms/step\n",
            "Epoch 31/100\n",
            "169/169 - 1s - loss: 0.8783 - accuracy: 0.7084 - val_loss: 1.1699 - val_accuracy: 0.6416 - 813ms/epoch - 5ms/step\n",
            "Epoch 32/100\n",
            "169/169 - 1s - loss: 0.8629 - accuracy: 0.7006 - val_loss: 1.1584 - val_accuracy: 0.6387 - 809ms/epoch - 5ms/step\n",
            "Epoch 33/100\n",
            "169/169 - 1s - loss: 0.8637 - accuracy: 0.7049 - val_loss: 1.2205 - val_accuracy: 0.6238 - 815ms/epoch - 5ms/step\n",
            "Epoch 34/100\n",
            "169/169 - 1s - loss: 1.4976 - accuracy: 0.4734 - val_loss: 1.6791 - val_accuracy: 0.4684 - 812ms/epoch - 5ms/step\n",
            "Epoch 35/100\n",
            "169/169 - 1s - loss: 1.2008 - accuracy: 0.5772 - val_loss: 1.4532 - val_accuracy: 0.5896 - 818ms/epoch - 5ms/step\n",
            "Epoch 36/100\n",
            "169/169 - 1s - loss: 1.0521 - accuracy: 0.6259 - val_loss: 1.2645 - val_accuracy: 0.5874 - 817ms/epoch - 5ms/step\n",
            "Epoch 37/100\n",
            "169/169 - 1s - loss: 0.9594 - accuracy: 0.6634 - val_loss: 1.2977 - val_accuracy: 0.6208 - 821ms/epoch - 5ms/step\n",
            "Epoch 38/100\n",
            "169/169 - 1s - loss: 0.9208 - accuracy: 0.6850 - val_loss: 1.2225 - val_accuracy: 0.6357 - 817ms/epoch - 5ms/step\n",
            "Epoch 39/100\n",
            "169/169 - 1s - loss: 0.8182 - accuracy: 0.7090 - val_loss: 1.3914 - val_accuracy: 0.5814 - 812ms/epoch - 5ms/step\n",
            "Epoch 40/100\n",
            "169/169 - 1s - loss: 1.4508 - accuracy: 0.4883 - val_loss: 1.5779 - val_accuracy: 0.5078 - 811ms/epoch - 5ms/step\n",
            "Epoch 41/100\n",
            "169/169 - 1s - loss: 1.1229 - accuracy: 0.6017 - val_loss: 1.3048 - val_accuracy: 0.5985 - 813ms/epoch - 5ms/step\n",
            "Epoch 42/100\n",
            "169/169 - 1s - loss: 1.0909 - accuracy: 0.6181 - val_loss: 1.4939 - val_accuracy: 0.5219 - 827ms/epoch - 5ms/step\n",
            "Epoch 43/100\n",
            "169/169 - 1s - loss: 1.1596 - accuracy: 0.5919 - val_loss: 1.3278 - val_accuracy: 0.5680 - 817ms/epoch - 5ms/step\n",
            "Epoch 44/100\n",
            "169/169 - 1s - loss: 0.9145 - accuracy: 0.6737 - val_loss: 1.2676 - val_accuracy: 0.6164 - 814ms/epoch - 5ms/step\n",
            "Epoch 45/100\n",
            "169/169 - 1s - loss: 0.8606 - accuracy: 0.6962 - val_loss: 1.3161 - val_accuracy: 0.6037 - 822ms/epoch - 5ms/step\n",
            "Epoch 46/100\n",
            "169/169 - 1s - loss: 0.8954 - accuracy: 0.6824 - val_loss: 1.2968 - val_accuracy: 0.6558 - 820ms/epoch - 5ms/step\n",
            "Epoch 47/100\n",
            "169/169 - 1s - loss: 0.7716 - accuracy: 0.7295 - val_loss: 1.2710 - val_accuracy: 0.6372 - 821ms/epoch - 5ms/step\n",
            "Epoch 48/100\n",
            "169/169 - 1s - loss: 0.8732 - accuracy: 0.6938 - val_loss: 1.3127 - val_accuracy: 0.6164 - 813ms/epoch - 5ms/step\n",
            "Epoch 49/100\n",
            "169/169 - 1s - loss: 1.5134 - accuracy: 0.4617 - val_loss: 1.5744 - val_accuracy: 0.4677 - 824ms/epoch - 5ms/step\n",
            "Epoch 50/100\n",
            "169/169 - 1s - loss: 1.3080 - accuracy: 0.5370 - val_loss: 1.4738 - val_accuracy: 0.5138 - 821ms/epoch - 5ms/step\n",
            "Epoch 51/100\n",
            "169/169 - 1s - loss: 1.2112 - accuracy: 0.5671 - val_loss: 1.3400 - val_accuracy: 0.5517 - 810ms/epoch - 5ms/step\n",
            "Epoch 52/100\n",
            "169/169 - 1s - loss: 1.0456 - accuracy: 0.6264 - val_loss: 1.2778 - val_accuracy: 0.5926 - 829ms/epoch - 5ms/step\n",
            "Epoch 53/100\n",
            "169/169 - 1s - loss: 0.9959 - accuracy: 0.6439 - val_loss: 1.3910 - val_accuracy: 0.5881 - 808ms/epoch - 5ms/step\n",
            "Epoch 54/100\n",
            "169/169 - 1s - loss: 0.9094 - accuracy: 0.6785 - val_loss: 1.3851 - val_accuracy: 0.5866 - 826ms/epoch - 5ms/step\n",
            "Epoch 55/100\n",
            "169/169 - 1s - loss: 0.9510 - accuracy: 0.6651 - val_loss: 1.1886 - val_accuracy: 0.6327 - 819ms/epoch - 5ms/step\n",
            "Epoch 56/100\n",
            "169/169 - 1s - loss: 0.8312 - accuracy: 0.7129 - val_loss: 1.2213 - val_accuracy: 0.6446 - 811ms/epoch - 5ms/step\n",
            "Epoch 57/100\n",
            "169/169 - 1s - loss: 0.8582 - accuracy: 0.7060 - val_loss: 1.2991 - val_accuracy: 0.6156 - 812ms/epoch - 5ms/step\n",
            "Epoch 58/100\n",
            "169/169 - 1s - loss: 0.8751 - accuracy: 0.7029 - val_loss: 1.2183 - val_accuracy: 0.6372 - 815ms/epoch - 5ms/step\n",
            "Epoch 59/100\n",
            "169/169 - 1s - loss: 0.8974 - accuracy: 0.6861 - val_loss: 1.2403 - val_accuracy: 0.6446 - 816ms/epoch - 5ms/step\n",
            "Epoch 60/100\n",
            "169/169 - 1s - loss: 0.7339 - accuracy: 0.7412 - val_loss: 1.3681 - val_accuracy: 0.5918 - 812ms/epoch - 5ms/step\n",
            "Epoch 61/100\n",
            "169/169 - 1s - loss: 1.6846 - accuracy: 0.4020 - val_loss: 1.3950 - val_accuracy: 0.5361 - 809ms/epoch - 5ms/step\n",
            "Epoch 62/100\n",
            "169/169 - 1s - loss: 1.3165 - accuracy: 0.5286 - val_loss: 1.5146 - val_accuracy: 0.4565 - 812ms/epoch - 5ms/step\n",
            "Epoch 63/100\n",
            "169/169 - 1s - loss: 1.1729 - accuracy: 0.5744 - val_loss: 1.2853 - val_accuracy: 0.5792 - 819ms/epoch - 5ms/step\n",
            "Epoch 64/100\n",
            "169/169 - 1s - loss: 1.0399 - accuracy: 0.6311 - val_loss: 1.4423 - val_accuracy: 0.5903 - 806ms/epoch - 5ms/step\n",
            "Epoch 65/100\n",
            "169/169 - 1s - loss: 1.0528 - accuracy: 0.6331 - val_loss: 2.0075 - val_accuracy: 0.5584 - 819ms/epoch - 5ms/step\n",
            "Epoch 66/100\n",
            "169/169 - 1s - loss: 0.9683 - accuracy: 0.6700 - val_loss: 1.3379 - val_accuracy: 0.6082 - 820ms/epoch - 5ms/step\n",
            "Epoch 67/100\n",
            "169/169 - 1s - loss: 0.8348 - accuracy: 0.7105 - val_loss: 1.2488 - val_accuracy: 0.6387 - 822ms/epoch - 5ms/step\n",
            "Epoch 68/100\n",
            "169/169 - 1s - loss: 0.7619 - accuracy: 0.7406 - val_loss: 1.2811 - val_accuracy: 0.6565 - 810ms/epoch - 5ms/step\n",
            "Epoch 69/100\n",
            "169/169 - 1s - loss: 0.7385 - accuracy: 0.7430 - val_loss: 1.3374 - val_accuracy: 0.6164 - 819ms/epoch - 5ms/step\n",
            "Epoch 70/100\n",
            "169/169 - 1s - loss: 0.7706 - accuracy: 0.7441 - val_loss: 1.2781 - val_accuracy: 0.6208 - 814ms/epoch - 5ms/step\n",
            "Epoch 71/100\n",
            "169/169 - 1s - loss: 1.0993 - accuracy: 0.6119 - val_loss: 1.4028 - val_accuracy: 0.5836 - 816ms/epoch - 5ms/step\n",
            "Epoch 72/100\n",
            "169/169 - 1s - loss: 0.8571 - accuracy: 0.7029 - val_loss: 1.4696 - val_accuracy: 0.6178 - 819ms/epoch - 5ms/step\n",
            "Epoch 73/100\n",
            "169/169 - 1s - loss: 0.7767 - accuracy: 0.7401 - val_loss: 1.4161 - val_accuracy: 0.6201 - 828ms/epoch - 5ms/step\n",
            "Epoch 74/100\n",
            "169/169 - 1s - loss: 0.7514 - accuracy: 0.7432 - val_loss: 1.5045 - val_accuracy: 0.6268 - 827ms/epoch - 5ms/step\n",
            "Epoch 75/100\n",
            "169/169 - 1s - loss: 0.8486 - accuracy: 0.7181 - val_loss: 1.2920 - val_accuracy: 0.6461 - 829ms/epoch - 5ms/step\n",
            "Epoch 76/100\n",
            "169/169 - 1s - loss: 0.7544 - accuracy: 0.7514 - val_loss: 1.2983 - val_accuracy: 0.6431 - 811ms/epoch - 5ms/step\n",
            "Epoch 77/100\n",
            "169/169 - 1s - loss: 0.6880 - accuracy: 0.7765 - val_loss: 1.3475 - val_accuracy: 0.5963 - 821ms/epoch - 5ms/step\n",
            "Epoch 78/100\n",
            "169/169 - 1s - loss: 1.5990 - accuracy: 0.4254 - val_loss: 1.8874 - val_accuracy: 0.3673 - 821ms/epoch - 5ms/step\n",
            "Epoch 79/100\n",
            "169/169 - 1s - loss: 1.6938 - accuracy: 0.3765 - val_loss: 1.8844 - val_accuracy: 0.3509 - 811ms/epoch - 5ms/step\n",
            "Epoch 80/100\n",
            "169/169 - 1s - loss: 1.5464 - accuracy: 0.4563 - val_loss: 1.7169 - val_accuracy: 0.4283 - 819ms/epoch - 5ms/step\n",
            "Epoch 81/100\n",
            "169/169 - 1s - loss: 1.3417 - accuracy: 0.5253 - val_loss: 1.4085 - val_accuracy: 0.5405 - 816ms/epoch - 5ms/step\n",
            "Epoch 82/100\n",
            "169/169 - 1s - loss: 1.2836 - accuracy: 0.5346 - val_loss: 1.5129 - val_accuracy: 0.5316 - 818ms/epoch - 5ms/step\n",
            "Epoch 83/100\n",
            "169/169 - 1s - loss: 1.0828 - accuracy: 0.6145 - val_loss: 1.4096 - val_accuracy: 0.5613 - 819ms/epoch - 5ms/step\n",
            "Epoch 84/100\n",
            "169/169 - 1s - loss: 1.1817 - accuracy: 0.5874 - val_loss: 1.4325 - val_accuracy: 0.5375 - 809ms/epoch - 5ms/step\n",
            "Epoch 85/100\n",
            "169/169 - 1s - loss: 1.2941 - accuracy: 0.5377 - val_loss: 1.5608 - val_accuracy: 0.5011 - 811ms/epoch - 5ms/step\n",
            "Epoch 86/100\n",
            "169/169 - 1s - loss: 1.0991 - accuracy: 0.6112 - val_loss: 1.6410 - val_accuracy: 0.5152 - 817ms/epoch - 5ms/step\n",
            "Epoch 87/100\n",
            "169/169 - 1s - loss: 1.1660 - accuracy: 0.5846 - val_loss: 1.3986 - val_accuracy: 0.5651 - 820ms/epoch - 5ms/step\n",
            "Epoch 88/100\n",
            "169/169 - 1s - loss: 0.9514 - accuracy: 0.6668 - val_loss: 1.3963 - val_accuracy: 0.5933 - 824ms/epoch - 5ms/step\n",
            "Epoch 89/100\n",
            "169/169 - 1s - loss: 0.9766 - accuracy: 0.6547 - val_loss: 1.3970 - val_accuracy: 0.6126 - 818ms/epoch - 5ms/step\n",
            "Epoch 90/100\n",
            "169/169 - 1s - loss: 0.9566 - accuracy: 0.6666 - val_loss: 1.4336 - val_accuracy: 0.6141 - 821ms/epoch - 5ms/step\n",
            "Epoch 91/100\n",
            "169/169 - 1s - loss: 0.9460 - accuracy: 0.6791 - val_loss: 1.4900 - val_accuracy: 0.6349 - 813ms/epoch - 5ms/step\n",
            "Epoch 92/100\n",
            "169/169 - 1s - loss: 0.8473 - accuracy: 0.7066 - val_loss: 1.5142 - val_accuracy: 0.6305 - 814ms/epoch - 5ms/step\n",
            "Epoch 93/100\n",
            "169/169 - 1s - loss: 0.8125 - accuracy: 0.7110 - val_loss: 1.4313 - val_accuracy: 0.6387 - 852ms/epoch - 5ms/step\n",
            "Epoch 94/100\n",
            "169/169 - 1s - loss: 0.7967 - accuracy: 0.7174 - val_loss: 1.4194 - val_accuracy: 0.6097 - 882ms/epoch - 5ms/step\n",
            "Epoch 95/100\n",
            "169/169 - 1s - loss: 0.7933 - accuracy: 0.7259 - val_loss: 1.4196 - val_accuracy: 0.6320 - 885ms/epoch - 5ms/step\n",
            "Epoch 96/100\n",
            "169/169 - 1s - loss: 0.7822 - accuracy: 0.7337 - val_loss: 1.5196 - val_accuracy: 0.6498 - 846ms/epoch - 5ms/step\n",
            "Epoch 97/100\n",
            "169/169 - 1s - loss: 0.7900 - accuracy: 0.7248 - val_loss: 1.4071 - val_accuracy: 0.6297 - 818ms/epoch - 5ms/step\n",
            "Epoch 98/100\n",
            "169/169 - 1s - loss: 0.6811 - accuracy: 0.7588 - val_loss: 1.4666 - val_accuracy: 0.6357 - 819ms/epoch - 5ms/step\n",
            "Epoch 99/100\n",
            "169/169 - 1s - loss: 0.7055 - accuracy: 0.7639 - val_loss: 1.3706 - val_accuracy: 0.6595 - 831ms/epoch - 5ms/step\n",
            "Epoch 100/100\n",
            "169/169 - 1s - loss: 0.7119 - accuracy: 0.7549 - val_loss: 1.3913 - val_accuracy: 0.6506 - 815ms/epoch - 5ms/step\n",
            "Model: \"sequential_23\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " reshape_22 (Reshape)        (None, 128, 40, 1)        0         \n",
            "                                                                 \n",
            " conv2d_44 (Conv2D)          (None, 128, 40, 8)        80        \n",
            "                                                                 \n",
            " max_pooling2d_42 (MaxPoolin  (None, 64, 20, 8)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " batch_normalization_21 (Bat  (None, 64, 20, 8)        32        \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv2d_45 (Conv2D)          (None, 64, 20, 16)        12816     \n",
            "                                                                 \n",
            " max_pooling2d_43 (MaxPoolin  (None, 32, 10, 16)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_21 (Dropout)        (None, 32, 10, 16)        0         \n",
            "                                                                 \n",
            " flatten_21 (Flatten)        (None, 5120)              0         \n",
            "                                                                 \n",
            " y_pred (Dense)              (None, 10)                51210     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 64,138\n",
            "Trainable params: 64,122\n",
            "Non-trainable params: 16\n",
            "_________________________________________________________________\n",
            "None\n",
            "Result of fold:1\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 2.7961 - accuracy: 0.4556\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 10%|█         | 1/10 [01:24<12:42, 84.70s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(40, 128)\n",
            "Epoch 1/100\n",
            "169/169 - 2s - loss: 2.3261 - accuracy: 0.2564 - val_loss: 2.1199 - val_accuracy: 0.2524 - 2s/epoch - 10ms/step\n",
            "Epoch 2/100\n",
            "169/169 - 1s - loss: 2.0197 - accuracy: 0.2997 - val_loss: 2.0399 - val_accuracy: 0.2687 - 819ms/epoch - 5ms/step\n",
            "Epoch 3/100\n",
            "169/169 - 1s - loss: 1.8659 - accuracy: 0.3511 - val_loss: 1.9733 - val_accuracy: 0.3675 - 827ms/epoch - 5ms/step\n",
            "Epoch 4/100\n",
            "169/169 - 1s - loss: 1.7976 - accuracy: 0.3782 - val_loss: 1.9851 - val_accuracy: 0.3623 - 817ms/epoch - 5ms/step\n",
            "Epoch 5/100\n",
            "169/169 - 1s - loss: 1.8054 - accuracy: 0.3680 - val_loss: 2.0677 - val_accuracy: 0.2962 - 822ms/epoch - 5ms/step\n",
            "Epoch 6/100\n",
            "169/169 - 1s - loss: 1.6953 - accuracy: 0.4072 - val_loss: 1.9449 - val_accuracy: 0.4031 - 824ms/epoch - 5ms/step\n",
            "Epoch 7/100\n",
            "169/169 - 1s - loss: 1.6455 - accuracy: 0.4278 - val_loss: 1.9120 - val_accuracy: 0.4499 - 826ms/epoch - 5ms/step\n",
            "Epoch 8/100\n",
            "169/169 - 1s - loss: 1.6071 - accuracy: 0.4551 - val_loss: 1.8161 - val_accuracy: 0.4566 - 815ms/epoch - 5ms/step\n",
            "Epoch 9/100\n",
            "169/169 - 1s - loss: 1.5225 - accuracy: 0.4681 - val_loss: 1.9246 - val_accuracy: 0.4410 - 823ms/epoch - 5ms/step\n",
            "Epoch 10/100\n",
            "169/169 - 1s - loss: 1.6388 - accuracy: 0.4328 - val_loss: 2.2245 - val_accuracy: 0.2829 - 818ms/epoch - 5ms/step\n",
            "Epoch 11/100\n",
            "169/169 - 1s - loss: 1.5232 - accuracy: 0.4729 - val_loss: 1.9101 - val_accuracy: 0.4313 - 816ms/epoch - 5ms/step\n",
            "Epoch 12/100\n",
            "169/169 - 1s - loss: 1.4484 - accuracy: 0.5019 - val_loss: 2.0336 - val_accuracy: 0.4558 - 814ms/epoch - 5ms/step\n",
            "Epoch 13/100\n",
            "169/169 - 1s - loss: 1.3547 - accuracy: 0.5277 - val_loss: 2.0459 - val_accuracy: 0.4499 - 817ms/epoch - 5ms/step\n",
            "Epoch 14/100\n",
            "169/169 - 1s - loss: 1.3379 - accuracy: 0.5447 - val_loss: 1.9237 - val_accuracy: 0.4774 - 818ms/epoch - 5ms/step\n",
            "Epoch 15/100\n",
            "169/169 - 1s - loss: 1.3520 - accuracy: 0.5425 - val_loss: 1.9069 - val_accuracy: 0.4573 - 821ms/epoch - 5ms/step\n",
            "Epoch 16/100\n",
            "169/169 - 1s - loss: 1.2392 - accuracy: 0.5735 - val_loss: 1.8413 - val_accuracy: 0.5471 - 826ms/epoch - 5ms/step\n",
            "Epoch 17/100\n",
            "169/169 - 1s - loss: 1.2200 - accuracy: 0.5774 - val_loss: 1.8409 - val_accuracy: 0.4996 - 822ms/epoch - 5ms/step\n",
            "Epoch 18/100\n",
            "169/169 - 1s - loss: 1.1670 - accuracy: 0.5995 - val_loss: 1.6034 - val_accuracy: 0.5746 - 819ms/epoch - 5ms/step\n",
            "Epoch 19/100\n",
            "169/169 - 1s - loss: 1.1072 - accuracy: 0.6173 - val_loss: 1.7574 - val_accuracy: 0.5293 - 818ms/epoch - 5ms/step\n",
            "Epoch 20/100\n",
            "169/169 - 1s - loss: 1.1481 - accuracy: 0.5997 - val_loss: 1.7412 - val_accuracy: 0.5612 - 816ms/epoch - 5ms/step\n",
            "Epoch 21/100\n",
            "169/169 - 1s - loss: 1.1141 - accuracy: 0.6224 - val_loss: 1.5234 - val_accuracy: 0.5872 - 817ms/epoch - 5ms/step\n",
            "Epoch 22/100\n",
            "169/169 - 1s - loss: 1.0841 - accuracy: 0.6251 - val_loss: 1.6619 - val_accuracy: 0.6102 - 807ms/epoch - 5ms/step\n",
            "Epoch 23/100\n",
            "169/169 - 1s - loss: 1.0356 - accuracy: 0.6517 - val_loss: 1.6517 - val_accuracy: 0.5561 - 822ms/epoch - 5ms/step\n",
            "Epoch 24/100\n",
            "169/169 - 1s - loss: 0.9895 - accuracy: 0.6582 - val_loss: 1.4797 - val_accuracy: 0.6407 - 827ms/epoch - 5ms/step\n",
            "Epoch 25/100\n",
            "169/169 - 1s - loss: 1.0106 - accuracy: 0.6576 - val_loss: 1.5435 - val_accuracy: 0.5984 - 820ms/epoch - 5ms/step\n",
            "Epoch 26/100\n",
            "169/169 - 1s - loss: 1.1346 - accuracy: 0.6077 - val_loss: 1.5379 - val_accuracy: 0.6214 - 829ms/epoch - 5ms/step\n",
            "Epoch 27/100\n",
            "169/169 - 1s - loss: 0.9401 - accuracy: 0.6782 - val_loss: 1.5236 - val_accuracy: 0.6006 - 824ms/epoch - 5ms/step\n",
            "Epoch 28/100\n",
            "169/169 - 1s - loss: 0.9094 - accuracy: 0.6944 - val_loss: 1.5011 - val_accuracy: 0.5961 - 819ms/epoch - 5ms/step\n",
            "Epoch 29/100\n",
            "169/169 - 1s - loss: 0.8823 - accuracy: 0.6972 - val_loss: 1.3778 - val_accuracy: 0.6407 - 830ms/epoch - 5ms/step\n",
            "Epoch 30/100\n",
            "169/169 - 1s - loss: 0.9569 - accuracy: 0.6799 - val_loss: 1.4878 - val_accuracy: 0.6511 - 825ms/epoch - 5ms/step\n",
            "Epoch 31/100\n",
            "169/169 - 1s - loss: 0.8223 - accuracy: 0.7211 - val_loss: 1.5334 - val_accuracy: 0.6392 - 827ms/epoch - 5ms/step\n",
            "Epoch 32/100\n",
            "169/169 - 1s - loss: 0.8631 - accuracy: 0.7150 - val_loss: 1.4092 - val_accuracy: 0.6592 - 820ms/epoch - 5ms/step\n",
            "Epoch 33/100\n",
            "169/169 - 1s - loss: 0.8299 - accuracy: 0.7152 - val_loss: 1.4964 - val_accuracy: 0.6310 - 827ms/epoch - 5ms/step\n",
            "Epoch 34/100\n",
            "169/169 - 1s - loss: 0.7900 - accuracy: 0.7295 - val_loss: 1.5317 - val_accuracy: 0.6392 - 824ms/epoch - 5ms/step\n",
            "Epoch 35/100\n",
            "169/169 - 1s - loss: 0.7658 - accuracy: 0.7390 - val_loss: 1.5055 - val_accuracy: 0.6385 - 819ms/epoch - 5ms/step\n",
            "Epoch 36/100\n",
            "169/169 - 1s - loss: 0.7258 - accuracy: 0.7562 - val_loss: 1.4760 - val_accuracy: 0.6496 - 830ms/epoch - 5ms/step\n",
            "Epoch 37/100\n",
            "169/169 - 1s - loss: 0.7705 - accuracy: 0.7462 - val_loss: 1.4769 - val_accuracy: 0.6526 - 822ms/epoch - 5ms/step\n",
            "Epoch 38/100\n",
            "169/169 - 1s - loss: 0.7262 - accuracy: 0.7544 - val_loss: 1.6161 - val_accuracy: 0.6147 - 827ms/epoch - 5ms/step\n",
            "Epoch 39/100\n",
            "169/169 - 1s - loss: 0.7527 - accuracy: 0.7508 - val_loss: 1.4260 - val_accuracy: 0.6808 - 827ms/epoch - 5ms/step\n",
            "Epoch 40/100\n",
            "169/169 - 1s - loss: 0.6937 - accuracy: 0.7705 - val_loss: 1.6421 - val_accuracy: 0.6466 - 827ms/epoch - 5ms/step\n",
            "Epoch 41/100\n",
            "169/169 - 1s - loss: 0.7538 - accuracy: 0.7462 - val_loss: 1.5393 - val_accuracy: 0.6570 - 827ms/epoch - 5ms/step\n",
            "Epoch 42/100\n",
            "169/169 - 1s - loss: 0.6738 - accuracy: 0.7742 - val_loss: 1.6741 - val_accuracy: 0.6726 - 833ms/epoch - 5ms/step\n",
            "Epoch 43/100\n",
            "169/169 - 1s - loss: 0.6732 - accuracy: 0.7674 - val_loss: 1.6453 - val_accuracy: 0.6385 - 832ms/epoch - 5ms/step\n",
            "Epoch 44/100\n",
            "169/169 - 1s - loss: 0.6459 - accuracy: 0.7830 - val_loss: 1.5960 - val_accuracy: 0.6733 - 825ms/epoch - 5ms/step\n",
            "Epoch 45/100\n",
            "169/169 - 1s - loss: 0.6465 - accuracy: 0.7822 - val_loss: 1.5043 - val_accuracy: 0.6578 - 826ms/epoch - 5ms/step\n",
            "Epoch 46/100\n",
            "169/169 - 1s - loss: 0.7404 - accuracy: 0.7549 - val_loss: 1.4659 - val_accuracy: 0.6615 - 831ms/epoch - 5ms/step\n",
            "Epoch 47/100\n",
            "169/169 - 1s - loss: 0.6772 - accuracy: 0.7768 - val_loss: 1.4921 - val_accuracy: 0.6540 - 826ms/epoch - 5ms/step\n",
            "Epoch 48/100\n",
            "169/169 - 1s - loss: 0.6807 - accuracy: 0.7735 - val_loss: 1.6670 - val_accuracy: 0.6726 - 824ms/epoch - 5ms/step\n",
            "Epoch 49/100\n",
            "169/169 - 1s - loss: 0.7141 - accuracy: 0.7631 - val_loss: 1.5381 - val_accuracy: 0.6875 - 811ms/epoch - 5ms/step\n",
            "Epoch 50/100\n",
            "169/169 - 1s - loss: 0.6203 - accuracy: 0.7859 - val_loss: 1.5319 - val_accuracy: 0.6964 - 815ms/epoch - 5ms/step\n",
            "Epoch 51/100\n",
            "169/169 - 1s - loss: 0.6212 - accuracy: 0.7930 - val_loss: 1.4975 - val_accuracy: 0.6986 - 814ms/epoch - 5ms/step\n",
            "Epoch 52/100\n",
            "169/169 - 1s - loss: 0.6042 - accuracy: 0.7909 - val_loss: 1.6577 - val_accuracy: 0.6964 - 821ms/epoch - 5ms/step\n",
            "Epoch 53/100\n",
            "169/169 - 1s - loss: 0.6000 - accuracy: 0.7947 - val_loss: 1.6272 - val_accuracy: 0.6526 - 812ms/epoch - 5ms/step\n",
            "Epoch 54/100\n",
            "169/169 - 1s - loss: 0.6122 - accuracy: 0.7980 - val_loss: 1.6486 - val_accuracy: 0.6897 - 817ms/epoch - 5ms/step\n",
            "Epoch 55/100\n",
            "169/169 - 1s - loss: 0.6622 - accuracy: 0.7778 - val_loss: 1.6268 - val_accuracy: 0.6719 - 811ms/epoch - 5ms/step\n",
            "Epoch 56/100\n",
            "169/169 - 1s - loss: 0.7562 - accuracy: 0.7425 - val_loss: 1.6547 - val_accuracy: 0.6726 - 816ms/epoch - 5ms/step\n",
            "Epoch 57/100\n",
            "169/169 - 1s - loss: 0.6186 - accuracy: 0.7930 - val_loss: 1.4816 - val_accuracy: 0.6800 - 811ms/epoch - 5ms/step\n",
            "Epoch 58/100\n",
            "169/169 - 1s - loss: 0.5870 - accuracy: 0.8084 - val_loss: 2.1351 - val_accuracy: 0.6644 - 821ms/epoch - 5ms/step\n",
            "Epoch 59/100\n",
            "169/169 - 1s - loss: 0.6089 - accuracy: 0.8023 - val_loss: 1.4811 - val_accuracy: 0.6771 - 825ms/epoch - 5ms/step\n",
            "Epoch 60/100\n",
            "169/169 - 1s - loss: 0.5856 - accuracy: 0.8038 - val_loss: 1.6222 - val_accuracy: 0.6845 - 812ms/epoch - 5ms/step\n",
            "Epoch 61/100\n",
            "169/169 - 1s - loss: 0.5911 - accuracy: 0.8045 - val_loss: 1.5303 - val_accuracy: 0.6808 - 824ms/epoch - 5ms/step\n",
            "Epoch 62/100\n",
            "169/169 - 1s - loss: 0.5420 - accuracy: 0.8192 - val_loss: 1.6444 - val_accuracy: 0.7001 - 821ms/epoch - 5ms/step\n",
            "Epoch 63/100\n",
            "169/169 - 1s - loss: 0.5483 - accuracy: 0.8132 - val_loss: 1.7093 - val_accuracy: 0.6808 - 821ms/epoch - 5ms/step\n",
            "Epoch 64/100\n",
            "169/169 - 1s - loss: 0.5663 - accuracy: 0.8078 - val_loss: 1.5914 - val_accuracy: 0.6830 - 823ms/epoch - 5ms/step\n",
            "Epoch 65/100\n",
            "169/169 - 1s - loss: 0.5334 - accuracy: 0.8179 - val_loss: 1.7000 - val_accuracy: 0.6897 - 815ms/epoch - 5ms/step\n",
            "Epoch 66/100\n",
            "169/169 - 1s - loss: 0.5433 - accuracy: 0.8162 - val_loss: 1.6714 - val_accuracy: 0.6882 - 836ms/epoch - 5ms/step\n",
            "Epoch 67/100\n",
            "169/169 - 1s - loss: 0.5750 - accuracy: 0.8067 - val_loss: 1.8363 - val_accuracy: 0.6459 - 829ms/epoch - 5ms/step\n",
            "Epoch 68/100\n",
            "169/169 - 1s - loss: 0.5886 - accuracy: 0.7960 - val_loss: 1.7002 - val_accuracy: 0.6726 - 828ms/epoch - 5ms/step\n",
            "Epoch 69/100\n",
            "169/169 - 1s - loss: 0.5252 - accuracy: 0.8182 - val_loss: 1.8694 - val_accuracy: 0.6919 - 825ms/epoch - 5ms/step\n",
            "Epoch 70/100\n",
            "169/169 - 1s - loss: 0.5424 - accuracy: 0.8203 - val_loss: 1.6089 - val_accuracy: 0.6837 - 824ms/epoch - 5ms/step\n",
            "Epoch 71/100\n",
            "169/169 - 1s - loss: 0.5555 - accuracy: 0.8201 - val_loss: 1.5943 - val_accuracy: 0.6533 - 830ms/epoch - 5ms/step\n",
            "Epoch 72/100\n",
            "169/169 - 1s - loss: 0.5645 - accuracy: 0.8132 - val_loss: 1.8461 - val_accuracy: 0.7023 - 831ms/epoch - 5ms/step\n",
            "Epoch 73/100\n",
            "169/169 - 1s - loss: 0.5506 - accuracy: 0.8188 - val_loss: 1.7551 - val_accuracy: 0.6696 - 828ms/epoch - 5ms/step\n",
            "Epoch 74/100\n",
            "169/169 - 1s - loss: 0.5699 - accuracy: 0.8166 - val_loss: 1.6156 - val_accuracy: 0.6414 - 829ms/epoch - 5ms/step\n",
            "Epoch 75/100\n",
            "169/169 - 1s - loss: 0.5981 - accuracy: 0.8036 - val_loss: 1.7090 - val_accuracy: 0.6867 - 831ms/epoch - 5ms/step\n",
            "Epoch 76/100\n",
            "169/169 - 1s - loss: 0.5186 - accuracy: 0.8292 - val_loss: 1.7810 - val_accuracy: 0.6741 - 835ms/epoch - 5ms/step\n",
            "Epoch 77/100\n",
            "169/169 - 1s - loss: 0.5488 - accuracy: 0.8138 - val_loss: 1.7051 - val_accuracy: 0.6978 - 833ms/epoch - 5ms/step\n",
            "Epoch 78/100\n",
            "169/169 - 1s - loss: 0.5389 - accuracy: 0.8188 - val_loss: 1.7327 - val_accuracy: 0.6949 - 831ms/epoch - 5ms/step\n",
            "Epoch 79/100\n",
            "169/169 - 1s - loss: 0.5662 - accuracy: 0.8188 - val_loss: 1.6453 - val_accuracy: 0.6696 - 825ms/epoch - 5ms/step\n",
            "Epoch 80/100\n",
            "169/169 - 1s - loss: 0.9365 - accuracy: 0.6987 - val_loss: 1.6708 - val_accuracy: 0.5984 - 827ms/epoch - 5ms/step\n",
            "Epoch 81/100\n",
            "169/169 - 1s - loss: 0.6608 - accuracy: 0.7835 - val_loss: 1.7486 - val_accuracy: 0.6414 - 825ms/epoch - 5ms/step\n",
            "Epoch 82/100\n",
            "169/169 - 1s - loss: 0.6246 - accuracy: 0.8091 - val_loss: 1.7559 - val_accuracy: 0.6563 - 817ms/epoch - 5ms/step\n",
            "Epoch 83/100\n",
            "169/169 - 1s - loss: 0.5821 - accuracy: 0.8084 - val_loss: 1.7916 - val_accuracy: 0.6793 - 826ms/epoch - 5ms/step\n",
            "Epoch 84/100\n",
            "169/169 - 1s - loss: 0.5121 - accuracy: 0.8255 - val_loss: 1.6550 - val_accuracy: 0.6882 - 818ms/epoch - 5ms/step\n",
            "Epoch 85/100\n",
            "169/169 - 1s - loss: 0.4966 - accuracy: 0.8323 - val_loss: 1.7156 - val_accuracy: 0.6852 - 814ms/epoch - 5ms/step\n",
            "Epoch 86/100\n",
            "169/169 - 1s - loss: 0.5077 - accuracy: 0.8340 - val_loss: 1.7619 - val_accuracy: 0.6815 - 825ms/epoch - 5ms/step\n",
            "Epoch 87/100\n",
            "169/169 - 1s - loss: 0.4707 - accuracy: 0.8398 - val_loss: 1.7502 - val_accuracy: 0.6830 - 817ms/epoch - 5ms/step\n",
            "Epoch 88/100\n",
            "169/169 - 1s - loss: 0.4553 - accuracy: 0.8504 - val_loss: 1.8067 - val_accuracy: 0.7164 - 821ms/epoch - 5ms/step\n",
            "Epoch 89/100\n",
            "169/169 - 1s - loss: 0.4766 - accuracy: 0.8379 - val_loss: 1.7193 - val_accuracy: 0.6815 - 816ms/epoch - 5ms/step\n",
            "Epoch 90/100\n",
            "169/169 - 1s - loss: 0.5154 - accuracy: 0.8260 - val_loss: 1.7672 - val_accuracy: 0.6748 - 819ms/epoch - 5ms/step\n",
            "Epoch 91/100\n",
            "169/169 - 1s - loss: 0.4753 - accuracy: 0.8405 - val_loss: 1.7240 - val_accuracy: 0.6563 - 808ms/epoch - 5ms/step\n",
            "Epoch 92/100\n",
            "169/169 - 1s - loss: 0.5581 - accuracy: 0.8218 - val_loss: 1.8737 - val_accuracy: 0.7008 - 818ms/epoch - 5ms/step\n",
            "Epoch 93/100\n",
            "169/169 - 1s - loss: 0.5035 - accuracy: 0.8310 - val_loss: 1.8325 - val_accuracy: 0.6875 - 817ms/epoch - 5ms/step\n",
            "Epoch 94/100\n",
            "169/169 - 1s - loss: 0.4958 - accuracy: 0.8390 - val_loss: 1.6194 - val_accuracy: 0.6644 - 821ms/epoch - 5ms/step\n",
            "Epoch 95/100\n",
            "169/169 - 1s - loss: 0.4888 - accuracy: 0.8401 - val_loss: 1.8943 - val_accuracy: 0.6897 - 824ms/epoch - 5ms/step\n",
            "Epoch 96/100\n",
            "169/169 - 1s - loss: 0.4699 - accuracy: 0.8394 - val_loss: 1.5605 - val_accuracy: 0.6971 - 821ms/epoch - 5ms/step\n",
            "Epoch 97/100\n",
            "169/169 - 1s - loss: 0.5124 - accuracy: 0.8299 - val_loss: 1.6358 - val_accuracy: 0.6785 - 821ms/epoch - 5ms/step\n",
            "Epoch 98/100\n",
            "169/169 - 1s - loss: 0.4604 - accuracy: 0.8450 - val_loss: 1.7912 - val_accuracy: 0.6860 - 817ms/epoch - 5ms/step\n",
            "Epoch 99/100\n",
            "169/169 - 1s - loss: 0.4431 - accuracy: 0.8485 - val_loss: 1.9272 - val_accuracy: 0.6971 - 826ms/epoch - 5ms/step\n",
            "Epoch 100/100\n",
            "169/169 - 1s - loss: 0.4394 - accuracy: 0.8502 - val_loss: 1.9322 - val_accuracy: 0.6949 - 813ms/epoch - 5ms/step\n",
            "Model: \"sequential_25\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " reshape_24 (Reshape)        (None, 128, 40, 1)        0         \n",
            "                                                                 \n",
            " conv2d_48 (Conv2D)          (None, 128, 40, 8)        80        \n",
            "                                                                 \n",
            " max_pooling2d_46 (MaxPoolin  (None, 64, 20, 8)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " batch_normalization_23 (Bat  (None, 64, 20, 8)        32        \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv2d_49 (Conv2D)          (None, 64, 20, 16)        12816     \n",
            "                                                                 \n",
            " max_pooling2d_47 (MaxPoolin  (None, 32, 10, 16)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_23 (Dropout)        (None, 32, 10, 16)        0         \n",
            "                                                                 \n",
            " flatten_23 (Flatten)        (None, 5120)              0         \n",
            "                                                                 \n",
            " y_pred (Dense)              (None, 10)                51210     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 64,138\n",
            "Trainable params: 64,122\n",
            "Non-trainable params: 16\n",
            "_________________________________________________________________\n",
            "None\n",
            "Result of fold:2\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 2.5855 - accuracy: 0.5477\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 20%|██        | 2/10 [02:49<11:18, 84.75s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(40, 128)\n",
            "Epoch 1/100\n",
            "167/167 - 2s - loss: 2.2116 - accuracy: 0.2769 - val_loss: 1.9854 - val_accuracy: 0.3256 - 2s/epoch - 10ms/step\n",
            "Epoch 2/100\n",
            "167/167 - 1s - loss: 1.8676 - accuracy: 0.3629 - val_loss: 1.7421 - val_accuracy: 0.3968 - 809ms/epoch - 5ms/step\n",
            "Epoch 3/100\n",
            "167/167 - 1s - loss: 1.6744 - accuracy: 0.4146 - val_loss: 1.6896 - val_accuracy: 0.4501 - 805ms/epoch - 5ms/step\n",
            "Epoch 4/100\n",
            "167/167 - 1s - loss: 1.6420 - accuracy: 0.4475 - val_loss: 1.7940 - val_accuracy: 0.3323 - 807ms/epoch - 5ms/step\n",
            "Epoch 5/100\n",
            "167/167 - 1s - loss: 1.5996 - accuracy: 0.4602 - val_loss: 1.9149 - val_accuracy: 0.4321 - 814ms/epoch - 5ms/step\n",
            "Epoch 6/100\n",
            "167/167 - 1s - loss: 1.4422 - accuracy: 0.5099 - val_loss: 1.7088 - val_accuracy: 0.4501 - 814ms/epoch - 5ms/step\n",
            "Epoch 7/100\n",
            "167/167 - 1s - loss: 1.3703 - accuracy: 0.5308 - val_loss: 1.6295 - val_accuracy: 0.5094 - 806ms/epoch - 5ms/step\n",
            "Epoch 8/100\n",
            "167/167 - 1s - loss: 1.3280 - accuracy: 0.5561 - val_loss: 1.6921 - val_accuracy: 0.4734 - 803ms/epoch - 5ms/step\n",
            "Epoch 9/100\n",
            "167/167 - 1s - loss: 1.3355 - accuracy: 0.5463 - val_loss: 1.4882 - val_accuracy: 0.5551 - 804ms/epoch - 5ms/step\n",
            "Epoch 10/100\n",
            "167/167 - 1s - loss: 1.2905 - accuracy: 0.5608 - val_loss: 1.8956 - val_accuracy: 0.5004 - 810ms/epoch - 5ms/step\n",
            "Epoch 11/100\n",
            "167/167 - 1s - loss: 1.1767 - accuracy: 0.6038 - val_loss: 1.5950 - val_accuracy: 0.5394 - 815ms/epoch - 5ms/step\n",
            "Epoch 12/100\n",
            "167/167 - 1s - loss: 1.1802 - accuracy: 0.6032 - val_loss: 1.6330 - val_accuracy: 0.5589 - 803ms/epoch - 5ms/step\n",
            "Epoch 13/100\n",
            "167/167 - 1s - loss: 1.0723 - accuracy: 0.6356 - val_loss: 1.4020 - val_accuracy: 0.6189 - 805ms/epoch - 5ms/step\n",
            "Epoch 14/100\n",
            "167/167 - 1s - loss: 1.0397 - accuracy: 0.6456 - val_loss: 1.3958 - val_accuracy: 0.6062 - 801ms/epoch - 5ms/step\n",
            "Epoch 15/100\n",
            "167/167 - 1s - loss: 1.0314 - accuracy: 0.6512 - val_loss: 1.4535 - val_accuracy: 0.6174 - 802ms/epoch - 5ms/step\n",
            "Epoch 16/100\n",
            "167/167 - 1s - loss: 0.9599 - accuracy: 0.6668 - val_loss: 1.4289 - val_accuracy: 0.6332 - 814ms/epoch - 5ms/step\n",
            "Epoch 17/100\n",
            "167/167 - 1s - loss: 0.9490 - accuracy: 0.6762 - val_loss: 1.4128 - val_accuracy: 0.6257 - 801ms/epoch - 5ms/step\n",
            "Epoch 18/100\n",
            "167/167 - 1s - loss: 0.8995 - accuracy: 0.6964 - val_loss: 1.4250 - val_accuracy: 0.6519 - 805ms/epoch - 5ms/step\n",
            "Epoch 19/100\n",
            "167/167 - 1s - loss: 0.8939 - accuracy: 0.6951 - val_loss: 1.5411 - val_accuracy: 0.6354 - 812ms/epoch - 5ms/step\n",
            "Epoch 20/100\n",
            "167/167 - 1s - loss: 0.8555 - accuracy: 0.6981 - val_loss: 1.4833 - val_accuracy: 0.6512 - 807ms/epoch - 5ms/step\n",
            "Epoch 21/100\n",
            "167/167 - 1s - loss: 0.8944 - accuracy: 0.7002 - val_loss: 1.6632 - val_accuracy: 0.6519 - 809ms/epoch - 5ms/step\n",
            "Epoch 22/100\n",
            "167/167 - 1s - loss: 0.8556 - accuracy: 0.7062 - val_loss: 1.6905 - val_accuracy: 0.5836 - 811ms/epoch - 5ms/step\n",
            "Epoch 23/100\n",
            "167/167 - 1s - loss: 0.8483 - accuracy: 0.7139 - val_loss: 1.4565 - val_accuracy: 0.6692 - 804ms/epoch - 5ms/step\n",
            "Epoch 24/100\n",
            "167/167 - 1s - loss: 0.8643 - accuracy: 0.7073 - val_loss: 1.4292 - val_accuracy: 0.6564 - 799ms/epoch - 5ms/step\n",
            "Epoch 25/100\n",
            "167/167 - 1s - loss: 0.7805 - accuracy: 0.7340 - val_loss: 1.4067 - val_accuracy: 0.6414 - 806ms/epoch - 5ms/step\n",
            "Epoch 26/100\n",
            "167/167 - 1s - loss: 0.7522 - accuracy: 0.7462 - val_loss: 1.4348 - val_accuracy: 0.6407 - 819ms/epoch - 5ms/step\n",
            "Epoch 27/100\n",
            "167/167 - 1s - loss: 0.7483 - accuracy: 0.7452 - val_loss: 1.3039 - val_accuracy: 0.6602 - 816ms/epoch - 5ms/step\n",
            "Epoch 28/100\n",
            "167/167 - 1s - loss: 0.7290 - accuracy: 0.7510 - val_loss: 1.4107 - val_accuracy: 0.6309 - 822ms/epoch - 5ms/step\n",
            "Epoch 29/100\n",
            "167/167 - 1s - loss: 0.7628 - accuracy: 0.7439 - val_loss: 1.5146 - val_accuracy: 0.6339 - 824ms/epoch - 5ms/step\n",
            "Epoch 30/100\n",
            "167/167 - 1s - loss: 0.7653 - accuracy: 0.7460 - val_loss: 1.3742 - val_accuracy: 0.6542 - 816ms/epoch - 5ms/step\n",
            "Epoch 31/100\n",
            "167/167 - 1s - loss: 0.7345 - accuracy: 0.7561 - val_loss: 1.3338 - val_accuracy: 0.6767 - 819ms/epoch - 5ms/step\n",
            "Epoch 32/100\n",
            "167/167 - 1s - loss: 0.7066 - accuracy: 0.7629 - val_loss: 1.4823 - val_accuracy: 0.6174 - 802ms/epoch - 5ms/step\n",
            "Epoch 33/100\n",
            "167/167 - 1s - loss: 1.0276 - accuracy: 0.6475 - val_loss: 1.4965 - val_accuracy: 0.6662 - 820ms/epoch - 5ms/step\n",
            "Epoch 34/100\n",
            "167/167 - 1s - loss: 0.6854 - accuracy: 0.7630 - val_loss: 1.4702 - val_accuracy: 0.6504 - 818ms/epoch - 5ms/step\n",
            "Epoch 35/100\n",
            "167/167 - 1s - loss: 0.7441 - accuracy: 0.7597 - val_loss: 1.4036 - val_accuracy: 0.6564 - 818ms/epoch - 5ms/step\n",
            "Epoch 36/100\n",
            "167/167 - 1s - loss: 0.6649 - accuracy: 0.7777 - val_loss: 1.3245 - val_accuracy: 0.6834 - 804ms/epoch - 5ms/step\n",
            "Epoch 37/100\n",
            "167/167 - 1s - loss: 0.6438 - accuracy: 0.7786 - val_loss: 1.4870 - val_accuracy: 0.6452 - 806ms/epoch - 5ms/step\n",
            "Epoch 38/100\n",
            "167/167 - 1s - loss: 0.6399 - accuracy: 0.7788 - val_loss: 1.4771 - val_accuracy: 0.6527 - 811ms/epoch - 5ms/step\n",
            "Epoch 39/100\n",
            "167/167 - 1s - loss: 0.6503 - accuracy: 0.7809 - val_loss: 1.4763 - val_accuracy: 0.6714 - 817ms/epoch - 5ms/step\n",
            "Epoch 40/100\n",
            "167/167 - 1s - loss: 0.6280 - accuracy: 0.7837 - val_loss: 1.4257 - val_accuracy: 0.7014 - 816ms/epoch - 5ms/step\n",
            "Epoch 41/100\n",
            "167/167 - 1s - loss: 0.6422 - accuracy: 0.7916 - val_loss: 1.4921 - val_accuracy: 0.6834 - 818ms/epoch - 5ms/step\n",
            "Epoch 42/100\n",
            "167/167 - 1s - loss: 0.5917 - accuracy: 0.7932 - val_loss: 1.4576 - val_accuracy: 0.7172 - 818ms/epoch - 5ms/step\n",
            "Epoch 43/100\n",
            "167/167 - 1s - loss: 0.5755 - accuracy: 0.8036 - val_loss: 1.3386 - val_accuracy: 0.7142 - 804ms/epoch - 5ms/step\n",
            "Epoch 44/100\n",
            "167/167 - 1s - loss: 0.5426 - accuracy: 0.8163 - val_loss: 1.4091 - val_accuracy: 0.7337 - 819ms/epoch - 5ms/step\n",
            "Epoch 45/100\n",
            "167/167 - 1s - loss: 0.5601 - accuracy: 0.8182 - val_loss: 1.4689 - val_accuracy: 0.7307 - 800ms/epoch - 5ms/step\n",
            "Epoch 46/100\n",
            "167/167 - 1s - loss: 0.5834 - accuracy: 0.8079 - val_loss: 1.3138 - val_accuracy: 0.7082 - 803ms/epoch - 5ms/step\n",
            "Epoch 47/100\n",
            "167/167 - 1s - loss: 0.5227 - accuracy: 0.8289 - val_loss: 1.3455 - val_accuracy: 0.7239 - 811ms/epoch - 5ms/step\n",
            "Epoch 48/100\n",
            "167/167 - 1s - loss: 0.5400 - accuracy: 0.8193 - val_loss: 1.6026 - val_accuracy: 0.7404 - 808ms/epoch - 5ms/step\n",
            "Epoch 49/100\n",
            "167/167 - 1s - loss: 0.5134 - accuracy: 0.8280 - val_loss: 1.4558 - val_accuracy: 0.7427 - 808ms/epoch - 5ms/step\n",
            "Epoch 50/100\n",
            "167/167 - 1s - loss: 0.4799 - accuracy: 0.8268 - val_loss: 1.3368 - val_accuracy: 0.7397 - 800ms/epoch - 5ms/step\n",
            "Epoch 51/100\n",
            "167/167 - 1s - loss: 0.5234 - accuracy: 0.8238 - val_loss: 1.4108 - val_accuracy: 0.7479 - 804ms/epoch - 5ms/step\n",
            "Epoch 52/100\n",
            "167/167 - 1s - loss: 0.4708 - accuracy: 0.8411 - val_loss: 1.5899 - val_accuracy: 0.7172 - 804ms/epoch - 5ms/step\n",
            "Epoch 53/100\n",
            "167/167 - 1s - loss: 0.5219 - accuracy: 0.8368 - val_loss: 1.5755 - val_accuracy: 0.7449 - 793ms/epoch - 5ms/step\n",
            "Epoch 54/100\n",
            "167/167 - 1s - loss: 0.5295 - accuracy: 0.8216 - val_loss: 1.4727 - val_accuracy: 0.7239 - 796ms/epoch - 5ms/step\n",
            "Epoch 55/100\n",
            "167/167 - 1s - loss: 0.4549 - accuracy: 0.8475 - val_loss: 1.4904 - val_accuracy: 0.7359 - 799ms/epoch - 5ms/step\n",
            "Epoch 56/100\n",
            "167/167 - 1s - loss: 0.4898 - accuracy: 0.8341 - val_loss: 1.6042 - val_accuracy: 0.7254 - 804ms/epoch - 5ms/step\n",
            "Epoch 57/100\n",
            "167/167 - 1s - loss: 0.4759 - accuracy: 0.8450 - val_loss: 1.5513 - val_accuracy: 0.7352 - 805ms/epoch - 5ms/step\n",
            "Epoch 58/100\n",
            "167/167 - 1s - loss: 0.4774 - accuracy: 0.8460 - val_loss: 1.4684 - val_accuracy: 0.7382 - 845ms/epoch - 5ms/step\n",
            "Epoch 59/100\n",
            "167/167 - 1s - loss: 0.4948 - accuracy: 0.8381 - val_loss: 1.3451 - val_accuracy: 0.7269 - 893ms/epoch - 5ms/step\n",
            "Epoch 60/100\n",
            "167/167 - 1s - loss: 0.4490 - accuracy: 0.8537 - val_loss: 1.4129 - val_accuracy: 0.7239 - 892ms/epoch - 5ms/step\n",
            "Epoch 61/100\n",
            "167/167 - 1s - loss: 0.4390 - accuracy: 0.8533 - val_loss: 1.5118 - val_accuracy: 0.7449 - 815ms/epoch - 5ms/step\n",
            "Epoch 62/100\n",
            "167/167 - 1s - loss: 0.4010 - accuracy: 0.8696 - val_loss: 1.4340 - val_accuracy: 0.7322 - 804ms/epoch - 5ms/step\n",
            "Epoch 63/100\n",
            "167/167 - 1s - loss: 0.5888 - accuracy: 0.8124 - val_loss: 1.3824 - val_accuracy: 0.7157 - 808ms/epoch - 5ms/step\n",
            "Epoch 64/100\n",
            "167/167 - 1s - loss: 0.4668 - accuracy: 0.8437 - val_loss: 1.5518 - val_accuracy: 0.7404 - 799ms/epoch - 5ms/step\n",
            "Epoch 65/100\n",
            "167/167 - 1s - loss: 0.4062 - accuracy: 0.8647 - val_loss: 1.7657 - val_accuracy: 0.7509 - 808ms/epoch - 5ms/step\n",
            "Epoch 66/100\n",
            "167/167 - 1s - loss: 0.4706 - accuracy: 0.8426 - val_loss: 1.4431 - val_accuracy: 0.7427 - 799ms/epoch - 5ms/step\n",
            "Epoch 67/100\n",
            "167/167 - 1s - loss: 0.3867 - accuracy: 0.8698 - val_loss: 1.6117 - val_accuracy: 0.7502 - 803ms/epoch - 5ms/step\n",
            "Epoch 68/100\n",
            "167/167 - 1s - loss: 0.3740 - accuracy: 0.8750 - val_loss: 1.6117 - val_accuracy: 0.7434 - 808ms/epoch - 5ms/step\n",
            "Epoch 69/100\n",
            "167/167 - 1s - loss: 0.4197 - accuracy: 0.8668 - val_loss: 1.4951 - val_accuracy: 0.7314 - 799ms/epoch - 5ms/step\n",
            "Epoch 70/100\n",
            "167/167 - 1s - loss: 0.3823 - accuracy: 0.8692 - val_loss: 1.6006 - val_accuracy: 0.7532 - 810ms/epoch - 5ms/step\n",
            "Epoch 71/100\n",
            "167/167 - 1s - loss: 0.4065 - accuracy: 0.8649 - val_loss: 1.6970 - val_accuracy: 0.7404 - 804ms/epoch - 5ms/step\n",
            "Epoch 72/100\n",
            "167/167 - 1s - loss: 0.3793 - accuracy: 0.8713 - val_loss: 1.5442 - val_accuracy: 0.7382 - 806ms/epoch - 5ms/step\n",
            "Epoch 73/100\n",
            "167/167 - 1s - loss: 0.3796 - accuracy: 0.8739 - val_loss: 1.4418 - val_accuracy: 0.6819 - 803ms/epoch - 5ms/step\n",
            "Epoch 74/100\n",
            "167/167 - 1s - loss: 0.4026 - accuracy: 0.8799 - val_loss: 1.5085 - val_accuracy: 0.7322 - 805ms/epoch - 5ms/step\n",
            "Epoch 75/100\n",
            "167/167 - 1s - loss: 0.3746 - accuracy: 0.8747 - val_loss: 1.4181 - val_accuracy: 0.7652 - 806ms/epoch - 5ms/step\n",
            "Epoch 76/100\n",
            "167/167 - 1s - loss: 0.3380 - accuracy: 0.8844 - val_loss: 1.4874 - val_accuracy: 0.7524 - 803ms/epoch - 5ms/step\n",
            "Epoch 77/100\n",
            "167/167 - 1s - loss: 0.4003 - accuracy: 0.8681 - val_loss: 1.7002 - val_accuracy: 0.7209 - 811ms/epoch - 5ms/step\n",
            "Epoch 78/100\n",
            "167/167 - 1s - loss: 0.4222 - accuracy: 0.8629 - val_loss: 1.6756 - val_accuracy: 0.7382 - 799ms/epoch - 5ms/step\n",
            "Epoch 79/100\n",
            "167/167 - 1s - loss: 0.5646 - accuracy: 0.8300 - val_loss: 1.6232 - val_accuracy: 0.7397 - 803ms/epoch - 5ms/step\n",
            "Epoch 80/100\n",
            "167/167 - 1s - loss: 0.3557 - accuracy: 0.8799 - val_loss: 1.7138 - val_accuracy: 0.7442 - 804ms/epoch - 5ms/step\n",
            "Epoch 81/100\n",
            "167/167 - 1s - loss: 0.3349 - accuracy: 0.8872 - val_loss: 1.8115 - val_accuracy: 0.7434 - 804ms/epoch - 5ms/step\n",
            "Epoch 82/100\n",
            "167/167 - 1s - loss: 0.3429 - accuracy: 0.8908 - val_loss: 1.7054 - val_accuracy: 0.7442 - 811ms/epoch - 5ms/step\n",
            "Epoch 83/100\n",
            "167/167 - 1s - loss: 0.3711 - accuracy: 0.8824 - val_loss: 1.6481 - val_accuracy: 0.7442 - 809ms/epoch - 5ms/step\n",
            "Epoch 84/100\n",
            "167/167 - 1s - loss: 0.3450 - accuracy: 0.8874 - val_loss: 1.8881 - val_accuracy: 0.7322 - 811ms/epoch - 5ms/step\n",
            "Epoch 85/100\n",
            "167/167 - 1s - loss: 0.3048 - accuracy: 0.8974 - val_loss: 1.7413 - val_accuracy: 0.7449 - 808ms/epoch - 5ms/step\n",
            "Epoch 86/100\n",
            "167/167 - 1s - loss: 0.3317 - accuracy: 0.8944 - val_loss: 1.4385 - val_accuracy: 0.7359 - 808ms/epoch - 5ms/step\n",
            "Epoch 87/100\n",
            "167/167 - 1s - loss: 0.3258 - accuracy: 0.8944 - val_loss: 1.6977 - val_accuracy: 0.7404 - 809ms/epoch - 5ms/step\n",
            "Epoch 88/100\n",
            "167/167 - 1s - loss: 0.4274 - accuracy: 0.8717 - val_loss: 1.9298 - val_accuracy: 0.7359 - 794ms/epoch - 5ms/step\n",
            "Epoch 89/100\n",
            "167/167 - 1s - loss: 0.5305 - accuracy: 0.8362 - val_loss: 2.0272 - val_accuracy: 0.7524 - 800ms/epoch - 5ms/step\n",
            "Epoch 90/100\n",
            "167/167 - 1s - loss: 0.3141 - accuracy: 0.8992 - val_loss: 1.8221 - val_accuracy: 0.7104 - 797ms/epoch - 5ms/step\n",
            "Epoch 91/100\n",
            "167/167 - 1s - loss: 0.3641 - accuracy: 0.8882 - val_loss: 1.7816 - val_accuracy: 0.7412 - 806ms/epoch - 5ms/step\n",
            "Epoch 92/100\n",
            "167/167 - 1s - loss: 0.3069 - accuracy: 0.8998 - val_loss: 1.8278 - val_accuracy: 0.7322 - 809ms/epoch - 5ms/step\n",
            "Epoch 93/100\n",
            "167/167 - 1s - loss: 0.2702 - accuracy: 0.9056 - val_loss: 1.9524 - val_accuracy: 0.7622 - 814ms/epoch - 5ms/step\n",
            "Epoch 94/100\n",
            "167/167 - 1s - loss: 0.3088 - accuracy: 0.8959 - val_loss: 1.5856 - val_accuracy: 0.7479 - 810ms/epoch - 5ms/step\n",
            "Epoch 95/100\n",
            "167/167 - 1s - loss: 0.3386 - accuracy: 0.8946 - val_loss: 1.7706 - val_accuracy: 0.7299 - 803ms/epoch - 5ms/step\n",
            "Epoch 96/100\n",
            "167/167 - 1s - loss: 0.2924 - accuracy: 0.9021 - val_loss: 1.9077 - val_accuracy: 0.7404 - 805ms/epoch - 5ms/step\n",
            "Epoch 97/100\n",
            "167/167 - 1s - loss: 0.3781 - accuracy: 0.8957 - val_loss: 2.2547 - val_accuracy: 0.7202 - 809ms/epoch - 5ms/step\n",
            "Epoch 98/100\n",
            "167/167 - 1s - loss: 0.3348 - accuracy: 0.8863 - val_loss: 1.5590 - val_accuracy: 0.7584 - 799ms/epoch - 5ms/step\n",
            "Epoch 99/100\n",
            "167/167 - 1s - loss: 0.2990 - accuracy: 0.9060 - val_loss: 1.6322 - val_accuracy: 0.7464 - 805ms/epoch - 5ms/step\n",
            "Epoch 100/100\n",
            "167/167 - 1s - loss: 0.3139 - accuracy: 0.9026 - val_loss: 1.6243 - val_accuracy: 0.7389 - 804ms/epoch - 5ms/step\n",
            "Model: \"sequential_27\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " reshape_26 (Reshape)        (None, 128, 40, 1)        0         \n",
            "                                                                 \n",
            " conv2d_52 (Conv2D)          (None, 128, 40, 8)        80        \n",
            "                                                                 \n",
            " max_pooling2d_50 (MaxPoolin  (None, 64, 20, 8)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " batch_normalization_25 (Bat  (None, 64, 20, 8)        32        \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv2d_53 (Conv2D)          (None, 64, 20, 16)        12816     \n",
            "                                                                 \n",
            " max_pooling2d_51 (MaxPoolin  (None, 32, 10, 16)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_25 (Dropout)        (None, 32, 10, 16)        0         \n",
            "                                                                 \n",
            " flatten_25 (Flatten)        (None, 5120)              0         \n",
            "                                                                 \n",
            " y_pred (Dense)              (None, 10)                51210     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 64,138\n",
            "Trainable params: 64,122\n",
            "Non-trainable params: 16\n",
            "_________________________________________________________________\n",
            "None\n",
            "Result of fold:3\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 3.7627 - accuracy: 0.4160\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 30%|███       | 3/10 [04:13<09:49, 84.26s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(40, 128)\n",
            "Epoch 1/100\n",
            "167/167 - 2s - loss: 2.2475 - accuracy: 0.2374 - val_loss: 2.0711 - val_accuracy: 0.2472 - 2s/epoch - 10ms/step\n",
            "Epoch 2/100\n",
            "167/167 - 1s - loss: 1.8746 - accuracy: 0.3549 - val_loss: 1.8459 - val_accuracy: 0.4012 - 812ms/epoch - 5ms/step\n",
            "Epoch 3/100\n",
            "167/167 - 1s - loss: 1.7001 - accuracy: 0.4147 - val_loss: 1.8372 - val_accuracy: 0.4125 - 804ms/epoch - 5ms/step\n",
            "Epoch 4/100\n",
            "167/167 - 1s - loss: 1.6169 - accuracy: 0.4506 - val_loss: 1.7282 - val_accuracy: 0.4305 - 809ms/epoch - 5ms/step\n",
            "Epoch 5/100\n",
            "167/167 - 1s - loss: 1.5023 - accuracy: 0.4694 - val_loss: 1.7752 - val_accuracy: 0.4523 - 808ms/epoch - 5ms/step\n",
            "Epoch 6/100\n",
            "167/167 - 1s - loss: 1.3907 - accuracy: 0.5167 - val_loss: 1.6723 - val_accuracy: 0.4598 - 805ms/epoch - 5ms/step\n",
            "Epoch 7/100\n",
            "167/167 - 1s - loss: 1.2736 - accuracy: 0.5494 - val_loss: 1.6317 - val_accuracy: 0.4906 - 808ms/epoch - 5ms/step\n",
            "Epoch 8/100\n",
            "167/167 - 1s - loss: 1.2575 - accuracy: 0.5481 - val_loss: 1.4111 - val_accuracy: 0.5770 - 832ms/epoch - 5ms/step\n",
            "Epoch 9/100\n",
            "167/167 - 1s - loss: 1.1619 - accuracy: 0.5898 - val_loss: 1.2811 - val_accuracy: 0.6161 - 801ms/epoch - 5ms/step\n",
            "Epoch 10/100\n",
            "167/167 - 1s - loss: 1.1245 - accuracy: 0.6109 - val_loss: 1.2801 - val_accuracy: 0.6168 - 799ms/epoch - 5ms/step\n",
            "Epoch 11/100\n",
            "167/167 - 1s - loss: 1.0578 - accuracy: 0.6295 - val_loss: 1.3501 - val_accuracy: 0.6326 - 796ms/epoch - 5ms/step\n",
            "Epoch 12/100\n",
            "167/167 - 1s - loss: 1.0406 - accuracy: 0.6363 - val_loss: 1.3242 - val_accuracy: 0.6364 - 802ms/epoch - 5ms/step\n",
            "Epoch 13/100\n",
            "167/167 - 1s - loss: 1.0246 - accuracy: 0.6393 - val_loss: 1.2065 - val_accuracy: 0.6672 - 788ms/epoch - 5ms/step\n",
            "Epoch 14/100\n",
            "167/167 - 1s - loss: 1.0028 - accuracy: 0.6530 - val_loss: 1.1515 - val_accuracy: 0.6529 - 800ms/epoch - 5ms/step\n",
            "Epoch 15/100\n",
            "167/167 - 1s - loss: 1.0944 - accuracy: 0.6160 - val_loss: 1.2287 - val_accuracy: 0.6589 - 798ms/epoch - 5ms/step\n",
            "Epoch 16/100\n",
            "167/167 - 1s - loss: 0.9611 - accuracy: 0.6735 - val_loss: 1.2721 - val_accuracy: 0.6627 - 796ms/epoch - 5ms/step\n",
            "Epoch 17/100\n",
            "167/167 - 1s - loss: 0.9240 - accuracy: 0.6793 - val_loss: 1.3302 - val_accuracy: 0.6491 - 797ms/epoch - 5ms/step\n",
            "Epoch 18/100\n",
            "167/167 - 1s - loss: 0.9178 - accuracy: 0.6711 - val_loss: 1.3619 - val_accuracy: 0.6454 - 798ms/epoch - 5ms/step\n",
            "Epoch 19/100\n",
            "167/167 - 1s - loss: 0.9050 - accuracy: 0.6893 - val_loss: 1.3193 - val_accuracy: 0.6642 - 801ms/epoch - 5ms/step\n",
            "Epoch 20/100\n",
            "167/167 - 1s - loss: 0.9145 - accuracy: 0.6838 - val_loss: 1.2671 - val_accuracy: 0.6634 - 796ms/epoch - 5ms/step\n",
            "Epoch 21/100\n",
            "167/167 - 1s - loss: 0.9018 - accuracy: 0.6882 - val_loss: 1.2898 - val_accuracy: 0.6769 - 796ms/epoch - 5ms/step\n",
            "Epoch 22/100\n",
            "167/167 - 1s - loss: 0.8708 - accuracy: 0.6957 - val_loss: 1.3125 - val_accuracy: 0.6589 - 803ms/epoch - 5ms/step\n",
            "Epoch 23/100\n",
            "167/167 - 1s - loss: 0.8624 - accuracy: 0.6987 - val_loss: 1.3858 - val_accuracy: 0.6153 - 796ms/epoch - 5ms/step\n",
            "Epoch 24/100\n",
            "167/167 - 1s - loss: 0.8936 - accuracy: 0.6836 - val_loss: 1.4440 - val_accuracy: 0.6784 - 804ms/epoch - 5ms/step\n",
            "Epoch 25/100\n",
            "167/167 - 1s - loss: 0.8679 - accuracy: 0.7032 - val_loss: 1.3618 - val_accuracy: 0.6544 - 796ms/epoch - 5ms/step\n",
            "Epoch 26/100\n",
            "167/167 - 1s - loss: 0.8337 - accuracy: 0.7158 - val_loss: 1.6236 - val_accuracy: 0.6529 - 788ms/epoch - 5ms/step\n",
            "Epoch 27/100\n",
            "167/167 - 1s - loss: 0.8585 - accuracy: 0.7107 - val_loss: 1.4658 - val_accuracy: 0.6386 - 799ms/epoch - 5ms/step\n",
            "Epoch 28/100\n",
            "167/167 - 1s - loss: 0.9189 - accuracy: 0.6829 - val_loss: 1.3267 - val_accuracy: 0.6882 - 797ms/epoch - 5ms/step\n",
            "Epoch 29/100\n",
            "167/167 - 1s - loss: 0.8189 - accuracy: 0.7073 - val_loss: 1.4711 - val_accuracy: 0.6634 - 804ms/epoch - 5ms/step\n",
            "Epoch 30/100\n",
            "167/167 - 1s - loss: 0.8209 - accuracy: 0.7092 - val_loss: 1.4482 - val_accuracy: 0.6702 - 812ms/epoch - 5ms/step\n",
            "Epoch 31/100\n",
            "167/167 - 1s - loss: 0.8539 - accuracy: 0.7047 - val_loss: 1.4424 - val_accuracy: 0.6544 - 803ms/epoch - 5ms/step\n",
            "Epoch 32/100\n",
            "167/167 - 1s - loss: 0.8076 - accuracy: 0.7220 - val_loss: 1.5270 - val_accuracy: 0.6739 - 806ms/epoch - 5ms/step\n",
            "Epoch 33/100\n",
            "167/167 - 1s - loss: 0.7914 - accuracy: 0.7246 - val_loss: 1.3490 - val_accuracy: 0.6664 - 797ms/epoch - 5ms/step\n",
            "Epoch 34/100\n",
            "167/167 - 1s - loss: 0.7793 - accuracy: 0.7265 - val_loss: 1.4697 - val_accuracy: 0.6837 - 803ms/epoch - 5ms/step\n",
            "Epoch 35/100\n",
            "167/167 - 1s - loss: 0.7550 - accuracy: 0.7323 - val_loss: 1.4554 - val_accuracy: 0.6814 - 796ms/epoch - 5ms/step\n",
            "Epoch 36/100\n",
            "167/167 - 1s - loss: 0.8004 - accuracy: 0.7197 - val_loss: 1.4836 - val_accuracy: 0.6672 - 791ms/epoch - 5ms/step\n",
            "Epoch 37/100\n",
            "167/167 - 1s - loss: 0.7951 - accuracy: 0.7197 - val_loss: 1.3503 - val_accuracy: 0.7137 - 800ms/epoch - 5ms/step\n",
            "Epoch 38/100\n",
            "167/167 - 1s - loss: 0.8081 - accuracy: 0.7293 - val_loss: 1.3970 - val_accuracy: 0.6566 - 797ms/epoch - 5ms/step\n",
            "Epoch 39/100\n",
            "167/167 - 1s - loss: 0.8169 - accuracy: 0.7205 - val_loss: 1.4339 - val_accuracy: 0.6604 - 808ms/epoch - 5ms/step\n",
            "Epoch 40/100\n",
            "167/167 - 1s - loss: 0.8765 - accuracy: 0.7028 - val_loss: 1.5658 - val_accuracy: 0.6236 - 804ms/epoch - 5ms/step\n",
            "Epoch 41/100\n",
            "167/167 - 1s - loss: 0.7930 - accuracy: 0.7246 - val_loss: 1.5015 - val_accuracy: 0.6687 - 813ms/epoch - 5ms/step\n",
            "Epoch 42/100\n",
            "167/167 - 1s - loss: 0.7954 - accuracy: 0.7284 - val_loss: 1.4190 - val_accuracy: 0.6694 - 791ms/epoch - 5ms/step\n",
            "Epoch 43/100\n",
            "167/167 - 1s - loss: 0.7268 - accuracy: 0.7521 - val_loss: 1.5370 - val_accuracy: 0.6409 - 794ms/epoch - 5ms/step\n",
            "Epoch 44/100\n",
            "167/167 - 1s - loss: 0.7390 - accuracy: 0.7412 - val_loss: 1.5310 - val_accuracy: 0.6484 - 793ms/epoch - 5ms/step\n",
            "Epoch 45/100\n",
            "167/167 - 1s - loss: 0.7642 - accuracy: 0.7370 - val_loss: 1.6251 - val_accuracy: 0.6784 - 802ms/epoch - 5ms/step\n",
            "Epoch 46/100\n",
            "167/167 - 1s - loss: 0.7382 - accuracy: 0.7444 - val_loss: 1.4507 - val_accuracy: 0.6597 - 795ms/epoch - 5ms/step\n",
            "Epoch 47/100\n",
            "167/167 - 1s - loss: 0.7074 - accuracy: 0.7532 - val_loss: 1.4259 - val_accuracy: 0.6769 - 797ms/epoch - 5ms/step\n",
            "Epoch 48/100\n",
            "167/167 - 1s - loss: 0.6827 - accuracy: 0.7523 - val_loss: 1.7101 - val_accuracy: 0.6777 - 797ms/epoch - 5ms/step\n",
            "Epoch 49/100\n",
            "167/167 - 1s - loss: 0.7508 - accuracy: 0.7440 - val_loss: 1.4586 - val_accuracy: 0.6717 - 792ms/epoch - 5ms/step\n",
            "Epoch 50/100\n",
            "167/167 - 1s - loss: 0.7072 - accuracy: 0.7560 - val_loss: 1.4626 - val_accuracy: 0.6912 - 796ms/epoch - 5ms/step\n",
            "Epoch 51/100\n",
            "167/167 - 1s - loss: 0.7652 - accuracy: 0.7353 - val_loss: 1.3527 - val_accuracy: 0.7175 - 795ms/epoch - 5ms/step\n",
            "Epoch 52/100\n",
            "167/167 - 1s - loss: 0.8752 - accuracy: 0.7028 - val_loss: 1.6432 - val_accuracy: 0.6875 - 802ms/epoch - 5ms/step\n",
            "Epoch 53/100\n",
            "167/167 - 1s - loss: 0.7631 - accuracy: 0.7410 - val_loss: 1.4879 - val_accuracy: 0.7070 - 802ms/epoch - 5ms/step\n",
            "Epoch 54/100\n",
            "167/167 - 1s - loss: 0.7159 - accuracy: 0.7592 - val_loss: 1.4903 - val_accuracy: 0.6777 - 802ms/epoch - 5ms/step\n",
            "Epoch 55/100\n",
            "167/167 - 1s - loss: 0.6774 - accuracy: 0.7703 - val_loss: 1.3816 - val_accuracy: 0.7032 - 799ms/epoch - 5ms/step\n",
            "Epoch 56/100\n",
            "167/167 - 1s - loss: 0.6551 - accuracy: 0.7718 - val_loss: 1.5158 - val_accuracy: 0.7213 - 802ms/epoch - 5ms/step\n",
            "Epoch 57/100\n",
            "167/167 - 1s - loss: 0.6831 - accuracy: 0.7645 - val_loss: 1.4842 - val_accuracy: 0.6521 - 802ms/epoch - 5ms/step\n",
            "Epoch 58/100\n",
            "167/167 - 1s - loss: 0.6712 - accuracy: 0.7707 - val_loss: 1.4116 - val_accuracy: 0.7145 - 796ms/epoch - 5ms/step\n",
            "Epoch 59/100\n",
            "167/167 - 1s - loss: 0.6530 - accuracy: 0.7795 - val_loss: 1.5652 - val_accuracy: 0.6995 - 793ms/epoch - 5ms/step\n",
            "Epoch 60/100\n",
            "167/167 - 1s - loss: 0.6576 - accuracy: 0.7707 - val_loss: 1.5704 - val_accuracy: 0.7190 - 808ms/epoch - 5ms/step\n",
            "Epoch 61/100\n",
            "167/167 - 1s - loss: 0.6565 - accuracy: 0.7756 - val_loss: 1.4314 - val_accuracy: 0.7100 - 801ms/epoch - 5ms/step\n",
            "Epoch 62/100\n",
            "167/167 - 1s - loss: 0.7557 - accuracy: 0.7289 - val_loss: 1.6060 - val_accuracy: 0.7002 - 799ms/epoch - 5ms/step\n",
            "Epoch 63/100\n",
            "167/167 - 1s - loss: 0.6803 - accuracy: 0.7637 - val_loss: 1.6055 - val_accuracy: 0.6905 - 803ms/epoch - 5ms/step\n",
            "Epoch 64/100\n",
            "167/167 - 1s - loss: 0.6501 - accuracy: 0.7748 - val_loss: 1.5840 - val_accuracy: 0.6679 - 795ms/epoch - 5ms/step\n",
            "Epoch 65/100\n",
            "167/167 - 1s - loss: 0.6774 - accuracy: 0.7724 - val_loss: 1.7401 - val_accuracy: 0.7047 - 799ms/epoch - 5ms/step\n",
            "Epoch 66/100\n",
            "167/167 - 1s - loss: 0.7102 - accuracy: 0.7562 - val_loss: 1.5813 - val_accuracy: 0.6905 - 796ms/epoch - 5ms/step\n",
            "Epoch 67/100\n",
            "167/167 - 1s - loss: 0.6601 - accuracy: 0.7763 - val_loss: 1.5758 - val_accuracy: 0.7122 - 798ms/epoch - 5ms/step\n",
            "Epoch 68/100\n",
            "167/167 - 1s - loss: 0.6396 - accuracy: 0.7823 - val_loss: 1.5376 - val_accuracy: 0.7130 - 800ms/epoch - 5ms/step\n",
            "Epoch 69/100\n",
            "167/167 - 1s - loss: 0.6286 - accuracy: 0.7868 - val_loss: 1.4621 - val_accuracy: 0.7062 - 800ms/epoch - 5ms/step\n",
            "Epoch 70/100\n",
            "167/167 - 1s - loss: 0.6537 - accuracy: 0.7765 - val_loss: 1.5277 - val_accuracy: 0.6980 - 802ms/epoch - 5ms/step\n",
            "Epoch 71/100\n",
            "167/167 - 1s - loss: 0.5889 - accuracy: 0.7972 - val_loss: 1.6363 - val_accuracy: 0.7077 - 791ms/epoch - 5ms/step\n",
            "Epoch 72/100\n",
            "167/167 - 1s - loss: 0.6575 - accuracy: 0.7774 - val_loss: 1.5661 - val_accuracy: 0.6799 - 798ms/epoch - 5ms/step\n",
            "Epoch 73/100\n",
            "167/167 - 1s - loss: 0.6193 - accuracy: 0.7895 - val_loss: 1.6360 - val_accuracy: 0.7348 - 793ms/epoch - 5ms/step\n",
            "Epoch 74/100\n",
            "167/167 - 1s - loss: 0.5806 - accuracy: 0.8002 - val_loss: 1.8138 - val_accuracy: 0.7348 - 802ms/epoch - 5ms/step\n",
            "Epoch 75/100\n",
            "167/167 - 1s - loss: 0.6245 - accuracy: 0.7883 - val_loss: 1.7888 - val_accuracy: 0.6942 - 805ms/epoch - 5ms/step\n",
            "Epoch 76/100\n",
            "167/167 - 1s - loss: 0.5975 - accuracy: 0.7955 - val_loss: 1.6533 - val_accuracy: 0.7168 - 795ms/epoch - 5ms/step\n",
            "Epoch 77/100\n",
            "167/167 - 1s - loss: 0.5412 - accuracy: 0.8186 - val_loss: 1.6443 - val_accuracy: 0.7243 - 805ms/epoch - 5ms/step\n",
            "Epoch 78/100\n",
            "167/167 - 1s - loss: 0.5741 - accuracy: 0.8023 - val_loss: 1.6307 - val_accuracy: 0.7273 - 799ms/epoch - 5ms/step\n",
            "Epoch 79/100\n",
            "167/167 - 1s - loss: 0.5282 - accuracy: 0.8148 - val_loss: 1.7351 - val_accuracy: 0.7107 - 797ms/epoch - 5ms/step\n",
            "Epoch 80/100\n",
            "167/167 - 1s - loss: 0.5656 - accuracy: 0.8023 - val_loss: 1.7131 - val_accuracy: 0.7378 - 797ms/epoch - 5ms/step\n",
            "Epoch 81/100\n",
            "167/167 - 1s - loss: 0.5703 - accuracy: 0.8028 - val_loss: 1.6421 - val_accuracy: 0.7040 - 796ms/epoch - 5ms/step\n",
            "Epoch 82/100\n",
            "167/167 - 1s - loss: 0.5245 - accuracy: 0.8201 - val_loss: 1.8311 - val_accuracy: 0.7010 - 804ms/epoch - 5ms/step\n",
            "Epoch 83/100\n",
            "167/167 - 1s - loss: 0.5946 - accuracy: 0.8107 - val_loss: 1.7979 - val_accuracy: 0.7198 - 799ms/epoch - 5ms/step\n",
            "Epoch 84/100\n",
            "167/167 - 1s - loss: 0.5195 - accuracy: 0.8199 - val_loss: 1.7528 - val_accuracy: 0.7032 - 795ms/epoch - 5ms/step\n",
            "Epoch 85/100\n",
            "167/167 - 1s - loss: 0.5296 - accuracy: 0.8248 - val_loss: 1.6716 - val_accuracy: 0.7318 - 796ms/epoch - 5ms/step\n",
            "Epoch 86/100\n",
            "167/167 - 1s - loss: 0.5626 - accuracy: 0.8055 - val_loss: 1.7222 - val_accuracy: 0.7355 - 789ms/epoch - 5ms/step\n",
            "Epoch 87/100\n",
            "167/167 - 1s - loss: 0.6176 - accuracy: 0.7979 - val_loss: 1.6774 - val_accuracy: 0.7122 - 797ms/epoch - 5ms/step\n",
            "Epoch 88/100\n",
            "167/167 - 1s - loss: 0.6327 - accuracy: 0.7820 - val_loss: 1.8770 - val_accuracy: 0.7213 - 792ms/epoch - 5ms/step\n",
            "Epoch 89/100\n",
            "167/167 - 1s - loss: 0.5290 - accuracy: 0.8214 - val_loss: 1.7036 - val_accuracy: 0.7122 - 796ms/epoch - 5ms/step\n",
            "Epoch 90/100\n",
            "167/167 - 1s - loss: 0.4885 - accuracy: 0.8325 - val_loss: 1.7608 - val_accuracy: 0.7220 - 806ms/epoch - 5ms/step\n",
            "Epoch 91/100\n",
            "167/167 - 1s - loss: 0.5288 - accuracy: 0.8239 - val_loss: 1.8228 - val_accuracy: 0.6882 - 796ms/epoch - 5ms/step\n",
            "Epoch 92/100\n",
            "167/167 - 1s - loss: 0.4780 - accuracy: 0.8372 - val_loss: 1.6817 - val_accuracy: 0.6980 - 799ms/epoch - 5ms/step\n",
            "Epoch 93/100\n",
            "167/167 - 1s - loss: 0.5173 - accuracy: 0.8188 - val_loss: 1.8281 - val_accuracy: 0.7137 - 800ms/epoch - 5ms/step\n",
            "Epoch 94/100\n",
            "167/167 - 1s - loss: 0.4992 - accuracy: 0.8340 - val_loss: 1.7989 - val_accuracy: 0.6672 - 800ms/epoch - 5ms/step\n",
            "Epoch 95/100\n",
            "167/167 - 1s - loss: 0.8588 - accuracy: 0.7132 - val_loss: 1.6457 - val_accuracy: 0.6897 - 799ms/epoch - 5ms/step\n",
            "Epoch 96/100\n",
            "167/167 - 1s - loss: 0.5504 - accuracy: 0.8130 - val_loss: 1.9679 - val_accuracy: 0.7205 - 803ms/epoch - 5ms/step\n",
            "Epoch 97/100\n",
            "167/167 - 1s - loss: 0.5035 - accuracy: 0.8273 - val_loss: 1.8725 - val_accuracy: 0.7153 - 795ms/epoch - 5ms/step\n",
            "Epoch 98/100\n",
            "167/167 - 1s - loss: 0.4588 - accuracy: 0.8421 - val_loss: 1.8769 - val_accuracy: 0.7183 - 795ms/epoch - 5ms/step\n",
            "Epoch 99/100\n",
            "167/167 - 1s - loss: 0.5365 - accuracy: 0.8190 - val_loss: 1.8155 - val_accuracy: 0.7137 - 793ms/epoch - 5ms/step\n",
            "Epoch 100/100\n",
            "167/167 - 1s - loss: 0.4770 - accuracy: 0.8419 - val_loss: 1.8278 - val_accuracy: 0.7160 - 797ms/epoch - 5ms/step\n",
            "Model: \"sequential_29\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " reshape_28 (Reshape)        (None, 128, 40, 1)        0         \n",
            "                                                                 \n",
            " conv2d_56 (Conv2D)          (None, 128, 40, 8)        80        \n",
            "                                                                 \n",
            " max_pooling2d_54 (MaxPoolin  (None, 64, 20, 8)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " batch_normalization_27 (Bat  (None, 64, 20, 8)        32        \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv2d_57 (Conv2D)          (None, 64, 20, 16)        12816     \n",
            "                                                                 \n",
            " max_pooling2d_55 (MaxPoolin  (None, 32, 10, 16)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_27 (Dropout)        (None, 32, 10, 16)        0         \n",
            "                                                                 \n",
            " flatten_27 (Flatten)        (None, 5120)              0         \n",
            "                                                                 \n",
            " y_pred (Dense)              (None, 10)                51210     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 64,138\n",
            "Trainable params: 64,122\n",
            "Non-trainable params: 16\n",
            "_________________________________________________________________\n",
            "None\n",
            "Result of fold:4\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 4.0511 - accuracy: 0.4837\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 40%|████      | 4/10 [05:35<08:21, 83.54s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(40, 128)\n",
            "Epoch 1/100\n",
            "168/168 - 2s - loss: 2.3421 - accuracy: 0.2315 - val_loss: 2.0540 - val_accuracy: 0.2212 - 2s/epoch - 10ms/step\n",
            "Epoch 2/100\n",
            "168/168 - 1s - loss: 1.9978 - accuracy: 0.2816 - val_loss: 1.9728 - val_accuracy: 0.2601 - 812ms/epoch - 5ms/step\n",
            "Epoch 3/100\n",
            "168/168 - 1s - loss: 1.8730 - accuracy: 0.3283 - val_loss: 1.9386 - val_accuracy: 0.3430 - 816ms/epoch - 5ms/step\n",
            "Epoch 4/100\n",
            "168/168 - 1s - loss: 1.7691 - accuracy: 0.3754 - val_loss: 1.8548 - val_accuracy: 0.3625 - 807ms/epoch - 5ms/step\n",
            "Epoch 5/100\n",
            "168/168 - 1s - loss: 1.7042 - accuracy: 0.4012 - val_loss: 1.7162 - val_accuracy: 0.4148 - 805ms/epoch - 5ms/step\n",
            "Epoch 6/100\n",
            "168/168 - 1s - loss: 1.7457 - accuracy: 0.3999 - val_loss: 1.8141 - val_accuracy: 0.3789 - 804ms/epoch - 5ms/step\n",
            "Epoch 7/100\n",
            "168/168 - 1s - loss: 1.6447 - accuracy: 0.4217 - val_loss: 1.7597 - val_accuracy: 0.4133 - 806ms/epoch - 5ms/step\n",
            "Epoch 8/100\n",
            "168/168 - 1s - loss: 1.5675 - accuracy: 0.4443 - val_loss: 1.9359 - val_accuracy: 0.3954 - 811ms/epoch - 5ms/step\n",
            "Epoch 9/100\n",
            "168/168 - 1s - loss: 1.6071 - accuracy: 0.4355 - val_loss: 1.8718 - val_accuracy: 0.4066 - 803ms/epoch - 5ms/step\n",
            "Epoch 10/100\n",
            "168/168 - 1s - loss: 1.4815 - accuracy: 0.4679 - val_loss: 2.0412 - val_accuracy: 0.3520 - 808ms/epoch - 5ms/step\n",
            "Epoch 11/100\n",
            "168/168 - 1s - loss: 1.5036 - accuracy: 0.4748 - val_loss: 1.9257 - val_accuracy: 0.3789 - 805ms/epoch - 5ms/step\n",
            "Epoch 12/100\n",
            "168/168 - 1s - loss: 1.4570 - accuracy: 0.4847 - val_loss: 2.1907 - val_accuracy: 0.4283 - 811ms/epoch - 5ms/step\n",
            "Epoch 13/100\n",
            "168/168 - 1s - loss: 1.3988 - accuracy: 0.5043 - val_loss: 1.8148 - val_accuracy: 0.3827 - 812ms/epoch - 5ms/step\n",
            "Epoch 14/100\n",
            "168/168 - 1s - loss: 1.4824 - accuracy: 0.4787 - val_loss: 1.9427 - val_accuracy: 0.4596 - 806ms/epoch - 5ms/step\n",
            "Epoch 15/100\n",
            "168/168 - 1s - loss: 1.3069 - accuracy: 0.5325 - val_loss: 1.8289 - val_accuracy: 0.5075 - 806ms/epoch - 5ms/step\n",
            "Epoch 16/100\n",
            "168/168 - 1s - loss: 1.2739 - accuracy: 0.5546 - val_loss: 1.8524 - val_accuracy: 0.5411 - 804ms/epoch - 5ms/step\n",
            "Epoch 17/100\n",
            "168/168 - 1s - loss: 1.2361 - accuracy: 0.5669 - val_loss: 1.7532 - val_accuracy: 0.5695 - 807ms/epoch - 5ms/step\n",
            "Epoch 18/100\n",
            "168/168 - 1s - loss: 1.1890 - accuracy: 0.5895 - val_loss: 1.6193 - val_accuracy: 0.5897 - 802ms/epoch - 5ms/step\n",
            "Epoch 19/100\n",
            "168/168 - 1s - loss: 1.1116 - accuracy: 0.6058 - val_loss: 1.7385 - val_accuracy: 0.5919 - 806ms/epoch - 5ms/step\n",
            "Epoch 20/100\n",
            "168/168 - 1s - loss: 1.1943 - accuracy: 0.6003 - val_loss: 1.6996 - val_accuracy: 0.5501 - 803ms/epoch - 5ms/step\n",
            "Epoch 21/100\n",
            "168/168 - 1s - loss: 1.0632 - accuracy: 0.6302 - val_loss: 1.7792 - val_accuracy: 0.5882 - 801ms/epoch - 5ms/step\n",
            "Epoch 22/100\n",
            "168/168 - 1s - loss: 1.0245 - accuracy: 0.6441 - val_loss: 1.6303 - val_accuracy: 0.5874 - 803ms/epoch - 5ms/step\n",
            "Epoch 23/100\n",
            "168/168 - 1s - loss: 0.9796 - accuracy: 0.6607 - val_loss: 1.5456 - val_accuracy: 0.5994 - 793ms/epoch - 5ms/step\n",
            "Epoch 24/100\n",
            "168/168 - 1s - loss: 1.0669 - accuracy: 0.6484 - val_loss: 1.6340 - val_accuracy: 0.6001 - 800ms/epoch - 5ms/step\n",
            "Epoch 25/100\n",
            "168/168 - 1s - loss: 1.1247 - accuracy: 0.6157 - val_loss: 1.6057 - val_accuracy: 0.5202 - 828ms/epoch - 5ms/step\n",
            "Epoch 26/100\n",
            "168/168 - 1s - loss: 1.0607 - accuracy: 0.6321 - val_loss: 1.6465 - val_accuracy: 0.6151 - 858ms/epoch - 5ms/step\n",
            "Epoch 27/100\n",
            "168/168 - 1s - loss: 0.9667 - accuracy: 0.6747 - val_loss: 1.5971 - val_accuracy: 0.6368 - 897ms/epoch - 5ms/step\n",
            "Epoch 28/100\n",
            "168/168 - 1s - loss: 0.9174 - accuracy: 0.6861 - val_loss: 1.5432 - val_accuracy: 0.6368 - 823ms/epoch - 5ms/step\n",
            "Epoch 29/100\n",
            "168/168 - 1s - loss: 0.8862 - accuracy: 0.6971 - val_loss: 1.5697 - val_accuracy: 0.6375 - 798ms/epoch - 5ms/step\n",
            "Epoch 30/100\n",
            "168/168 - 1s - loss: 0.8369 - accuracy: 0.7199 - val_loss: 1.7972 - val_accuracy: 0.6263 - 808ms/epoch - 5ms/step\n",
            "Epoch 31/100\n",
            "168/168 - 1s - loss: 0.8920 - accuracy: 0.6958 - val_loss: 1.8284 - val_accuracy: 0.5874 - 800ms/epoch - 5ms/step\n",
            "Epoch 32/100\n",
            "168/168 - 1s - loss: 0.8698 - accuracy: 0.7007 - val_loss: 1.9086 - val_accuracy: 0.6532 - 808ms/epoch - 5ms/step\n",
            "Epoch 33/100\n",
            "168/168 - 1s - loss: 0.8516 - accuracy: 0.7158 - val_loss: 1.4069 - val_accuracy: 0.6547 - 797ms/epoch - 5ms/step\n",
            "Epoch 34/100\n",
            "168/168 - 1s - loss: 0.8205 - accuracy: 0.7242 - val_loss: 1.5146 - val_accuracy: 0.6644 - 803ms/epoch - 5ms/step\n",
            "Epoch 35/100\n",
            "168/168 - 1s - loss: 0.8027 - accuracy: 0.7332 - val_loss: 1.4141 - val_accuracy: 0.6592 - 811ms/epoch - 5ms/step\n",
            "Epoch 36/100\n",
            "168/168 - 1s - loss: 0.7594 - accuracy: 0.7422 - val_loss: 1.5563 - val_accuracy: 0.6570 - 805ms/epoch - 5ms/step\n",
            "Epoch 37/100\n",
            "168/168 - 1s - loss: 0.7513 - accuracy: 0.7472 - val_loss: 1.7473 - val_accuracy: 0.6779 - 807ms/epoch - 5ms/step\n",
            "Epoch 38/100\n",
            "168/168 - 1s - loss: 0.7558 - accuracy: 0.7493 - val_loss: 1.4908 - val_accuracy: 0.6652 - 803ms/epoch - 5ms/step\n",
            "Epoch 39/100\n",
            "168/168 - 1s - loss: 0.7640 - accuracy: 0.7493 - val_loss: 1.6968 - val_accuracy: 0.6809 - 807ms/epoch - 5ms/step\n",
            "Epoch 40/100\n",
            "168/168 - 1s - loss: 0.7394 - accuracy: 0.7487 - val_loss: 1.6270 - val_accuracy: 0.6622 - 797ms/epoch - 5ms/step\n",
            "Epoch 41/100\n",
            "168/168 - 1s - loss: 0.7255 - accuracy: 0.7569 - val_loss: 2.5169 - val_accuracy: 0.6360 - 809ms/epoch - 5ms/step\n",
            "Epoch 42/100\n",
            "168/168 - 1s - loss: 0.7811 - accuracy: 0.7397 - val_loss: 1.6788 - val_accuracy: 0.6794 - 802ms/epoch - 5ms/step\n",
            "Epoch 43/100\n",
            "168/168 - 1s - loss: 0.6851 - accuracy: 0.7685 - val_loss: 1.6484 - val_accuracy: 0.7048 - 807ms/epoch - 5ms/step\n",
            "Epoch 44/100\n",
            "168/168 - 1s - loss: 0.7213 - accuracy: 0.7696 - val_loss: 1.7180 - val_accuracy: 0.6517 - 798ms/epoch - 5ms/step\n",
            "Epoch 45/100\n",
            "168/168 - 1s - loss: 0.7595 - accuracy: 0.7541 - val_loss: 1.7158 - val_accuracy: 0.6816 - 792ms/epoch - 5ms/step\n",
            "Epoch 46/100\n",
            "168/168 - 1s - loss: 0.7042 - accuracy: 0.7694 - val_loss: 1.5723 - val_accuracy: 0.6794 - 804ms/epoch - 5ms/step\n",
            "Epoch 47/100\n",
            "168/168 - 1s - loss: 0.7419 - accuracy: 0.7610 - val_loss: 1.5360 - val_accuracy: 0.6532 - 806ms/epoch - 5ms/step\n",
            "Epoch 48/100\n",
            "168/168 - 1s - loss: 0.7203 - accuracy: 0.7565 - val_loss: 1.5383 - val_accuracy: 0.6861 - 810ms/epoch - 5ms/step\n",
            "Epoch 49/100\n",
            "168/168 - 1s - loss: 0.6613 - accuracy: 0.7763 - val_loss: 1.6083 - val_accuracy: 0.6996 - 815ms/epoch - 5ms/step\n",
            "Epoch 50/100\n",
            "168/168 - 1s - loss: 0.6693 - accuracy: 0.7883 - val_loss: 1.6836 - val_accuracy: 0.6659 - 804ms/epoch - 5ms/step\n",
            "Epoch 51/100\n",
            "168/168 - 1s - loss: 0.6531 - accuracy: 0.7881 - val_loss: 1.7398 - val_accuracy: 0.6943 - 803ms/epoch - 5ms/step\n",
            "Epoch 52/100\n",
            "168/168 - 1s - loss: 0.6338 - accuracy: 0.7905 - val_loss: 1.5390 - val_accuracy: 0.7040 - 807ms/epoch - 5ms/step\n",
            "Epoch 53/100\n",
            "168/168 - 1s - loss: 0.5827 - accuracy: 0.8027 - val_loss: 1.5825 - val_accuracy: 0.7003 - 803ms/epoch - 5ms/step\n",
            "Epoch 54/100\n",
            "168/168 - 1s - loss: 0.6038 - accuracy: 0.7997 - val_loss: 1.7259 - val_accuracy: 0.7033 - 808ms/epoch - 5ms/step\n",
            "Epoch 55/100\n",
            "168/168 - 1s - loss: 0.5975 - accuracy: 0.8031 - val_loss: 1.7572 - val_accuracy: 0.6756 - 803ms/epoch - 5ms/step\n",
            "Epoch 56/100\n",
            "168/168 - 1s - loss: 0.6505 - accuracy: 0.7930 - val_loss: 1.8691 - val_accuracy: 0.6786 - 804ms/epoch - 5ms/step\n",
            "Epoch 57/100\n",
            "168/168 - 1s - loss: 0.6442 - accuracy: 0.7836 - val_loss: 1.6742 - val_accuracy: 0.7078 - 804ms/epoch - 5ms/step\n",
            "Epoch 58/100\n",
            "168/168 - 1s - loss: 0.5723 - accuracy: 0.8085 - val_loss: 2.0050 - val_accuracy: 0.7078 - 800ms/epoch - 5ms/step\n",
            "Epoch 59/100\n",
            "168/168 - 1s - loss: 0.6019 - accuracy: 0.7995 - val_loss: 1.7950 - val_accuracy: 0.7152 - 802ms/epoch - 5ms/step\n",
            "Epoch 60/100\n",
            "168/168 - 1s - loss: 0.5630 - accuracy: 0.8092 - val_loss: 2.0257 - val_accuracy: 0.6592 - 806ms/epoch - 5ms/step\n",
            "Epoch 61/100\n",
            "168/168 - 1s - loss: 0.5990 - accuracy: 0.7947 - val_loss: 1.7828 - val_accuracy: 0.6996 - 804ms/epoch - 5ms/step\n",
            "Epoch 62/100\n",
            "168/168 - 1s - loss: 0.5317 - accuracy: 0.8186 - val_loss: 1.8024 - val_accuracy: 0.7063 - 802ms/epoch - 5ms/step\n",
            "Epoch 63/100\n",
            "168/168 - 1s - loss: 0.5542 - accuracy: 0.8152 - val_loss: 1.9838 - val_accuracy: 0.7130 - 802ms/epoch - 5ms/step\n",
            "Epoch 64/100\n",
            "168/168 - 1s - loss: 0.5364 - accuracy: 0.8279 - val_loss: 1.7749 - val_accuracy: 0.7078 - 805ms/epoch - 5ms/step\n",
            "Epoch 65/100\n",
            "168/168 - 1s - loss: 0.5175 - accuracy: 0.8287 - val_loss: 1.6376 - val_accuracy: 0.7182 - 801ms/epoch - 5ms/step\n",
            "Epoch 66/100\n",
            "168/168 - 1s - loss: 0.5100 - accuracy: 0.8231 - val_loss: 1.7214 - val_accuracy: 0.7190 - 804ms/epoch - 5ms/step\n",
            "Epoch 67/100\n",
            "168/168 - 1s - loss: 0.5260 - accuracy: 0.8290 - val_loss: 1.7550 - val_accuracy: 0.7152 - 795ms/epoch - 5ms/step\n",
            "Epoch 68/100\n",
            "168/168 - 1s - loss: 0.5652 - accuracy: 0.8135 - val_loss: 1.6602 - val_accuracy: 0.6831 - 799ms/epoch - 5ms/step\n",
            "Epoch 69/100\n",
            "168/168 - 1s - loss: 0.5165 - accuracy: 0.8275 - val_loss: 1.7470 - val_accuracy: 0.6958 - 798ms/epoch - 5ms/step\n",
            "Epoch 70/100\n",
            "168/168 - 1s - loss: 0.5215 - accuracy: 0.8274 - val_loss: 1.6058 - val_accuracy: 0.7294 - 800ms/epoch - 5ms/step\n",
            "Epoch 71/100\n",
            "168/168 - 1s - loss: 0.6372 - accuracy: 0.7990 - val_loss: 1.6666 - val_accuracy: 0.5807 - 804ms/epoch - 5ms/step\n",
            "Epoch 72/100\n",
            "168/168 - 1s - loss: 0.7462 - accuracy: 0.7696 - val_loss: 2.2885 - val_accuracy: 0.6973 - 797ms/epoch - 5ms/step\n",
            "Epoch 73/100\n",
            "168/168 - 1s - loss: 0.5340 - accuracy: 0.8214 - val_loss: 1.7699 - val_accuracy: 0.7123 - 800ms/epoch - 5ms/step\n",
            "Epoch 74/100\n",
            "168/168 - 1s - loss: 0.4938 - accuracy: 0.8397 - val_loss: 1.7865 - val_accuracy: 0.7160 - 808ms/epoch - 5ms/step\n",
            "Epoch 75/100\n",
            "168/168 - 1s - loss: 0.4500 - accuracy: 0.8501 - val_loss: 1.6815 - val_accuracy: 0.7220 - 808ms/epoch - 5ms/step\n",
            "Epoch 76/100\n",
            "168/168 - 1s - loss: 0.4527 - accuracy: 0.8496 - val_loss: 1.7902 - val_accuracy: 0.7115 - 810ms/epoch - 5ms/step\n",
            "Epoch 77/100\n",
            "168/168 - 1s - loss: 0.4871 - accuracy: 0.8365 - val_loss: 1.7685 - val_accuracy: 0.7123 - 805ms/epoch - 5ms/step\n",
            "Epoch 78/100\n",
            "168/168 - 1s - loss: 0.4523 - accuracy: 0.8470 - val_loss: 1.7132 - val_accuracy: 0.7227 - 805ms/epoch - 5ms/step\n",
            "Epoch 79/100\n",
            "168/168 - 1s - loss: 0.4470 - accuracy: 0.8475 - val_loss: 1.8202 - val_accuracy: 0.7093 - 803ms/epoch - 5ms/step\n",
            "Epoch 80/100\n",
            "168/168 - 1s - loss: 0.4937 - accuracy: 0.8414 - val_loss: 1.7575 - val_accuracy: 0.7145 - 806ms/epoch - 5ms/step\n",
            "Epoch 81/100\n",
            "168/168 - 1s - loss: 0.4718 - accuracy: 0.8530 - val_loss: 1.3568 - val_accuracy: 0.7115 - 805ms/epoch - 5ms/step\n",
            "Epoch 82/100\n",
            "168/168 - 1s - loss: 0.5411 - accuracy: 0.8354 - val_loss: 1.4735 - val_accuracy: 0.7280 - 804ms/epoch - 5ms/step\n",
            "Epoch 83/100\n",
            "168/168 - 1s - loss: 0.4053 - accuracy: 0.8591 - val_loss: 1.8805 - val_accuracy: 0.7294 - 804ms/epoch - 5ms/step\n",
            "Epoch 84/100\n",
            "168/168 - 1s - loss: 0.4094 - accuracy: 0.8595 - val_loss: 1.6810 - val_accuracy: 0.6958 - 804ms/epoch - 5ms/step\n",
            "Epoch 85/100\n",
            "168/168 - 1s - loss: 0.6038 - accuracy: 0.8003 - val_loss: 1.7739 - val_accuracy: 0.7302 - 799ms/epoch - 5ms/step\n",
            "Epoch 86/100\n",
            "168/168 - 1s - loss: 0.3911 - accuracy: 0.8685 - val_loss: 1.5894 - val_accuracy: 0.7272 - 809ms/epoch - 5ms/step\n",
            "Epoch 87/100\n",
            "168/168 - 1s - loss: 0.3822 - accuracy: 0.8705 - val_loss: 1.7860 - val_accuracy: 0.7272 - 801ms/epoch - 5ms/step\n",
            "Epoch 88/100\n",
            "168/168 - 1s - loss: 0.4105 - accuracy: 0.8660 - val_loss: 1.5939 - val_accuracy: 0.6951 - 805ms/epoch - 5ms/step\n",
            "Epoch 89/100\n",
            "168/168 - 1s - loss: 0.4563 - accuracy: 0.8563 - val_loss: 1.5397 - val_accuracy: 0.6637 - 809ms/epoch - 5ms/step\n",
            "Epoch 90/100\n",
            "168/168 - 1s - loss: 0.5277 - accuracy: 0.8326 - val_loss: 1.6371 - val_accuracy: 0.7040 - 814ms/epoch - 5ms/step\n",
            "Epoch 91/100\n",
            "168/168 - 1s - loss: 0.4763 - accuracy: 0.8464 - val_loss: 1.6205 - val_accuracy: 0.7182 - 802ms/epoch - 5ms/step\n",
            "Epoch 92/100\n",
            "168/168 - 1s - loss: 0.4185 - accuracy: 0.8582 - val_loss: 1.7865 - val_accuracy: 0.7130 - 799ms/epoch - 5ms/step\n",
            "Epoch 93/100\n",
            "168/168 - 1s - loss: 0.4478 - accuracy: 0.8580 - val_loss: 1.7475 - val_accuracy: 0.7093 - 809ms/epoch - 5ms/step\n",
            "Epoch 94/100\n",
            "168/168 - 1s - loss: 0.4413 - accuracy: 0.8617 - val_loss: 1.6606 - val_accuracy: 0.7287 - 802ms/epoch - 5ms/step\n",
            "Epoch 95/100\n",
            "168/168 - 1s - loss: 0.3654 - accuracy: 0.8774 - val_loss: 1.7983 - val_accuracy: 0.7280 - 807ms/epoch - 5ms/step\n",
            "Epoch 96/100\n",
            "168/168 - 1s - loss: 0.3863 - accuracy: 0.8774 - val_loss: 1.7690 - val_accuracy: 0.7354 - 800ms/epoch - 5ms/step\n",
            "Epoch 97/100\n",
            "168/168 - 1s - loss: 0.4215 - accuracy: 0.8578 - val_loss: 1.8387 - val_accuracy: 0.7332 - 808ms/epoch - 5ms/step\n",
            "Epoch 98/100\n",
            "168/168 - 1s - loss: 0.4178 - accuracy: 0.8617 - val_loss: 1.8176 - val_accuracy: 0.7362 - 803ms/epoch - 5ms/step\n",
            "Epoch 99/100\n",
            "168/168 - 1s - loss: 0.3403 - accuracy: 0.8828 - val_loss: 1.9441 - val_accuracy: 0.7272 - 812ms/epoch - 5ms/step\n",
            "Epoch 100/100\n",
            "168/168 - 1s - loss: 0.4038 - accuracy: 0.8729 - val_loss: 1.8238 - val_accuracy: 0.7167 - 804ms/epoch - 5ms/step\n",
            "Model: \"sequential_31\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " reshape_30 (Reshape)        (None, 128, 40, 1)        0         \n",
            "                                                                 \n",
            " conv2d_60 (Conv2D)          (None, 128, 40, 8)        80        \n",
            "                                                                 \n",
            " max_pooling2d_58 (MaxPoolin  (None, 64, 20, 8)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " batch_normalization_29 (Bat  (None, 64, 20, 8)        32        \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv2d_61 (Conv2D)          (None, 64, 20, 16)        12816     \n",
            "                                                                 \n",
            " max_pooling2d_59 (MaxPoolin  (None, 32, 10, 16)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_29 (Dropout)        (None, 32, 10, 16)        0         \n",
            "                                                                 \n",
            " flatten_29 (Flatten)        (None, 5120)              0         \n",
            "                                                                 \n",
            " y_pred (Dense)              (None, 10)                51210     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 64,138\n",
            "Trainable params: 64,122\n",
            "Non-trainable params: 16\n",
            "_________________________________________________________________\n",
            "None\n",
            "Result of fold:5\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 2.2363 - accuracy: 0.5076\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 50%|█████     | 5/10 [06:58<06:56, 83.37s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(40, 128)\n",
            "Epoch 1/100\n",
            "170/170 - 2s - loss: 2.1714 - accuracy: 0.2991 - val_loss: 2.0871 - val_accuracy: 0.2893 - 2s/epoch - 10ms/step\n",
            "Epoch 2/100\n",
            "170/170 - 1s - loss: 1.9211 - accuracy: 0.3456 - val_loss: 1.9244 - val_accuracy: 0.3779 - 811ms/epoch - 5ms/step\n",
            "Epoch 3/100\n",
            "170/170 - 1s - loss: 1.7770 - accuracy: 0.3792 - val_loss: 1.7917 - val_accuracy: 0.4428 - 821ms/epoch - 5ms/step\n",
            "Epoch 4/100\n",
            "170/170 - 1s - loss: 1.6232 - accuracy: 0.4394 - val_loss: 1.7850 - val_accuracy: 0.4052 - 817ms/epoch - 5ms/step\n",
            "Epoch 5/100\n",
            "170/170 - 1s - loss: 1.6041 - accuracy: 0.4499 - val_loss: 1.7249 - val_accuracy: 0.4716 - 816ms/epoch - 5ms/step\n",
            "Epoch 6/100\n",
            "170/170 - 1s - loss: 1.5527 - accuracy: 0.4742 - val_loss: 1.6628 - val_accuracy: 0.4598 - 818ms/epoch - 5ms/step\n",
            "Epoch 7/100\n",
            "170/170 - 1s - loss: 1.4617 - accuracy: 0.4973 - val_loss: 1.6767 - val_accuracy: 0.4723 - 816ms/epoch - 5ms/step\n",
            "Epoch 8/100\n",
            "170/170 - 1s - loss: 1.4182 - accuracy: 0.5162 - val_loss: 1.5654 - val_accuracy: 0.5181 - 809ms/epoch - 5ms/step\n",
            "Epoch 9/100\n",
            "170/170 - 1s - loss: 1.4002 - accuracy: 0.5121 - val_loss: 1.7816 - val_accuracy: 0.4834 - 816ms/epoch - 5ms/step\n",
            "Epoch 10/100\n",
            "170/170 - 1s - loss: 1.3473 - accuracy: 0.5294 - val_loss: 1.7501 - val_accuracy: 0.5011 - 808ms/epoch - 5ms/step\n",
            "Epoch 11/100\n",
            "170/170 - 1s - loss: 1.3034 - accuracy: 0.5490 - val_loss: 1.6090 - val_accuracy: 0.5173 - 814ms/epoch - 5ms/step\n",
            "Epoch 12/100\n",
            "170/170 - 1s - loss: 1.2343 - accuracy: 0.5699 - val_loss: 1.6013 - val_accuracy: 0.5808 - 812ms/epoch - 5ms/step\n",
            "Epoch 13/100\n",
            "170/170 - 1s - loss: 1.1757 - accuracy: 0.5893 - val_loss: 1.4811 - val_accuracy: 0.6155 - 810ms/epoch - 5ms/step\n",
            "Epoch 14/100\n",
            "170/170 - 1s - loss: 1.1928 - accuracy: 0.5968 - val_loss: 1.3618 - val_accuracy: 0.6052 - 812ms/epoch - 5ms/step\n",
            "Epoch 15/100\n",
            "170/170 - 1s - loss: 1.1094 - accuracy: 0.6203 - val_loss: 1.4688 - val_accuracy: 0.6118 - 816ms/epoch - 5ms/step\n",
            "Epoch 16/100\n",
            "170/170 - 1s - loss: 1.0542 - accuracy: 0.6406 - val_loss: 1.3804 - val_accuracy: 0.6214 - 812ms/epoch - 5ms/step\n",
            "Epoch 17/100\n",
            "170/170 - 1s - loss: 1.0950 - accuracy: 0.6378 - val_loss: 1.4978 - val_accuracy: 0.6125 - 810ms/epoch - 5ms/step\n",
            "Epoch 18/100\n",
            "170/170 - 1s - loss: 1.0276 - accuracy: 0.6504 - val_loss: 1.4757 - val_accuracy: 0.6590 - 816ms/epoch - 5ms/step\n",
            "Epoch 19/100\n",
            "170/170 - 1s - loss: 0.9806 - accuracy: 0.6709 - val_loss: 1.5711 - val_accuracy: 0.6007 - 815ms/epoch - 5ms/step\n",
            "Epoch 20/100\n",
            "170/170 - 1s - loss: 0.9829 - accuracy: 0.6633 - val_loss: 1.5086 - val_accuracy: 0.6649 - 808ms/epoch - 5ms/step\n",
            "Epoch 21/100\n",
            "170/170 - 1s - loss: 0.9397 - accuracy: 0.6832 - val_loss: 1.6248 - val_accuracy: 0.6140 - 813ms/epoch - 5ms/step\n",
            "Epoch 22/100\n",
            "170/170 - 1s - loss: 0.9506 - accuracy: 0.6817 - val_loss: 1.5081 - val_accuracy: 0.6450 - 819ms/epoch - 5ms/step\n",
            "Epoch 23/100\n",
            "170/170 - 1s - loss: 0.9976 - accuracy: 0.6613 - val_loss: 1.4141 - val_accuracy: 0.6760 - 816ms/epoch - 5ms/step\n",
            "Epoch 24/100\n",
            "170/170 - 1s - loss: 0.8866 - accuracy: 0.7052 - val_loss: 1.6271 - val_accuracy: 0.6804 - 819ms/epoch - 5ms/step\n",
            "Epoch 25/100\n",
            "170/170 - 1s - loss: 0.9174 - accuracy: 0.7048 - val_loss: 1.3395 - val_accuracy: 0.6716 - 807ms/epoch - 5ms/step\n",
            "Epoch 26/100\n",
            "170/170 - 1s - loss: 0.8686 - accuracy: 0.7078 - val_loss: 1.4152 - val_accuracy: 0.6657 - 817ms/epoch - 5ms/step\n",
            "Epoch 27/100\n",
            "170/170 - 1s - loss: 0.8200 - accuracy: 0.7320 - val_loss: 1.3822 - val_accuracy: 0.6782 - 819ms/epoch - 5ms/step\n",
            "Epoch 28/100\n",
            "170/170 - 1s - loss: 0.8514 - accuracy: 0.7179 - val_loss: 1.3815 - val_accuracy: 0.6886 - 822ms/epoch - 5ms/step\n",
            "Epoch 29/100\n",
            "170/170 - 1s - loss: 0.7733 - accuracy: 0.7356 - val_loss: 1.5761 - val_accuracy: 0.6959 - 810ms/epoch - 5ms/step\n",
            "Epoch 30/100\n",
            "170/170 - 1s - loss: 0.7904 - accuracy: 0.7257 - val_loss: 1.5408 - val_accuracy: 0.6613 - 813ms/epoch - 5ms/step\n",
            "Epoch 31/100\n",
            "170/170 - 1s - loss: 0.7384 - accuracy: 0.7510 - val_loss: 1.5156 - val_accuracy: 0.7026 - 819ms/epoch - 5ms/step\n",
            "Epoch 32/100\n",
            "170/170 - 1s - loss: 0.7395 - accuracy: 0.7560 - val_loss: 1.8751 - val_accuracy: 0.5697 - 817ms/epoch - 5ms/step\n",
            "Epoch 33/100\n",
            "170/170 - 1s - loss: 0.7153 - accuracy: 0.7602 - val_loss: 1.6724 - val_accuracy: 0.6915 - 821ms/epoch - 5ms/step\n",
            "Epoch 34/100\n",
            "170/170 - 1s - loss: 0.7055 - accuracy: 0.7696 - val_loss: 1.4504 - val_accuracy: 0.7048 - 815ms/epoch - 5ms/step\n",
            "Epoch 35/100\n",
            "170/170 - 1s - loss: 0.7149 - accuracy: 0.7668 - val_loss: 1.5644 - val_accuracy: 0.6745 - 819ms/epoch - 5ms/step\n",
            "Epoch 36/100\n",
            "170/170 - 1s - loss: 0.7569 - accuracy: 0.7464 - val_loss: 1.5003 - val_accuracy: 0.6546 - 811ms/epoch - 5ms/step\n",
            "Epoch 37/100\n",
            "170/170 - 1s - loss: 0.7032 - accuracy: 0.7630 - val_loss: 1.5167 - val_accuracy: 0.6716 - 825ms/epoch - 5ms/step\n",
            "Epoch 38/100\n",
            "170/170 - 1s - loss: 0.6939 - accuracy: 0.7685 - val_loss: 1.4495 - val_accuracy: 0.7004 - 824ms/epoch - 5ms/step\n",
            "Epoch 39/100\n",
            "170/170 - 1s - loss: 0.6319 - accuracy: 0.7818 - val_loss: 1.5814 - val_accuracy: 0.6878 - 828ms/epoch - 5ms/step\n",
            "Epoch 40/100\n",
            "170/170 - 1s - loss: 0.6190 - accuracy: 0.7840 - val_loss: 1.4001 - val_accuracy: 0.7018 - 833ms/epoch - 5ms/step\n",
            "Epoch 41/100\n",
            "170/170 - 1s - loss: 0.6352 - accuracy: 0.7899 - val_loss: 1.5343 - val_accuracy: 0.6893 - 819ms/epoch - 5ms/step\n",
            "Epoch 42/100\n",
            "170/170 - 1s - loss: 0.6276 - accuracy: 0.7853 - val_loss: 1.5839 - val_accuracy: 0.7240 - 833ms/epoch - 5ms/step\n",
            "Epoch 43/100\n",
            "170/170 - 1s - loss: 0.6457 - accuracy: 0.7862 - val_loss: 1.9569 - val_accuracy: 0.6893 - 832ms/epoch - 5ms/step\n",
            "Epoch 44/100\n",
            "170/170 - 1s - loss: 0.6936 - accuracy: 0.7713 - val_loss: 1.7511 - val_accuracy: 0.6937 - 825ms/epoch - 5ms/step\n",
            "Epoch 45/100\n",
            "170/170 - 1s - loss: 0.5803 - accuracy: 0.8073 - val_loss: 1.6589 - val_accuracy: 0.7210 - 821ms/epoch - 5ms/step\n",
            "Epoch 46/100\n",
            "170/170 - 1s - loss: 0.5825 - accuracy: 0.8064 - val_loss: 1.7807 - val_accuracy: 0.7085 - 830ms/epoch - 5ms/step\n",
            "Epoch 47/100\n",
            "170/170 - 1s - loss: 0.5694 - accuracy: 0.8113 - val_loss: 1.6998 - val_accuracy: 0.7188 - 840ms/epoch - 5ms/step\n",
            "Epoch 48/100\n",
            "170/170 - 1s - loss: 0.7051 - accuracy: 0.7716 - val_loss: 1.8175 - val_accuracy: 0.6937 - 839ms/epoch - 5ms/step\n",
            "Epoch 49/100\n",
            "170/170 - 1s - loss: 0.5622 - accuracy: 0.8148 - val_loss: 1.8215 - val_accuracy: 0.7122 - 834ms/epoch - 5ms/step\n",
            "Epoch 50/100\n",
            "170/170 - 1s - loss: 0.6259 - accuracy: 0.8062 - val_loss: 1.5624 - val_accuracy: 0.7137 - 829ms/epoch - 5ms/step\n",
            "Epoch 51/100\n",
            "170/170 - 1s - loss: 0.5597 - accuracy: 0.8148 - val_loss: 1.4642 - val_accuracy: 0.7321 - 832ms/epoch - 5ms/step\n",
            "Epoch 52/100\n",
            "170/170 - 1s - loss: 0.5791 - accuracy: 0.8088 - val_loss: 1.7136 - val_accuracy: 0.7107 - 830ms/epoch - 5ms/step\n",
            "Epoch 53/100\n",
            "170/170 - 1s - loss: 0.5553 - accuracy: 0.8128 - val_loss: 1.5765 - val_accuracy: 0.7299 - 825ms/epoch - 5ms/step\n",
            "Epoch 54/100\n",
            "170/170 - 1s - loss: 0.5886 - accuracy: 0.8076 - val_loss: 1.6046 - val_accuracy: 0.7122 - 831ms/epoch - 5ms/step\n",
            "Epoch 55/100\n",
            "170/170 - 1s - loss: 0.5756 - accuracy: 0.8174 - val_loss: 1.3464 - val_accuracy: 0.7277 - 835ms/epoch - 5ms/step\n",
            "Epoch 56/100\n",
            "170/170 - 1s - loss: 0.4763 - accuracy: 0.8444 - val_loss: 1.4252 - val_accuracy: 0.7321 - 818ms/epoch - 5ms/step\n",
            "Epoch 57/100\n",
            "170/170 - 1s - loss: 0.4936 - accuracy: 0.8311 - val_loss: 1.4995 - val_accuracy: 0.7240 - 825ms/epoch - 5ms/step\n",
            "Epoch 58/100\n",
            "170/170 - 1s - loss: 0.5012 - accuracy: 0.8324 - val_loss: 1.5971 - val_accuracy: 0.7255 - 807ms/epoch - 5ms/step\n",
            "Epoch 59/100\n",
            "170/170 - 1s - loss: 0.5018 - accuracy: 0.8320 - val_loss: 1.5896 - val_accuracy: 0.7026 - 811ms/epoch - 5ms/step\n",
            "Epoch 60/100\n",
            "170/170 - 1s - loss: 0.5236 - accuracy: 0.8313 - val_loss: 1.6625 - val_accuracy: 0.6967 - 815ms/epoch - 5ms/step\n",
            "Epoch 61/100\n",
            "170/170 - 1s - loss: 0.7775 - accuracy: 0.7425 - val_loss: 1.4256 - val_accuracy: 0.7380 - 814ms/epoch - 5ms/step\n",
            "Epoch 62/100\n",
            "170/170 - 1s - loss: 0.5041 - accuracy: 0.8281 - val_loss: 1.4504 - val_accuracy: 0.7181 - 815ms/epoch - 5ms/step\n",
            "Epoch 63/100\n",
            "170/170 - 1s - loss: 0.5495 - accuracy: 0.8139 - val_loss: 1.5709 - val_accuracy: 0.7232 - 806ms/epoch - 5ms/step\n",
            "Epoch 64/100\n",
            "170/170 - 1s - loss: 0.5058 - accuracy: 0.8279 - val_loss: 1.5549 - val_accuracy: 0.7232 - 817ms/epoch - 5ms/step\n",
            "Epoch 65/100\n",
            "170/170 - 1s - loss: 0.4940 - accuracy: 0.8372 - val_loss: 1.7435 - val_accuracy: 0.7299 - 815ms/epoch - 5ms/step\n",
            "Epoch 66/100\n",
            "170/170 - 1s - loss: 0.4894 - accuracy: 0.8405 - val_loss: 1.5658 - val_accuracy: 0.7336 - 822ms/epoch - 5ms/step\n",
            "Epoch 67/100\n",
            "170/170 - 1s - loss: 0.4506 - accuracy: 0.8459 - val_loss: 1.5042 - val_accuracy: 0.7395 - 813ms/epoch - 5ms/step\n",
            "Epoch 68/100\n",
            "170/170 - 1s - loss: 0.5086 - accuracy: 0.8294 - val_loss: 1.8304 - val_accuracy: 0.7210 - 816ms/epoch - 5ms/step\n",
            "Epoch 69/100\n",
            "170/170 - 1s - loss: 0.4677 - accuracy: 0.8423 - val_loss: 1.9401 - val_accuracy: 0.6967 - 806ms/epoch - 5ms/step\n",
            "Epoch 70/100\n",
            "170/170 - 1s - loss: 0.7753 - accuracy: 0.7731 - val_loss: 1.7774 - val_accuracy: 0.6819 - 811ms/epoch - 5ms/step\n",
            "Epoch 71/100\n",
            "170/170 - 1s - loss: 0.4707 - accuracy: 0.8409 - val_loss: 1.6086 - val_accuracy: 0.7321 - 816ms/epoch - 5ms/step\n",
            "Epoch 72/100\n",
            "170/170 - 1s - loss: 0.4372 - accuracy: 0.8492 - val_loss: 1.6737 - val_accuracy: 0.7277 - 814ms/epoch - 5ms/step\n",
            "Epoch 73/100\n",
            "170/170 - 1s - loss: 0.4502 - accuracy: 0.8460 - val_loss: 1.6364 - val_accuracy: 0.7351 - 811ms/epoch - 5ms/step\n",
            "Epoch 74/100\n",
            "170/170 - 1s - loss: 0.5261 - accuracy: 0.8215 - val_loss: 1.6327 - val_accuracy: 0.7122 - 816ms/epoch - 5ms/step\n",
            "Epoch 75/100\n",
            "170/170 - 1s - loss: 0.4908 - accuracy: 0.8353 - val_loss: 1.7808 - val_accuracy: 0.7144 - 812ms/epoch - 5ms/step\n",
            "Epoch 76/100\n",
            "170/170 - 1s - loss: 0.5054 - accuracy: 0.8302 - val_loss: 1.7272 - val_accuracy: 0.7284 - 818ms/epoch - 5ms/step\n",
            "Epoch 77/100\n",
            "170/170 - 1s - loss: 0.5028 - accuracy: 0.8398 - val_loss: 1.7291 - val_accuracy: 0.7041 - 818ms/epoch - 5ms/step\n",
            "Epoch 78/100\n",
            "170/170 - 1s - loss: 0.4756 - accuracy: 0.8460 - val_loss: 1.8994 - val_accuracy: 0.7232 - 815ms/epoch - 5ms/step\n",
            "Epoch 79/100\n",
            "170/170 - 1s - loss: 0.4630 - accuracy: 0.8473 - val_loss: 2.0396 - val_accuracy: 0.7026 - 814ms/epoch - 5ms/step\n",
            "Epoch 80/100\n",
            "170/170 - 1s - loss: 0.4891 - accuracy: 0.8462 - val_loss: 1.5042 - val_accuracy: 0.7210 - 824ms/epoch - 5ms/step\n",
            "Epoch 81/100\n",
            "170/170 - 1s - loss: 0.4655 - accuracy: 0.8497 - val_loss: 1.7805 - val_accuracy: 0.7225 - 809ms/epoch - 5ms/step\n",
            "Epoch 82/100\n",
            "170/170 - 1s - loss: 0.4269 - accuracy: 0.8566 - val_loss: 2.0057 - val_accuracy: 0.7432 - 813ms/epoch - 5ms/step\n",
            "Epoch 83/100\n",
            "170/170 - 1s - loss: 0.4241 - accuracy: 0.8577 - val_loss: 1.8432 - val_accuracy: 0.7210 - 801ms/epoch - 5ms/step\n",
            "Epoch 84/100\n",
            "170/170 - 1s - loss: 0.4545 - accuracy: 0.8586 - val_loss: 1.7396 - val_accuracy: 0.7299 - 820ms/epoch - 5ms/step\n",
            "Epoch 85/100\n",
            "170/170 - 1s - loss: 0.4243 - accuracy: 0.8610 - val_loss: 1.8753 - val_accuracy: 0.7314 - 822ms/epoch - 5ms/step\n",
            "Epoch 86/100\n",
            "170/170 - 1s - loss: 0.3832 - accuracy: 0.8710 - val_loss: 1.6672 - val_accuracy: 0.7218 - 815ms/epoch - 5ms/step\n",
            "Epoch 87/100\n",
            "170/170 - 1s - loss: 0.4406 - accuracy: 0.8542 - val_loss: 1.7412 - val_accuracy: 0.7144 - 803ms/epoch - 5ms/step\n",
            "Epoch 88/100\n",
            "170/170 - 1s - loss: 0.5235 - accuracy: 0.8235 - val_loss: 1.7373 - val_accuracy: 0.7041 - 811ms/epoch - 5ms/step\n",
            "Epoch 89/100\n",
            "170/170 - 1s - loss: 0.4556 - accuracy: 0.8486 - val_loss: 1.5443 - val_accuracy: 0.7336 - 817ms/epoch - 5ms/step\n",
            "Epoch 90/100\n",
            "170/170 - 1s - loss: 0.3952 - accuracy: 0.8652 - val_loss: 1.4885 - val_accuracy: 0.7424 - 819ms/epoch - 5ms/step\n",
            "Epoch 91/100\n",
            "170/170 - 1s - loss: 0.4146 - accuracy: 0.8652 - val_loss: 1.6692 - val_accuracy: 0.7351 - 816ms/epoch - 5ms/step\n",
            "Epoch 92/100\n",
            "170/170 - 1s - loss: 0.5016 - accuracy: 0.8379 - val_loss: 1.8160 - val_accuracy: 0.7292 - 808ms/epoch - 5ms/step\n",
            "Epoch 93/100\n",
            "170/170 - 1s - loss: 0.5253 - accuracy: 0.8339 - val_loss: 2.0705 - val_accuracy: 0.7269 - 854ms/epoch - 5ms/step\n",
            "Epoch 94/100\n",
            "170/170 - 1s - loss: 0.4156 - accuracy: 0.8584 - val_loss: 1.7041 - val_accuracy: 0.7255 - 900ms/epoch - 5ms/step\n",
            "Epoch 95/100\n",
            "170/170 - 1s - loss: 0.5538 - accuracy: 0.8178 - val_loss: 2.1210 - val_accuracy: 0.6406 - 901ms/epoch - 5ms/step\n",
            "Epoch 96/100\n",
            "170/170 - 1s - loss: 0.4950 - accuracy: 0.8431 - val_loss: 1.8152 - val_accuracy: 0.7306 - 820ms/epoch - 5ms/step\n",
            "Epoch 97/100\n",
            "170/170 - 1s - loss: 0.3961 - accuracy: 0.8654 - val_loss: 1.8610 - val_accuracy: 0.7410 - 811ms/epoch - 5ms/step\n",
            "Epoch 98/100\n",
            "170/170 - 1s - loss: 0.4217 - accuracy: 0.8612 - val_loss: 1.8356 - val_accuracy: 0.7299 - 815ms/epoch - 5ms/step\n",
            "Epoch 99/100\n",
            "170/170 - 1s - loss: 0.3836 - accuracy: 0.8734 - val_loss: 1.5778 - val_accuracy: 0.7395 - 822ms/epoch - 5ms/step\n",
            "Epoch 100/100\n",
            "170/170 - 1s - loss: 0.4012 - accuracy: 0.8647 - val_loss: 2.0752 - val_accuracy: 0.7232 - 814ms/epoch - 5ms/step\n",
            "Model: \"sequential_33\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " reshape_32 (Reshape)        (None, 128, 40, 1)        0         \n",
            "                                                                 \n",
            " conv2d_64 (Conv2D)          (None, 128, 40, 8)        80        \n",
            "                                                                 \n",
            " max_pooling2d_62 (MaxPoolin  (None, 64, 20, 8)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " batch_normalization_31 (Bat  (None, 64, 20, 8)        32        \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv2d_65 (Conv2D)          (None, 64, 20, 16)        12816     \n",
            "                                                                 \n",
            " max_pooling2d_63 (MaxPoolin  (None, 32, 10, 16)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_31 (Dropout)        (None, 32, 10, 16)        0         \n",
            "                                                                 \n",
            " flatten_31 (Flatten)        (None, 5120)              0         \n",
            "                                                                 \n",
            " y_pred (Dense)              (None, 10)                51210     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 64,138\n",
            "Trainable params: 64,122\n",
            "Non-trainable params: 16\n",
            "_________________________________________________________________\n",
            "None\n",
            "Result of fold:6\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 4.1238 - accuracy: 0.4703\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 60%|██████    | 6/10 [08:23<05:34, 83.73s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(40, 128)\n",
            "Epoch 1/100\n",
            "169/169 - 2s - loss: 2.2508 - accuracy: 0.2480 - val_loss: 1.9870 - val_accuracy: 0.3195 - 2s/epoch - 10ms/step\n",
            "Epoch 2/100\n",
            "169/169 - 1s - loss: 1.9702 - accuracy: 0.3232 - val_loss: 1.9428 - val_accuracy: 0.3447 - 811ms/epoch - 5ms/step\n",
            "Epoch 3/100\n",
            "169/169 - 1s - loss: 1.8684 - accuracy: 0.3573 - val_loss: 1.9287 - val_accuracy: 0.3632 - 816ms/epoch - 5ms/step\n",
            "Epoch 4/100\n",
            "169/169 - 1s - loss: 1.7015 - accuracy: 0.4033 - val_loss: 1.8088 - val_accuracy: 0.4151 - 811ms/epoch - 5ms/step\n",
            "Epoch 5/100\n",
            "169/169 - 1s - loss: 1.5201 - accuracy: 0.4631 - val_loss: 1.7953 - val_accuracy: 0.3907 - 820ms/epoch - 5ms/step\n",
            "Epoch 6/100\n",
            "169/169 - 1s - loss: 1.3824 - accuracy: 0.5015 - val_loss: 1.4837 - val_accuracy: 0.5130 - 811ms/epoch - 5ms/step\n",
            "Epoch 7/100\n",
            "169/169 - 1s - loss: 1.3631 - accuracy: 0.5287 - val_loss: 1.4638 - val_accuracy: 0.5100 - 808ms/epoch - 5ms/step\n",
            "Epoch 8/100\n",
            "169/169 - 1s - loss: 1.2565 - accuracy: 0.5599 - val_loss: 1.3861 - val_accuracy: 0.5500 - 815ms/epoch - 5ms/step\n",
            "Epoch 9/100\n",
            "169/169 - 1s - loss: 1.1643 - accuracy: 0.5941 - val_loss: 1.3524 - val_accuracy: 0.5760 - 819ms/epoch - 5ms/step\n",
            "Epoch 10/100\n",
            "169/169 - 1s - loss: 1.1288 - accuracy: 0.6103 - val_loss: 1.2923 - val_accuracy: 0.5663 - 820ms/epoch - 5ms/step\n",
            "Epoch 11/100\n",
            "169/169 - 1s - loss: 1.1249 - accuracy: 0.6162 - val_loss: 1.2951 - val_accuracy: 0.5752 - 811ms/epoch - 5ms/step\n",
            "Epoch 12/100\n",
            "169/169 - 1s - loss: 1.0237 - accuracy: 0.6514 - val_loss: 1.2695 - val_accuracy: 0.5804 - 811ms/epoch - 5ms/step\n",
            "Epoch 13/100\n",
            "169/169 - 1s - loss: 0.9847 - accuracy: 0.6620 - val_loss: 1.2053 - val_accuracy: 0.5997 - 813ms/epoch - 5ms/step\n",
            "Epoch 14/100\n",
            "169/169 - 1s - loss: 0.9744 - accuracy: 0.6733 - val_loss: 1.2961 - val_accuracy: 0.5612 - 806ms/epoch - 5ms/step\n",
            "Epoch 15/100\n",
            "169/169 - 1s - loss: 0.9610 - accuracy: 0.6642 - val_loss: 1.1933 - val_accuracy: 0.6256 - 807ms/epoch - 5ms/step\n",
            "Epoch 16/100\n",
            "169/169 - 1s - loss: 0.9003 - accuracy: 0.6966 - val_loss: 1.1695 - val_accuracy: 0.6427 - 814ms/epoch - 5ms/step\n",
            "Epoch 17/100\n",
            "169/169 - 1s - loss: 0.8770 - accuracy: 0.7016 - val_loss: 1.1824 - val_accuracy: 0.6271 - 808ms/epoch - 5ms/step\n",
            "Epoch 18/100\n",
            "169/169 - 1s - loss: 0.8984 - accuracy: 0.6901 - val_loss: 1.4799 - val_accuracy: 0.5463 - 814ms/epoch - 5ms/step\n",
            "Epoch 19/100\n",
            "169/169 - 1s - loss: 0.9212 - accuracy: 0.6824 - val_loss: 1.2507 - val_accuracy: 0.6405 - 816ms/epoch - 5ms/step\n",
            "Epoch 20/100\n",
            "169/169 - 1s - loss: 0.8412 - accuracy: 0.7144 - val_loss: 1.2896 - val_accuracy: 0.6494 - 802ms/epoch - 5ms/step\n",
            "Epoch 21/100\n",
            "169/169 - 1s - loss: 0.8294 - accuracy: 0.7168 - val_loss: 1.3114 - val_accuracy: 0.6546 - 805ms/epoch - 5ms/step\n",
            "Epoch 22/100\n",
            "169/169 - 1s - loss: 0.8833 - accuracy: 0.7077 - val_loss: 1.2377 - val_accuracy: 0.6160 - 805ms/epoch - 5ms/step\n",
            "Epoch 23/100\n",
            "169/169 - 1s - loss: 0.8762 - accuracy: 0.7009 - val_loss: 1.2200 - val_accuracy: 0.6657 - 811ms/epoch - 5ms/step\n",
            "Epoch 24/100\n",
            "169/169 - 1s - loss: 0.7680 - accuracy: 0.7305 - val_loss: 1.1942 - val_accuracy: 0.6679 - 815ms/epoch - 5ms/step\n",
            "Epoch 25/100\n",
            "169/169 - 1s - loss: 0.7672 - accuracy: 0.7389 - val_loss: 1.1566 - val_accuracy: 0.6575 - 814ms/epoch - 5ms/step\n",
            "Epoch 26/100\n",
            "169/169 - 1s - loss: 0.7273 - accuracy: 0.7463 - val_loss: 1.3434 - val_accuracy: 0.6694 - 812ms/epoch - 5ms/step\n",
            "Epoch 27/100\n",
            "169/169 - 1s - loss: 0.7536 - accuracy: 0.7380 - val_loss: 1.1743 - val_accuracy: 0.6850 - 809ms/epoch - 5ms/step\n",
            "Epoch 28/100\n",
            "169/169 - 1s - loss: 0.7610 - accuracy: 0.7396 - val_loss: 1.1757 - val_accuracy: 0.6761 - 820ms/epoch - 5ms/step\n",
            "Epoch 29/100\n",
            "169/169 - 1s - loss: 0.7189 - accuracy: 0.7487 - val_loss: 1.2837 - val_accuracy: 0.6850 - 814ms/epoch - 5ms/step\n",
            "Epoch 30/100\n",
            "169/169 - 1s - loss: 0.7335 - accuracy: 0.7541 - val_loss: 1.2878 - val_accuracy: 0.6738 - 811ms/epoch - 5ms/step\n",
            "Epoch 31/100\n",
            "169/169 - 1s - loss: 0.7265 - accuracy: 0.7502 - val_loss: 1.4916 - val_accuracy: 0.6672 - 812ms/epoch - 5ms/step\n",
            "Epoch 32/100\n",
            "169/169 - 1s - loss: 0.7203 - accuracy: 0.7593 - val_loss: 1.2084 - val_accuracy: 0.6990 - 809ms/epoch - 5ms/step\n",
            "Epoch 33/100\n",
            "169/169 - 1s - loss: 0.7257 - accuracy: 0.7582 - val_loss: 1.2680 - val_accuracy: 0.6946 - 818ms/epoch - 5ms/step\n",
            "Epoch 34/100\n",
            "169/169 - 1s - loss: 0.7142 - accuracy: 0.7535 - val_loss: 1.3278 - val_accuracy: 0.6879 - 810ms/epoch - 5ms/step\n",
            "Epoch 35/100\n",
            "169/169 - 1s - loss: 0.7137 - accuracy: 0.7559 - val_loss: 1.2912 - val_accuracy: 0.6857 - 810ms/epoch - 5ms/step\n",
            "Epoch 36/100\n",
            "169/169 - 1s - loss: 0.6475 - accuracy: 0.7752 - val_loss: 1.2739 - val_accuracy: 0.6887 - 816ms/epoch - 5ms/step\n",
            "Epoch 37/100\n",
            "169/169 - 1s - loss: 0.6701 - accuracy: 0.7776 - val_loss: 1.2678 - val_accuracy: 0.6790 - 817ms/epoch - 5ms/step\n",
            "Epoch 38/100\n",
            "169/169 - 1s - loss: 0.6130 - accuracy: 0.7930 - val_loss: 1.2254 - val_accuracy: 0.7057 - 811ms/epoch - 5ms/step\n",
            "Epoch 39/100\n",
            "169/169 - 1s - loss: 0.5864 - accuracy: 0.7969 - val_loss: 1.3782 - val_accuracy: 0.6857 - 807ms/epoch - 5ms/step\n",
            "Epoch 40/100\n",
            "169/169 - 1s - loss: 0.5983 - accuracy: 0.8002 - val_loss: 1.2470 - val_accuracy: 0.6664 - 822ms/epoch - 5ms/step\n",
            "Epoch 41/100\n",
            "169/169 - 1s - loss: 0.6292 - accuracy: 0.7941 - val_loss: 1.3255 - val_accuracy: 0.6894 - 810ms/epoch - 5ms/step\n",
            "Epoch 42/100\n",
            "169/169 - 1s - loss: 0.7017 - accuracy: 0.7680 - val_loss: 1.5610 - val_accuracy: 0.5063 - 808ms/epoch - 5ms/step\n",
            "Epoch 43/100\n",
            "169/169 - 1s - loss: 0.9116 - accuracy: 0.6887 - val_loss: 1.4890 - val_accuracy: 0.6597 - 806ms/epoch - 5ms/step\n",
            "Epoch 44/100\n",
            "169/169 - 1s - loss: 0.6495 - accuracy: 0.7878 - val_loss: 1.4804 - val_accuracy: 0.6953 - 809ms/epoch - 5ms/step\n",
            "Epoch 45/100\n",
            "169/169 - 1s - loss: 0.5979 - accuracy: 0.8062 - val_loss: 1.3714 - val_accuracy: 0.6946 - 812ms/epoch - 5ms/step\n",
            "Epoch 46/100\n",
            "169/169 - 1s - loss: 0.5593 - accuracy: 0.8086 - val_loss: 1.4471 - val_accuracy: 0.6931 - 812ms/epoch - 5ms/step\n",
            "Epoch 47/100\n",
            "169/169 - 1s - loss: 0.5701 - accuracy: 0.8152 - val_loss: 1.4483 - val_accuracy: 0.6938 - 814ms/epoch - 5ms/step\n",
            "Epoch 48/100\n",
            "169/169 - 1s - loss: 0.5433 - accuracy: 0.8136 - val_loss: 1.8135 - val_accuracy: 0.6879 - 802ms/epoch - 5ms/step\n",
            "Epoch 49/100\n",
            "169/169 - 1s - loss: 0.5936 - accuracy: 0.7967 - val_loss: 1.3766 - val_accuracy: 0.6716 - 811ms/epoch - 5ms/step\n",
            "Epoch 50/100\n",
            "169/169 - 1s - loss: 0.5392 - accuracy: 0.8141 - val_loss: 1.5278 - val_accuracy: 0.6798 - 819ms/epoch - 5ms/step\n",
            "Epoch 51/100\n",
            "169/169 - 1s - loss: 0.5827 - accuracy: 0.8008 - val_loss: 1.5191 - val_accuracy: 0.6560 - 810ms/epoch - 5ms/step\n",
            "Epoch 52/100\n",
            "169/169 - 1s - loss: 0.5528 - accuracy: 0.8156 - val_loss: 1.4611 - val_accuracy: 0.6790 - 813ms/epoch - 5ms/step\n",
            "Epoch 53/100\n",
            "169/169 - 1s - loss: 0.6288 - accuracy: 0.7872 - val_loss: 1.5318 - val_accuracy: 0.6486 - 812ms/epoch - 5ms/step\n",
            "Epoch 54/100\n",
            "169/169 - 1s - loss: 0.5876 - accuracy: 0.7976 - val_loss: 1.5452 - val_accuracy: 0.6768 - 819ms/epoch - 5ms/step\n",
            "Epoch 55/100\n",
            "169/169 - 1s - loss: 0.5531 - accuracy: 0.8080 - val_loss: 1.4761 - val_accuracy: 0.6916 - 810ms/epoch - 5ms/step\n",
            "Epoch 56/100\n",
            "169/169 - 1s - loss: 0.5080 - accuracy: 0.8293 - val_loss: 1.4644 - val_accuracy: 0.6597 - 814ms/epoch - 5ms/step\n",
            "Epoch 57/100\n",
            "169/169 - 1s - loss: 0.5013 - accuracy: 0.8245 - val_loss: 1.3415 - val_accuracy: 0.6990 - 816ms/epoch - 5ms/step\n",
            "Epoch 58/100\n",
            "169/169 - 1s - loss: 0.5112 - accuracy: 0.8286 - val_loss: 1.5455 - val_accuracy: 0.6835 - 813ms/epoch - 5ms/step\n",
            "Epoch 59/100\n",
            "169/169 - 1s - loss: 0.5016 - accuracy: 0.8306 - val_loss: 1.4079 - val_accuracy: 0.7005 - 809ms/epoch - 5ms/step\n",
            "Epoch 60/100\n",
            "169/169 - 1s - loss: 0.4889 - accuracy: 0.8352 - val_loss: 1.5404 - val_accuracy: 0.6850 - 814ms/epoch - 5ms/step\n",
            "Epoch 61/100\n",
            "169/169 - 1s - loss: 0.4975 - accuracy: 0.8319 - val_loss: 1.6220 - val_accuracy: 0.6938 - 820ms/epoch - 5ms/step\n",
            "Epoch 62/100\n",
            "169/169 - 1s - loss: 0.4865 - accuracy: 0.8349 - val_loss: 1.4451 - val_accuracy: 0.7124 - 820ms/epoch - 5ms/step\n",
            "Epoch 63/100\n",
            "169/169 - 1s - loss: 0.5530 - accuracy: 0.8095 - val_loss: 1.5449 - val_accuracy: 0.6998 - 813ms/epoch - 5ms/step\n",
            "Epoch 64/100\n",
            "169/169 - 1s - loss: 0.4478 - accuracy: 0.8460 - val_loss: 1.6039 - val_accuracy: 0.7272 - 812ms/epoch - 5ms/step\n",
            "Epoch 65/100\n",
            "169/169 - 1s - loss: 0.4642 - accuracy: 0.8436 - val_loss: 1.6562 - val_accuracy: 0.7005 - 811ms/epoch - 5ms/step\n",
            "Epoch 66/100\n",
            "169/169 - 1s - loss: 0.4954 - accuracy: 0.8408 - val_loss: 1.7190 - val_accuracy: 0.6842 - 816ms/epoch - 5ms/step\n",
            "Epoch 67/100\n",
            "169/169 - 1s - loss: 0.4810 - accuracy: 0.8347 - val_loss: 1.5003 - val_accuracy: 0.7072 - 805ms/epoch - 5ms/step\n",
            "Epoch 68/100\n",
            "169/169 - 1s - loss: 0.4747 - accuracy: 0.8403 - val_loss: 1.4773 - val_accuracy: 0.6790 - 807ms/epoch - 5ms/step\n",
            "Epoch 69/100\n",
            "169/169 - 1s - loss: 0.4846 - accuracy: 0.8423 - val_loss: 1.5285 - val_accuracy: 0.6768 - 815ms/epoch - 5ms/step\n",
            "Epoch 70/100\n",
            "169/169 - 1s - loss: 0.4657 - accuracy: 0.8397 - val_loss: 1.5295 - val_accuracy: 0.7102 - 814ms/epoch - 5ms/step\n",
            "Epoch 71/100\n",
            "169/169 - 1s - loss: 0.4797 - accuracy: 0.8438 - val_loss: 1.7851 - val_accuracy: 0.6990 - 822ms/epoch - 5ms/step\n",
            "Epoch 72/100\n",
            "169/169 - 1s - loss: 0.7650 - accuracy: 0.7528 - val_loss: 1.3256 - val_accuracy: 0.6449 - 814ms/epoch - 5ms/step\n",
            "Epoch 73/100\n",
            "169/169 - 1s - loss: 0.6317 - accuracy: 0.7872 - val_loss: 1.4330 - val_accuracy: 0.6723 - 813ms/epoch - 5ms/step\n",
            "Epoch 74/100\n",
            "169/169 - 1s - loss: 0.5389 - accuracy: 0.8208 - val_loss: 1.5531 - val_accuracy: 0.6775 - 807ms/epoch - 5ms/step\n",
            "Epoch 75/100\n",
            "169/169 - 1s - loss: 0.5753 - accuracy: 0.8104 - val_loss: 1.5709 - val_accuracy: 0.6738 - 808ms/epoch - 5ms/step\n",
            "Epoch 76/100\n",
            "169/169 - 1s - loss: 0.4863 - accuracy: 0.8347 - val_loss: 1.5011 - val_accuracy: 0.7057 - 821ms/epoch - 5ms/step\n",
            "Epoch 77/100\n",
            "169/169 - 1s - loss: 0.4723 - accuracy: 0.8428 - val_loss: 1.4721 - val_accuracy: 0.7131 - 824ms/epoch - 5ms/step\n",
            "Epoch 78/100\n",
            "169/169 - 1s - loss: 0.4697 - accuracy: 0.8497 - val_loss: 1.8398 - val_accuracy: 0.7094 - 813ms/epoch - 5ms/step\n",
            "Epoch 79/100\n",
            "169/169 - 1s - loss: 0.3808 - accuracy: 0.8703 - val_loss: 1.4088 - val_accuracy: 0.7161 - 803ms/epoch - 5ms/step\n",
            "Epoch 80/100\n",
            "169/169 - 1s - loss: 0.4267 - accuracy: 0.8575 - val_loss: 1.8110 - val_accuracy: 0.7235 - 811ms/epoch - 5ms/step\n",
            "Epoch 81/100\n",
            "169/169 - 1s - loss: 0.3999 - accuracy: 0.8666 - val_loss: 1.6353 - val_accuracy: 0.7213 - 813ms/epoch - 5ms/step\n",
            "Epoch 82/100\n",
            "169/169 - 1s - loss: 0.3982 - accuracy: 0.8668 - val_loss: 1.7759 - val_accuracy: 0.7250 - 815ms/epoch - 5ms/step\n",
            "Epoch 83/100\n",
            "169/169 - 1s - loss: 0.4441 - accuracy: 0.8592 - val_loss: 1.4081 - val_accuracy: 0.7205 - 819ms/epoch - 5ms/step\n",
            "Epoch 84/100\n",
            "169/169 - 1s - loss: 0.3915 - accuracy: 0.8731 - val_loss: 1.5575 - val_accuracy: 0.7109 - 817ms/epoch - 5ms/step\n",
            "Epoch 85/100\n",
            "169/169 - 1s - loss: 0.4098 - accuracy: 0.8658 - val_loss: 1.4434 - val_accuracy: 0.7146 - 816ms/epoch - 5ms/step\n",
            "Epoch 86/100\n",
            "169/169 - 1s - loss: 0.4319 - accuracy: 0.8590 - val_loss: 1.6261 - val_accuracy: 0.7176 - 821ms/epoch - 5ms/step\n",
            "Epoch 87/100\n",
            "169/169 - 1s - loss: 0.3884 - accuracy: 0.8655 - val_loss: 1.5358 - val_accuracy: 0.7331 - 824ms/epoch - 5ms/step\n",
            "Epoch 88/100\n",
            "169/169 - 1s - loss: 0.3525 - accuracy: 0.8821 - val_loss: 1.5642 - val_accuracy: 0.7042 - 823ms/epoch - 5ms/step\n",
            "Epoch 89/100\n",
            "169/169 - 1s - loss: 0.4119 - accuracy: 0.8610 - val_loss: 1.7707 - val_accuracy: 0.7213 - 813ms/epoch - 5ms/step\n",
            "Epoch 90/100\n",
            "169/169 - 1s - loss: 0.4083 - accuracy: 0.8632 - val_loss: 1.6657 - val_accuracy: 0.7205 - 826ms/epoch - 5ms/step\n",
            "Epoch 91/100\n",
            "169/169 - 1s - loss: 0.3541 - accuracy: 0.8810 - val_loss: 1.5334 - val_accuracy: 0.7198 - 818ms/epoch - 5ms/step\n",
            "Epoch 92/100\n",
            "169/169 - 1s - loss: 0.4246 - accuracy: 0.8660 - val_loss: 1.7466 - val_accuracy: 0.6953 - 833ms/epoch - 5ms/step\n",
            "Epoch 93/100\n",
            "169/169 - 1s - loss: 0.3794 - accuracy: 0.8771 - val_loss: 2.0169 - val_accuracy: 0.7131 - 819ms/epoch - 5ms/step\n",
            "Epoch 94/100\n",
            "169/169 - 1s - loss: 0.3592 - accuracy: 0.8799 - val_loss: 1.8242 - val_accuracy: 0.7265 - 819ms/epoch - 5ms/step\n",
            "Epoch 95/100\n",
            "169/169 - 1s - loss: 0.3827 - accuracy: 0.8764 - val_loss: 1.6965 - val_accuracy: 0.7057 - 817ms/epoch - 5ms/step\n",
            "Epoch 96/100\n",
            "169/169 - 1s - loss: 0.3744 - accuracy: 0.8747 - val_loss: 1.8161 - val_accuracy: 0.7102 - 814ms/epoch - 5ms/step\n",
            "Epoch 97/100\n",
            "169/169 - 1s - loss: 0.3982 - accuracy: 0.8729 - val_loss: 1.6171 - val_accuracy: 0.7109 - 822ms/epoch - 5ms/step\n",
            "Epoch 98/100\n",
            "169/169 - 1s - loss: 0.4101 - accuracy: 0.8738 - val_loss: 1.5684 - val_accuracy: 0.7131 - 822ms/epoch - 5ms/step\n",
            "Epoch 99/100\n",
            "169/169 - 1s - loss: 0.3465 - accuracy: 0.8825 - val_loss: 1.6962 - val_accuracy: 0.7213 - 811ms/epoch - 5ms/step\n",
            "Epoch 100/100\n",
            "169/169 - 1s - loss: 0.3388 - accuracy: 0.8870 - val_loss: 1.8490 - val_accuracy: 0.7116 - 816ms/epoch - 5ms/step\n",
            "Model: \"sequential_35\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " reshape_34 (Reshape)        (None, 128, 40, 1)        0         \n",
            "                                                                 \n",
            " conv2d_68 (Conv2D)          (None, 128, 40, 8)        80        \n",
            "                                                                 \n",
            " max_pooling2d_66 (MaxPoolin  (None, 64, 20, 8)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " batch_normalization_33 (Bat  (None, 64, 20, 8)        32        \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv2d_69 (Conv2D)          (None, 64, 20, 16)        12816     \n",
            "                                                                 \n",
            " max_pooling2d_67 (MaxPoolin  (None, 32, 10, 16)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_33 (Dropout)        (None, 32, 10, 16)        0         \n",
            "                                                                 \n",
            " flatten_33 (Flatten)        (None, 5120)              0         \n",
            "                                                                 \n",
            " y_pred (Dense)              (None, 10)                51210     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 64,138\n",
            "Trainable params: 64,122\n",
            "Non-trainable params: 16\n",
            "_________________________________________________________________\n",
            "None\n",
            "Result of fold:7\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 3.5128 - accuracy: 0.4611\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 70%|███████   | 7/10 [09:47<04:11, 83.79s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(40, 128)\n",
            "Epoch 1/100\n",
            "170/170 - 2s - loss: 2.1589 - accuracy: 0.2845 - val_loss: 2.0750 - val_accuracy: 0.3091 - 2s/epoch - 10ms/step\n",
            "Epoch 2/100\n",
            "170/170 - 1s - loss: 1.9451 - accuracy: 0.3242 - val_loss: 1.9745 - val_accuracy: 0.2678 - 837ms/epoch - 5ms/step\n",
            "Epoch 3/100\n",
            "170/170 - 1s - loss: 1.7596 - accuracy: 0.3790 - val_loss: 1.8387 - val_accuracy: 0.3745 - 820ms/epoch - 5ms/step\n",
            "Epoch 4/100\n",
            "170/170 - 1s - loss: 1.7090 - accuracy: 0.4098 - val_loss: 1.8552 - val_accuracy: 0.3473 - 825ms/epoch - 5ms/step\n",
            "Epoch 5/100\n",
            "170/170 - 1s - loss: 1.5496 - accuracy: 0.4631 - val_loss: 1.7371 - val_accuracy: 0.4511 - 827ms/epoch - 5ms/step\n",
            "Epoch 6/100\n",
            "170/170 - 1s - loss: 1.6826 - accuracy: 0.4328 - val_loss: 1.9032 - val_accuracy: 0.3539 - 829ms/epoch - 5ms/step\n",
            "Epoch 7/100\n",
            "170/170 - 1s - loss: 1.5122 - accuracy: 0.4747 - val_loss: 1.8772 - val_accuracy: 0.4224 - 828ms/epoch - 5ms/step\n",
            "Epoch 8/100\n",
            "170/170 - 1s - loss: 1.4349 - accuracy: 0.4994 - val_loss: 1.9182 - val_accuracy: 0.4238 - 818ms/epoch - 5ms/step\n",
            "Epoch 9/100\n",
            "170/170 - 1s - loss: 1.4223 - accuracy: 0.5233 - val_loss: 1.6591 - val_accuracy: 0.4893 - 834ms/epoch - 5ms/step\n",
            "Epoch 10/100\n",
            "170/170 - 1s - loss: 1.3408 - accuracy: 0.5468 - val_loss: 1.6671 - val_accuracy: 0.5099 - 832ms/epoch - 5ms/step\n",
            "Epoch 11/100\n",
            "170/170 - 1s - loss: 1.2818 - accuracy: 0.5562 - val_loss: 1.7477 - val_accuracy: 0.5136 - 835ms/epoch - 5ms/step\n",
            "Epoch 12/100\n",
            "170/170 - 1s - loss: 1.4032 - accuracy: 0.5229 - val_loss: 1.9564 - val_accuracy: 0.3834 - 836ms/epoch - 5ms/step\n",
            "Epoch 13/100\n",
            "170/170 - 1s - loss: 1.4472 - accuracy: 0.4922 - val_loss: 2.0257 - val_accuracy: 0.4113 - 833ms/epoch - 5ms/step\n",
            "Epoch 14/100\n",
            "170/170 - 1s - loss: 1.2674 - accuracy: 0.5661 - val_loss: 2.0420 - val_accuracy: 0.4650 - 842ms/epoch - 5ms/step\n",
            "Epoch 15/100\n",
            "170/170 - 1s - loss: 1.4186 - accuracy: 0.5279 - val_loss: 2.0664 - val_accuracy: 0.4371 - 822ms/epoch - 5ms/step\n",
            "Epoch 16/100\n",
            "170/170 - 1s - loss: 1.4341 - accuracy: 0.4927 - val_loss: 1.9871 - val_accuracy: 0.4547 - 819ms/epoch - 5ms/step\n",
            "Epoch 17/100\n",
            "170/170 - 1s - loss: 1.2227 - accuracy: 0.5877 - val_loss: 1.6779 - val_accuracy: 0.5438 - 834ms/epoch - 5ms/step\n",
            "Epoch 18/100\n",
            "170/170 - 1s - loss: 1.1395 - accuracy: 0.6145 - val_loss: 1.5339 - val_accuracy: 0.5659 - 840ms/epoch - 5ms/step\n",
            "Epoch 19/100\n",
            "170/170 - 1s - loss: 1.0211 - accuracy: 0.6504 - val_loss: 1.5848 - val_accuracy: 0.5953 - 843ms/epoch - 5ms/step\n",
            "Epoch 20/100\n",
            "170/170 - 1s - loss: 0.9938 - accuracy: 0.6554 - val_loss: 1.4343 - val_accuracy: 0.6041 - 837ms/epoch - 5ms/step\n",
            "Epoch 21/100\n",
            "170/170 - 1s - loss: 0.9587 - accuracy: 0.6662 - val_loss: 1.6045 - val_accuracy: 0.6152 - 847ms/epoch - 5ms/step\n",
            "Epoch 22/100\n",
            "170/170 - 1s - loss: 0.9745 - accuracy: 0.6708 - val_loss: 1.5727 - val_accuracy: 0.6203 - 815ms/epoch - 5ms/step\n",
            "Epoch 23/100\n",
            "170/170 - 1s - loss: 0.9347 - accuracy: 0.6797 - val_loss: 1.6869 - val_accuracy: 0.6196 - 822ms/epoch - 5ms/step\n",
            "Epoch 24/100\n",
            "170/170 - 1s - loss: 1.0095 - accuracy: 0.6675 - val_loss: 1.4675 - val_accuracy: 0.6416 - 824ms/epoch - 5ms/step\n",
            "Epoch 25/100\n",
            "170/170 - 1s - loss: 0.9166 - accuracy: 0.6949 - val_loss: 1.4688 - val_accuracy: 0.6424 - 828ms/epoch - 5ms/step\n",
            "Epoch 26/100\n",
            "170/170 - 1s - loss: 0.9057 - accuracy: 0.6898 - val_loss: 1.5139 - val_accuracy: 0.6512 - 824ms/epoch - 5ms/step\n",
            "Epoch 27/100\n",
            "170/170 - 1s - loss: 0.8618 - accuracy: 0.7025 - val_loss: 1.5780 - val_accuracy: 0.6600 - 820ms/epoch - 5ms/step\n",
            "Epoch 28/100\n",
            "170/170 - 1s - loss: 0.8759 - accuracy: 0.7047 - val_loss: 1.6707 - val_accuracy: 0.6240 - 821ms/epoch - 5ms/step\n",
            "Epoch 29/100\n",
            "170/170 - 1s - loss: 0.9657 - accuracy: 0.6734 - val_loss: 1.5380 - val_accuracy: 0.5982 - 820ms/epoch - 5ms/step\n",
            "Epoch 30/100\n",
            "170/170 - 1s - loss: 0.9788 - accuracy: 0.6668 - val_loss: 1.8124 - val_accuracy: 0.6387 - 821ms/epoch - 5ms/step\n",
            "Epoch 31/100\n",
            "170/170 - 1s - loss: 0.9241 - accuracy: 0.7023 - val_loss: 1.5820 - val_accuracy: 0.6711 - 825ms/epoch - 5ms/step\n",
            "Epoch 32/100\n",
            "170/170 - 1s - loss: 0.8607 - accuracy: 0.6994 - val_loss: 1.7272 - val_accuracy: 0.6416 - 820ms/epoch - 5ms/step\n",
            "Epoch 33/100\n",
            "170/170 - 1s - loss: 0.8438 - accuracy: 0.7220 - val_loss: 1.5782 - val_accuracy: 0.6475 - 818ms/epoch - 5ms/step\n",
            "Epoch 34/100\n",
            "170/170 - 1s - loss: 0.7838 - accuracy: 0.7330 - val_loss: 1.8325 - val_accuracy: 0.6674 - 819ms/epoch - 5ms/step\n",
            "Epoch 35/100\n",
            "170/170 - 1s - loss: 0.8401 - accuracy: 0.7205 - val_loss: 1.5911 - val_accuracy: 0.6748 - 825ms/epoch - 5ms/step\n",
            "Epoch 36/100\n",
            "170/170 - 1s - loss: 0.8424 - accuracy: 0.7213 - val_loss: 1.6993 - val_accuracy: 0.6659 - 822ms/epoch - 5ms/step\n",
            "Epoch 37/100\n",
            "170/170 - 1s - loss: 0.7877 - accuracy: 0.7328 - val_loss: 1.4752 - val_accuracy: 0.6549 - 817ms/epoch - 5ms/step\n",
            "Epoch 38/100\n",
            "170/170 - 1s - loss: 0.7625 - accuracy: 0.7402 - val_loss: 1.5724 - val_accuracy: 0.6703 - 812ms/epoch - 5ms/step\n",
            "Epoch 39/100\n",
            "170/170 - 1s - loss: 0.7789 - accuracy: 0.7382 - val_loss: 1.6173 - val_accuracy: 0.6615 - 826ms/epoch - 5ms/step\n",
            "Epoch 40/100\n",
            "170/170 - 1s - loss: 0.8168 - accuracy: 0.7260 - val_loss: 1.7467 - val_accuracy: 0.6196 - 817ms/epoch - 5ms/step\n",
            "Epoch 41/100\n",
            "170/170 - 1s - loss: 0.7753 - accuracy: 0.7336 - val_loss: 1.6634 - val_accuracy: 0.6799 - 813ms/epoch - 5ms/step\n",
            "Epoch 42/100\n",
            "170/170 - 1s - loss: 0.7599 - accuracy: 0.7435 - val_loss: 1.7033 - val_accuracy: 0.6637 - 823ms/epoch - 5ms/step\n",
            "Epoch 43/100\n",
            "170/170 - 1s - loss: 0.7224 - accuracy: 0.7511 - val_loss: 1.6518 - val_accuracy: 0.6740 - 808ms/epoch - 5ms/step\n",
            "Epoch 44/100\n",
            "170/170 - 1s - loss: 0.6987 - accuracy: 0.7619 - val_loss: 1.5875 - val_accuracy: 0.6726 - 808ms/epoch - 5ms/step\n",
            "Epoch 45/100\n",
            "170/170 - 1s - loss: 0.7912 - accuracy: 0.7286 - val_loss: 1.7969 - val_accuracy: 0.6424 - 816ms/epoch - 5ms/step\n",
            "Epoch 46/100\n",
            "170/170 - 1s - loss: 0.7345 - accuracy: 0.7522 - val_loss: 1.7484 - val_accuracy: 0.6696 - 812ms/epoch - 5ms/step\n",
            "Epoch 47/100\n",
            "170/170 - 1s - loss: 0.7935 - accuracy: 0.7422 - val_loss: 1.6811 - val_accuracy: 0.6689 - 814ms/epoch - 5ms/step\n",
            "Epoch 48/100\n",
            "170/170 - 1s - loss: 0.6711 - accuracy: 0.7684 - val_loss: 1.7082 - val_accuracy: 0.6836 - 814ms/epoch - 5ms/step\n",
            "Epoch 49/100\n",
            "170/170 - 1s - loss: 0.6670 - accuracy: 0.7695 - val_loss: 1.8497 - val_accuracy: 0.6667 - 815ms/epoch - 5ms/step\n",
            "Epoch 50/100\n",
            "170/170 - 1s - loss: 0.6443 - accuracy: 0.7827 - val_loss: 1.8369 - val_accuracy: 0.6814 - 811ms/epoch - 5ms/step\n",
            "Epoch 51/100\n",
            "170/170 - 1s - loss: 0.6802 - accuracy: 0.7737 - val_loss: 1.7436 - val_accuracy: 0.6784 - 825ms/epoch - 5ms/step\n",
            "Epoch 52/100\n",
            "170/170 - 1s - loss: 0.6839 - accuracy: 0.7759 - val_loss: 1.7694 - val_accuracy: 0.6755 - 818ms/epoch - 5ms/step\n",
            "Epoch 53/100\n",
            "170/170 - 1s - loss: 0.6603 - accuracy: 0.7777 - val_loss: 1.7418 - val_accuracy: 0.6623 - 814ms/epoch - 5ms/step\n",
            "Epoch 54/100\n",
            "170/170 - 1s - loss: 0.6452 - accuracy: 0.7869 - val_loss: 1.7696 - val_accuracy: 0.6799 - 815ms/epoch - 5ms/step\n",
            "Epoch 55/100\n",
            "170/170 - 1s - loss: 0.6529 - accuracy: 0.7904 - val_loss: 1.5666 - val_accuracy: 0.6843 - 812ms/epoch - 5ms/step\n",
            "Epoch 56/100\n",
            "170/170 - 1s - loss: 0.6065 - accuracy: 0.7956 - val_loss: 1.6410 - val_accuracy: 0.6865 - 809ms/epoch - 5ms/step\n",
            "Epoch 57/100\n",
            "170/170 - 1s - loss: 0.6420 - accuracy: 0.7790 - val_loss: 1.8242 - val_accuracy: 0.6917 - 811ms/epoch - 5ms/step\n",
            "Epoch 58/100\n",
            "170/170 - 1s - loss: 0.6380 - accuracy: 0.7943 - val_loss: 1.6131 - val_accuracy: 0.6328 - 815ms/epoch - 5ms/step\n",
            "Epoch 59/100\n",
            "170/170 - 1s - loss: 0.7855 - accuracy: 0.7400 - val_loss: 2.0618 - val_accuracy: 0.6564 - 856ms/epoch - 5ms/step\n",
            "Epoch 60/100\n",
            "170/170 - 1s - loss: 0.7093 - accuracy: 0.7672 - val_loss: 1.6701 - val_accuracy: 0.6843 - 916ms/epoch - 5ms/step\n",
            "Epoch 61/100\n",
            "170/170 - 1s - loss: 0.6113 - accuracy: 0.7954 - val_loss: 1.7585 - val_accuracy: 0.6865 - 895ms/epoch - 5ms/step\n",
            "Epoch 62/100\n",
            "170/170 - 1s - loss: 0.5775 - accuracy: 0.8055 - val_loss: 1.7395 - val_accuracy: 0.6865 - 839ms/epoch - 5ms/step\n",
            "Epoch 63/100\n",
            "170/170 - 1s - loss: 0.5404 - accuracy: 0.8191 - val_loss: 1.9033 - val_accuracy: 0.6718 - 825ms/epoch - 5ms/step\n",
            "Epoch 64/100\n",
            "170/170 - 1s - loss: 0.5866 - accuracy: 0.8068 - val_loss: 1.6814 - val_accuracy: 0.7005 - 823ms/epoch - 5ms/step\n",
            "Epoch 65/100\n",
            "170/170 - 1s - loss: 0.5384 - accuracy: 0.8250 - val_loss: 1.7084 - val_accuracy: 0.6976 - 818ms/epoch - 5ms/step\n",
            "Epoch 66/100\n",
            "170/170 - 1s - loss: 0.4982 - accuracy: 0.8322 - val_loss: 2.0360 - val_accuracy: 0.7093 - 814ms/epoch - 5ms/step\n",
            "Epoch 67/100\n",
            "170/170 - 1s - loss: 0.5752 - accuracy: 0.8153 - val_loss: 1.8269 - val_accuracy: 0.6777 - 812ms/epoch - 5ms/step\n",
            "Epoch 68/100\n",
            "170/170 - 1s - loss: 0.6089 - accuracy: 0.8066 - val_loss: 1.5798 - val_accuracy: 0.6726 - 818ms/epoch - 5ms/step\n",
            "Epoch 69/100\n",
            "170/170 - 1s - loss: 0.5235 - accuracy: 0.8234 - val_loss: 1.7795 - val_accuracy: 0.6873 - 823ms/epoch - 5ms/step\n",
            "Epoch 70/100\n",
            "170/170 - 1s - loss: 0.5301 - accuracy: 0.8311 - val_loss: 1.9108 - val_accuracy: 0.6703 - 806ms/epoch - 5ms/step\n",
            "Epoch 71/100\n",
            "170/170 - 1s - loss: 0.5629 - accuracy: 0.8171 - val_loss: 1.7928 - val_accuracy: 0.6909 - 818ms/epoch - 5ms/step\n",
            "Epoch 72/100\n",
            "170/170 - 1s - loss: 0.4813 - accuracy: 0.8359 - val_loss: 1.7659 - val_accuracy: 0.7035 - 807ms/epoch - 5ms/step\n",
            "Epoch 73/100\n",
            "170/170 - 1s - loss: 0.5241 - accuracy: 0.8265 - val_loss: 1.7017 - val_accuracy: 0.6932 - 814ms/epoch - 5ms/step\n",
            "Epoch 74/100\n",
            "170/170 - 1s - loss: 0.4560 - accuracy: 0.8416 - val_loss: 1.6696 - val_accuracy: 0.6630 - 816ms/epoch - 5ms/step\n",
            "Epoch 75/100\n",
            "170/170 - 1s - loss: 0.4804 - accuracy: 0.8420 - val_loss: 1.6446 - val_accuracy: 0.7211 - 812ms/epoch - 5ms/step\n",
            "Epoch 76/100\n",
            "170/170 - 1s - loss: 0.4619 - accuracy: 0.8434 - val_loss: 1.7644 - val_accuracy: 0.7093 - 821ms/epoch - 5ms/step\n",
            "Epoch 77/100\n",
            "170/170 - 1s - loss: 0.4504 - accuracy: 0.8567 - val_loss: 1.8365 - val_accuracy: 0.7042 - 815ms/epoch - 5ms/step\n",
            "Epoch 78/100\n",
            "170/170 - 1s - loss: 0.5063 - accuracy: 0.8383 - val_loss: 1.9338 - val_accuracy: 0.7020 - 818ms/epoch - 5ms/step\n",
            "Epoch 79/100\n",
            "170/170 - 1s - loss: 0.6715 - accuracy: 0.7803 - val_loss: 1.8105 - val_accuracy: 0.6321 - 814ms/epoch - 5ms/step\n",
            "Epoch 80/100\n",
            "170/170 - 1s - loss: 0.6820 - accuracy: 0.7923 - val_loss: 2.1443 - val_accuracy: 0.6858 - 822ms/epoch - 5ms/step\n",
            "Epoch 81/100\n",
            "170/170 - 1s - loss: 0.5228 - accuracy: 0.8386 - val_loss: 1.6040 - val_accuracy: 0.6976 - 814ms/epoch - 5ms/step\n",
            "Epoch 82/100\n",
            "170/170 - 1s - loss: 0.4722 - accuracy: 0.8456 - val_loss: 1.7810 - val_accuracy: 0.7035 - 813ms/epoch - 5ms/step\n",
            "Epoch 83/100\n",
            "170/170 - 1s - loss: 0.4462 - accuracy: 0.8493 - val_loss: 1.6653 - val_accuracy: 0.7035 - 821ms/epoch - 5ms/step\n",
            "Epoch 84/100\n",
            "170/170 - 1s - loss: 0.4321 - accuracy: 0.8559 - val_loss: 1.9658 - val_accuracy: 0.7042 - 810ms/epoch - 5ms/step\n",
            "Epoch 85/100\n",
            "170/170 - 1s - loss: 0.4498 - accuracy: 0.8585 - val_loss: 1.7963 - val_accuracy: 0.7145 - 826ms/epoch - 5ms/step\n",
            "Epoch 86/100\n",
            "170/170 - 1s - loss: 0.4893 - accuracy: 0.8401 - val_loss: 1.7683 - val_accuracy: 0.7196 - 813ms/epoch - 5ms/step\n",
            "Epoch 87/100\n",
            "170/170 - 1s - loss: 0.4358 - accuracy: 0.8574 - val_loss: 1.6922 - val_accuracy: 0.7116 - 819ms/epoch - 5ms/step\n",
            "Epoch 88/100\n",
            "170/170 - 1s - loss: 0.3854 - accuracy: 0.8712 - val_loss: 1.8862 - val_accuracy: 0.7167 - 812ms/epoch - 5ms/step\n",
            "Epoch 89/100\n",
            "170/170 - 1s - loss: 0.4061 - accuracy: 0.8644 - val_loss: 1.7147 - val_accuracy: 0.6740 - 827ms/epoch - 5ms/step\n",
            "Epoch 90/100\n",
            "170/170 - 1s - loss: 0.3936 - accuracy: 0.8730 - val_loss: 1.9219 - val_accuracy: 0.7204 - 814ms/epoch - 5ms/step\n",
            "Epoch 91/100\n",
            "170/170 - 1s - loss: 0.3759 - accuracy: 0.8758 - val_loss: 1.9753 - val_accuracy: 0.6968 - 815ms/epoch - 5ms/step\n",
            "Epoch 92/100\n",
            "170/170 - 1s - loss: 0.3751 - accuracy: 0.8734 - val_loss: 1.8018 - val_accuracy: 0.7211 - 817ms/epoch - 5ms/step\n",
            "Epoch 93/100\n",
            "170/170 - 1s - loss: 0.3706 - accuracy: 0.8782 - val_loss: 1.7841 - val_accuracy: 0.7219 - 825ms/epoch - 5ms/step\n",
            "Epoch 94/100\n",
            "170/170 - 1s - loss: 0.3687 - accuracy: 0.8762 - val_loss: 1.8744 - val_accuracy: 0.7057 - 822ms/epoch - 5ms/step\n",
            "Epoch 95/100\n",
            "170/170 - 1s - loss: 0.3983 - accuracy: 0.8699 - val_loss: 2.1239 - val_accuracy: 0.7189 - 814ms/epoch - 5ms/step\n",
            "Epoch 96/100\n",
            "170/170 - 1s - loss: 0.4185 - accuracy: 0.8635 - val_loss: 2.2016 - val_accuracy: 0.7219 - 816ms/epoch - 5ms/step\n",
            "Epoch 97/100\n",
            "170/170 - 1s - loss: 0.3653 - accuracy: 0.8767 - val_loss: 2.0113 - val_accuracy: 0.7226 - 816ms/epoch - 5ms/step\n",
            "Epoch 98/100\n",
            "170/170 - 1s - loss: 0.3674 - accuracy: 0.8765 - val_loss: 1.8038 - val_accuracy: 0.7329 - 819ms/epoch - 5ms/step\n",
            "Epoch 99/100\n",
            "170/170 - 1s - loss: 0.4741 - accuracy: 0.8473 - val_loss: 2.1591 - val_accuracy: 0.7226 - 818ms/epoch - 5ms/step\n",
            "Epoch 100/100\n",
            "170/170 - 1s - loss: 0.4530 - accuracy: 0.8629 - val_loss: 1.8223 - val_accuracy: 0.7042 - 814ms/epoch - 5ms/step\n",
            "Model: \"sequential_37\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " reshape_36 (Reshape)        (None, 128, 40, 1)        0         \n",
            "                                                                 \n",
            " conv2d_72 (Conv2D)          (None, 128, 40, 8)        80        \n",
            "                                                                 \n",
            " max_pooling2d_70 (MaxPoolin  (None, 64, 20, 8)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " batch_normalization_35 (Bat  (None, 64, 20, 8)        32        \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv2d_73 (Conv2D)          (None, 64, 20, 16)        12816     \n",
            "                                                                 \n",
            " max_pooling2d_71 (MaxPoolin  (None, 32, 10, 16)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_35 (Dropout)        (None, 32, 10, 16)        0         \n",
            "                                                                 \n",
            " flatten_35 (Flatten)        (None, 5120)              0         \n",
            "                                                                 \n",
            " y_pred (Dense)              (None, 10)                51210     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 64,138\n",
            "Trainable params: 64,122\n",
            "Non-trainable params: 16\n",
            "_________________________________________________________________\n",
            "None\n",
            "Result of fold:8\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 4.0428 - accuracy: 0.4722\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 80%|████████  | 8/10 [11:11<02:48, 84.11s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(40, 128)\n",
            "Epoch 1/100\n",
            "170/170 - 2s - loss: 2.2429 - accuracy: 0.2722 - val_loss: 1.9959 - val_accuracy: 0.2467 - 2s/epoch - 10ms/step\n",
            "Epoch 2/100\n",
            "170/170 - 1s - loss: 1.8368 - accuracy: 0.3708 - val_loss: 1.8434 - val_accuracy: 0.3146 - 821ms/epoch - 5ms/step\n",
            "Epoch 3/100\n",
            "170/170 - 1s - loss: 1.7922 - accuracy: 0.3914 - val_loss: 1.7476 - val_accuracy: 0.4476 - 820ms/epoch - 5ms/step\n",
            "Epoch 4/100\n",
            "170/170 - 1s - loss: 1.6138 - accuracy: 0.4429 - val_loss: 1.7796 - val_accuracy: 0.3693 - 816ms/epoch - 5ms/step\n",
            "Epoch 5/100\n",
            "170/170 - 1s - loss: 1.5399 - accuracy: 0.4743 - val_loss: 1.6701 - val_accuracy: 0.4734 - 835ms/epoch - 5ms/step\n",
            "Epoch 6/100\n",
            "170/170 - 1s - loss: 1.5034 - accuracy: 0.4751 - val_loss: 1.6307 - val_accuracy: 0.4269 - 824ms/epoch - 5ms/step\n",
            "Epoch 7/100\n",
            "170/170 - 1s - loss: 1.3760 - accuracy: 0.5205 - val_loss: 1.5515 - val_accuracy: 0.5096 - 814ms/epoch - 5ms/step\n",
            "Epoch 8/100\n",
            "170/170 - 1s - loss: 1.3672 - accuracy: 0.5231 - val_loss: 1.4860 - val_accuracy: 0.5244 - 814ms/epoch - 5ms/step\n",
            "Epoch 9/100\n",
            "170/170 - 1s - loss: 1.3045 - accuracy: 0.5454 - val_loss: 1.5573 - val_accuracy: 0.4734 - 818ms/epoch - 5ms/step\n",
            "Epoch 10/100\n",
            "170/170 - 1s - loss: 1.3130 - accuracy: 0.5417 - val_loss: 1.5358 - val_accuracy: 0.5030 - 818ms/epoch - 5ms/step\n",
            "Epoch 11/100\n",
            "170/170 - 1s - loss: 1.2438 - accuracy: 0.5630 - val_loss: 1.3881 - val_accuracy: 0.5406 - 818ms/epoch - 5ms/step\n",
            "Epoch 12/100\n",
            "170/170 - 1s - loss: 1.2501 - accuracy: 0.5646 - val_loss: 1.3839 - val_accuracy: 0.5798 - 817ms/epoch - 5ms/step\n",
            "Epoch 13/100\n",
            "170/170 - 1s - loss: 1.2113 - accuracy: 0.5787 - val_loss: 1.3471 - val_accuracy: 0.5783 - 828ms/epoch - 5ms/step\n",
            "Epoch 14/100\n",
            "170/170 - 1s - loss: 1.1701 - accuracy: 0.5960 - val_loss: 1.4076 - val_accuracy: 0.5687 - 816ms/epoch - 5ms/step\n",
            "Epoch 15/100\n",
            "170/170 - 1s - loss: 1.1455 - accuracy: 0.6065 - val_loss: 1.3118 - val_accuracy: 0.6056 - 825ms/epoch - 5ms/step\n",
            "Epoch 16/100\n",
            "170/170 - 1s - loss: 1.0988 - accuracy: 0.6219 - val_loss: 1.4592 - val_accuracy: 0.5355 - 815ms/epoch - 5ms/step\n",
            "Epoch 17/100\n",
            "170/170 - 1s - loss: 1.1041 - accuracy: 0.6230 - val_loss: 1.4041 - val_accuracy: 0.5377 - 817ms/epoch - 5ms/step\n",
            "Epoch 18/100\n",
            "170/170 - 1s - loss: 1.1125 - accuracy: 0.6123 - val_loss: 1.3972 - val_accuracy: 0.6226 - 818ms/epoch - 5ms/step\n",
            "Epoch 19/100\n",
            "170/170 - 1s - loss: 1.0416 - accuracy: 0.6455 - val_loss: 1.3406 - val_accuracy: 0.6108 - 825ms/epoch - 5ms/step\n",
            "Epoch 20/100\n",
            "170/170 - 1s - loss: 1.0675 - accuracy: 0.6352 - val_loss: 1.2692 - val_accuracy: 0.5968 - 815ms/epoch - 5ms/step\n",
            "Epoch 21/100\n",
            "170/170 - 1s - loss: 1.0332 - accuracy: 0.6473 - val_loss: 1.3612 - val_accuracy: 0.5812 - 821ms/epoch - 5ms/step\n",
            "Epoch 22/100\n",
            "170/170 - 1s - loss: 1.0118 - accuracy: 0.6508 - val_loss: 1.2343 - val_accuracy: 0.6322 - 817ms/epoch - 5ms/step\n",
            "Epoch 23/100\n",
            "170/170 - 1s - loss: 0.9751 - accuracy: 0.6623 - val_loss: 1.2835 - val_accuracy: 0.6411 - 817ms/epoch - 5ms/step\n",
            "Epoch 24/100\n",
            "170/170 - 1s - loss: 0.9626 - accuracy: 0.6689 - val_loss: 1.2947 - val_accuracy: 0.6359 - 818ms/epoch - 5ms/step\n",
            "Epoch 25/100\n",
            "170/170 - 1s - loss: 1.0121 - accuracy: 0.6523 - val_loss: 1.3446 - val_accuracy: 0.5820 - 832ms/epoch - 5ms/step\n",
            "Epoch 26/100\n",
            "170/170 - 1s - loss: 1.0011 - accuracy: 0.6581 - val_loss: 1.2706 - val_accuracy: 0.6337 - 823ms/epoch - 5ms/step\n",
            "Epoch 27/100\n",
            "170/170 - 1s - loss: 0.9707 - accuracy: 0.6665 - val_loss: 1.1693 - val_accuracy: 0.6492 - 821ms/epoch - 5ms/step\n",
            "Epoch 28/100\n",
            "170/170 - 1s - loss: 0.9936 - accuracy: 0.6571 - val_loss: 1.3620 - val_accuracy: 0.6329 - 817ms/epoch - 5ms/step\n",
            "Epoch 29/100\n",
            "170/170 - 1s - loss: 0.9142 - accuracy: 0.6841 - val_loss: 1.3458 - val_accuracy: 0.6551 - 813ms/epoch - 5ms/step\n",
            "Epoch 30/100\n",
            "170/170 - 1s - loss: 0.8579 - accuracy: 0.7085 - val_loss: 1.2349 - val_accuracy: 0.6632 - 824ms/epoch - 5ms/step\n",
            "Epoch 31/100\n",
            "170/170 - 1s - loss: 0.8627 - accuracy: 0.7075 - val_loss: 1.3224 - val_accuracy: 0.6396 - 817ms/epoch - 5ms/step\n",
            "Epoch 32/100\n",
            "170/170 - 1s - loss: 0.8835 - accuracy: 0.6950 - val_loss: 1.3751 - val_accuracy: 0.6558 - 822ms/epoch - 5ms/step\n",
            "Epoch 33/100\n",
            "170/170 - 1s - loss: 0.9098 - accuracy: 0.6944 - val_loss: 1.3772 - val_accuracy: 0.6004 - 824ms/epoch - 5ms/step\n",
            "Epoch 34/100\n",
            "170/170 - 1s - loss: 0.9631 - accuracy: 0.6658 - val_loss: 1.3159 - val_accuracy: 0.6292 - 814ms/epoch - 5ms/step\n",
            "Epoch 35/100\n",
            "170/170 - 1s - loss: 0.8784 - accuracy: 0.6994 - val_loss: 1.3102 - val_accuracy: 0.6470 - 830ms/epoch - 5ms/step\n",
            "Epoch 36/100\n",
            "170/170 - 1s - loss: 0.8277 - accuracy: 0.7157 - val_loss: 1.3454 - val_accuracy: 0.6514 - 813ms/epoch - 5ms/step\n",
            "Epoch 37/100\n",
            "170/170 - 1s - loss: 0.8306 - accuracy: 0.7195 - val_loss: 1.2142 - val_accuracy: 0.6470 - 832ms/epoch - 5ms/step\n",
            "Epoch 38/100\n",
            "170/170 - 1s - loss: 0.8307 - accuracy: 0.7129 - val_loss: 1.3146 - val_accuracy: 0.6278 - 814ms/epoch - 5ms/step\n",
            "Epoch 39/100\n",
            "170/170 - 1s - loss: 0.7858 - accuracy: 0.7229 - val_loss: 1.3703 - val_accuracy: 0.6396 - 811ms/epoch - 5ms/step\n",
            "Epoch 40/100\n",
            "170/170 - 1s - loss: 0.8274 - accuracy: 0.7269 - val_loss: 1.2527 - val_accuracy: 0.6625 - 820ms/epoch - 5ms/step\n",
            "Epoch 41/100\n",
            "170/170 - 1s - loss: 0.7702 - accuracy: 0.7319 - val_loss: 1.3054 - val_accuracy: 0.6691 - 822ms/epoch - 5ms/step\n",
            "Epoch 42/100\n",
            "170/170 - 1s - loss: 0.7993 - accuracy: 0.7277 - val_loss: 1.4277 - val_accuracy: 0.6507 - 822ms/epoch - 5ms/step\n",
            "Epoch 43/100\n",
            "170/170 - 1s - loss: 0.7631 - accuracy: 0.7467 - val_loss: 1.2430 - val_accuracy: 0.6529 - 807ms/epoch - 5ms/step\n",
            "Epoch 44/100\n",
            "170/170 - 1s - loss: 0.7513 - accuracy: 0.7461 - val_loss: 1.3693 - val_accuracy: 0.6662 - 814ms/epoch - 5ms/step\n",
            "Epoch 45/100\n",
            "170/170 - 1s - loss: 0.7825 - accuracy: 0.7352 - val_loss: 1.3662 - val_accuracy: 0.6758 - 817ms/epoch - 5ms/step\n",
            "Epoch 46/100\n",
            "170/170 - 1s - loss: 0.7454 - accuracy: 0.7459 - val_loss: 1.3091 - val_accuracy: 0.6625 - 823ms/epoch - 5ms/step\n",
            "Epoch 47/100\n",
            "170/170 - 1s - loss: 0.7263 - accuracy: 0.7546 - val_loss: 1.2993 - val_accuracy: 0.6617 - 825ms/epoch - 5ms/step\n",
            "Epoch 48/100\n",
            "170/170 - 1s - loss: 0.7271 - accuracy: 0.7504 - val_loss: 1.6537 - val_accuracy: 0.6706 - 820ms/epoch - 5ms/step\n",
            "Epoch 49/100\n",
            "170/170 - 1s - loss: 0.7521 - accuracy: 0.7406 - val_loss: 1.5045 - val_accuracy: 0.6366 - 823ms/epoch - 5ms/step\n",
            "Epoch 50/100\n",
            "170/170 - 1s - loss: 0.7147 - accuracy: 0.7544 - val_loss: 1.3165 - val_accuracy: 0.6846 - 843ms/epoch - 5ms/step\n",
            "Epoch 51/100\n",
            "170/170 - 1s - loss: 0.7734 - accuracy: 0.7437 - val_loss: 1.3606 - val_accuracy: 0.6581 - 838ms/epoch - 5ms/step\n",
            "Epoch 52/100\n",
            "170/170 - 1s - loss: 0.7148 - accuracy: 0.7614 - val_loss: 1.3564 - val_accuracy: 0.6462 - 823ms/epoch - 5ms/step\n",
            "Epoch 53/100\n",
            "170/170 - 1s - loss: 0.6691 - accuracy: 0.7694 - val_loss: 1.4335 - val_accuracy: 0.6787 - 822ms/epoch - 5ms/step\n",
            "Epoch 54/100\n",
            "170/170 - 1s - loss: 0.6975 - accuracy: 0.7644 - val_loss: 1.3813 - val_accuracy: 0.6315 - 831ms/epoch - 5ms/step\n",
            "Epoch 55/100\n",
            "170/170 - 1s - loss: 0.6849 - accuracy: 0.7688 - val_loss: 1.2643 - val_accuracy: 0.6750 - 817ms/epoch - 5ms/step\n",
            "Epoch 56/100\n",
            "170/170 - 1s - loss: 0.6485 - accuracy: 0.7770 - val_loss: 1.2546 - val_accuracy: 0.6787 - 821ms/epoch - 5ms/step\n",
            "Epoch 57/100\n",
            "170/170 - 1s - loss: 0.6411 - accuracy: 0.7808 - val_loss: 1.2837 - val_accuracy: 0.6736 - 834ms/epoch - 5ms/step\n",
            "Epoch 58/100\n",
            "170/170 - 1s - loss: 0.6400 - accuracy: 0.7886 - val_loss: 1.3046 - val_accuracy: 0.6979 - 828ms/epoch - 5ms/step\n",
            "Epoch 59/100\n",
            "170/170 - 1s - loss: 0.6456 - accuracy: 0.7867 - val_loss: 1.3205 - val_accuracy: 0.6795 - 817ms/epoch - 5ms/step\n",
            "Epoch 60/100\n",
            "170/170 - 1s - loss: 0.7585 - accuracy: 0.7465 - val_loss: 1.4447 - val_accuracy: 0.6743 - 824ms/epoch - 5ms/step\n",
            "Epoch 61/100\n",
            "170/170 - 1s - loss: 0.6666 - accuracy: 0.7729 - val_loss: 1.3802 - val_accuracy: 0.6876 - 818ms/epoch - 5ms/step\n",
            "Epoch 62/100\n",
            "170/170 - 1s - loss: 0.6149 - accuracy: 0.7864 - val_loss: 1.3276 - val_accuracy: 0.7053 - 804ms/epoch - 5ms/step\n",
            "Epoch 63/100\n",
            "170/170 - 1s - loss: 0.6812 - accuracy: 0.7701 - val_loss: 1.4541 - val_accuracy: 0.6669 - 819ms/epoch - 5ms/step\n",
            "Epoch 64/100\n",
            "170/170 - 1s - loss: 0.6932 - accuracy: 0.7670 - val_loss: 1.3199 - val_accuracy: 0.7068 - 828ms/epoch - 5ms/step\n",
            "Epoch 65/100\n",
            "170/170 - 1s - loss: 0.6115 - accuracy: 0.7923 - val_loss: 1.3300 - val_accuracy: 0.7090 - 827ms/epoch - 5ms/step\n",
            "Epoch 66/100\n",
            "170/170 - 1s - loss: 0.5501 - accuracy: 0.8076 - val_loss: 1.4606 - val_accuracy: 0.6839 - 835ms/epoch - 5ms/step\n",
            "Epoch 67/100\n",
            "170/170 - 1s - loss: 0.5475 - accuracy: 0.8174 - val_loss: 1.3212 - val_accuracy: 0.6950 - 822ms/epoch - 5ms/step\n",
            "Epoch 68/100\n",
            "170/170 - 1s - loss: 0.5819 - accuracy: 0.8102 - val_loss: 1.4127 - val_accuracy: 0.7024 - 834ms/epoch - 5ms/step\n",
            "Epoch 69/100\n",
            "170/170 - 1s - loss: 0.5436 - accuracy: 0.8087 - val_loss: 1.4312 - val_accuracy: 0.7134 - 824ms/epoch - 5ms/step\n",
            "Epoch 70/100\n",
            "170/170 - 1s - loss: 0.6245 - accuracy: 0.7928 - val_loss: 1.2264 - val_accuracy: 0.6965 - 818ms/epoch - 5ms/step\n",
            "Epoch 71/100\n",
            "170/170 - 1s - loss: 0.5947 - accuracy: 0.7967 - val_loss: 1.3334 - val_accuracy: 0.6994 - 819ms/epoch - 5ms/step\n",
            "Epoch 72/100\n",
            "170/170 - 1s - loss: 0.5831 - accuracy: 0.8091 - val_loss: 1.3585 - val_accuracy: 0.7068 - 832ms/epoch - 5ms/step\n",
            "Epoch 73/100\n",
            "170/170 - 1s - loss: 0.5623 - accuracy: 0.8085 - val_loss: 1.4388 - val_accuracy: 0.6824 - 816ms/epoch - 5ms/step\n",
            "Epoch 74/100\n",
            "170/170 - 1s - loss: 0.6571 - accuracy: 0.7858 - val_loss: 1.4073 - val_accuracy: 0.7134 - 811ms/epoch - 5ms/step\n",
            "Epoch 75/100\n",
            "170/170 - 1s - loss: 0.5762 - accuracy: 0.8072 - val_loss: 1.5295 - val_accuracy: 0.6854 - 816ms/epoch - 5ms/step\n",
            "Epoch 76/100\n",
            "170/170 - 1s - loss: 0.6117 - accuracy: 0.7912 - val_loss: 1.3329 - val_accuracy: 0.7001 - 819ms/epoch - 5ms/step\n",
            "Epoch 77/100\n",
            "170/170 - 1s - loss: 0.6529 - accuracy: 0.7847 - val_loss: 1.2744 - val_accuracy: 0.6876 - 815ms/epoch - 5ms/step\n",
            "Epoch 78/100\n",
            "170/170 - 1s - loss: 0.5347 - accuracy: 0.8231 - val_loss: 1.4338 - val_accuracy: 0.7097 - 817ms/epoch - 5ms/step\n",
            "Epoch 79/100\n",
            "170/170 - 1s - loss: 0.5699 - accuracy: 0.8152 - val_loss: 1.2985 - val_accuracy: 0.6965 - 822ms/epoch - 5ms/step\n",
            "Epoch 80/100\n",
            "170/170 - 1s - loss: 0.5622 - accuracy: 0.8100 - val_loss: 1.3211 - val_accuracy: 0.6832 - 812ms/epoch - 5ms/step\n",
            "Epoch 81/100\n",
            "170/170 - 1s - loss: 0.5453 - accuracy: 0.8144 - val_loss: 1.4169 - val_accuracy: 0.7223 - 818ms/epoch - 5ms/step\n",
            "Epoch 82/100\n",
            "170/170 - 1s - loss: 0.5203 - accuracy: 0.8255 - val_loss: 1.4660 - val_accuracy: 0.6957 - 816ms/epoch - 5ms/step\n",
            "Epoch 83/100\n",
            "170/170 - 1s - loss: 0.5403 - accuracy: 0.8187 - val_loss: 1.3589 - val_accuracy: 0.7149 - 813ms/epoch - 5ms/step\n",
            "Epoch 84/100\n",
            "170/170 - 1s - loss: 0.5283 - accuracy: 0.8246 - val_loss: 1.3592 - val_accuracy: 0.7009 - 814ms/epoch - 5ms/step\n",
            "Epoch 85/100\n",
            "170/170 - 1s - loss: 0.5762 - accuracy: 0.8111 - val_loss: 1.3964 - val_accuracy: 0.7201 - 807ms/epoch - 5ms/step\n",
            "Epoch 86/100\n",
            "170/170 - 1s - loss: 0.4717 - accuracy: 0.8464 - val_loss: 1.4855 - val_accuracy: 0.6935 - 822ms/epoch - 5ms/step\n",
            "Epoch 87/100\n",
            "170/170 - 1s - loss: 0.5029 - accuracy: 0.8298 - val_loss: 1.6543 - val_accuracy: 0.7097 - 821ms/epoch - 5ms/step\n",
            "Epoch 88/100\n",
            "170/170 - 1s - loss: 0.5185 - accuracy: 0.8301 - val_loss: 1.4281 - val_accuracy: 0.7112 - 811ms/epoch - 5ms/step\n",
            "Epoch 89/100\n",
            "170/170 - 1s - loss: 0.5072 - accuracy: 0.8379 - val_loss: 1.3764 - val_accuracy: 0.7068 - 815ms/epoch - 5ms/step\n",
            "Epoch 90/100\n",
            "170/170 - 1s - loss: 0.5028 - accuracy: 0.8327 - val_loss: 1.4061 - val_accuracy: 0.6677 - 821ms/epoch - 5ms/step\n",
            "Epoch 91/100\n",
            "170/170 - 1s - loss: 0.7458 - accuracy: 0.7439 - val_loss: 1.3248 - val_accuracy: 0.7208 - 830ms/epoch - 5ms/step\n",
            "Epoch 92/100\n",
            "170/170 - 1s - loss: 0.5912 - accuracy: 0.8015 - val_loss: 1.3487 - val_accuracy: 0.7090 - 812ms/epoch - 5ms/step\n",
            "Epoch 93/100\n",
            "170/170 - 1s - loss: 0.4574 - accuracy: 0.8416 - val_loss: 1.4900 - val_accuracy: 0.7157 - 817ms/epoch - 5ms/step\n",
            "Epoch 94/100\n",
            "170/170 - 1s - loss: 0.4840 - accuracy: 0.8397 - val_loss: 1.3941 - val_accuracy: 0.7053 - 809ms/epoch - 5ms/step\n",
            "Epoch 95/100\n",
            "170/170 - 1s - loss: 0.4717 - accuracy: 0.8468 - val_loss: 1.4874 - val_accuracy: 0.7238 - 813ms/epoch - 5ms/step\n",
            "Epoch 96/100\n",
            "170/170 - 1s - loss: 0.4301 - accuracy: 0.8532 - val_loss: 1.4003 - val_accuracy: 0.7149 - 811ms/epoch - 5ms/step\n",
            "Epoch 97/100\n",
            "170/170 - 1s - loss: 0.4930 - accuracy: 0.8357 - val_loss: 1.3494 - val_accuracy: 0.7297 - 814ms/epoch - 5ms/step\n",
            "Epoch 98/100\n",
            "170/170 - 1s - loss: 0.4287 - accuracy: 0.8565 - val_loss: 1.5254 - val_accuracy: 0.7245 - 816ms/epoch - 5ms/step\n",
            "Epoch 99/100\n",
            "170/170 - 1s - loss: 0.4564 - accuracy: 0.8469 - val_loss: 1.3461 - val_accuracy: 0.7068 - 810ms/epoch - 5ms/step\n",
            "Epoch 100/100\n",
            "170/170 - 1s - loss: 0.4805 - accuracy: 0.8416 - val_loss: 1.5351 - val_accuracy: 0.6883 - 827ms/epoch - 5ms/step\n",
            "Model: \"sequential_39\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " reshape_38 (Reshape)        (None, 128, 40, 1)        0         \n",
            "                                                                 \n",
            " conv2d_76 (Conv2D)          (None, 128, 40, 8)        80        \n",
            "                                                                 \n",
            " max_pooling2d_74 (MaxPoolin  (None, 64, 20, 8)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " batch_normalization_37 (Bat  (None, 64, 20, 8)        32        \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv2d_77 (Conv2D)          (None, 64, 20, 16)        12816     \n",
            "                                                                 \n",
            " max_pooling2d_75 (MaxPoolin  (None, 32, 10, 16)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_37 (Dropout)        (None, 32, 10, 16)        0         \n",
            "                                                                 \n",
            " flatten_37 (Flatten)        (None, 5120)              0         \n",
            "                                                                 \n",
            " y_pred (Dense)              (None, 10)                51210     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 64,138\n",
            "Trainable params: 64,122\n",
            "Non-trainable params: 16\n",
            "_________________________________________________________________\n",
            "None\n",
            "Result of fold:9\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 5.5651 - accuracy: 0.5508\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 90%|█████████ | 9/10 [13:35<01:42, 102.72s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(40, 128)\n",
            "Epoch 1/100\n",
            "169/169 - 2s - loss: 2.2667 - accuracy: 0.2648 - val_loss: 2.1395 - val_accuracy: 0.2528 - 2s/epoch - 10ms/step\n",
            "Epoch 2/100\n",
            "169/169 - 1s - loss: 1.9245 - accuracy: 0.3373 - val_loss: 1.9952 - val_accuracy: 0.3503 - 754ms/epoch - 4ms/step\n",
            "Epoch 3/100\n",
            "169/169 - 1s - loss: 1.8102 - accuracy: 0.3643 - val_loss: 1.9574 - val_accuracy: 0.2956 - 759ms/epoch - 4ms/step\n",
            "Epoch 4/100\n",
            "169/169 - 1s - loss: 1.7172 - accuracy: 0.3896 - val_loss: 1.9478 - val_accuracy: 0.2927 - 762ms/epoch - 5ms/step\n",
            "Epoch 5/100\n",
            "169/169 - 1s - loss: 1.6786 - accuracy: 0.3957 - val_loss: 1.9007 - val_accuracy: 0.3392 - 758ms/epoch - 4ms/step\n",
            "Epoch 6/100\n",
            "169/169 - 1s - loss: 1.6534 - accuracy: 0.4109 - val_loss: 1.8019 - val_accuracy: 0.4228 - 759ms/epoch - 4ms/step\n",
            "Epoch 7/100\n",
            "169/169 - 1s - loss: 1.5869 - accuracy: 0.4392 - val_loss: 1.6321 - val_accuracy: 0.4412 - 756ms/epoch - 4ms/step\n",
            "Epoch 8/100\n",
            "169/169 - 1s - loss: 1.5532 - accuracy: 0.4602 - val_loss: 1.5916 - val_accuracy: 0.4693 - 753ms/epoch - 4ms/step\n",
            "Epoch 9/100\n",
            "169/169 - 1s - loss: 1.4588 - accuracy: 0.4970 - val_loss: 1.5971 - val_accuracy: 0.4642 - 751ms/epoch - 4ms/step\n",
            "Epoch 10/100\n",
            "169/169 - 1s - loss: 1.4298 - accuracy: 0.4965 - val_loss: 1.6575 - val_accuracy: 0.4516 - 747ms/epoch - 4ms/step\n",
            "Epoch 11/100\n",
            "169/169 - 1s - loss: 1.3790 - accuracy: 0.5183 - val_loss: 1.5818 - val_accuracy: 0.5100 - 753ms/epoch - 4ms/step\n",
            "Epoch 12/100\n",
            "169/169 - 1s - loss: 1.3332 - accuracy: 0.5298 - val_loss: 1.6065 - val_accuracy: 0.4922 - 755ms/epoch - 4ms/step\n",
            "Epoch 13/100\n",
            "169/169 - 1s - loss: 1.3266 - accuracy: 0.5435 - val_loss: 1.6036 - val_accuracy: 0.4834 - 749ms/epoch - 4ms/step\n",
            "Epoch 14/100\n",
            "169/169 - 1s - loss: 1.4131 - accuracy: 0.5142 - val_loss: 1.8429 - val_accuracy: 0.3023 - 753ms/epoch - 4ms/step\n",
            "Epoch 15/100\n",
            "169/169 - 1s - loss: 1.2568 - accuracy: 0.5566 - val_loss: 1.4284 - val_accuracy: 0.5602 - 754ms/epoch - 4ms/step\n",
            "Epoch 16/100\n",
            "169/169 - 1s - loss: 1.1251 - accuracy: 0.6065 - val_loss: 1.4189 - val_accuracy: 0.5965 - 754ms/epoch - 4ms/step\n",
            "Epoch 17/100\n",
            "169/169 - 1s - loss: 1.0812 - accuracy: 0.6254 - val_loss: 1.3741 - val_accuracy: 0.5898 - 750ms/epoch - 4ms/step\n",
            "Epoch 18/100\n",
            "169/169 - 1s - loss: 1.0827 - accuracy: 0.6241 - val_loss: 1.4056 - val_accuracy: 0.5920 - 749ms/epoch - 4ms/step\n",
            "Epoch 19/100\n",
            "169/169 - 1s - loss: 1.0100 - accuracy: 0.6466 - val_loss: 1.3806 - val_accuracy: 0.5950 - 749ms/epoch - 4ms/step\n",
            "Epoch 20/100\n",
            "169/169 - 1s - loss: 0.9642 - accuracy: 0.6701 - val_loss: 1.2903 - val_accuracy: 0.6231 - 754ms/epoch - 4ms/step\n",
            "Epoch 21/100\n",
            "169/169 - 1s - loss: 0.9496 - accuracy: 0.6679 - val_loss: 1.1856 - val_accuracy: 0.6548 - 757ms/epoch - 4ms/step\n",
            "Epoch 22/100\n",
            "169/169 - 1s - loss: 0.9275 - accuracy: 0.6764 - val_loss: 1.2021 - val_accuracy: 0.6593 - 740ms/epoch - 4ms/step\n",
            "Epoch 23/100\n",
            "169/169 - 1s - loss: 0.9093 - accuracy: 0.6857 - val_loss: 1.2273 - val_accuracy: 0.6438 - 757ms/epoch - 4ms/step\n",
            "Epoch 24/100\n",
            "169/169 - 1s - loss: 0.9031 - accuracy: 0.6906 - val_loss: 1.3439 - val_accuracy: 0.6068 - 752ms/epoch - 4ms/step\n",
            "Epoch 25/100\n",
            "169/169 - 1s - loss: 0.8579 - accuracy: 0.7101 - val_loss: 1.2738 - val_accuracy: 0.6467 - 751ms/epoch - 4ms/step\n",
            "Epoch 26/100\n",
            "169/169 - 1s - loss: 0.8351 - accuracy: 0.7134 - val_loss: 1.2120 - val_accuracy: 0.6704 - 748ms/epoch - 4ms/step\n",
            "Epoch 27/100\n",
            "169/169 - 1s - loss: 0.8255 - accuracy: 0.7136 - val_loss: 1.2181 - val_accuracy: 0.6733 - 746ms/epoch - 4ms/step\n",
            "Epoch 28/100\n",
            "169/169 - 1s - loss: 0.7842 - accuracy: 0.7265 - val_loss: 1.2570 - val_accuracy: 0.6681 - 753ms/epoch - 4ms/step\n",
            "Epoch 29/100\n",
            "169/169 - 1s - loss: 0.7982 - accuracy: 0.7241 - val_loss: 1.3420 - val_accuracy: 0.6467 - 756ms/epoch - 4ms/step\n",
            "Epoch 30/100\n",
            "169/169 - 1s - loss: 0.7551 - accuracy: 0.7363 - val_loss: 1.3480 - val_accuracy: 0.6681 - 745ms/epoch - 4ms/step\n",
            "Epoch 31/100\n",
            "169/169 - 1s - loss: 0.7202 - accuracy: 0.7496 - val_loss: 1.3087 - val_accuracy: 0.6541 - 741ms/epoch - 4ms/step\n",
            "Epoch 32/100\n",
            "169/169 - 1s - loss: 0.7492 - accuracy: 0.7396 - val_loss: 1.3071 - val_accuracy: 0.6644 - 744ms/epoch - 4ms/step\n",
            "Epoch 33/100\n",
            "169/169 - 1s - loss: 0.7421 - accuracy: 0.7476 - val_loss: 1.2455 - val_accuracy: 0.6408 - 746ms/epoch - 4ms/step\n",
            "Epoch 34/100\n",
            "169/169 - 1s - loss: 0.6986 - accuracy: 0.7615 - val_loss: 1.1624 - val_accuracy: 0.6726 - 751ms/epoch - 4ms/step\n",
            "Epoch 35/100\n",
            "169/169 - 1s - loss: 0.6950 - accuracy: 0.7581 - val_loss: 1.3512 - val_accuracy: 0.6622 - 742ms/epoch - 4ms/step\n",
            "Epoch 36/100\n",
            "169/169 - 1s - loss: 0.7354 - accuracy: 0.7502 - val_loss: 1.3274 - val_accuracy: 0.6733 - 753ms/epoch - 4ms/step\n",
            "Epoch 37/100\n",
            "169/169 - 1s - loss: 0.6798 - accuracy: 0.7692 - val_loss: 1.2265 - val_accuracy: 0.6807 - 748ms/epoch - 4ms/step\n",
            "Epoch 38/100\n",
            "169/169 - 1s - loss: 0.6514 - accuracy: 0.7794 - val_loss: 1.3057 - val_accuracy: 0.6748 - 754ms/epoch - 4ms/step\n",
            "Epoch 39/100\n",
            "169/169 - 1s - loss: 0.6486 - accuracy: 0.7837 - val_loss: 1.2390 - val_accuracy: 0.6814 - 757ms/epoch - 4ms/step\n",
            "Epoch 40/100\n",
            "169/169 - 1s - loss: 0.6480 - accuracy: 0.7837 - val_loss: 1.1897 - val_accuracy: 0.6933 - 750ms/epoch - 4ms/step\n",
            "Epoch 41/100\n",
            "169/169 - 1s - loss: 0.6230 - accuracy: 0.7914 - val_loss: 1.2876 - val_accuracy: 0.6970 - 750ms/epoch - 4ms/step\n",
            "Epoch 42/100\n",
            "169/169 - 1s - loss: 0.6040 - accuracy: 0.7986 - val_loss: 1.3289 - val_accuracy: 0.6681 - 747ms/epoch - 4ms/step\n",
            "Epoch 43/100\n",
            "169/169 - 1s - loss: 0.6300 - accuracy: 0.7812 - val_loss: 1.2013 - val_accuracy: 0.6859 - 749ms/epoch - 4ms/step\n",
            "Epoch 44/100\n",
            "169/169 - 1s - loss: 0.5962 - accuracy: 0.7923 - val_loss: 1.3208 - val_accuracy: 0.7073 - 755ms/epoch - 4ms/step\n",
            "Epoch 45/100\n",
            "169/169 - 1s - loss: 0.5987 - accuracy: 0.7944 - val_loss: 1.3002 - val_accuracy: 0.6718 - 747ms/epoch - 4ms/step\n",
            "Epoch 46/100\n",
            "169/169 - 1s - loss: 0.5863 - accuracy: 0.8051 - val_loss: 1.3438 - val_accuracy: 0.6955 - 751ms/epoch - 4ms/step\n",
            "Epoch 47/100\n",
            "169/169 - 1s - loss: 0.6436 - accuracy: 0.7911 - val_loss: 1.4138 - val_accuracy: 0.6748 - 752ms/epoch - 4ms/step\n",
            "Epoch 48/100\n",
            "169/169 - 1s - loss: 0.6276 - accuracy: 0.7818 - val_loss: 1.3428 - val_accuracy: 0.6918 - 759ms/epoch - 4ms/step\n",
            "Epoch 49/100\n",
            "169/169 - 1s - loss: 0.6113 - accuracy: 0.7927 - val_loss: 1.3680 - val_accuracy: 0.6615 - 748ms/epoch - 4ms/step\n",
            "Epoch 50/100\n",
            "169/169 - 1s - loss: 0.6185 - accuracy: 0.7957 - val_loss: 1.3402 - val_accuracy: 0.6718 - 767ms/epoch - 5ms/step\n",
            "Epoch 51/100\n",
            "169/169 - 1s - loss: 0.5922 - accuracy: 0.7981 - val_loss: 1.2891 - val_accuracy: 0.6630 - 754ms/epoch - 4ms/step\n",
            "Epoch 52/100\n",
            "169/169 - 1s - loss: 0.6495 - accuracy: 0.7848 - val_loss: 1.4159 - val_accuracy: 0.6704 - 753ms/epoch - 4ms/step\n",
            "Epoch 53/100\n",
            "169/169 - 1s - loss: 0.5817 - accuracy: 0.8055 - val_loss: 1.3370 - val_accuracy: 0.6851 - 747ms/epoch - 4ms/step\n",
            "Epoch 54/100\n",
            "169/169 - 1s - loss: 0.5540 - accuracy: 0.8132 - val_loss: 1.3462 - val_accuracy: 0.7029 - 761ms/epoch - 5ms/step\n",
            "Epoch 55/100\n",
            "169/169 - 1s - loss: 0.5760 - accuracy: 0.8053 - val_loss: 1.2082 - val_accuracy: 0.6903 - 751ms/epoch - 4ms/step\n",
            "Epoch 56/100\n",
            "169/169 - 1s - loss: 0.5061 - accuracy: 0.8284 - val_loss: 1.2771 - val_accuracy: 0.6940 - 762ms/epoch - 5ms/step\n",
            "Epoch 57/100\n",
            "169/169 - 1s - loss: 0.5001 - accuracy: 0.8297 - val_loss: 1.2890 - val_accuracy: 0.6881 - 751ms/epoch - 4ms/step\n",
            "Epoch 58/100\n",
            "169/169 - 1s - loss: 0.5285 - accuracy: 0.8269 - val_loss: 1.4672 - val_accuracy: 0.6814 - 755ms/epoch - 4ms/step\n",
            "Epoch 59/100\n",
            "169/169 - 1s - loss: 0.5440 - accuracy: 0.8180 - val_loss: 1.4644 - val_accuracy: 0.6896 - 753ms/epoch - 4ms/step\n",
            "Epoch 60/100\n",
            "169/169 - 1s - loss: 0.5340 - accuracy: 0.8180 - val_loss: 1.3628 - val_accuracy: 0.6792 - 755ms/epoch - 4ms/step\n",
            "Epoch 61/100\n",
            "169/169 - 1s - loss: 0.5305 - accuracy: 0.8262 - val_loss: 1.3763 - val_accuracy: 0.6718 - 747ms/epoch - 4ms/step\n",
            "Epoch 62/100\n",
            "169/169 - 1s - loss: 0.5520 - accuracy: 0.8155 - val_loss: 1.6671 - val_accuracy: 0.6674 - 743ms/epoch - 4ms/step\n",
            "Epoch 63/100\n",
            "169/169 - 1s - loss: 0.5662 - accuracy: 0.8123 - val_loss: 1.3012 - val_accuracy: 0.6851 - 749ms/epoch - 4ms/step\n",
            "Epoch 64/100\n",
            "169/169 - 1s - loss: 0.5013 - accuracy: 0.8310 - val_loss: 1.5040 - val_accuracy: 0.6933 - 761ms/epoch - 5ms/step\n",
            "Epoch 65/100\n",
            "169/169 - 1s - loss: 0.5895 - accuracy: 0.8090 - val_loss: 1.4865 - val_accuracy: 0.6689 - 750ms/epoch - 4ms/step\n",
            "Epoch 66/100\n",
            "169/169 - 1s - loss: 0.5354 - accuracy: 0.8188 - val_loss: 1.3553 - val_accuracy: 0.6874 - 755ms/epoch - 4ms/step\n",
            "Epoch 67/100\n",
            "169/169 - 1s - loss: 0.5273 - accuracy: 0.8238 - val_loss: 1.3971 - val_accuracy: 0.6792 - 747ms/epoch - 4ms/step\n",
            "Epoch 68/100\n",
            "169/169 - 1s - loss: 0.5344 - accuracy: 0.8266 - val_loss: 1.4625 - val_accuracy: 0.6541 - 751ms/epoch - 4ms/step\n",
            "Epoch 69/100\n",
            "169/169 - 1s - loss: 0.4968 - accuracy: 0.8328 - val_loss: 1.4860 - val_accuracy: 0.6770 - 744ms/epoch - 4ms/step\n",
            "Epoch 70/100\n",
            "169/169 - 1s - loss: 0.5054 - accuracy: 0.8251 - val_loss: 1.6325 - val_accuracy: 0.6896 - 754ms/epoch - 4ms/step\n",
            "Epoch 71/100\n",
            "169/169 - 1s - loss: 0.5200 - accuracy: 0.8306 - val_loss: 1.6020 - val_accuracy: 0.6785 - 746ms/epoch - 4ms/step\n",
            "Epoch 72/100\n",
            "169/169 - 1s - loss: 0.4858 - accuracy: 0.8351 - val_loss: 1.4788 - val_accuracy: 0.6837 - 759ms/epoch - 4ms/step\n",
            "Epoch 73/100\n",
            "169/169 - 1s - loss: 0.4333 - accuracy: 0.8558 - val_loss: 1.4647 - val_accuracy: 0.6733 - 746ms/epoch - 4ms/step\n",
            "Epoch 74/100\n",
            "169/169 - 1s - loss: 0.4899 - accuracy: 0.8371 - val_loss: 1.4328 - val_accuracy: 0.6859 - 748ms/epoch - 4ms/step\n",
            "Epoch 75/100\n",
            "169/169 - 1s - loss: 0.4822 - accuracy: 0.8325 - val_loss: 1.7019 - val_accuracy: 0.6585 - 750ms/epoch - 4ms/step\n",
            "Epoch 76/100\n",
            "169/169 - 1s - loss: 0.8206 - accuracy: 0.7347 - val_loss: 1.8083 - val_accuracy: 0.5270 - 748ms/epoch - 4ms/step\n",
            "Epoch 77/100\n",
            "169/169 - 1s - loss: 0.9264 - accuracy: 0.6990 - val_loss: 1.6082 - val_accuracy: 0.6962 - 746ms/epoch - 4ms/step\n",
            "Epoch 78/100\n",
            "169/169 - 1s - loss: 0.5782 - accuracy: 0.8175 - val_loss: 1.4763 - val_accuracy: 0.6674 - 748ms/epoch - 4ms/step\n",
            "Epoch 79/100\n",
            "169/169 - 1s - loss: 0.4580 - accuracy: 0.8408 - val_loss: 1.5830 - val_accuracy: 0.6741 - 752ms/epoch - 4ms/step\n",
            "Epoch 80/100\n",
            "169/169 - 1s - loss: 0.4714 - accuracy: 0.8430 - val_loss: 1.4313 - val_accuracy: 0.6800 - 751ms/epoch - 4ms/step\n",
            "Epoch 81/100\n",
            "169/169 - 1s - loss: 0.4551 - accuracy: 0.8458 - val_loss: 1.4956 - val_accuracy: 0.6940 - 758ms/epoch - 4ms/step\n",
            "Epoch 82/100\n",
            "169/169 - 1s - loss: 0.4518 - accuracy: 0.8465 - val_loss: 1.6598 - val_accuracy: 0.6763 - 756ms/epoch - 4ms/step\n",
            "Epoch 83/100\n",
            "169/169 - 1s - loss: 0.4623 - accuracy: 0.8404 - val_loss: 1.6944 - val_accuracy: 0.6800 - 756ms/epoch - 4ms/step\n",
            "Epoch 84/100\n",
            "169/169 - 1s - loss: 0.4993 - accuracy: 0.8404 - val_loss: 1.6206 - val_accuracy: 0.6755 - 748ms/epoch - 4ms/step\n",
            "Epoch 85/100\n",
            "169/169 - 1s - loss: 0.4780 - accuracy: 0.8493 - val_loss: 1.5257 - val_accuracy: 0.6755 - 750ms/epoch - 4ms/step\n",
            "Epoch 86/100\n",
            "169/169 - 1s - loss: 0.4379 - accuracy: 0.8489 - val_loss: 1.6674 - val_accuracy: 0.6711 - 757ms/epoch - 4ms/step\n",
            "Epoch 87/100\n",
            "169/169 - 1s - loss: 0.4449 - accuracy: 0.8536 - val_loss: 1.4988 - val_accuracy: 0.6896 - 751ms/epoch - 4ms/step\n",
            "Epoch 88/100\n",
            "169/169 - 1s - loss: 0.4396 - accuracy: 0.8500 - val_loss: 1.4262 - val_accuracy: 0.6829 - 753ms/epoch - 4ms/step\n",
            "Epoch 89/100\n",
            "169/169 - 1s - loss: 0.4783 - accuracy: 0.8482 - val_loss: 1.6685 - val_accuracy: 0.5920 - 747ms/epoch - 4ms/step\n",
            "Epoch 90/100\n",
            "169/169 - 1s - loss: 0.4837 - accuracy: 0.8336 - val_loss: 1.5715 - val_accuracy: 0.6844 - 753ms/epoch - 4ms/step\n",
            "Epoch 91/100\n",
            "169/169 - 1s - loss: 0.4230 - accuracy: 0.8598 - val_loss: 1.7096 - val_accuracy: 0.6829 - 751ms/epoch - 4ms/step\n",
            "Epoch 92/100\n",
            "169/169 - 1s - loss: 0.4772 - accuracy: 0.8449 - val_loss: 1.8183 - val_accuracy: 0.6874 - 747ms/epoch - 4ms/step\n",
            "Epoch 93/100\n",
            "169/169 - 1s - loss: 0.5713 - accuracy: 0.8258 - val_loss: 1.9753 - val_accuracy: 0.6408 - 753ms/epoch - 4ms/step\n",
            "Epoch 94/100\n",
            "169/169 - 1s - loss: 0.4820 - accuracy: 0.8436 - val_loss: 1.6973 - val_accuracy: 0.6911 - 757ms/epoch - 4ms/step\n",
            "Epoch 95/100\n",
            "169/169 - 1s - loss: 0.4430 - accuracy: 0.8569 - val_loss: 1.4621 - val_accuracy: 0.6977 - 765ms/epoch - 5ms/step\n",
            "Epoch 96/100\n",
            "169/169 - 1s - loss: 0.4243 - accuracy: 0.8683 - val_loss: 1.4258 - val_accuracy: 0.6896 - 755ms/epoch - 4ms/step\n",
            "Epoch 97/100\n",
            "169/169 - 1s - loss: 0.4334 - accuracy: 0.8569 - val_loss: 1.6050 - val_accuracy: 0.6829 - 758ms/epoch - 4ms/step\n",
            "Epoch 98/100\n",
            "169/169 - 1s - loss: 0.3990 - accuracy: 0.8704 - val_loss: 1.7468 - val_accuracy: 0.6859 - 750ms/epoch - 4ms/step\n",
            "Epoch 99/100\n",
            "169/169 - 1s - loss: 0.4157 - accuracy: 0.8617 - val_loss: 1.6460 - val_accuracy: 0.6718 - 757ms/epoch - 4ms/step\n",
            "Epoch 100/100\n",
            "169/169 - 1s - loss: 0.5954 - accuracy: 0.8055 - val_loss: 1.5764 - val_accuracy: 0.6497 - 753ms/epoch - 4ms/step\n",
            "Model: \"sequential_41\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " reshape_40 (Reshape)        (None, 128, 40, 1)        0         \n",
            "                                                                 \n",
            " conv2d_80 (Conv2D)          (None, 128, 40, 8)        80        \n",
            "                                                                 \n",
            " max_pooling2d_78 (MaxPoolin  (None, 64, 20, 8)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " batch_normalization_39 (Bat  (None, 64, 20, 8)        32        \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv2d_81 (Conv2D)          (None, 64, 20, 16)        12816     \n",
            "                                                                 \n",
            " max_pooling2d_79 (MaxPoolin  (None, 32, 10, 16)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_39 (Dropout)        (None, 32, 10, 16)        0         \n",
            "                                                                 \n",
            " flatten_39 (Flatten)        (None, 5120)              0         \n",
            "                                                                 \n",
            " y_pred (Dense)              (None, 10)                51210     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 64,138\n",
            "Trainable params: 64,122\n",
            "Non-trainable params: 16\n",
            "_________________________________________________________________\n",
            "None\n",
            "Result of fold:10\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 2.9154 - accuracy: 0.4296\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [14:53<00:00, 89.33s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sUTn_42P_TGs"
      },
      "outputs": [],
      "source": [
        "# import tensorflow as tf\n",
        "# from tensorflow.keras.models import Sequential\n",
        "# from tensorflow.keras.layers import Dense, InputLayer, Dropout, Conv1D, Convolution2D, Activation, Flatten, Reshape, MaxPooling1D, MaxPooling2D, BatchNormalization, TimeDistributed,LeakyReLU,SpatialDropout2D,GlobalAveragePooling2D\n",
        "# from tensorflow.keras.optimizers import Adam,SGD\n",
        "# from tensorflow.keras import regularizers\n",
        "# EPOCHS = 100\n",
        "# # this controls the batch size, or you can manipulate the tf.data.Dataset objects yourself\n",
        "# BATCH_SIZE = 32\n",
        "# input_length=len(X_train[0])\n",
        "# callbacks = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UN1Q-i4onwTV"
      },
      "outputs": [],
      "source": [
        "# def getModel():\n",
        "#   model = Sequential()\n",
        "#   input_shape = (40,128,1)\n",
        "#   model.add(Conv2D(8, kernel_size=3, activation='relu', kernel_constraint=tf.keras.constraints.MaxNorm(1), padding='same'))\n",
        "#   model.add(MaxPooling2D(pool_size=2, strides=2, padding='same'))\n",
        "#   model.add(BatchNormalization())\n",
        "#   #model.add(Dropout(0.5))\n",
        "#   model.add(Conv2D(16, kernel_size=10, activation='relu', kernel_constraint=tf.keras.constraints.MaxNorm(1), padding='same'))\n",
        "#   model.add(MaxPooling2D(pool_size=2, strides=2, padding='same'))\n",
        "#   model.add(Dropout(0.2))\n",
        "#   model.add(Flatten())\n",
        "#   model.add(Dense(10, activation='softmax', name='y_pred'))\n",
        "#   return model\n",
        "\n",
        "# # this controls the learning rate\n",
        "\n",
        "\n",
        "\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cEAePPkfzllH",
        "outputId": "e481623b-fc31-401a-a5a3-c9594a580a10"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "169/169 - 2s - loss: 2.2584 - accuracy: 0.2749 - val_loss: 2.0392 - val_accuracy: 0.2437 - 2s/epoch - 9ms/step\n",
            "Epoch 2/100\n",
            "169/169 - 1s - loss: 1.8167 - accuracy: 0.3496 - val_loss: 2.0764 - val_accuracy: 0.2922 - 744ms/epoch - 4ms/step\n",
            "Epoch 3/100\n",
            "169/169 - 1s - loss: 1.7208 - accuracy: 0.3970 - val_loss: 1.8055 - val_accuracy: 0.3790 - 752ms/epoch - 4ms/step\n",
            "Epoch 4/100\n",
            "169/169 - 1s - loss: 1.5838 - accuracy: 0.4354 - val_loss: 1.7570 - val_accuracy: 0.3940 - 750ms/epoch - 4ms/step\n",
            "Epoch 5/100\n",
            "169/169 - 1s - loss: 1.5174 - accuracy: 0.4622 - val_loss: 1.8724 - val_accuracy: 0.4007 - 750ms/epoch - 4ms/step\n",
            "Epoch 6/100\n",
            "169/169 - 1s - loss: 1.4605 - accuracy: 0.4774 - val_loss: 1.6394 - val_accuracy: 0.4274 - 751ms/epoch - 4ms/step\n",
            "Epoch 7/100\n",
            "169/169 - 1s - loss: 1.4059 - accuracy: 0.5010 - val_loss: 1.6763 - val_accuracy: 0.4307 - 751ms/epoch - 4ms/step\n",
            "Epoch 8/100\n",
            "169/169 - 1s - loss: 1.3594 - accuracy: 0.5211 - val_loss: 1.7346 - val_accuracy: 0.4457 - 752ms/epoch - 4ms/step\n",
            "Epoch 9/100\n",
            "169/169 - 1s - loss: 1.2563 - accuracy: 0.5542 - val_loss: 1.7051 - val_accuracy: 0.5058 - 746ms/epoch - 4ms/step\n",
            "Epoch 10/100\n",
            "169/169 - 1s - loss: 1.2576 - accuracy: 0.5556 - val_loss: 1.8071 - val_accuracy: 0.4958 - 748ms/epoch - 4ms/step\n",
            "Epoch 11/100\n",
            "169/169 - 1s - loss: 1.4210 - accuracy: 0.4927 - val_loss: 1.8835 - val_accuracy: 0.4541 - 746ms/epoch - 4ms/step\n",
            "Epoch 12/100\n",
            "169/169 - 1s - loss: 1.2112 - accuracy: 0.5701 - val_loss: 1.6297 - val_accuracy: 0.5743 - 747ms/epoch - 4ms/step\n",
            "Epoch 13/100\n",
            "169/169 - 1s - loss: 1.1592 - accuracy: 0.5978 - val_loss: 1.6178 - val_accuracy: 0.5326 - 748ms/epoch - 4ms/step\n",
            "Epoch 14/100\n",
            "169/169 - 1s - loss: 1.0848 - accuracy: 0.6275 - val_loss: 1.5095 - val_accuracy: 0.5593 - 740ms/epoch - 4ms/step\n",
            "Epoch 15/100\n",
            "169/169 - 1s - loss: 1.0451 - accuracy: 0.6437 - val_loss: 1.4301 - val_accuracy: 0.6093 - 751ms/epoch - 4ms/step\n",
            "Epoch 16/100\n",
            "169/169 - 1s - loss: 0.9901 - accuracy: 0.6639 - val_loss: 1.3972 - val_accuracy: 0.5927 - 755ms/epoch - 4ms/step\n",
            "Epoch 17/100\n",
            "169/169 - 1s - loss: 1.1351 - accuracy: 0.6086 - val_loss: 1.3490 - val_accuracy: 0.5977 - 750ms/epoch - 4ms/step\n",
            "Epoch 18/100\n",
            "169/169 - 1s - loss: 0.9640 - accuracy: 0.6782 - val_loss: 1.3589 - val_accuracy: 0.6010 - 751ms/epoch - 4ms/step\n",
            "Epoch 19/100\n",
            "169/169 - 1s - loss: 0.9192 - accuracy: 0.6872 - val_loss: 1.3723 - val_accuracy: 0.6411 - 754ms/epoch - 4ms/step\n",
            "Epoch 20/100\n",
            "169/169 - 1s - loss: 0.8854 - accuracy: 0.7078 - val_loss: 1.4669 - val_accuracy: 0.6160 - 757ms/epoch - 4ms/step\n",
            "Epoch 21/100\n",
            "169/169 - 1s - loss: 0.9148 - accuracy: 0.6885 - val_loss: 1.2386 - val_accuracy: 0.6661 - 754ms/epoch - 4ms/step\n",
            "Epoch 22/100\n",
            "169/169 - 1s - loss: 0.8469 - accuracy: 0.7187 - val_loss: 1.3829 - val_accuracy: 0.6361 - 755ms/epoch - 4ms/step\n",
            "Epoch 23/100\n",
            "169/169 - 1s - loss: 0.8067 - accuracy: 0.7234 - val_loss: 1.4642 - val_accuracy: 0.6444 - 761ms/epoch - 5ms/step\n",
            "Epoch 24/100\n",
            "169/169 - 1s - loss: 0.7858 - accuracy: 0.7390 - val_loss: 1.5559 - val_accuracy: 0.6461 - 761ms/epoch - 5ms/step\n",
            "Epoch 25/100\n",
            "169/169 - 1s - loss: 0.8175 - accuracy: 0.7275 - val_loss: 1.5011 - val_accuracy: 0.6411 - 767ms/epoch - 5ms/step\n",
            "Epoch 26/100\n",
            "169/169 - 1s - loss: 0.7389 - accuracy: 0.7433 - val_loss: 1.6425 - val_accuracy: 0.6444 - 758ms/epoch - 4ms/step\n",
            "Epoch 27/100\n",
            "169/169 - 1s - loss: 0.7311 - accuracy: 0.7635 - val_loss: 1.7311 - val_accuracy: 0.6394 - 756ms/epoch - 4ms/step\n",
            "Epoch 28/100\n",
            "169/169 - 1s - loss: 0.7174 - accuracy: 0.7605 - val_loss: 1.5664 - val_accuracy: 0.6377 - 758ms/epoch - 4ms/step\n",
            "Epoch 29/100\n",
            "169/169 - 1s - loss: 0.7523 - accuracy: 0.7578 - val_loss: 1.4140 - val_accuracy: 0.6544 - 752ms/epoch - 4ms/step\n",
            "Epoch 30/100\n",
            "169/169 - 1s - loss: 0.7326 - accuracy: 0.7594 - val_loss: 1.3726 - val_accuracy: 0.6344 - 759ms/epoch - 4ms/step\n",
            "Epoch 31/100\n",
            "169/169 - 1s - loss: 0.6587 - accuracy: 0.7815 - val_loss: 1.3308 - val_accuracy: 0.6544 - 757ms/epoch - 4ms/step\n",
            "Epoch 32/100\n",
            "169/169 - 1s - loss: 0.6800 - accuracy: 0.7773 - val_loss: 1.3924 - val_accuracy: 0.6494 - 750ms/epoch - 4ms/step\n",
            "Epoch 33/100\n",
            "169/169 - 1s - loss: 0.6765 - accuracy: 0.7735 - val_loss: 1.4439 - val_accuracy: 0.6778 - 756ms/epoch - 4ms/step\n",
            "Epoch 34/100\n",
            "169/169 - 1s - loss: 0.5991 - accuracy: 0.8031 - val_loss: 1.4847 - val_accuracy: 0.6511 - 756ms/epoch - 4ms/step\n",
            "Epoch 35/100\n",
            "169/169 - 1s - loss: 0.6273 - accuracy: 0.7923 - val_loss: 1.8994 - val_accuracy: 0.6761 - 759ms/epoch - 4ms/step\n",
            "Epoch 36/100\n",
            "169/169 - 1s - loss: 0.6907 - accuracy: 0.7799 - val_loss: 1.7534 - val_accuracy: 0.6611 - 754ms/epoch - 4ms/step\n",
            "Epoch 37/100\n",
            "169/169 - 1s - loss: 0.6032 - accuracy: 0.7964 - val_loss: 1.5783 - val_accuracy: 0.6912 - 755ms/epoch - 4ms/step\n",
            "Epoch 38/100\n",
            "169/169 - 1s - loss: 0.6003 - accuracy: 0.8012 - val_loss: 1.8675 - val_accuracy: 0.6544 - 749ms/epoch - 4ms/step\n",
            "Epoch 39/100\n",
            "169/169 - 1s - loss: 0.6013 - accuracy: 0.8085 - val_loss: 1.6488 - val_accuracy: 0.6728 - 767ms/epoch - 5ms/step\n",
            "Epoch 40/100\n",
            "169/169 - 1s - loss: 0.5472 - accuracy: 0.8192 - val_loss: 1.6290 - val_accuracy: 0.6528 - 761ms/epoch - 5ms/step\n",
            "Epoch 41/100\n",
            "169/169 - 1s - loss: 0.6078 - accuracy: 0.7953 - val_loss: 1.5671 - val_accuracy: 0.6895 - 751ms/epoch - 4ms/step\n",
            "Epoch 42/100\n",
            "169/169 - 1s - loss: 0.5545 - accuracy: 0.8187 - val_loss: 1.5092 - val_accuracy: 0.6828 - 760ms/epoch - 4ms/step\n",
            "Epoch 43/100\n",
            "169/169 - 1s - loss: 0.5457 - accuracy: 0.8179 - val_loss: 1.4480 - val_accuracy: 0.6861 - 753ms/epoch - 4ms/step\n",
            "Epoch 44/100\n",
            "169/169 - 1s - loss: 0.5355 - accuracy: 0.8246 - val_loss: 1.4674 - val_accuracy: 0.7179 - 748ms/epoch - 4ms/step\n",
            "Epoch 45/100\n",
            "169/169 - 1s - loss: 0.5133 - accuracy: 0.8315 - val_loss: 1.6160 - val_accuracy: 0.6962 - 753ms/epoch - 4ms/step\n",
            "Epoch 46/100\n",
            "169/169 - 1s - loss: 0.5358 - accuracy: 0.8168 - val_loss: 1.8652 - val_accuracy: 0.6828 - 752ms/epoch - 4ms/step\n",
            "Epoch 47/100\n",
            "169/169 - 1s - loss: 0.5796 - accuracy: 0.8051 - val_loss: 1.5671 - val_accuracy: 0.6928 - 757ms/epoch - 4ms/step\n",
            "Epoch 48/100\n",
            "169/169 - 1s - loss: 0.5280 - accuracy: 0.8257 - val_loss: 1.8449 - val_accuracy: 0.6578 - 760ms/epoch - 4ms/step\n",
            "Epoch 49/100\n",
            "169/169 - 1s - loss: 0.5762 - accuracy: 0.8068 - val_loss: 1.7087 - val_accuracy: 0.6895 - 751ms/epoch - 4ms/step\n",
            "Epoch 50/100\n",
            "169/169 - 1s - loss: 0.5195 - accuracy: 0.8272 - val_loss: 1.7366 - val_accuracy: 0.6878 - 751ms/epoch - 4ms/step\n",
            "Epoch 51/100\n",
            "169/169 - 1s - loss: 0.5048 - accuracy: 0.8367 - val_loss: 1.6869 - val_accuracy: 0.6912 - 757ms/epoch - 4ms/step\n",
            "Epoch 52/100\n",
            "169/169 - 1s - loss: 0.4099 - accuracy: 0.8571 - val_loss: 1.8150 - val_accuracy: 0.6962 - 754ms/epoch - 4ms/step\n",
            "Epoch 53/100\n",
            "169/169 - 1s - loss: 0.4218 - accuracy: 0.8590 - val_loss: 1.8409 - val_accuracy: 0.7129 - 755ms/epoch - 4ms/step\n",
            "Epoch 54/100\n",
            "169/169 - 1s - loss: 0.4632 - accuracy: 0.8493 - val_loss: 1.7825 - val_accuracy: 0.7045 - 757ms/epoch - 4ms/step\n",
            "Epoch 55/100\n",
            "169/169 - 1s - loss: 0.4484 - accuracy: 0.8493 - val_loss: 1.8159 - val_accuracy: 0.6594 - 754ms/epoch - 4ms/step\n",
            "Epoch 56/100\n",
            "169/169 - 1s - loss: 0.5623 - accuracy: 0.8228 - val_loss: 2.0679 - val_accuracy: 0.6694 - 752ms/epoch - 4ms/step\n",
            "Epoch 57/100\n",
            "169/169 - 1s - loss: 0.4943 - accuracy: 0.8406 - val_loss: 1.7712 - val_accuracy: 0.6995 - 744ms/epoch - 4ms/step\n",
            "Epoch 58/100\n",
            "169/169 - 1s - loss: 0.4626 - accuracy: 0.8557 - val_loss: 2.0565 - val_accuracy: 0.6845 - 742ms/epoch - 4ms/step\n",
            "Epoch 59/100\n",
            "169/169 - 1s - loss: 0.5228 - accuracy: 0.8345 - val_loss: 1.6481 - val_accuracy: 0.7045 - 752ms/epoch - 4ms/step\n",
            "Epoch 60/100\n",
            "169/169 - 1s - loss: 0.4140 - accuracy: 0.8623 - val_loss: 1.8048 - val_accuracy: 0.6778 - 764ms/epoch - 5ms/step\n",
            "Epoch 61/100\n",
            "169/169 - 1s - loss: 0.4395 - accuracy: 0.8616 - val_loss: 1.7399 - val_accuracy: 0.6778 - 755ms/epoch - 4ms/step\n",
            "Epoch 62/100\n",
            "169/169 - 1s - loss: 0.5330 - accuracy: 0.8289 - val_loss: 1.6796 - val_accuracy: 0.6845 - 759ms/epoch - 4ms/step\n",
            "Epoch 63/100\n",
            "169/169 - 1s - loss: 0.4331 - accuracy: 0.8610 - val_loss: 1.4780 - val_accuracy: 0.6561 - 758ms/epoch - 4ms/step\n",
            "Epoch 64/100\n",
            "169/169 - 1s - loss: 0.4006 - accuracy: 0.8703 - val_loss: 1.5735 - val_accuracy: 0.6978 - 754ms/epoch - 4ms/step\n",
            "Epoch 65/100\n",
            "169/169 - 1s - loss: 0.4150 - accuracy: 0.8726 - val_loss: 1.8105 - val_accuracy: 0.7028 - 750ms/epoch - 4ms/step\n",
            "Epoch 66/100\n",
            "169/169 - 1s - loss: 0.4347 - accuracy: 0.8568 - val_loss: 1.5945 - val_accuracy: 0.6995 - 748ms/epoch - 4ms/step\n",
            "Epoch 67/100\n",
            "169/169 - 1s - loss: 0.4401 - accuracy: 0.8555 - val_loss: 1.6679 - val_accuracy: 0.7028 - 756ms/epoch - 4ms/step\n",
            "Epoch 68/100\n",
            "169/169 - 1s - loss: 0.3777 - accuracy: 0.8819 - val_loss: 1.9554 - val_accuracy: 0.6912 - 750ms/epoch - 4ms/step\n",
            "Epoch 69/100\n",
            "169/169 - 1s - loss: 0.3725 - accuracy: 0.8778 - val_loss: 1.7985 - val_accuracy: 0.6795 - 740ms/epoch - 4ms/step\n",
            "Epoch 70/100\n",
            "169/169 - 1s - loss: 0.4227 - accuracy: 0.8631 - val_loss: 2.0028 - val_accuracy: 0.7045 - 749ms/epoch - 4ms/step\n",
            "Epoch 71/100\n",
            "169/169 - 1s - loss: 0.4987 - accuracy: 0.8510 - val_loss: 1.8791 - val_accuracy: 0.6895 - 744ms/epoch - 4ms/step\n",
            "Epoch 72/100\n",
            "169/169 - 1s - loss: 0.4081 - accuracy: 0.8768 - val_loss: 1.6969 - val_accuracy: 0.7312 - 746ms/epoch - 4ms/step\n",
            "Epoch 73/100\n",
            "169/169 - 1s - loss: 0.4170 - accuracy: 0.8694 - val_loss: 1.7779 - val_accuracy: 0.6711 - 753ms/epoch - 4ms/step\n",
            "Epoch 74/100\n",
            "169/169 - 1s - loss: 0.4153 - accuracy: 0.8698 - val_loss: 1.9371 - val_accuracy: 0.7179 - 741ms/epoch - 4ms/step\n",
            "Epoch 75/100\n",
            "169/169 - 1s - loss: 0.3262 - accuracy: 0.8926 - val_loss: 2.0118 - val_accuracy: 0.6461 - 753ms/epoch - 4ms/step\n",
            "Epoch 76/100\n",
            "169/169 - 1s - loss: 0.3887 - accuracy: 0.8761 - val_loss: 2.2209 - val_accuracy: 0.7129 - 748ms/epoch - 4ms/step\n",
            "Epoch 77/100\n",
            "169/169 - 1s - loss: 0.3953 - accuracy: 0.8779 - val_loss: 2.0557 - val_accuracy: 0.6811 - 752ms/epoch - 4ms/step\n",
            "Epoch 78/100\n",
            "169/169 - 1s - loss: 0.3697 - accuracy: 0.8778 - val_loss: 2.5486 - val_accuracy: 0.7262 - 746ms/epoch - 4ms/step\n",
            "Epoch 79/100\n",
            "169/169 - 1s - loss: 0.3907 - accuracy: 0.8774 - val_loss: 2.2766 - val_accuracy: 0.7012 - 748ms/epoch - 4ms/step\n",
            "Epoch 80/100\n",
            "169/169 - 1s - loss: 0.3722 - accuracy: 0.8897 - val_loss: 2.2289 - val_accuracy: 0.6895 - 760ms/epoch - 4ms/step\n",
            "Epoch 81/100\n",
            "169/169 - 1s - loss: 0.4213 - accuracy: 0.8718 - val_loss: 2.2454 - val_accuracy: 0.6861 - 757ms/epoch - 4ms/step\n",
            "Epoch 82/100\n",
            "169/169 - 1s - loss: 0.4000 - accuracy: 0.8781 - val_loss: 2.2521 - val_accuracy: 0.6962 - 757ms/epoch - 4ms/step\n",
            "Epoch 83/100\n",
            "169/169 - 1s - loss: 0.4260 - accuracy: 0.8694 - val_loss: 2.2711 - val_accuracy: 0.7129 - 753ms/epoch - 4ms/step\n",
            "Epoch 84/100\n",
            "169/169 - 1s - loss: 0.3385 - accuracy: 0.8936 - val_loss: 2.1214 - val_accuracy: 0.6945 - 749ms/epoch - 4ms/step\n",
            "Epoch 85/100\n",
            "169/169 - 1s - loss: 0.3779 - accuracy: 0.8824 - val_loss: 2.0321 - val_accuracy: 0.7212 - 742ms/epoch - 4ms/step\n",
            "Epoch 86/100\n",
            "169/169 - 1s - loss: 0.3065 - accuracy: 0.9041 - val_loss: 1.9430 - val_accuracy: 0.6912 - 750ms/epoch - 4ms/step\n",
            "Epoch 87/100\n",
            "169/169 - 1s - loss: 0.3182 - accuracy: 0.9002 - val_loss: 1.9634 - val_accuracy: 0.6912 - 752ms/epoch - 4ms/step\n",
            "Epoch 88/100\n",
            "169/169 - 1s - loss: 0.2976 - accuracy: 0.9097 - val_loss: 2.3083 - val_accuracy: 0.6828 - 744ms/epoch - 4ms/step\n",
            "Epoch 89/100\n",
            "169/169 - 1s - loss: 0.3624 - accuracy: 0.8904 - val_loss: 2.0837 - val_accuracy: 0.6912 - 753ms/epoch - 4ms/step\n",
            "Epoch 90/100\n",
            "169/169 - 1s - loss: 0.3662 - accuracy: 0.8872 - val_loss: 1.8048 - val_accuracy: 0.6995 - 751ms/epoch - 4ms/step\n",
            "Epoch 91/100\n",
            "169/169 - 1s - loss: 0.3137 - accuracy: 0.8971 - val_loss: 2.1681 - val_accuracy: 0.7162 - 755ms/epoch - 4ms/step\n",
            "Epoch 92/100\n",
            "169/169 - 1s - loss: 0.2842 - accuracy: 0.9069 - val_loss: 2.7637 - val_accuracy: 0.7129 - 751ms/epoch - 4ms/step\n",
            "Epoch 93/100\n",
            "169/169 - 1s - loss: 0.3277 - accuracy: 0.8988 - val_loss: 2.4200 - val_accuracy: 0.7129 - 762ms/epoch - 5ms/step\n",
            "Epoch 94/100\n",
            "169/169 - 1s - loss: 0.3370 - accuracy: 0.8999 - val_loss: 2.8556 - val_accuracy: 0.7078 - 763ms/epoch - 5ms/step\n",
            "Epoch 95/100\n",
            "169/169 - 1s - loss: 0.3670 - accuracy: 0.8884 - val_loss: 2.0502 - val_accuracy: 0.7162 - 756ms/epoch - 4ms/step\n",
            "Epoch 96/100\n",
            "169/169 - 1s - loss: 0.3451 - accuracy: 0.8947 - val_loss: 2.2669 - val_accuracy: 0.7229 - 749ms/epoch - 4ms/step\n",
            "Epoch 97/100\n",
            "169/169 - 1s - loss: 0.3575 - accuracy: 0.8967 - val_loss: 1.9828 - val_accuracy: 0.7028 - 748ms/epoch - 4ms/step\n",
            "Epoch 98/100\n",
            "169/169 - 1s - loss: 0.2991 - accuracy: 0.9043 - val_loss: 2.2286 - val_accuracy: 0.6945 - 740ms/epoch - 4ms/step\n",
            "Epoch 99/100\n",
            "169/169 - 1s - loss: 0.2927 - accuracy: 0.9077 - val_loss: 1.9349 - val_accuracy: 0.6661 - 740ms/epoch - 4ms/step\n",
            "Epoch 100/100\n",
            "169/169 - 1s - loss: 0.3854 - accuracy: 0.8819 - val_loss: 2.1646 - val_accuracy: 0.7062 - 740ms/epoch - 4ms/step\n",
            "Model: \"sequential_9\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_18 (Conv2D)          (None, 40, 128, 8)        80        \n",
            "                                                                 \n",
            " max_pooling2d_18 (MaxPoolin  (None, 20, 64, 8)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " batch_normalization (BatchN  (None, 20, 64, 8)        32        \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " conv2d_19 (Conv2D)          (None, 20, 64, 16)        12816     \n",
            "                                                                 \n",
            " max_pooling2d_19 (MaxPoolin  (None, 10, 32, 16)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_13 (Dropout)        (None, 10, 32, 16)        0         \n",
            "                                                                 \n",
            " flatten_9 (Flatten)         (None, 5120)              0         \n",
            "                                                                 \n",
            " y_pred (Dense)              (None, 10)                51210     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 64,138\n",
            "Trainable params: 64,122\n",
            "Non-trainable params: 16\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "# opt = Adam(learning_rate=0.005, beta_1=0.9, beta_2=0.999)\n",
        "# #sgd = SGD(lr=0.001, momentum=0.0, decay=0.0, nesterov=False)\n",
        "# optimizer=opt\n",
        "# model=getModel()\n",
        "\n",
        "# # train the neural network\n",
        "\n",
        "# model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
        "\n",
        "# model.fit(X_train,Y_train, batch_size=BATCH_SIZE, epochs=EPOCHS, validation_data=(X_val,Y_val), verbose=2, callbacks=callbacks)\n",
        "# print(model.summary())\n",
        "# # Use this flag to disable per-channel quantization for a model.\n",
        "# # This can reduce RAM usage for convolutional models, but may have\n",
        "# # an impact on accuracy.\n",
        "# disable_per_channel_quantization = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z8jHfvnOnw1G"
      },
      "outputs": [],
      "source": [
        "# # Save the model to disk\n",
        "# model.save('/content/drive/MyDrive/Thesis_Keras/TrivediCNN/data/saved_models/spectro')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ujLL2n-o-bu8",
        "outputId": "d27ed791-f8e0-4c90-f3c0-f50758434c59"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "47/47 [==============================] - 0s 3ms/step - loss: 1.8684 - accuracy: 0.6918\n"
          ]
        }
      ],
      "source": [
        "# score = model.evaluate(\n",
        "#         x=X_test,\n",
        "#         y=Y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nGuO4KB__puz"
      },
      "source": [
        "模型名称： TrivediCNN\n",
        "\n",
        "准确度： 0.6918"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vLAkLFThlOBF"
      },
      "outputs": [],
      "source": [
        "# "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 721
        },
        "id": "yferRfxW1ZSz",
        "outputId": "e3b635d3-efd0-4f6f-e1d8-50199ca4326e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_data.py:236: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
            "  \"Numerical issues were encountered \"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_data.py:255: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
            "  \"Numerical issues were encountered \"\n"
          ]
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA+kAAAFACAYAAADAsT1wAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOy9eYxl6Xne955z7r7UrVt7dVV1Ve8z3bOTHJJyaC5qhcKYoShDJqUgghXZhgkkNmRZigYMRCoQGAwo0VQSkBACCYL9TxJJlrLJNuWQkkiL2ww5w9l732qvulV19+Vs+WOgGWqe54jVrWmyuu7zAwg03znnfN/51nPuvfX+nDiOYxNCCCGEEEIIIcQPHfeHXQEhhBBCCCGEEEK8hl7ShRBCCCGEEEKIA4Je0oUQQgghhBBCiAOCXtKFEEIIIYQQQogDgl7ShRBCCCGEEEKIA4Je0oUQQgghhBBCiAOCXtKFEEIIIYQQQhx64nD5h12FfeHcrid96fc+8/q/vYJPjwnaaYiltzE2+/UQYn7Bgdj6B7GceOBBLNXAmJlZWIgg5gRYTnYLP7MIc3g9N8BYcYUWbf0qxjpHsD6G1TGHHBaNYOGpjQwtO9XBWKaBsd4kxsIcDot0EyvpkLZIIihgrHQLYw4OC4tTGAuz+y+nc3IAMS+PlXdu4MnZHbye1yf1IWPFzKw/ijF/Esd05UWcIzEZF+0FMmVdPo2jUSynWOlBrHOrDDEnZIOSlMOOM7NoHNs8c4t0Gjk9KGI5UQYnRExiZny98bA61jtC1jDS6PlbOADTbTy1cZaviSePrUPs+uY4xNyrZPASUl0Sa/Fj2XrVnsfY2ENbENuq4bgoP4MDnbWtmVlnmgQfaPKD34TfwzYPO9iv1e+SxcHM8jUcG/0KrvGDEp7bx66xoEjGX8LH3MV5vEffx/0pl8XxMpLH+bm8OoaFkHHq1nlbpFpY0YgcmtnDGFtPB3NkXRkjG46Zda+NQCy3hXWPsGvpXsBiQZEWbWEe1xG2pqZbGPSwG6w/htfLniCbqpmN5HGTWF/HzcDdJTfOlngf68jGpJUTNuUWjr84gwWx57ooxPHD1vKk+ZAmU36Aw4I+swyqpDFIH7JnIzOzpaObEHt4DB/Y/Bjb50YL592Do6sQO5nboGUvD/D8ago3jn84cgFit0K87/9x5QmIPf3V+2jZ7BmObd/p+v7WhiiNJ4+9jMcV13g/tI7gRaMUdmSJnN+dwL5pzZP58CDZlM0sncZrnhivQezF55YgFlfInt7Ge5n5T/w5iO2Nm4+RfWgKy6HPYOTdxfL8OShTxjUolcIFtHcT93kzs6v//F/S+GEhWj992+e4MxfvQk2S4Tu6EEIIIYQQQghxyIiMf7jxN/GD/vm5XtKFEEIIIYQQQgwFYXz7L+k/6JdmvaQLIYQQQgghhBgKIvZ3RQcMvaQLIYQQQgghhBgK7uTn7j9o9JIuhBBCCCGEEGIoCG8vb/oPhdt/SR+88WfzYZen1556Bv+0Pr+N2RXDLB63dxpjbg2zl2d3959pPMpiZsgCJlu2yhVMw1g/gWV3pvDcziwv2ydZqjO7eI8skzvLaurtYCbYoMQ/DQpI1uJBlWTVHcP7duok07iL58Y8sTy9H5ZpN8ySa5Ik/c3T2LmTC7u07IUiprk+P/kqxK52Ma39n6bPQKy9SdIbs+y7PZ5SIk6RLKsextpzGEt1iIWgRvowwzOL9tM4xbt7mMlz5Mr+xmSfjB+WLdnMzN3G9YFlRw5JhuLsFg4CJ8RYb5IXHi9hmuCBj/dYItlP25uYKprZBVh/OSk+F69cwgXC7XIbBZRNDmMZt/0y33BYll/G5noFYux+wvfVIVbf5lnpmbGgcwUXptQJnLNRQAweexgb8MS0FnvY38VVvJ9BmWSuJktLqoPH+WSNNTPzX8K2dIkRonEEM+22K5g9n9lMnDTeS5TlfR2TrNkhyQjcI+tx6TimfE+RbN/teoLeglgeuh6Oi8weXrM3i+0TkzHpBAnpfPJ4frGCaoRCBut4pMyztr+Zep/f9401oghos3UND4tI1nX2PJnfIGOyxTdlahSZxHnXuowZ6CvXWGZ5LKM3ycdfkCf7GLGmsD0n3SZl5/G4TtJcjLDN93xcr2ZzuK69d+ISxP6zImZif7V/hJa9SRYnVp9/cPGnIHZrB9VA1RJO5MW3c5XUjS3MLM+y9E+fw8Xu1hqem7qF4zwgQ7+xRGwFZtZawBiz+7DM/Znm/mxD/dUEO0oXj72+jWv0CEnkHqXwOYat+xvv4nt/dg4zzsdkDyxfwHZjZpYBVttcsj+YmRXX8MGFzUUvYek+7Ojn7kIIIYQQQgghxAEh1Eu6EEIIIYQQQghxMNA36UIIIYQQQgghxAHhcP5NuhBCCCGEEEIIcQ9y8HO76yVdCCGEEEIIIcSQoL9JF0IIIYQQQgghDgjhwX9Hv/2X9NzaG6n+M2isMDOz4hp6DJhqq3UEdRBeD69X2cBzByN4nIsWldeuSdQ3faIxWH8XqksGFaJCIa2W2eMqqBzRZXWn8Jquj8fRa5JB5SXpt6bQ3xAxXVsHbyi7g30TErNLkv7NiNbNW0HPQx9NH9YfRyfNE2//LsR+Y/artGj2dyYlF8v+dvEixIopHCxfyp+G2NYy6lGiQkJbFLAfXKIRilOo4GB6HqblSKHl47U6pVHNERNbEYsRUwzVrbH5YGbmEu0TVQsRRR0ba2lyj9kaVy8NIuxvr4eV96/jcUxgFBSwjqy/mbrQzCy/TtSSRPfC2rd9gnR4ljkbEzRUAV7U7ZO1dwvrzvRtxApo80drtOhlQw1V/hZpo+dRVVREU5aFRBXDdHRmZj7ZI8I06QfSvGzvbi/iZHRCvvZ6RCfGVHoZohqMd9Av5VSwbLeF7egR1ZAZn9/5tf2NycwLqOQq17GFslN8/O0+SOo+hRv9YIyoWwtE37ZB3F8J/ZDaIGP6Gs7w2gjez+4cDqxMBgdLZ4/4wMwsvY7lsPWPacfcPt5POI5l96bImNziatzcCrbF4CbuYznyHMX26d4SHuhmyYZlZgGZUOEaTuYU0a35pG/iSdynRytkwzGzRhfL+fNbqFplpEt4j39QfhRimRS/77Ec1mnLw7VueRfnWK+J/djwyHNDggP1/AlUxTG+tbGI1yRKQ7YX7D6M9Vk6SfzGZpYJcPztnME5tlPD/sqS/TPdxDLSDd4W7Hki6f3lzTSxeajqsnSDr38tw/UqQ55F2D7G9ruQPHdE5BnKzCxLlKW5XaLerCY8Oxxy9HN3IYQQQgghhBDigBAa/1DnIKGXdCGEEEIIIYQQQ0F0GH/uLoQQQgghhBBC3IvcC9+kD+cfIgghhBBCCCGEEAcQfZMuhBBCCCGEEGIouBe+SddLuhBCCCGEEEKIoSBKMCMcJG77JT16oPX6vxs1rh4Js6hayBLdQW8CY0w55RPjSh/NIVRNYGbmRNgR6YUWxIIBNodzA++R6a6YrsrMLCQaoKiIN0mqaGEe/xohu40xpocyM3MyRM/CFFGk7KT7eTNMLWVmlnsR3RGjV1GbsncCNSNBAa95rYUqp9WQ+ILMbNLFyn+jj/qaW/4kxCaI1+NIuQGxWgcHb/U011DtNYjK50WMjV5h4xf7dlDcn97JzCzaw1h7iYyLszhBxwuoj6m1cTIWMrwf1m6ht6d0GedYZ46eDnhEyZUm+iwzswIZlxG3o2E5RAPZmWHuOSwjScnll/ZXDtMNuSVs33QOb9xfJgulmTkDrBPT0TGVXkyUP7mLOLe3rs3wsqt4PlUqEYWM1yZrHVE+RvmEdZ9oLfObOFGYnqd9FteqB4+tQGy9hTolM7OtLbLw97Fst0vUQkzfRpR7IdN5zXIPaSqNcz77JaK9W8fjArIPbbydKJrmyIA245sbIfbxmt1tXCezRFvXn+drUJDCa2Z28XymO426OJ86o+QBJeH2giLRZeUw5tWxPiniOQzzZJFnG3XCHzE6TDVITm+fwLZ0PLIuMd3aOnFGmVmKqAEHVTw/JBqqOINtltrA54Z6gy/w7PzcKh6b38Bzc3vkmTDEZ8Kdk7zRdx7DZ4fxMj5AponCjWx31ruM60o3Ye//4iQeG5E1yCHqTrYuFdawD5uniZaty98L9tbJmkhgelCfqJDzW1gf9p5hxpXNfbTeWUC20Iiph8kzdyZB/zb3Z+QZjuyB22j2s5GTuxDLp3F+tvtMHGvWncHx2yR6vQfn1uj5hx19ky6EEEIIIYQQQhwQwnsgLZte0oUQQgghhBBCDAWH8ufuQgghhBBCCCHEvYh+7i6EEEIIIYQQQhwQQpJX6KChl3QhhBBCCCGEEENBpL9JF0IIIYQQQgghDgaH8ufu/fob6ovUKGpqzMzaZ1Hz0N1FRUCURjVG+Qqe65FiMkS1EBFthJmZX0bdQZ/o41I72BweMdqwX0gkKbCYMiizheWw8+PjqOoYTBDt0xrXnnjb2Oa5TaJ2QZuJpYj/g2nvmDLPzCzdxTbvTKH2ZO9+PG789DbEPjL9HMS+0T1Ky/4/tx6D2AtrsxCLiRrokTnULOU8dNfELlGCEDWGmVl5AjUaK0V0zcQu6Rtilcnt4ZhKN7mLbOd+oubIYacNfByTq3sViPW3cd4EU8RJaGaVadTZ9TZxEDEdWAZPtc4CURolrLEjV/b3CWkPzX6WQjsj1RqxersJSjiqcSG6l8xxogAcxcXu6irqAzN1fs/FVYylWzh+Uz2M9apEG+aT48Z4R6Q6RIVH2oK1ZXcay8nNY+ekiCbOzKy5hooxtl5lcXqavYSL4isbxyCWpL/MbeJ953FZM58opyK2HhMVVI4oiDrzfAzMn8N17dYH8PzGdRyUYRkbje398S7fh/Ir5HlgHicKu0emKWTPVR7Zu83MHDI0epPYZxHRt+aXsd7ZEGNJez+xeVqY3d+6xJ5Z8ht4LtU4Et2jmVlvlqg3A2xMp0eUcEyHSMaFQ1SKZmaZXaawxHIi0o1uQOpDnk/CDO8Ipl1skUeH5ntQObrb3p+30yFropmZrWJnbO2gD6y/hPPJI4q7mPRhscSfwysFbKRmDxcXh3SN6+D9nHgnKmbfMXodYl+tnaT18cgzU6uD9RnEuI5k1nBgMIUam+9mZmmyp5dWsC1r53CsBJP4XOftYn32iI7OzKwzTZSRk+Td5zj6cnt9HH/VPI7TD88/T8uu+bgHXmris8OZMvEPDgH6ubsQQgghhBBCCHFAiO7CN+mDwcA+9alPWRAEFoahvetd77KPfvSjd3w9vaQLIYQQQgghhBgK7oYnPZ1O26c+9SnL5XIWBIF98pOftEceecROnz59R9fTS7oQQgghhBBCiKHgbvzc3XEcy+Ve+5ONMAwtDENz2N+U7BO9pAshhBBCCCGEGAruVnb3KIrsV37lV2x9fd0++MEP2qlTp+74WnpJF0IIIYQQQggxFIRJmYe/D08++eTr/z5//rydP3/+r/1313XtN37jN6zdbttv/uZv2s2bN+3oUZ7o+vvhxHGckJaS89Avfu71f7ePJJxKPpxgmWjLt/D84gpmqty9D7M99sawjOJaQmbRJsadCGPpFmZ7bM9gdkWaQTKhr9vTJGvxLCm7TjJFk0zE7SXMiuu1eVbTqEAu4GM5xVv7y1gbkOS9Y6/wdJqVlxsQu/6TmI5z+u9g6ulHx5Yhtj3ALKnfvLFIy7ZrmKF49BK2OcvEvfk43s/73/ESHtfFrJnvnbhEq7M2wCzpf/z8IxDL3sBMpyzTeGEL7yVM8wHIMqD2SNZst4/nMzNBnMXY+AJmJTUzq21hG6U2MLW3X8Vx6uZI9meS7dbv8uy7XhbPz2Qw1t3C9NrOgOkbMFRYxuPY3DYzyy5iquduE/v76Bxm0H3P5BWIfaO2BDGWjd/MrLuO8yG7TTJX79DTAbY2dDFhrJmZ+ROYGdchVg+njv04cgzHVbeP4yfo8/VvegLXoCwxNdxYxxT/cYh9myNZlHttkqrezDxyj14ax28UEqPDBhoUXLJuOySW5qIFavAIivvb+qnFgFhPWMZtM7PuLOnvaUxLnibt093BtnBIm7H1y8zMGWA8u4cxlhE9SpMs8FmMeV1eNl9T8fyYZESP8tgWmS2cIyHJSh8lZJtnzy2pFo7zME/qU8F5k61gH/brPMO/08JKsfWTPfOwfdonZozOaTIozSx7A+coMwaxccpIE4sGy+Rvxu1AbJ74OMwtJOYHdt+DaW6VYZn72VhzM6TRyZBemMENoufjmGx2yWJj3MJxdBTVGoslLOfZ7XmIrV2ZgJjb59+Mlm7gDU0/jVnSr/0EdkTxfqxjfQc7onCR33fnKHlmH8E+C9r4nWnxCnm+IbfI1nczs94RLCdbwcHP1l4zs5d+4tf4hQ8Jf3Dlbbd9zj848e3bOv4P//APLZPJ2Ic//OHbLsuMdrcQQgghhBBCCCH2Q6PRsHb7tU/LB4OBPf/88zY3N3fH19PP3YUQQgghhBBCDAXRXUgct7u7a5///OctiiKL49je/e5329vedvvf2P8VekkXQgghhBBCCDEU3A0F2+Lion3mM595y66nl3QhhBBCCCGEEEPBnSaO+0Gil3QhhBBCCCGEEEPB3VKwvZXoJV0IIYQQQgghxFAQ3oW/SX+ruW0F2+Lv/MYbJycYK7Ib+O6fQtuBhcTW0R8juhaikmBamDTRVZlxZVBxFW97MEJ0OMSAEBHrTiZBwREQNcKAaLHCAtHR3SL1Idfz0XRlZmYR0W0wfU1hA89lihI2npN+LdJewLKPPLYGsWNl1G1crqNaY+XiFMTK1/gEY2ONKUUGIxjrTWC9R8+iFiuXQq1GlNAYG6+inyrVwLo7ZCZGzDDGZmxCP+RJ3zLdUEB0L2xMMlVgf5LrO1idcus4GX2iJQrLuA64ZfTZhF3+OaMTkPYtoo7EW8MJxeZ3tka0T8R80yV6OzOzsMSUSlh3phva7y+ymDrJjK/TbB3wR7GOXgfbMbtD1l60nZmZWfxjqK85VsU5/92rCxBzmbJsFzuH3YuZmTuFiqgUuWa/hdfMl3EBDImWjcXMzOII6xT1sL8zqzjB2frF5qdfIXOE7ItmXB2W2cO6e0QPNajiucEkGfw97v5KNUk5pJ6DUbyf7DZR4eFyTPdUM7OAqK1y2xjrV8m5ZP1j61Kmxu+btWWf7C+p1j4nOJneg3ni+HIT1gGiOXSJoi6cItdkfUuK8ZoJOtgMUc/liOKT1N0hZTNVm9fmczG/ibHJ7+LaEOTI3lTGWJAnY7fE+zAke0mKPFuNXsI2b81hf7XmiVYtQbnH9ic2HwZjRIHqY1syLaBTxA3rfacv0vpcaeBz3UYdH14zKSxnqowP2Fdu4TNhhuzxZmaTI/hysHoBz2d77dQJXHB+7cz/DbEZj2+CX27fD7HpVB1ifoz7w8tdzAq+R3x9edbZZtYlD5BfevUMxErf4erEF/7Vv6Dxw8LvXHzPbZ/zj09/9S7UJBl9ky6EEEIIIYQQYii4F75J10u6EEIIIYQQQoih4G5kd3+r0Uu6EEIIIYQQQoihIOlPVA8SekkXQgghhBBCCDEU6Jt0IYQQQgghhBDigBDpb9KFEEIIIYQQQoiDQZikRTpA3PZL+vcqNlJtfoPFFVJQD9UazQWik6ig0iEmrg93A90WYY7Xp3wdzy9sE72Ph82RJvqivTN4vc4x4k4yM4do0LxN1CI45PQeGiuoViMkeh0zs4goTpg2pVnAdsvWiIKDjJYk7dP73/s8xP7p1J9D7Jud4xC7sItqDKaRYjo6M67iy5P+zhA1UJjBtqhdRz/PmbPLEKv3iN/EzIzpmEifMeUPu++Y6LziBA1Vqo2dRkwftD5M4defxAqNXEzQ7hB9XHuB+cAw5BL1V0R8hlmikTIzC4rkfog6x69iW+bH0J3UrWLZXhYnbXWE+f/M2l08v2s4XkpXiL6SqJxaRHFo8+RAMxspY7w3IOOCxApzqAaqb6LDb/LrfCvpfRXnzqvvwmNzJfQSOcRJ2E3joIrLfO1NM4UbmYvZEt5jt45KmsIl3HPiBP0lWxddMvQ9NEHRdW1wBBf+QhXHWmezyCtE8B5ErVG1iGPlaBk1etfq4xBbX+MetJjM5f44cWiRqRySJbVxkqyTs3zsh31cm6IUNjDbV1MdHCupLrke02SaWXeGdHgJx6rv4nxg6sOYrMfuLhaeXuQu2tIk9ndvgOcHRCsYreBAj9JkjSWqNTOzOJvg630TuSpOiEEH6xjVcS4mmMisM4OxLYfM7w2sY79Cxi7R9Q0qvGw2v9Or5PwRrH13cn+63Mo14nQzs9ghutQqjrXWkf2N6aCI53bJPvRnL99H65O7SvqMLN0+2Uqul7GBXTLWfKIZNDPbIYtvegbXT+cV3NtyX8QO/2/P/9cQ+50P/6+07FNZ7LRnO4sQ+7dXH4FY6wZ6gpk6M8HARsffeI2sI+FtmbgPDfomXQghhBBCCCGEOCAcym/ShRBCCCGEEEKIexF9ky6EEEIIIYQQQhwQwnvgJf3g11AIIYQQQgghhBgS9E26EEIIIYQQQoihINLfpAshhBBCCCGEEAeDe+Hn7rf9kj720hv/7idoJ3YeJXqVAroWvAw5boA6CG8T1Q2ZXfwEJElDwNRsO2fw1ttHUdPgTqLD4KF5dGjUegVa9moNGykYJ3XPYfsM2qiTSNWJaMTj+gSvjQPQIQoi1m5+iWgaFlFZ8f5jl2nZn5/7CsS+QhRl//vy2yG2fgX1PsVlvJfqJTJ+zCy7g0qloEy0dxH2d/UStk9nD9t8Zwn7u93HcWpmVrxF1F9o+rBgmnQEUYek2Ly5xtVLuR2MpbpESbiF16wvEeXKJF6PaeLMzLpTWE5psQGxxhbWPdXHslk5TAtoZhZl8GCPxMIWXsD3sb9nZ1BD5RJF2Mo14k00s5FXiN6MWKNYP7RnsD7pFo6p3i53ErY8vG+ftG9EdFXFUdQ5LZ6+BbFXaqhSNDM7+h9RD+Rfwrmz/QBZ94lZaJQY7lpHE/RvM+RT8g4ph+iuMl3SvhNEOZWglko3koRQfx2mNGRqK7dO9qsI25Gt72ZG94h8Ftebjy58G2IXiMPqpQHGkjSQYZ60UQHHObvHwQTui2yvjMh4fu0/YCiYwf2B4ZB5427gHEvSjnk9onDbYepYPD8sYtmOj9fL1ch+VeDPIkEF2yjcxfowpaZHmqx9hCh0E4Z9aodo5sj614uJc4/MMTcge+os71eHeHQHp3DsN9ZwH8qvkzpO4fXKS3VadmMXrxmfxXoyaR5TzwVXcfyFWb7uM5Vje54ogYmmi6t+McYUw7kr/DkogwZAC8mhMdrxqCLWm8YBRKxzr10zxv8waBKt6im8ZmsVx+Spf70HsX9x9eO07MYJHC9Mo8a0sXEZ18n+NLneNl//WPu2lsiimKAxPexEZFwcNPRNuhBCCCGEEEKIoSC8B9Ky6SVdCCGEEEIIIcRQoG/ShRBCCCGEEEKIA0Kkb9KFEEIIIYQQQoiDQahv0oUQQgghhBBCiIOBfu4uhBBCCCGEEEIcEKLDqGA7809eef3fReblMLNzpRWIjXkomfh3tYcg9vWLJyDGFCfdI0RTM0GcPWa2eAQ9GiMZ9E4s5FGzdF9+DWKTKdRIfblxlpa910F9A7EIWdAjipICejBCot9yEhRsUYgDMB5gzO3ub6DOjaFm5Inqd+mxtQjb999sfgBia8+jymf0Kn66xVQSO/dz30tQwDb3K0TJRRR1uRpej83jXhc9IQFRd5mZOVPkmkRd4mVRg5HJYKzbwLJdovExM2vPYlsGZTyuZlh3l6hZwgK2Y38pyX2IDdesoZKGKXKCUaJsbBKFEKmPmVmcI7o1n3QkUY9EAR6318Yx1WvjoEzXEpZU8oEtU1j6ReyHgNj12JjM7PDxF3aIBoi0j5HY5os4eNcmcN0fe4BMHDO7WsWbHHkF65khBiOPaYDIOpAiKiczM+86HkyseRah6ciCMlGjVXCsOA3e3zFZkx2ijWJaLZeozJjOi23fmT3+zYBDrI3tFdQFfuHpvwexLNqGbOQGXjBf5PtIi61BJRwDrG+ZeiluYYcVb/Cxz+ZJQCxf6TbGUiTGxuSgzNuclc3UVoNRMgYGGEsTT1f7KPZDZou3xfhfEH1XGsthCkC2j7A1jdXbjLfFYJSoQG8Q9SYZu0wHFvS4+ovVszuG5Rw5tYXlnMCKhy0cQPVN4lQ1M48oPoMajl+XGLBKm2RckON63PppvaNM6YptXvkmthvTtHam2ZhkDjVeH6Z/c/vkWY/oB2MyJgOiqHP3yGJuZkaUmuRxy/wS6a8n8L3gwjtxTy2+AiEzMxt7ngx+MiYjMhcd4pgNiKKuX+Vls3nikueguJ7QboeckHXEAUPfpAshhBBCCCGEGAruxs/dt7e37fOf/7zt7e2Z4zh2/vx5e+KJJ+74enpJF0IIIYQQQggxFNyNn7t7nmc/+7M/a8ePH7dut2tPPvmkPfTQQzY/P39H19NLuhBCCCGEEEKIoSC6Cz93r1arVq2+9vcH+Xze5ubmbGdnRy/pQgghhBBCCCHE38TdVrBtbm7atWvX7OTJk3d8Db2kCyGEEEIIIYQYCu705+5PPvnk6/8+f/68nT9/Ho7p9Xr22c9+1n7u537OCoXCHdfxtl/Sn7519PV/L4xj1kMzs26ImQJPFTchlnExbWeuhBna+y5me3RIlspwl2f3LJAslz83/Z8g9u4spk+9QDI9dyIs559N/AUteym3DbH/+TnMch4PMCNrqcrywCOtJkn3aGYRyRzskOzwMUuQncfjej7262cu/zgtu97BOg2uYVrx0k2sY75GMoiPYD+QbjAzngU3RTLYs2zCLBsmu153maTcTsAj2WkDVnYb2zfcxnZkmZ6jaW42CGdI55Ls0cwQ4JMsyukdkm3U48sIzSJKyolJ5n23g/MhItnH4wzP7u628fwsyao7qJD6kMz7/U0cGAWSfdd4dXhG1ofJ/Caf7NJ1jRSdavCszvk1PHhQIdm189hfpVt4bupVbIvd+/lkLJ/AtO2NwQjEctv72yx7x3GcOyxlu5llL2Oj98dJB41htnq2v2QvYVZnlgHczKx1ihnXus8AACAASURBVGSCJ+txqoX3zTK0Z+lWS8YKWb/MzLozeD9s/SxfI5nlSfb8MIPH9UcSvpUgYX4/SDfGceqP4ILaneJjgM1llmU/3SRt3iBrA7sXcj0zs4A8l/VHMcb6LEWWBharvIrt052k1bHdUzjWHDIdelNkPSbbS55lH08QfbCM+r1pjHVO4gUctpZvkXmD0h0zM/OJzYRZONYGmCad7WFehzyzEBOKmVlI1n1mjghIRvNOFstOzeEgmBnlN778wizExp/H42Ky1tVPkj1jEte0/DK2Ixs/ZkbX2ZBkFU/XyT4WkvUrR0xH5FnLjFsi/CM41irfwUUx2MDU6fEpPLfzEB8EnR28ZjxKJgqx17C1k61fhWW+fxZRtGVxCs9vzR/8LOd3gztNHPfUU0/9jf89CAL77Gc/a+95z3vsne985x2V8VccfEmcEEIIIYQQQghxQInj2H77t3/b5ubm7EMf+tDf+nr6ubsQQgghhBBCiKHgbiSOu3Dhgn3lK1+xo0eP2i//8i+bmdnP/MzP2GOPPXZH19NLuhBCCCGEEEKIoeBueNLvu+8++/3f//237Hp6SRdCCCGEEEIIMRTcDU/6W41e0oUQQgghhBBCDAV345v0txq9pAshhBBCCCGEGAruxt+kv9Xc9kt6fLn0+r+vbHD32/o8KnbWK+jByHmodJgYQd9VeQL9H4MQNQ1Xgilan5e30PXxq42PQCwmFhdWTn0H9VvlUeKpMbNKAeNMeebmsS0WKnv0mm9m2anQeD+HeovRItbHI4q7n5p/FmLnSy9D7H/Z+FFa9l986xGIzT2N9+j1sezMNmpGuvMliHk+V071RnHiNU8RNwfR82S2cErEZJak60Rnk6D/KGywKNEnZbC/WgtYx9RxnCNvn7tFy15p4djwI2y30SyOi1oXx/maoY6E6dLMzKIRoqEiOh23hooS1pZBEYMuUQqamRmpU2+STLw0iRHtzn6Xcqa6MjOLsljOaAmVLZNF7NvVPPZhewfX3ogoe8zM+uNYe79K2rJPtDtljJVW8F6OfJXf91YLnVOpM+gt65VxkhVGsH0yZD0eNLh3jOnWYqLx85gWkAyLCKendea5boiprdwe6R/ySX5A7I4eUWCx45J+vce0jWZ43x2ixWIaHzY/k5SY/TGMpZsYy+3srxyHKCQ9MnbNzNjqEJUw2j6Jx/UncKyliH7LwWXutbKJdoxprFyiB43JWGHtyPR4fL8x66CRywbzZGCRpvRu4RxjujWmOzMz83H7ZsPP8uQ5qtvHgc72ZPb8ZmaWQQskVWVWXyVatxZRd5HHXqYkNOM6vHST9HcKY91prORgAwfV+iuscc2yaDwzh6jMds+QZxGihGPaOta2YY4vQs4e0fKOYjlhgeiVy+TZkejbsjXeDx6xozWI1rd5AutTvoLHzf0prg0r/zkt2hbPrkNsEGBbbuyhApCtdUxF2z7BF6H+HukzYuy7B371fVfQN+lCCCGEEEIIIcQBQS/pQgghhBBCCCHEAUEv6UIIIYQQQgghxAFBL+lCCCGEEEIIIcQB4VAmjhNCCCGEEEIIIe5F9E26EEIIIYQQQghxQDiUL+nfq5bhWhez0xNbEDtaQL/KzgDVGgFxAVxaR49FtIoeDGeS6ETM7JPn/gRiZeIuWfVRL9WOUD3y57UzEHMd7v9Yb6OTJCYDI51DhcJiCdvssdINiP1u7+/QsusrqG5aJ9q8ygJ6NC51UWf3td0TEHv68hItm5ikrHYOh9uA2ONiD9UaAVGCWIk4YMysMoaFv3Mcx+SNBvb3Rg81GGycM10VU+6YmdVPEqVInuihMnhcbgzHaTGHbpVvXF+iZQdNojcbYN1XierDiTCWIQoipvQwM+vO4LGpFmlLpooh08kJcFy4IfFimdmgQsbLCI6XuI8qFYcUHpaJ9iRL2mKKqxgLebzJTg/75moLx1/YIH3Y378zxR8lIqocxiKiN+ssYZt157Hs7CbX8DHVlvsCcYcRi1Cng+uF18KyXTJvzLgmMdXGWJQh+je05lCNVC/i/ZDfwHi6Q5RnxBoaoqnIIrJTD0bxem7CnpwlNs9cgq4IIIe1yBjwSbeamcVEcdebwlh3hpxcZms8WXvJ2mDG1xEbEMUiWS6YliggeqjE5zwST29jRzKVWUymk0/WoOgIxrLr/LEuv0nqU8fnG7aPhcRySLbKRFdlmjwPMJ2d3UR9b5F0bUxiVPNmZv4M2WCIotMlStd+lalS8XJJez+bo0wrSMdQBvvWJQpTS9gKWJ9tPo71WbpvFY9rYmMOBjiu6nMYy13lSszcNsYql8kzQo+sDRPY4QPS32xcmJn55DmTzfn8Im5Y9RwubLkd7Ifjv8/3ofYMug/ZXnCEOASDAlF0ZrFspiQ042OVPXNHuQR/4SHnUL6kCyGEEEIIIYQQ9yJ6SRdCCCGEEEIIIQ4I7FfNBw29pAshhBBCCCGEGAqU3V0IIYQQQgghhDgg3As/d99/9iEhhBBCCCGEEELcVfRNuhBCCCGEEEKIoeBQ/k16+nt0Sw7RA5iZPfvSEsSuHhmD2IeOvgSxiSy6Oi4sT0MsLKOy7OQR1GyZmX2teRJiX11DndjOMroJmOqIKbn8MayPmZmTJp6HHioUwhQe98oe3vdIqgexXIqryNwRVI9ksljPQgbP//L10xBLfR11cksv8rLzF1YwmEMfxN4j4xBrzWCbByWiHmGeGjOLujjWnqtgzMOmtALpLgbT5gzQHmNmZv1RvGhmHFVdEVGeDVZQ/xF2sB8clys0iqfQj5ZOoQOmTsa+S3Rp/jiOn4goQcy4amYwhednSVv0tlAV6PZwXIRE72Rm5lZRx1ittiG2vYr3nWrishin96fSCW9wD9VuFbU0VKNWxPZJVfBegm30dHlEL2ZmFhENC9NQZWvYj8FpLPvxRdRA5jy+DnzlKq69toy+IpdoAQu3sD5M41M/RYs2O4c6nQ6ZT2w975H6dB7ABWNxtkaLvrmB601cwzEQk/0hPY7lxMQlFvdxnAatBAeRYVumOnhUpkE0cUSl2BvH45KUrOkGWUdwCbOgimO/Oo5zlqkLfY8v3KURXFv6Pmk3ot9iBESH6DUSziXNEaew3SJnf+usZXHBiX2cx/1xsjCZWexhPdNEn0nstBYUsd6DKpaT3k1qR9YY5CgS600Q1SBZbrI7fPz5RO3HVJl9okN0yb7a7+Aci9sJCkCiiQ2Z9pMoUJluLari9cbP7tKyV5dxDXKJem77P8xhHcmzTDBNnh1v4lyaeIE/Cw9KRIlJdGuDMh6XaeJxIzdx/AU5vgfWzpI4afNel2yW5EWuN46xkWv8viuXsM+CMo6X9Xdi2UyjlyevOQHRdppxLSHTtUVkXRoG7oWfu+ubdCGEEEIIIYQQQ8Gh/CZdCCGEEEIIIYS4F9E36UIIIYQQQgghxAEhvgd+5a+XdCGEEEIIIYQQQ4E86UIIIYQQQgghxAFBf5MuhBBCCCGEEEIcEA7l36SH35Pqvz/DlQOWQR1Ks4HanT+4+CjExsrohYkGRFlByri1U6XVuXJ5FmKVF/HWTz5LnDSEMI/ntme4gqOxhIMgfAC1MuxvI67dQAXbzU1UlgUd3o0O0Sz1ctiWDaKvKeRQ31a7H1USUZrf98gYtjnDZUOIzBu/jA1ENTVmlipiPbNZjLFP0foDot9aw7Gb38BzK1f4H7hEN4lSLo9ujB4aUyyPQ8Vai9hfcYW3RXQNXSohUatliKGEKeq6RLsYTaOmy8ys8Dx6QSrfJGNyjPiYjmCodwT7kK0DZmbONrpLdrewPnmi7cnu4fVilyhySJOHSQasFfwPaaI6aiwR7c5RovAjqqMMqbeZWdfjWpo3w/Rm0S6q8L6dWoDYw7Or9JofPPUKxP4sg860bgv7K9pAJU2fLfELpCHNbL6KDXLtBs67kcvYt43jeL2YKBKZas2Mry3lpTrEUmTt9QOy3xE3lU8UbI7PHzo8MkWZtqf7HlxwJiuoRV1ZI0rLm8z1ZxYRjVA0gxVyyD62d30UYplp3KcLJb4GtZp4k846xgqrZH4TzVeA08Fsn9rOpGsyk2hQJHM2jwsOG2dsbTDjY6A7vb8/yky1sZx0jeyVCUrMwRjRwhHdJFPKOSQWe1ifLj4uvQZRng18HAPsflI7eDlisrMUX4KsX8WD++Nk/ybtVr6K9+j5OMd2ZvmNO5PY5pkjRGk4hvc9OopzrLeOzxLsHae+xJ9Hu0Rxl8El0fpkSc0R7ViUIsrQHF//IrIve2M4ITyiQj5+BnXCH3rvC1hHh2tIn3rmxzG4i21UOYaDbSSHD2FrO0QVzdyFZrYwjnq+f774ZYg90z5Gzzf7lwnxw4H+Jl0IIYQQQgghhDgg6OfuQgghhBBCCCHEAeFuvKR/4QtfsO985ztWqVTss5/97N/6evv7HaQQQgghhBBCCHGPE8XObf/v+/G+973PPvGJT7xlddRLuhBCCCGEEEKIoSCOb/9/34+zZ89aqYS5b+4U/dxdCCGEEEIIIcRQcKc/d3/yySdf//f58+ft/Pnzb1WVgNvP7n7ujeyQc6NNeszKRUzjWHoes1Ky7NHrD2Am7ewMZpr0e1j1QZtnl01v47GtRfxIpLWAZWfqJDs7yYrrj/AUr3EZMz66y5gilpWTIckie9OY0TLb4D+ICAt4j0Ea65nyMAtoj2Q5Z9lPabZbM9t8O95PqkMyxDbw3P4E1ttZwjHwkZMv0bL/440zEAtfwIyYRj4Vi6rYPt4RYhxYxDbbewWzn5qZOSSx7WB0fxnae23sb5aV1FZw7JqZTTyHsYBkWw5JjGVZHX0Z69Ob5NmEA/Jh4sqP4X07abzvTAntAvdN1CDWJtluzcxW6pjxNibZhPsuyfx7H7ZvOovnsjWIZcU1M5srYxrbjTZmtQ+2yBjaw3tk2ZIHPNG4Gckc7PZwzdh7GO/RIccVvo0de3nvNC366YexntlJbKNKFbMON3cxJS/LXh5ukwXZzDbzxBpAlkqW+XfsZWyz6CL2w94ZvskHMzh+yzkcV1MFzJx+uTYBsVYL7zGuY8VTUzzN9IBkmfZreD9pF+97+QbWx+1iQw7m8Z7NzMpj2N9jWTy23cf6nJ7AtM5b3SLEbq5gHc3MYjJeskdxrIXHcZx2yR5YKmIfttpk8TSzoEYyiO8Re0OGjLUC1qdUxrLHZzEjdG+eKyZ2m7hZR11yLNkXvR3sG79C9rBygvGnR55brvF2ezP9JRwr6QmMDVp8L8hdxXhhHY9LepZ5Mx0y1NoLZJM3s+mv4zwp/Rn2Y3ORWAgiYnQo4ngucrGGFddIZvlRXBNjskwGW/g8cfQa9u3O/Xhu4x3kwd64pSnM4RzzlnB+tubJq8pz2GbdSVq0xen9pfEeLeL6ufofjkLsDy7NQaw5z5+DssRIkifZ6gt/js+ooWFscZM8n1zADPRmZvEUPhR84kP/EGJ+whe/v/4gjx8W7vQl/amnnnqLa5KMvkkXQgghhBBCCDEU3AMGNv1NuhBCCCGEEEIIcVDQN+lCCCGEEEIIIYaCu6Fg+63f+i17+eWXrdls2sc//nH76Ec/ah/4wAfu+Hp6SRdCCCGEEEIIMRzchd+7/8Iv/MJbej29pAshhBBCCCGEGAruxjfpbzV6SRdCCCGEEEIIMRTsx3v+w8aJ49ur5onP/qvX/+31+acQLlGHTX0H9Q3pOh7YOI5ahdY80e4Q20aY57fC6sk+QIlTeL7XwwP9MlEakXs2M3MHeH5wDDUPmRzRQ62iaqZyAXP9JZXt4+nmE91Gbxb1ITmi7xh/kajaxrh2ojNDYktYUS9P9FtEdzUguqukT8EyV3AMMU0J047FJJViF42CNpgk43mXt4UTkjE0TlQ1GaJ/q6Eih41Jl9uPuC6wgv3otfHGY/IRXukmURrt8nnXncRj20eJgo20T0RUgVbkmhtGapNriOA4ogX0S0SJRDRJdL2o8o6ojKCGqt5A50/2eVTfeMS41ydalyQc0j1s/SyeQ52TH+CY7mzhwlK8zD/vjUk3MNVRmMVKZmtk3SemQdZfZrZv9RxTJAYlHH8LZ9HbVGuRRdbMepdQpZfq7m8fckl9Umhqsyxa/WzALZDWPEbmE2mfwjL2d2YPT+0R1VFvNkG/lcMbin2yj5HjcgWcT90WLtz5EpkkZpZO4TVbTVwUUxk8zu8TDSnZpwdNrv4ytj2RyegQld5+r5eaxmcJh2j0zMwGO2QzCMiYJLoqJ4vtw9q83+P3ErYxzpSubK0LilifsEDGc0Ia5MItHNPVC3h++VVc/6I8jrWwiPdSO8c1kINRjLHnjjSxGbN1idGZ5f0dzWJjxiE2UobMMbuY4OR6E+xZ1kn4cjJokWeZAj4TjldxscsSTeujY6gdawS8H/7iufsg5nZxXPyj81+GmB/jcX9y6xzE2l9N8L8RepNkTI/gPXqF/T0fz1SIy9jMPjr/bYj9l+XLEFsNuUL67AJXux0WTvwfn77tc6587L+/CzVJRt+kCyGEEEIIIYQYDvRzdyGEEEIIIYQQ4mBwL/zcXS/pQgghhBBCCCGGA72kCyGEEEIIIYQQBwNldxdCCCGEEEIIIQ4K+iZdCCGEEEIIIYQ4GBzKb9LD8hteiNjjyqmwjIqAm8cxxX/2OtEN9fB6gwrRFUwRbUSb307pBtYzt0f0PAFRL5FL9sZIx3KDgfXHMeasoiYiJiqo6hqe251gZfCPg5heKmJ6FaKJY1qjtb9LrkfULGZmjk9UXWuo4Ig9jPmkjkZiTBVjZtafwDoNSJ9FeTyO6cCYqiO9Q5RwCeobjynySPtYCmNMw+KXcbDNnNmiZRfSOE9u1dDf5YfoxYqJomlQxrZIUjEy/Rv75DK/jud7fbK2EBXKoEKLptqeiNiBqDYqwvrkplChNldFN1XK5QvBzR1s87BLFheiEWIan/4MqXfC+HPb2G5snHf7qJJaHEctUbeEbbEcEU+hmRWvY9ljL2EbhVmiqiS6taiNsdw2H39BDuO9KbKXEHVn9cQuxPIpnMjtda4qKhJ9XAptRdYnfUvVXQS2F3Rn+fjLzmLDjZF+3Kyio9PJ4X2fm9yEWGNA3FJmdvHKLNZnAyejO8BYqoWLiEeUUwOiUDMzS3nYHlGAk8yvYd2zNXLcCFvAEjZ/1o9kjsZEvUTPJUX7Hbao8ecy9owSZzGYKeOekc9hrEf6K030UGZmoxUca3YEQ60u9kOwi2OArV9JCtQUKbo5j31bO4cTKkXWG6ZpZapJM7PcNsYmnkPfmtvB9o2zRPX2MM5Pl7SFmVmwhe2WJveTJQrA8k1crGoP4ILcTGFs/AW+D+3eh/UcjGJjbtVxH4qJnpa9YB0fqdGy2fNj5GPs/1l+EGJPzL0EsX964qsQ+7Mx1LyZmbV8HNMZ4tl8YR3XyYCsVQOihrx2g++/n7n6BMR+awxfsmZGucLtKws0fHjQN+lCCCGEEEIIIcRB4RB+ky6EEEIIIYQQQtyT6Jt0IYQQQgghhBDigKCXdCGEEEIIIYQQ4oBwDySOIykwhBBCCCGEEEII8cNA36QLIYQQQgghhBgK4nvg5+5OHN9eNR/9bz73+r9dYkEzM3MivGT7CFHSEB0EU0TsPEr0KkQdkrvJPRhMo8bUVjE5LszsT9mTRKZOFAqzzMmFOESdVL7K/B/8/C6xMoQFPDjVJtoxUsXeBHG4lLhypVBBhcdIvg+xvTYqPHrrRAeWw7KdVMKNk2rmrqHWgxEQ9ZzXI2o0Zu7iBiIKG1dMZZZukXLIMO8u8H5wejheMnsYY1oZ1hZMW8d0dEn40ziw3BzWvTqKC8HODuqu3DXe6Gwus3FOrG4UfxzryBR16W2+BhVXSXC/ywg7jvRXb4yfztYrl2gXM2iUs84RMgbGsA9nZ1FZZmbW6mH/tK+iNy/dJAo2otELx7Fsp8nHn8vUgCTEfvH2varRv6J8Ectheiczs8EIxvpjRL/Fqk7qk25gsD+JdSzMkAXDzEpEoeUl6ALfTI6o59breIPdJnMumhlRWJrDVKD729vYWuV1+c8WmaorJvsGuyZTQ6ZwC7MgYd1neyijO4MxVke2r4Ulsi+WecFLs+gD6wW4Xm28jA8ObH4yXS6LmZkFuKVTnV0wimPa7RDtJ+lv5xQf+wUy9vd2ilhOCtuSKeV6e0QJR/ZZM7PCEV6nN5PLYDn5NPZjmqi7rq8QF6OZFS7iwBy9iPdY+coViHUfWYTY7hl8hso0yB7Y5htb7UFsI4/Mp8I6np/bwXrXl3BcdOZ52Vmi6WRjla3HvUm8ZuUBVL09dd8f0bIfy6Jy78UBTog/2n0bxPrk5aVNFpxymk+8lQ46Pm/UUQfb7fPnlgt//5M0flhY/N3P3PY5N/7Rf3cXapKMvkkXQgghhBBCCDEc3AN/k66XdCGEEEIIIYQQQwH5QdeBQy/pQgghhBBCCCGGA72kCyGEEEIIIYQQBwT93F0IIYQQQgghhDgg6Jt0IYQQQgghhBDigHAYX9L7P1Z//d+dBOVKegUVAUxH0i2T65Pjqs+jaiFKYyxIMMD0jqK+ISYKt+woagzCDmonUmsYYyoJM67oKayh7iBJXQLX6+Oo6kzxn2z4Y6jryE5ihaIL2BGFNbxemujkwjxXm/mPYEdOjqO2wiGZG9YKZPykiR7lBu9wpjdjag2mMmNqqhTToBHtDtP4mJn5VaIt28Xxy3RrTP/h+ESftcGnclDG8/tTTKNG5tgIamHec/YixDZ7qEYzM7v07FGIjX4HG703hrHdcWxgNsqZgsiMa4gGOa4ZeTOpOraF28XOTROV3ehlvurnt7At3QDr3qtiHbuTWA4xJyWOvzBHNGrkfKYAzBD1V9zCOb/W5hogbwz1R/EELpbBLFmjI9Lju2TtTdBvMb1elCZrA9E7ep396cBaC7Ro8ydw/BXGUEvZrZM1jPwEbzCOc3Z8HBeMZpuvibvPTtL4m2G6vmiUaO+IripX4ptgVMT7CQMypls4KIvjuF/1ujgGQjIuzIwuGkzL5gQY68yTMVki7layNpiZuT7GmRYwqJBrkvo4ZKnLbuEgD8n6ZWZ2M4WOxlwO+zYic7ZfJQqrLNY7Im1rZhZ3iL5wl8T2sO68v1ghtGhzyTPGE+dehNhPVr8NsZf7cxB7pr4EsdUOcS4mlD2RQ73oYmEHYl9ePQ2xVh/H+YPHVmjZdgxDuSew4b77sSMQG3Sw3tlreL3yMg7K9gwff2w9ZlrKyCPr3wh5XiK65tINPv6YFo5p3bK75LlhFNel+hrud/9k+edp2ZkxfLgfEM1wuknUuOR28pukkKSxT+ZJaY2s3UmG4r+fED8sHMaXdCGEEEIIIYQQ4p5Ef5MuhBBCCCGEEEIcDO6Wgu25556z3/u937MoiuxHf/RH7SMf+cgdXyvhB5JCCCGEEEIIIcQhI76D/30foiiy3/3d37VPfOIT9rnPfc7+8i//0paXl++4inpJF0IIIYQQQggh7pDLly/bzMyMTU9PWyqVsh/5kR+xp59++o6vp5d0IYQQQgghhBBDgRPf/v++Hzs7OzY+Pv76/x8fH7edHUwMuV9u+2/SU94bmQE9knHbzMwfwayf+TXMzpjZw3MLmySbdYSx+nH8fMEn2eLNzMrXSFbyLMY6S5gZ1+mTjIseyx6ekGGd1Kl9jmTB7bKM0iSjJcm2HJJM42Zmlsd+CAbY5RHJkN0g7Zsi2TSzu7xo91tFiF0YPY71KWFbpjC5rLkkoznLum5mZiU8tn8UL+pmsH1YRulwHRuYZZQOinw+sH7wyWR3IuxvlrHbJcWwbN2v/QcMsezlLFNqvIkX/VoBU8ZWypi12swsqmBq0djZZ4Z1kuk03SRlJGQlZfYHRkjOZ1mUmdkgv4XHJWVY3z2N9x1gglea7TZ2yZrIsj8nbCAZkoWewewCuR28aHeMlB3y9u452MCZKRwv2TSOlVIO18nuCLZj80KVlp3bxHr6ZbI2FEh2bZKBvjuFh6UzLM20WdDANaNLbCgxyXKeX8Y1OsizDMNJCz/ikWpGZPcv3iL72E3sQ5ap2RyeWZ4dG1cwlmfLyDU8sED2hwFPrm1BEccv20sY/gQ2msPmYkJG8/1mIM/UyLpPLhmQfbo/ScZuQn285TwGN3ERIluydeZIFm4XBxCzoyTBTAssG3WUwuM8sk/363w+pFLYRrU+Gkn+7c7bsWyyoI9lcLNcKqC5xszsagezgD86chNi78hj6vTHi1cg5hNNTS3kdpUvbp2DWER0B08++EWIfauJ+/zXRjG2vITPefNHWPpxs6CD46/v4/34ZE0MybwLl3Hs5jf4+AvyGG8cJ4aoIpad28JzK1dwLs58nSuautO4LnbHyfgdxXNDsqSydwqHLANm/LmwPY/3GBHDyVBwh4njnnzyydf/ff78eTt//vxbVSNAieOEEEIIIYQQQgwHd5g47qmnnkr8b2NjY1arvfGhXa1Ws7Ex1F/uF/3cXQghhBBCCCGEuENOnDhha2trtrm5aUEQ2Ne+9jV7+9vxVzr7Rd+kCyGEEEIIIYQYDu6Cgs3zPPv5n/95+/SnP21RFNn73/9+W1hYuOPr6SVdCCGEEEIIIcRQcLc86Y899pg99thjb8m19JIuhBBCCCGEEGI4uEsv6W8lekkXQgghhBBCCDEcHMaX9MbKG64TpkkyMxu/iGntiTnCBsQc0ZkiqoRz6OV46NR1iGU87iH49vOo/soRJVxqByuZJZo4H60T1p/1adleHuvuraNXobBClAzELOSfRE9NnKSAIeGYmBbiDNGrjGM5QQpPfvcx1ISYmY2kUEfx76+exQNvYWMyRU66gae6RMVjZpZ6N3rh/vGJpyFWcFGz9HQDNSNfzy5BrL+HfejmuI7JiC6GaXeKK3hqZ5ZopCrYD0kmiez2/nJDEvubZUib99ZRo9K4QVxiZpYlpsGAWICYRs0j135ekQAAIABJREFUNhM2FxP1g6Q9mG7NiM6EXdNleiiywAc53hF9ktyzO4fjpTKNnrneAD0qDvmdlt/ny3m0QjwuZFhk9rDuxTVc11yizYm3+X0XyDprDi78PhlCO0RJw36e5iaMge7D2GnpLLZ5gVx0rNSB2FQBHXWvbhIvm5k5zf1trakeUTmSOcL0W0wVmNvk8724ShRGZKwOyHxgqkCmymKKRDOzHtGjsfnNnhGYGMgnc4npQc3M0m28R7ZvMB2dS+adR85lzwNmCWOVPCYwFS1bW7pE8xoQjZkRZZmZWTiFhfdiXBRZvaMKqXiPqOMSnkWo4omoD6M20YMSZSjb77wGn3OdNK5/39w6ATGnR3S7pH3nTqB7M4z4vFu/Pg6xb6/ic9D/tobn1t6NbT4+U4dYq7t/FWNMGi5DJvMzt45CLOhjP9y/tAqxf7bwJVr2qo8PtFsBLji7ZELtkQ3imSL+ne+ew7Nos7UyLGCwfBHv0Sfr185ZonCe5Co8j0ydgNsqAaZxZK85QdIaxO47j0F3kjysDQF36+fubyX6Jl0IIYQQQgghxHBwh570HyR6SRdCCCGEEEIIMRzom3QhhBBCCCGEEOJgoJ+7CyGEEEIIIYQQBwW9pAshhBBCCCGEEAcDfZMuhBBCCCGEEEIcFA7jS3p+9Q1FAdMDmJn5xETQncaYcxKVNm+bvwWxShpVOpcakxC7uIUxMzPLEg/Bw6jYqebRC7PbRPVDpYz1eXS0Rov+7toRiPWJ1qO1REbLGPpe4ibRMfW5/sMh6q90A2O5bTzXJR4gr491/NbkQ7Ts9jzRPIyh5iEsE0VdD++xfQy9E/kp7t2pZNB58YWn34f12cFymIbKI13jzGF9SiPEK2Rm901sYjln8L6fXkbtyWAdx1+2hv2dxqlkZmbFdaLXI1as9hxRvZF5HOWJNocoo8zMApI4kwwhc4l2J9XFk7tkejN9m5lZFi18tI2YooTpmPrjWPHuCeJWGexPeWdm5mSwLRvbpNFZQ5Jycgm6PQ+XOvMrGGs+iOtN5x1Yx3CAbZG7xjVA1QvYwCOXSEcERDEW4BxpnUKNT+0cGdBmFq0Szw1RcsVEabN8FAf15tYMxCqX+S4/2mHzDst2Ijxu9z48LiJaylSL6MW4CdR6Y6Rstq4xiykbfqN4clDgmXL9Clm7qZoPQ/0JJmFDUh0+9mNSDI2ROZ/dIbEGUR8m3DfTLrKymfIxJEM3Uydj18X7johS1cwsJo97TL/KFE3mMi8bhth6ambmDshYbeDizdR+tBxSHZ8otczMHFL3OIdj0qvg80mwgx2xsoodG/t8/I3MopfQI89GtU1UkeWvEgXgn6PSLTPJx1/rUeY5xNB3/vR+iDlM0XkW7+VcZR1i/9PN87Q+OY/oL1O450Qx2duIx2y2hI7Y4ATvBz/AiReRzN7pZ7Ef2F4ZnMJ3gNK7UI9nZtb1sR97RJvHtJ/HKvhe8ezqPF6PKIHNzByqYyRrdwvrOBQcxpd0IYQQQgghhBDiXuRe+Ln7/r/2EUIIIYQQQgghxF1F36QLIYQQQgghhBgO7oFv0vWSLoQQQgghhBBiKNDP3YUQQgghhBBCCLFv9E26EEIIIYQQQojh4B74Jv22X9If+3svv/7vlRZxE5jZ2SpqGb50/TTE+nXUBlyro2LCIb9J2GujIqe/VqT1GXueaErSRPM1ivqFEaIn83qoxbo5IL4VMwsfxLJjoqRxQqLI2URNQ0x0cpXje7TsZgvbt1dE7YlfYe2DbZ7dRo3F+AtcezL9LVRmdGaxPp0pohsimprcJgbDmyO07LqHcWZnyRFrHrFyWGcWY24Z1SEDovkwM/vWq8cgltkkehU0wFiWaYmOkQOLWB8zs40tHKuZGtYzKGJ/Z3ZJ3zT2p0szMxscQwWMR7Rj7jbO236VqIGmyD32eJv3x8i8I9odJ00GBtEcTp3AwfIzi89AbMPnY/JSawpijQHO726AZdea2D6dXVz/BmgnMzOzaBrb0u1i+4yMo9LwvzrxNMSyxPP1hdLfpWXvOLimtmawjTzStek21rs/uj9VoJlRpVeKWBvTRFGXYapLoifrTO9fv8XW+IiYb3LHUOUzaONY8Sfw3AHRbpqZWYj97TZw+4+Isic3i41WyWGH1db52PeaWE53Bhszs4NzOV3Heg/mcPx1cwnuL/YQRvohzuD56R2sd5jDcwP+2GFBmdSJbDABLtFUg+YyFSN7bkgYAy5R9qWb7H6IhrSHbVHAx7xELW9rkZSTJ5pCoqNzydrg9vF6bF8zMyt+l4wrsraEWSw808R+CHI4aZlaz8ysOzEKseZ9eEOjU6g3C1/ERaS4Tsb+OPeQeiv4vMWeMTLEHNY8jvf90yefh9jOAAf/q1dQO2xmli4R3RpZl5gyr1TEZ4lyDm9muoztaMb1bzvkOX7lIbyf4i2sY3AT99+VBteYEaMc/Z315k0sez2P70NsX8vs8gFYWMVYipj52D40FBzGl3QhhBBCCCGEEOJe5F74m3S9pAshhBBCCCGEGA70ki6EEEIIIYQQQhwM9E26EEIIIYQQQghxUNBLuhBCCCGEEEIIcUDQS7oQQgghhBBCCHEwOJQ/d//LCydf/7dT56evHkE12/3TG3ggWolst0/UBs+iAyvOEEUY0bWYmbUWMTaoogLmzNlliD1axRjjhT2undhYmcFgH3UJMVGzpNbRi5Bq47mNBPdSukH0LERxEhPtjpFYfxo1FqsLXH0TR0St4ROtDFGZZfNE30aUU06P97dH9FJeD9uieRTPjbJ43ymirnGJ3sSfJ24LM5uYRcdJMEXqSNQjrS522EgG2yfl8X7wR3CODgpYdoa0eS+Dbc4IkxRYTDe0i+1WIgZBpjrqMq2al7DKMt0aURO5KWy3iFxzEOK8e6mNc36rxxvjuy8uYdlknDLNF1PcpXNYR6p8MjOvheWwazZ2UQHzhzcfhdh4AZVc/8WJl2jZ+VM4vy+2piF2aRd9YpuruI9UZxsQO5Lj8+7mZSwnymA/unhJ88glu2S/6iyQDjOj48/dw/WcqaR6N1FbZ2Spc0h3uwOu32JjP0Pu2/HxuH4L67NTJgq1OtcAsbaMsqQfiL4r3WJXJPpKbqCkdBZxrfNauE4yHWdvhqwXRFf62gUwlGryPevNZIlOjPY33ooFuMS+diwZqgFZ4pkq0Ovya74Zph4042q24jJR4ZEhNCBmP3YvPlG6mZm1j2A5pRWyF/jkmYfoaZm+rUvUkGZcHzf7RRxrmTrOsQ5RZ17/EFHhHSUONTML1nEvCki7hTmyD41ixa+0JiF2oYYxt8PXAT9GVZwzIPOB7L9d8nzjE+VtZ5Xvv8U5XEja7JmSzLE00XbOfAMnRKpJ/HZm1p3DOjWOEo0faYrYI+8K5LjKdb4Pla7gIu9X8b47M1zjd+g5jC/pQgghhBBCCCHEPck98JK+v491hRBCCCGEEEKIexwnvv3//W34+te/br/4i79oH/vYx+zKlSv7Okcv6UIIIYQQQgghhoP4Dv73t2BhYcF+6Zd+ye6///59n6OfuwshhBBCCCGEGAp+0Inj5ufnb/scvaQLIYQQQgghhBgO7oG/Sb/tl/Sjc9uv/3ujRLLQGs9U/uIyZkIO9zCjIMtEzLKNGskWyrKPm5mld/A2J5/Gcvr/F2aR/+JxTA3fH8UyepO8t6M8SRdZxHp6aczOGJ8gqUFJU4R1krLdzNw+3jfLXh4VWdpXLKh4Da8X8qItKGAsJG0RNXEM9Fim+z0sO1vbf0bVkGS8HVRJW0xjhs4+ySru7pLsnGycmlkQ4vkByRYexyT7Pfmoj12v3eEd4ZAqpbI4/iKS/ZmNtZGLWO9eQkbfoI/1jIg1oPCBLYj95NHnIHaxjdm6v3brGC27lMd+bHZwEAwapN0K2D6dLo7TL104A7GY9I2ZWXqPZLwlS0ZErBVBEWPMyMCyxZuZhRWS6f4oyUTbwzm2tY1r/JaDsZU6ZmI3M3t89ibEPjj+IsROFjF1+r+3s1jFAdZxrcPLdkqY+ppld2fZcn2SUXrAiiFZ3M3MnCbWM90kGaXZEk8ygPfJWsVg1hMzszCP9fQn8Fivhe2TqWF98ht4HFtjzcx6U2T8TuL4i4j1pE9sJnEF+9Wp43psxq0ejKhAsvEXsRxqYSF7t5lZ0MY1IyCZ4Nm8jb39ZT7frw3CzCxkCZyJUSQkT4WD41hQJ0OeWQY8s3d2Ay/anSH7L+lG90gHYmMVTLm99RJmGk+i9jbyrEjawsi+6JBnoyRSxHjgkAWHrUHNo2wM4DNC5xZ/Ds/u4kVHruE90nKI9eSZb5+E2PQ3sNzRJreMNOexc9mawZ4p45uYIZ2tnSP8FcCaFbxosYoZ2tseVsgN8NzUMxcg5rh8/y0u4zUz9QWIdWawnEGJGHLyGAszfEzuPIwvK1tvJ/OOrH9DwR2+pD/55JOv//v8+fN2/vz51///r//6r9veHiqLfvqnf9re8Y533HZZ+iZdCCGEEEIIIcRQsP+P2/46Tz31VOJ/+9Vf/dU7vCpHL+lCCCGEEEIIIYaDe+Dn7sruLoQQQgghhBBC3AW+9a1v2cc//nG7ePGiPfXUU/bpT3/6+56jb9KFEEIIIYQQQgwFP+js7o8//rg9/vjjt3WOXtKFEEIIIYQQQgwH98DP3fWSLoQQQgghhBBiODiML+m7/+4NlZpb5Md0Z4nyh2grPJ/oTDokhqYEi9IkL98xVHWYmc2fxnT4Ow+jI2z12QmIZbchZMV17NmRG7y3W3Oo4OjOYCqAsLA/VVtxpAexgXH9VgoPtYhowvpotzCvgn6L1glUaDhprttguEwzt4t1j3rYZmmi0snUeTkDok9iFJaJ3mIXdRm9KbxHr4/nFp7hDqLYxXi+QTQYKaLW2Kfuz1tCJY2Z2cxoA2KtPrb5zrUqXpPcY2kF22Luj5Zp2cFNjLuPnYPY9Z9Adc7vtd4NsT7RpRWvcvXS9lIeYtkqmRA9onwMcPwFu+gvKq6QuZSkoyuSMbRPPRRTDcYuxgaVhB2HaISYHspt4HZQIPfIxoAbML+T2XeqD0Ps/3voAYhlZ3Dtjkm9By1S7z0+BthP2YhBiyo12Z6T3SWFLKGmy8zMChjvl7DuqS2se7aGl3MHWHF/BPvBIeu2GVcxZnK4vwR5olgcIbEuUW0RLWAS+QLW0yGqwX4R26eQx3NDsi+amfk+jukjlRbEcinsr3oP15BGC9fyapk/d9SJ0mvQxfthe7IRXalD1JB0T/V4PwzI3uYRxR17cKWaOKJgS9JAOuQxwWOqOFI2W6t2Eu6RwbRu6V2874g8DUdZrHjxFtEU4jb7GqSabF3afgTbIprDRcjdwj7MbfF9xCNrGKvP4DQemCHjijwO2O4Z7O/cdsIYIGWzdZYp2ByiVmNrOYuZmaVuYbv5p/Cin3zn/wux3Ltxbfjjn30Mj/P4XnCZ6EnXVnEMuWQMucSUGkzh+tcka7mZmUvWoMfn8bns/vIaPf+w84P+ufudoG/ShRBCCCGEEEIMB3pJF0IIIYQQQgghDgb6Jl0IIYQQQgghhDgo6CVdCCGEEEIIIYQ4GOibdCGEEEIIIYQQ4qCgl3QhhBBCCCGEEOKAcBhf0v3v0XW5CfYZpvwpHG1C7GgVnTaNPqoSVl+dgphDyuAiMrOJHOqpfmr2OxCrL6KWrRliffrE1fFSfZaWvXET43GXNDtR1KXWUT3S3SYKogT1TQpNM+agWcPcPtanexSvOb+IPrpmj7d6Lo1KiHIWNTmNKrZvvY3qm9Is+im693P1UmcHz3cCogXJEC9Mh+hV6nhuRMw1vQT9Vn+CqGpIf7MVIyoTnSHRo1TyxNWRQMol901UeiHRfNUeIDqm6lFaTpDHeIdMk+LZHYjFxKUyCHCskFAiA6LySTXxfjzSlHTekPUvSX9kVdSmBD4Zays4pplKh2mFXKK0NDOzNtEnEfVcfh3Pd4nZpTmP55ZX+H1XruF9p4iGql8tQ8zH5diypG/S3IBFz4/JMsD6NiRGufYZvJeZClcf7pE1LBiQfiCKnPZxMj+zZA0hCqwUiZnxseavYQMxVVamgfVmY98f2f8TT1BDTya7JntAiRtY7zQ3z5kRvejGBDm/RRSfRLmHvWrWKnEXbUjaI0WeW6IMWffTGMusEY0U0S4GVf5g5pCxEZLxx7SqsU9UlX2ikSKqQLMENRaJsTGQWcP1IqjjyMht87KzVNWKx3am8SjfxftuL5A5RrRsZmY5olP0yZiMyHqTewlH2/QzONAzm3wBDMt40dqDOPYj8mzkX8VKVi8RRSzZf/0EBS5VppH1OGZWQGZ8JEuvl7AXVC7jOO/u4T3+D3sfhtjoNL67VPL4LNsecA3pCHnunZlFLXT1OFZ+hejbOl0sZ2aMOwAXy7iIdYgu9U9uoRrXzOzX0JZ6qNDP3YUQQgghhBBCiIOCXtKFEEIIIYQQQoiDgRMf/Ld0vaQLIYQQQgghhBgODv47ul7ShRBCCCGEEEIMB/qbdCGEEEIIIYQQ4qBwD7ykk9yKQgghhBBCCCGE+GFw29+kf6/6pz9BfC1m5hJDhf8CqgSW9zDG9Efp96JLbHECtU3Xt8ZpfW595jTE/vjqDMTiNHoeGidR09Afwc82wgT/m7eAH9Uw7UR2B/0UaTQ/UFVHB2/FzMy6M1g2K6ewgedmGqg9Wc2OYh1vcAdW6hbGbpwgH1stonYiIKqs1gXsh5Fr/GOw8R0cl60j2LfdaaIlKhElDRnPUZ70KzfCWaqF5aSIVsvIdAo7RP+WIcq8i7wfAjKGsnWs+5EWxpoLWHbjHDpy+kt8HTCmvSPUV9HZMvIq3uPiBSy7ucCv6Y8S3RUZLkw5xWBztkU0hWGFOMvMLE30R0FE+paMoT5Z1vKbJHaFzwe/SLRPZOVnmpvOLFE8zaAGqHWG97UzIBct4Pku0z4RXVX6Go7zAW4jZmbmj5LOncQNZmqMKHZyOEFH0njuy1vE22RmfaKZszxRYBVwvHikLYI2dlhIVJ5RK2ERIgotI5qv3BR6jX782CsQ64ZYzpXmBC36Rg3dlP4q0aAR1dugypRyRP1FdGlmZg6Zjky3xuYD22tjdlxCk7OvQGLy+0qmHWM6RVb2/9/evcfYVRbsAn/WXvu+5z7TTqfT0lKgXG05XOSi/T6RBjlqlETDB0Yi0ZxKwBgOyqEmAuYQIgGaY/CUEL9DUAnxcozE5Ageo0j4Ioq0UP3kUmkp0Nt07rd9v50/8BTS59l0D37t7Ok8v4Rk+rL3Wu9633e9a63Ze94nIqLnwgM6CqqSEedDBzdQJBRxnGL8yFi1BooDfJCdS/m+rlDkxiyNquA7lh/QFcqtEtd0ERWX3sfHmBT3S/k+Hn/ZM3QGYEFEJ2I/z2Gx6ebu/2YHuX2yF/J9GQDkThJ9287zWmJXc+07s5rLSv3cr4GI9QOAyLSYwzLcPokunmcDcd5kRAzaVE4fi5xvBniu+5/n/W8qm6nxNkcqHBn6f4Y+IPe9Z5gv4JVxHgNDgbjQJ7l9uvr4vIk2uJGpiZP0pDQ/O6myxcBfdzczMzMzMzNrFX5INzMzMzMzM2sN/iTdzMzMzMzMrFX4Id3MzMzMzMysNfiTdDMzMzMzM7NWoVYTbjF+SDczMzMzM7NFYSF8kh7U63P7VcLpP//vh3+ulEW8DoD6QY4siBQ5CqCaFrE7IhJkaf8UlU3lOMKgOMwxCwDQtZLfr466WOJ4i952jmmoiuikoTc5ZgYAkgf59yClDt55XERwNIx2ObI+Cd2F9QGOqKgVuT7xA7wjlehw6j/vobIP9+2S+35q+HQqe+MPJ1FZyFVERMTmVEXCWGFAx10FUa58qpN3tKJ7ksrKVR7Tb+zmmKXEIW5HFR8I6KgaFe8Tili29DD3rdpPNK8jOKbWiJg5Tg/RUWRiWMXP56yjf1nzgtz33kI3lT25g2NKul/k8de1iyNt6jE+7ypJHf2V720u3kwkSaHE1UZVpRqJflVxfYAe05W0iHBbwpE2yTbu8NJejiRMDjefiaQiI8vtoj4qoknEwtRFRBgAGfOFCtcznOFxWo/ye2upJjPzAEQ7ud2WdHF8TRjhbY5Oc/vWXuETp/clXZ9onuueE9FNKj5TRW3FeaqSY62SkdWR82epU8SBieu0igiLT3NZo0iumhhrUU7elOdnoY/rGM2JeLJG+xbnrbrvkHPdJM8hqs0bxTiqWDc1D6jXqblFXkdEm1W6GkxCIgIQVbFRcX5Gcjx2w7y6Z9H3IqEYV+V2cf/XxnVMimt3V4YvlsNj4sIGoD7GA1CN885dXKbO43wfv25mvY5gG1jG18uJWb5PLe8R801cxLx28sm48axX5b4/2sXRiT86+EEqe/X3a6gs0WQilxr7Kq4UaHA/K4ZfWcxhqj4xMYc0mgfUHKbmhskP8jVj45ncvtkKv3m0oCffqQI/D53WPcJ1FJPQeJHHyutjHNVWb3DghUP8/jAvIqTb9Zzxxn+5VZafKC65dsuc3/OHH33tGNSkMX+SbmZmZmZmZotCo1+wthI/pJuZmZmZmdnicJy/7v7oo49i+/btiEaj6O/vx4033ohMpsHX3/6uwRdTzMzMzMzMzE4sQX3u//0j1q1bhy1btuD+++/HwMAAHn/88aO+xw/pZmZmZmZmtjjU63P/7x+wfv16hOHb63usXbsW4+NHX/zBD+lmZmZmZma2KBzvT9Lf7amnnsK555571NfN+W/Sq6+9s4JmtU3/1X24jFfjrEzxaojRabF66iy/LvfSEiprHxMrX56sVzjM9fE2y2KV8/oULz85JFbdVKvLRjp1WxRW8aqfkTivpFjoEquFj4vuUYsld+tVzgd6Z6gsE+fVK7PLefXTiSyvSDmS47b49dCZct9VscRn5HSuT+lN3mZ8UqzeK36dFM7qdIHkal6RX3lzjFfkj4izMNImlgYVq7tnDugzOD4jVqlWK/+WxUrGRS4bPYffXBCrmQNAtU+sOqtW6i2I94shXZrlZaJ/vPt8uW8lTPFYnTqd6zO5jusTdvKxVMV5DAD1Er8/PirOMZEuoM4xtdK4WoU7UtBzkBq/MZHogIDnoIIY5/GsWFlZrUAPoNgrVlHONFgB+sjqlMW5qFZyT+r5LxArp9crYu6VK1dzmw+sGqOyvlRz5zsAtMV4/uuO8zLBu2N9VPZahueqcrpBf4viUgeXlXmTqIjran6l6C8xTqNT+nyoilWze1fykvGZOJ9jsQi/d2SWK57NiWXcAdkY+Um17LpoNHHeVZfyHNLRJZZ6BlAQiS2VGbFvMV8Uxcry9Tj3TVBu/rOOsIvbt5LjPgvk1CBSFWr8wsEBXlEc0Nf03IRIxBHbVKval5fxsXQt4fQEAJgc5fESTIt5QIyBkpjjqymREBHTc1BkkOcHlegwOSjGxTBf79re4Jf1/F5PvuXqUipLZLju6swpdYjzpo3H2m9ePkPu+3ej66isQ6xgH3IVkVsu7oNK/N7kKL9XphUAiIhbkTjfEiJ1SL+ftlfhOha79Xys5tkkX0pw6r/yQH+17xwqq6TFCukN0pgyB/n+cXiW/w5Z3SMUlvDIaBdjQEzRAIB8L7dHgS9tqMUX6ee17/Ohe/PmzYd/3rhxIzZu3Hj433fddRcmJ/naes011+DCCy8EAPz85z9HGIbYsGHDUfflhePMzMzMzMxsUXi/n4zfc889Df/f7bff/p7vffrpp7F9+3bccccdCNRvY4+wSH99YmZmZmZmZovOcf6b9B07duAXv/gFbrvtNiQSDb55dgR/km5mZmZmZmZ2DDz88MOoVCq46667AACnnXYaNm3a9J7v8UO6mZmZmZmZLQr/kQvBNeO73/3unN/jh3QzMzMzMzNbHI7zQ/r74Yd0MzMzMzMzWxSO9yfp78ecH9LfHVtQm9LrzhUqHFuBNGcEBCJuI3OguXrkl/J741P6teWXOX8hpqquEmBEuk8ooiQarcFXrnEuQ42Tv4C8iIxqMooMEd2NI+l2KptO8mIFhTzHh0T2clxLZTdvb/9KuWvU1nLDqYUMqx0cp1Po5jOnt3+ayv7Tkv1y3/EIb/P3B06mstw0j9PIJPdXTIzzQKTe5cSYBIBiF5erU6QuEuWiIlkov4zbJ7mK2wcA+js446QuIpHe2N3PrxNjLSLieXKvdcp9R0VMWHWQ40g6RN07UpyN1pHgsmxZR98cmuKxWk7zeVIW0ZChOBerKmJMtGOsqMdAQqUiqdixuIh3LPHAUOOvUfRNXUSZocjHGJ0RZSJuMsyLfTeIn5Hl6rhF3aMreUdn9wxRWbGqD3znBGcLjUY4+mY8wTFU0YD7u/d0zhvqWK8y/IBChQ+8PMP7rh7gsuSImG9qYkyKoS+mPgBAaojbaHaIs3hmxBwUcmqdjJiLNhh/pS5uy6iIKlTzTU2srVOv8Aunx7kdASAc5X6Ii3O0mhBRb+3NxRQ2EpvkxqzPiEivURGnKI4738/bS+/nthjftUzWR52LaukiFbemrk3VBHf4ZJ3nXQBI7OOdJ8b5dTVxYxYRkY2FCN+fJBvccFfFtbbUxS9uP5Mn6WXLh6ls6BQ+xvF9+hqY3qdjYo/UbBRjdJjbcdmf9DjN/GoHlQVr+IZt6J95Hmh/i7c3s4rLZs9uLmIYAGrTPGFl3uD2Ufc8FZEUGIrzuNEzl7pnV22+60s81r54/jNU9i+d26jsb2WRbQZgy54rqOy1/RwrrYQiErOrk++t4zEREwxg+lW+r0vv5XNMnXeLQq31n9L9SbqZmZmZmZktDq3/jO6HdDMzMzMzM1scTsivu5uZmZmZmZktSP9g7vnx4Id0MzMzMzMzWxT8SbqZmZmZmZlZq/BDupmZmZmZmVlrCE7Er7u/O45FxbAAQC8nP6AWa25XKopn4mLOgLnirFeo7Df/tl5us30PV3R2FXfOwHqO9/llGLXEAAAezUlEQVTw0teprEfksj05dJbc9x4ZhyIGhkjqiIn4t9gsl2VVthmAkth1qcQNXB/lIJZKG8doTJ/KMQ3JYb3v+naOxMmewvlA6SWct9HTxmXTec5R+c2fzpH7VtF+qUNc995D/N6wzH1T7OLXza7g1xXW6BgMlES8RUVEW3Vz3EZJfB8nEed27M6IXCwAQ1MdVBaLct9+aP3fqCxX4ciUv+wdpDIZ8QWgHhERi7s5QmamzJE2wSBvM1vi+sxmVYgQUB3miJ56nCNtgg7us2qG+6su+jAQETAqrgrQsTK55VxWWsljINHGGy0X+Tzu7hITBoCzenig75nhHMgDIzzQq1Fus0JeZDk1utbleGKLj4soKXEu5quckfP0bp7jG31lrZri/1ET59iBMvdtbJzbNz7B/T0zh+i5qDhF0yIyrSLSxNR1sS7KRPJbw/oU+3nnkSSXlURMYVzEUkYajP3UkJj/VCpgLxfWI1y2/jTOh1qSFBdGAL/btZbKSgVxsRVjAGVxbWsyuhUAyj2ifdt4vpnt4Y6MJHmO7uzkSWQyyXNndELfa1XTfC7Hl/Kg7BDXknJNnMdVboyKKAOAagcPjkiSz8V2ETk1KqIL6yIKtDSjrwUqtiw+xe/P7+A5cWeviFYT+45m9XGX+PKLylI+xtUrR6hs7w6+QKT4ZQ3vw2c/znPlyLlcz1CkSCZEnPGKp8QEJh5yZleKzDsAU6fwvgt9Ik5W3FOqCEAVoabKAH0/qxqu7SWe65768Yep7DexDaKOuiOyy7jyGXFPqe7tIyI6LjbL43y2W4+/2ACXiduthvHVJzyRrNtq/Em6mZmZmZmZLQon5CfpZmZmZmZmZgtS6z+j+yHdzMzMzMzMFgl/km5mZmZmZmbWGhzBZmZmZmZmZtYqFsAn6XpJQDMzMzMzMzM77ub8SXpwxfjhn8sFjisAgOmXOQchMc6vU5EDMkJBJBsczItsi36RJQGgMMNxTMlR3ujIHziv4KdtIsdM1Cc20yCKbJAjVzIdXM/ChIjKmuHtlUR8QqlL/zYoIuKTKjmOI4mISJF6nLdZWcrHkg915k/6AG9z4GkRYyVilvLd3BbpHNcn3eCXYKX2fyDCQ3RuKGIwOneLfezR50Mg0j9kJFI3j1MVaxQTcV7lGTEwAAzs5coHVR4Xz33iTCqrdPDrwhnxe70Gs0ipjw+8LKLnAhFLND2ZprK6iEkKwgZjX8TwRWZ4ENREtFpYEn0rDrvWyRFL2TWiswHk1op4KdUWYiUTNbOoCKJsXkcQ/Wn/SVRWFDEuEG3WP8gTd98yjno7t2uf3HdRZIf926FTqOzggW4qC2ZEXKRocxWPBwDhLPd3ZIzP0YiK2hJURFij+K1aP5+46S4+cSMqYrGp2gCBeO+UuNYBQHGWjzsQ4y8yzHtXY7/UK8a52N7bGxXtpk5bFeWY4P0cnOXrw2xZz729XXyTodr80ChvMxjhtqjG1WQudw2IyLNAtGUocviSKZ63Z6a5b1XcqIoeBIDYFJ8P9Sm+CI4nOPKsmuFjqYv7i0DF2wFAjF9bjHBU16TYppQVsXVi3gaAQGyyKO6ZwgK/v30XH0+hj7dXXi5uEgBEYjxekq9xP468wtGmPcNibpjm7Y2fods8dgnP3ctSfO/51s5+Kiu38TZH13N/VdvFPUKnzmJMp7m8M8HtNpnl9imo65XU4KawKK4Fee7vnp18LqbenOTtVbgfKn36Hiw+yfsudfEN4Phafl1+jTieZdyOYYPzptkPirOjOjbvRKfmhlbjr7ubmZmZmZnZ4rAAvu7uh3QzMzMzMzNbHFr/Gd0P6WZmZmZmZrY4BP4k3czMzMzMzKxF+CHdzMzMzMzMrEV44TgzMzMzMzOz1nBCft198o2ud/6R4bgCAMBSEb3Uxtkj8WmOQFDRVCp66d/3cGSFiuUAgMxBLguL3DnRgorlEFFkKa53bqmO/6hkuE7lQ51UFoj4mZmTeXsi0ahhjEBlTMQqiGpGs1yYfIPjIMKSiLBqkLgSEUMjmudjTB7iSJDUiNj3LMd0VTM6/m16Ncd1lDr4GKN5fm9Y4jqWM/zevIhhSQ/L6iA5IaJqRJ8lJkUkV02MSTF2yxkdQzWyntsiPyDGdL+IkMmLCCwRzVcTZYCOVusQMVQfGdzF2xS5Ty+O8zk/PstRbQCQD7mBazXdRkeqiEivRBeP03JRnIyVBvsQ511Q5NdGZnmbpQkRnyV2kRdzDQAkhrg8Jl6q+vFgpZfLajz4/72yWu4bcRHR08FjrS7aLXNAXDNeEW2hU+9QE6lc6ryL8DCVkY2FHjHvL9eTbzLFG42HXNEZEZuXbzIeL5bhfZRF1BoAhNPc4ardVCxbVEwNtby4FiT0PKCiHKPtvNGqiElS4+LQPo7rO6Ri3gAEIpooFLFu9Srvp97DdUy1cVkkosdAPisi3EREWbqLL0RFEW9bFfGpiPJxx7vFhQ1ArZePUbW5arNUmo87PyPuL3QKrozxU2MNao5W0XyqvwN9D1bu4v6OiDm+JOIdSyvUhCH2PaPvRWqBiHBbwvVR8Xiza7k+CRFvtqpP5BsDWJHh6LDJEl8vDy3ja3KxncdfKGL0VB/WRnVcWj7H0WrTfTyHJTpExJiIPlTnUmRKz38x8ayh5v2iuE/MXcLXu8nT+XXxtVNy34NdY1R2UoqjIVeLVcwmS9xmu8f4mlwq6Wt/RETUlsRzgYoaXBROxId0MzMzMzMzswXJD+lmZmZmZmZmLcJ/k25mZmZmZmbWGo7336T/+Mc/xrZt2xAEATo7O3HjjTeip6fnPd/jh3QzMzMzMzNbHI7zQ/qnPvUpXHPNNQCAJ554Aj/72c+wadOm93yPH9LNzMzMzMxscTjOD+np9DsLNxaLRQQNFrt8tzk/pAdd76zyGTRYUfXMNfupbCA9TWUvjvBqzaUyVylaEysuTvAqlWG3WIYWwOzGBsv/HqEtxatKVsSqrx0pXsK0p8ES69XZNipb3smrQFbEqqaRgNt330QXlZXf5H0AQGKUV2yMZsULxTipikUyE5Ncn2K3HmQTH+CVSTs/c4jK3prq4G0e4tUnQ7EKslgME4BewbnSLsZAUpSJhAC5wno/r6A7+wFdIV7HE0glxWq5RW70rgzvp7+Nz6VD2Xa574g4nyrjGX7duFjNNc9927aP95EaaTD2k9xn2X7u26fqH+R986mIqlhAt7CywSBYyhsIxCrMtYLo7zIft1zJXa263qA6tTSPNZXoUBOr0kdyYm4Q6QlBRa/QqtpSDGlESmJlb3E+lDv4ze2nTMh9p+O8hO5kllesrca57pUU7zsUq0c3SreIT6sVoJt7fyXZXPJI++t6Nf/YX/l8nOnjssJSsfNObrNUJx94Z5rLRsT1CgCqheaSDUKxonlPD883pSr310xOrPYNoCpWnK8NizlenHfVNLdPx06xQvqIPvGyInUlN8ivDUSygUqyUEkL9Qb3QfUE170uVltWq/kH4nWhWM0fqh3f0iuNq9khITapVr2upHk/KTF01X0DAJR6RBupDYjECxRE6olKO5jR9yKp3XzkmSHed3KMJ9XcMj6gYrtI/5jWk9D0at53dq1IZWjjfavV1Ct7+dq97y/6/m9vcBKV1cRtVKmT99O+ks/5pe0zVJYMud5/LayU9UnvFwkKEZFmIsaAurdfvXKEd6J3jf3j4r55Hz9DjInbKJV+1PYWvy71or4Hm8jwPW5ukts8McFtGVT5dd1LRGpEg/Nudjm3pQhnQWGpfv8Jbx4WjvvRj36EZ555Bul0GnfeeedRX+9P0s3MzMzMzGxxeJ8Lx23evPnwzxs3bsTGjRsP//uuu+7C5CTHH15zzTW48MILce211+Laa6/F448/jl/96le4+uqr33Nffkg3MzMzMzOzReH9Lhx3zz33NPx/t99+e1Pb2LBhA7797W8f9SG9ue/AmZmZmZmZmdmcHDx48PDPzz//PJYvX37U9/iTdDMzMzMzM1scjvPfpD/22GM4ePAggiBAX1/fUVd2B/yQbmZmZmZmZouFWkH3GPr6178+5/f4Id3MzMzMzMwWh3lY3X2u5vyQHt/9ThRHVcQ5AMDLY6uo7I2VHN+wpI3DqQ4VOEug+gpHGKRFlFi5TUePVFZxjNXAEo5BW9HGZadmhnk/dY7VeH6M4y4AIDvBcUPDT3VSWdsBXmYwt5SXDCifyoOqUfRINMdlMdFugUgiq3A6hYxbq/DhAQAiOW6jtw71UFk0zjuPdHLcRtDL7dPXqfLkgLyIHZuaELFjEzxe4mMiJkScJUURL9a7gld0BIBrV2+jsuUxfu3zsydTWbbC+3kz201lB/dzGQBEstwPERFfo8ZAXaxYUeQkE9RCvbRFRGxTxVilRrksMcX9XU2IiLCiHvu5GY4MqmT43ImIt6sosvAQt6OKNmukLGJ7qkmuT7WbY1iifTx/lfM8KCPDekKO89SLEk+pKPMpIgUi/q38Bz63AWBazS08/SGS5rYod/EYCETEWLXBHDR1toi9E/E+Kior0sYxSfEkH3hVxPoBQDYnYsemuCw6y/UJstyPpSi/d6zCnZjkSxgAoK5iNlVi2hg35miUy2oiPrDaptuiLqKk0CHaUsVvJfm9s6tErFBUzwNFMSwr4hyLJNRkJWL4KjyB1VWUJ4BAvD82LiJmc7xNdV2tisiyQGQ+lvSlAFgq8guFMMr7yaR5spuZFXPsrL4Hi+R5/qyL/g4qYu4VUaBqQKt4RkBHLE6sVdcsPp7cIPdtchlPqIGI7wWAdjE/JER84fiIju86Utfp4/zeUf3exBtivhH3hGpODXbzhX4iJ2LMRPpbWtw7Ag3mG9ENkZKY48d4Ttz3Jkc4RxuMgZhIZw7FUO378EEqu6z/NSo7WOSL2Evjy+S+J8Z5nq4WeAzE9/ExJrm7ZRRy2z6Rmwggs5/Hb5gTcX9TYmAAwGZdfMI4ER/SzczMzMzMzBYkP6SbmZmZmZmZtYjj/Dfp74cf0s3MzMzMzGxxqOs/0Wolfkg3MzMzMzOzxcFfdzczMzMzMzNrEf66u5mZmZmZmVmLWACfpAf1+txqufrRew7/XC/r6KXkfs426Nwl4o8qXJbt521mV/Hr6hFRJmJh3v4fXBSd4QgE9bpqmv9moS5iYVRkDwCsWDpBZZcu2UNlfTGO9Xg1O0Blf9i/msrKFXEsAEqzHMERmeLfy6h4nnobRzck9nG/dr2m2zyocvnMSu7bQh+/LhARYXERLZTkpgUARHNirImUnHKa95Nfwq/LnSrimNo5cqUkonQAALPid2FRUceCOJ9E56i4tGi2QQyfSKlTkVVFEXFXbxdRHSKGqlZpEME2xJEimf1cz8wQ77uc4tdll3NZuUOPv4qI9EJcRBil+Hjqos3VXBeIPoSIGgKAiIiKU3FDcg7q4TomOjlrJpMUOTMAsiLWMhHjbap5pLCPM3ZSh0REToM4ThXjF+VEORn5qPqwHooyMU4BIBBRUhERBxaL8QlVKvA5GwxxhlByRJ938WkuUxF3JRFHp9pHzdEqWq/W4Nfus6vE395183ipizim+F4ePzFOT5V9COi5Jezl+VPdiai5JRKKeEbRXwAQqHuUlIj9jKqy5qLIulOiwwDUIOawkrgmi5NevbdQ4utLVfRXYVafjBExzgNxH1UTbVZT54OaelWUHSDj7FAUsWzi/IaoYyDO455eMSgBhCKDbWyC57X0i3xhzAw1d9+a79PXQBU5Gp9W9zz8urYDfN9RznCblUS8JwDExH1QlYcfIuLWNXNAZJmJTx1L3bzBkfX6Pii3ig9SxTOqc7YuzkU1BnqXiEkRwOpOvlkcyfOEvPdljlFL7xNzkGizfL/cNcpL+MXy3kEUBdN83sVm1PW3wX34So5WW7WEc92Wp8UFC8CjF/0vWX6i+M8rvjrn9zy574FjUJPG/Em6mZmZmZmZLQ4L4JN0P6SbmZmZmZnZ4lDz6u5mZmZmZmZmrcGfpJuZmZmZmZm1CD+km5mZmZmZmbUIR7CZmZmZmZmZtYZ6vfX/Jn3uEWz/et87/1AxAgCSIh6okBXZD0KqjSNOYiIeZXaW43CicR3/UZziSJLUmxwT0b6Xjycsclk5zREIU6fJXSM8lSMhgj+3U1lCxIlNncnHc9qZ+6msJ6EjYPbNcr6PioBZkuHoEhXJcFKKoxtGShxlAgC/2X06lYU7OfIiygkRMrZJRTzVddoVSt3cbiryZ6CXc91O6xyhsj3TvVT25kEuE6k5AICaiJqJjfHvx8J8cxFj4SA32openUfXFuOYpZEc99mhkQ4qk/Vu5+0FDY67KuKTajMinkVFnokonqBRvI+itlkSMWoqCUUcj4zzEvWJJXQcWLnI/V3NclsERTH4RdSMipHq6BInE4APLD1IZW9M91DZgeEufvMEzxdhjuuY4Knh7deKVLgSDzU5zqspEQsoYjYjIhYQAKKif2oisqomIh9rBR77gYr4VP0FAGUxiMT1MsiICEAVVyXqGCb5+DIZEZ0EYPoAN3p8VERgqRRIUaYiLatxfT+g5un4tDg/1bwvbhtEopaOA2sgUMNFpSGK+qioLPU6AKhkRFygGAO1jIhGE+d8Xc3H4zyvqGsqAIR8CZRtERPvV/dBpQ5utGK33ne5vclotZIYF01+lFQT0bgNJcRrxTUnMsZzdHKU6ygSdAEA8VneZvoQN3pyiLNSg4qIHZvhe71qv8hxBDB1Kt9v5Zdw3VUMpIpyrKaaO8nUOQIAlX6+GMQzHE9WEeO8pmKGRWRtYkgPlhTf1sl4vJrYTSji1tKHRJRnVo+/SlJFyvHriiJKT811JX58QFmUAXouUP2T5+Q5AMCu//Zf9f84QVzZt2nO7/nV6PeOQU0a8yfpZmZmZmZmtjj46+5mZmZmZmZmLcILx5mZmZmZmZm1COekm5mZmZmZmbUIf5JuZmZmZmZm1hrq/iTdzMzMzMzMrEUsgE/S5xzBds6t/+Ndb9avKXK6D0orOH4hKeLWCjMiLm0X57DEReSFik4CgOwKEe+zlOuTyIi8IKE4zXUMR0WeA4D0Qa6UareySDKrpLksxsloCHXqjlQTkTayTEVEDHB0SHoJR4cAOparIuKPwgj/Jqstyf0QEY02UxC5bAAKeT6galnl+4hK5jiDIzHGZarNVUwcAJQ7RRSPiJ8JC1yfiIikUXFB1YQ+GWsiFinMc1vEOY1OxvOo6BA1Vhq9VkUqVdMibkjFVVX4wOOTOv8oyqmCiIo+UxFhMoZKRTTNoS1U7EnT8W/ivareKq4FaBBjJfZd4VRLGVNTFa8rtzW4GIi2VFGDERWLJTap9t3ouGUsknit7EfRZpW0iolrFDvG5dFZboyYiCJTUVmqLZrtG2AOY1UMjJqaW8RAjYj5C2gwt6goM3E8ag5SfVPmtKm36yTik2REmZpGxGGr+six22DfMqZTlYlxKq/JIgm03KFPiEBE+6k+U/F6al5Sc1BEjV0ANXFtVOeT2k9EzPuqH8qdDY5bxK+qKMZQRPi2t/FFIxXjjlX3MQDQLeJxV2c4rzIqGn1Q5PIuj03K/Sj7Snwjviu3lMqKYmANJPmkzVf5BH11up/KXtvP+wCA2iSfuIG6B2uSjGmdw/bUPUasj/v7pD7ur444j6mhrM5Bm8ymqCyV4DGUiPKg7kvx/XU85LFSqen7oLECP0RUqnw/mxJRvQDwu49ukeUnio+lrpvze/5v/tFjUJPG/Em6mZmZmZmZLQ51f93dzMzMzMzMrCXUnZNuZmZmZmZm1iL8SbqZmZmZmZlZa/An6WZmZmZmZmatYgF8kj7n1d3NzMzMzMzM7NjQ6/Y3sHnz5mNVDzvG3HcLl/tu4XLfLVzuu4XLfbdwue8WNvffwuW+az1zekg3MzMzMzMzs2PHD+lmZmZmZmZmLSL81re+9a25vGHNmjXHqCp2rLnvFi733cLlvlu43HcLl/tu4XLfLWzuv4XLfddavHCcmZmZmZmZWYvw193NzMzMzMzMWkRTOek7duzAI488glqthssvvxxXXXXVsa6XvU9H66unn34ajz76KHp6egAAV155JS6//PL5qKodxYMPPogXXngBnZ2d2LJly3xXxxo4Wj+99NJLuPfee7F06VIAwEUXXYTPfvazx7ua1qTR0VFs3boVk5OTCIIAGzduxMc//vH5rpYdoZl+8rm3cJRKJdx5552oVCqoVqu4+OKLcfXVV893tewIzfST7zMXnlqths2bN6Onp8ervLeQoz6k12o1PPzww/jmN7+J3t5efOMb38AFF1yAFStWHI/62Rw021eXXnopvvSlL81TLa1ZH/nIR3DllVdi69at810Vew/N9NOZZ57pC98CEYYhrrvuOqxZswb5fB6bN2/GunXrfM1rMc32k8+9hSEWi+HOO+9EMplEpVLBHXfcgXPPPRdr166d76rZuzTbT77PXFieeOIJDA4OIp/Pz3dV7F2O+nX3Xbt2YdmyZejv70c0GsWll16K559//njUzebIfXViOeuss9DW1jbf1bCjcD+dWLq7uw8vnpNKpTA4OIjx8fF5rpUdyf10YgmCAMlkEgBQrVZRrVYRBME818qO5H468YyNjeGFF17wtx1a0FE/SR8fH0dvb+/hf/f29uK11147ppWy96fZvnruuefwyiuvYGBgAF/4whfQ19d3PKtptuj87W9/w6233oru7m5cd911WLly5XxXyZowPDyMPXv24NRTT53vqth7eK9+8rm3cNRqNdx2220YGhrCxz72MZx22mnzXSUTmukn32cuHN///vfx+c9/3p+ityAvHLfInH/++di6dSvuv/9+rFu3zl+lNjvGTj75ZDz44IO47777cOWVV+K+++6b7ypZEwqFArZs2YLrr78e6XR6vqtjDbxXP/ncW1gikQjuu+8+PPTQQ9i9ezfeeuut+a6SCUfrJ99nLhzbt29HZ2eno9da1FEf0nt6ejA2Nnb432NjY4cXg7DW0kxftbe3IxaLAQAuv/xyvP7668e1jmaLTTqdPvz1wPPOOw/VahXT09PzXCt7L5VKBVu2bMGGDRtw0UUXzXd1rIGj9ZPPvYUpk8ng7LPPxo4dO+a7KvYeGvWT7zMXjp07d2Lbtm246aab8J3vfAd//etf8cADD8x3tezvjvqQfsopp+DgwYMYHh5GpVLBs88+iwsuuOB41M3mqJm+mpiYOPzztm3bvBiS2TE2OTmJer0O4O11I2q1Gtrb2+e5VtZIvV7HQw89hMHBQXzyk5+c7+pYA830k8+9hWN6ehrZbBbA2yuI/+Uvf8Hg4OA818qO1Ew/+T5z4fjc5z6Hhx56CFu3bsXNN9+Mc845B1/96lfnu1r2d0f9m/QwDPHFL34Rd999N2q1Gi677DL/TVeLatRXP/nJT3DKKafgggsuwJNPPolt27YhDEO0tbXhxhtvnO9qWwPf+c538PLLL2NmZgY33HADrr76anz0ox+d72rZEVQ/VSoVAMAVV1yBP/7xj/j1r3+NMAwRj8dx8803e6GdFrZz504888wzOOmkk3DrrbcCAK699lqcd95581wze7dG/TQ6OgrA595CMzExga1bt6JWq6Fer+OSSy7B+eefP9/VsiM06iffZ5r9xwvq///XzGZmZmZmZmY2r7xwnJmZmZmZmVmL8EO6mZmZmZmZWYvwQ7qZmZmZmZlZi/BDupmZmZmZmVmL8EO6mZmZmZmZWYvwQ7qZmS1qt9xyC1566aX5roaZmZkZAEewmZnZCe666647/HOpVEI0GkUk8vbvqDdt2oQNGzbMV9XMzMzMiB/Szcxs0bjpppvw5S9/GevWrZvvqpiZmZlJ0fmugJmZ2Xx694P7T3/6U+zbtw/RaBTbtm3DkiVL8LWvfQ3PPfccfvnLXyIWi+GGG27A+vXrAQC5XA4/+MEP8OKLLyIIAlx22WW4+uqrD39Sb2ZmZjZXvoswMzN7l+3bt+Of/umf8Mgjj+Dkk0/G3XffjXq9joceegif+cxn8L3vfe/wa7du3YowDPHAAw/g3nvvxZ///Gf89re/ncfam5mZ2ULnh3QzM7N3OeOMM3DuueciDENcfPHFmJ6exlVXXYVoNIoPfehDGBkZQTabxeTkJF588UVcf/31SCaT6OzsxCc+8Qk8++yz830IZmZmtoD56+5mZmbv0tnZefjneDyOjo6Ow19fj8fjAIBCoYCJiQlUq1Vs2rTp8Ovr9Tp6e3uPb4XNzMzshOKHdDMzs/eht7cX0WgUDz/8MMIwnO/qmJmZ2QnCX3c3MzN7H7q7u7F+/Xr88Ic/RC6XQ61Ww9DQEF5++eX5rpqZmZktYP4k3czM7H36yle+gsceewy33HIL8vk8+vv78elPf3q+q2VmZmYLmHPSzczMzMzMzFqEv+5uZmZmZmZm1iL8kG5mZmZmZmbWIvyQbmZmZmZmZtYi/JBuZmZmZmZm1iL8kG5mZmZmZmbWIvyQbmZmZmZmZtYi/JBuZmZmZmZm1iL8kG5mZmZmZmbWIvyQbmZmZmZmZtYi/h8I5uB84wK3zgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 1440x360 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1.0000001  1.0000001  1.         1.         1.0000001  1.0000001\n",
            " 1.         0.99999994 1.0000001  1.         0.9999998  1.\n",
            " 1.         0.99999994 1.         1.         0.99999994 1.\n",
            " 1.         1.0000001  1.0000001  0.99999994 0.99999994 1.\n",
            " 1.0000001  1.0000001  1.0000001  1.0000001  1.         1.0000001\n",
            " 1.0000001  1.         1.         0.9999998  0.99999994 0.9999998\n",
            " 1.         1.         1.         0.99999994]\n",
            "[-1.1025136e-08  0.0000000e+00  6.8907102e-09  2.7562841e-09\n",
            "  0.0000000e+00  2.2050273e-08  5.5125682e-09  1.1025136e-08\n",
            " -4.1344261e-09  5.5125682e-09 -1.3781420e-09  0.0000000e+00\n",
            " -1.1025136e-08  1.1025136e-08 -1.1025136e-08 -2.2050273e-08\n",
            " -5.5125682e-09 -2.7562841e-09  1.1025136e-08  1.1025136e-08\n",
            "  0.0000000e+00 -5.5125682e-09 -5.5125682e-09  0.0000000e+00\n",
            " -1.1025136e-08 -1.1025136e-08  0.0000000e+00 -2.2050273e-08\n",
            "  0.0000000e+00  0.0000000e+00  0.0000000e+00 -5.5125682e-09\n",
            " -4.1344261e-09  1.1025136e-08 -5.5125682e-09 -5.5125682e-09\n",
            "  7.5797812e-09 -8.2688523e-09  0.0000000e+00  0.0000000e+00]\n"
          ]
        }
      ],
      "source": [
        "# mfccs = extract_feature(examplePath)\n",
        "# plt.figure(figsize=(20,5))\n",
        "# librosa.display.specshow(mfccs, sr=22050, x_axis='time', cmap='viridis')\n",
        "# plt.colorbar()\n",
        "# plt.show()\n",
        "# print (mfccs.var(axis=1))\n",
        "# print (mfccs.mean(axis=1))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jCqmewnpBd8q"
      },
      "outputs": [],
      "source": [
        "# import pandas as pd\n",
        "# import numpy as np\n",
        "# import tensorflow as tf\n",
        "# pd.plotting.register_matplotlib_converters()\n",
        "# import matplotlib.pyplot as plt\n",
        "# %matplotlib inline\n",
        "# import seaborn as sns\n",
        "\n",
        "# from sklearn.model_selection import train_test_split\n",
        "# from sklearn.metrics import classification_report\n",
        "# from sklearn.model_selection import GridSearchCV\n",
        "# from sklearn.preprocessing import MinMaxScaler\n",
        "# from tensorflow.keras.models import Sequential\n",
        "# from tensorflow.keras.layers import Conv2D, Flatten, Dense, MaxPool2D, Dropout\n",
        "# from tensorflow.keras.utils import to_categorical \n",
        "# import os,glob,skimage,librosa\n",
        "# import librosa.display\n",
        "\n",
        "# import warnings\n",
        "# warnings.filterwarnings(\"ignore\")    \n",
        "# root=\"/content/drive/MyDrive/Thesis_Keras/\"         #忽略警告信息\n",
        "# csvPth = '/content/drive/MyDrive/Thesis_Keras/UrbanSound8K/metadata/UrbanSound8K.csv'\n",
        "# examplePath = '/content/drive/MyDrive/Thesis_Keras/UrbanSound8K/audio/fold6/85249-2-0-79.wav'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "fXoRw0fnBe0Q",
        "outputId": "da99bbad-a9f5-4142-f79b-7a4dc3d260bc"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-a41f771d-9a8e-4782-be8a-21886678fbcc\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>slice_file_name</th>\n",
              "      <th>fsID</th>\n",
              "      <th>start</th>\n",
              "      <th>end</th>\n",
              "      <th>salience</th>\n",
              "      <th>fold</th>\n",
              "      <th>classID</th>\n",
              "      <th>class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>100032-3-0-0.wav</td>\n",
              "      <td>100032</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.317551</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>dog_bark</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>100263-2-0-117.wav</td>\n",
              "      <td>100263</td>\n",
              "      <td>58.5</td>\n",
              "      <td>62.500000</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>children_playing</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>100263-2-0-121.wav</td>\n",
              "      <td>100263</td>\n",
              "      <td>60.5</td>\n",
              "      <td>64.500000</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>children_playing</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>100263-2-0-126.wav</td>\n",
              "      <td>100263</td>\n",
              "      <td>63.0</td>\n",
              "      <td>67.000000</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>children_playing</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>100263-2-0-137.wav</td>\n",
              "      <td>100263</td>\n",
              "      <td>68.5</td>\n",
              "      <td>72.500000</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>children_playing</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a41f771d-9a8e-4782-be8a-21886678fbcc')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a41f771d-9a8e-4782-be8a-21886678fbcc button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a41f771d-9a8e-4782-be8a-21886678fbcc');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "      slice_file_name    fsID  start        end  salience  fold  classID  \\\n",
              "0    100032-3-0-0.wav  100032    0.0   0.317551         1     5        3   \n",
              "1  100263-2-0-117.wav  100263   58.5  62.500000         1     5        2   \n",
              "2  100263-2-0-121.wav  100263   60.5  64.500000         1     5        2   \n",
              "3  100263-2-0-126.wav  100263   63.0  67.000000         1     5        2   \n",
              "4  100263-2-0-137.wav  100263   68.5  72.500000         1     5        2   \n",
              "\n",
              "              class  \n",
              "0          dog_bark  \n",
              "1  children_playing  \n",
              "2  children_playing  \n",
              "3  children_playing  \n",
              "4  children_playing  "
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# df = pd.read_csv(csvPth)\n",
        "\n",
        "# df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ar1HSW5ex5vm",
        "outputId": "936e26a3-95a3-4622-a0ff-a9a3f136bead"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Your runtime has 27.3 gigabytes of available RAM\n",
            "\n",
            "You are using a high-RAM runtime!\n"
          ]
        }
      ],
      "source": [
        "# from psutil import virtual_memory\n",
        "# ram_gb = virtual_memory().total / 1e9\n",
        "# print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
        "\n",
        "# if ram_gb < 20:\n",
        "#   print('Not using a high-RAM runtime')\n",
        "# else:\n",
        "#   print('You are using a high-RAM runtime!')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kxV7SanMx24e",
        "outputId": "e2b831b9-ceb2-49b2-c6a9-4652cb87d9e6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EGfA4vnddqOa",
        "outputId": "691d3488-0dde-49fa-d3ee-dc3172bbf820"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43m流式输出内容被截断，只能显示最后 5000 行内容。\u001b[0m\n",
            "6943out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "6944out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "6945out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "6946out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "6947out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "6948out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "6949out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "6950out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "6951out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "6952out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "6953out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "6954out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "6955out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "6956out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "6957out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "6958out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "6959out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 110)\n",
            "shape:  (40, 118)\n",
            "shape:  (40, 128)\n",
            "6962out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "6963out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "6964out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "6965out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "6966out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "6967out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "6968out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "6969out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "6970out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "6971out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "6972out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "6973out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "6974out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "6975out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "6976out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "6977out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "6978out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "6979out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "6980out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "6981out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "6982out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "6983out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "6984out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "6985out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 81)\n",
            "shape:  (40, 128)\n",
            "6987out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "6988out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "6989out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "6990out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "6991out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "6992out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "6993out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "6994out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "6995out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "6996out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "6997out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "6998out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "6999out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7000out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7001out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7002out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7003out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7004out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7005out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7006out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7007out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7008out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7009out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7010out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7011out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7012out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7013out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7014out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7015out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7016out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7017out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7018out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7019out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 63)\n",
            "shape:  (40, 88)\n",
            "shape:  (40, 128)\n",
            "7022out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7023out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7024out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7025out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7026out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7027out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7028out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7029out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7030out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7031out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7032out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7033out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7034out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7035out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7036out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7037out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7038out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7039out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7040out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7041out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7042out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7043out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7044out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7045out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7046out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7047out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7048out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7049out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7050out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7051out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7052out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7053out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7054out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7055out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7056out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7057out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7058out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7059out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7060out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7061out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7062out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7063out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7064out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7065out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7066out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7067out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7068out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7069out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7070out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7071out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7072out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7073out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7074out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7075out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7076out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7077out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7078out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7079out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7080out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7081out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7082out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7083out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7084out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7085out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7086out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7087out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7088out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7089out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 126)\n",
            "shape:  (40, 128)\n",
            "7091out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7092out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7093out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7094out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7095out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7096out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7097out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7098out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7099out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7100out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7101out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7102out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7103out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7104out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7105out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7106out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7107out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7108out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7109out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7110out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7111out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7112out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7113out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7114out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7115out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7116out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7117out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7118out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7119out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7120out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7121out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7122out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7123out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7124out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7125out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7126out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7127out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7128out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7129out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7130out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7131out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7132out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7133out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7134out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7135out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7136out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7137out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7138out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7139out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7140out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7141out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7142out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7143out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7144out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7145out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7146out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7147out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7148out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7149out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7150out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7151out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7152out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7153out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7154out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7155out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7156out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7157out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7158out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7159out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7160out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7161out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7162out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7163out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7164out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7165out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7166out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7167out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7168out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7169out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7170out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7171out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7172out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7173out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7174out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7175out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7176out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7177out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7178out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7179out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7180out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7181out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7182out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7183out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7184out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7185out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7186out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7187out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7188out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7189out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7190out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7191out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7192out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7193out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7194out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7195out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7196out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7197out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7198out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7199out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7200out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7201out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7202out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7203out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7204out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7205out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7206out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7207out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7208out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7209out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7210out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7211out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7212out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7213out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7214out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7215out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7216out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7217out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7218out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7219out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 65)\n",
            "shape:  (40, 128)\n",
            "7221out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7222out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7223out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7224out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7225out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7226out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7227out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7228out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7229out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 39)\n",
            "shape:  (40, 128)\n",
            "7231out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7232out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7233out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7234out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7235out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7236out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7237out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7238out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7239out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7240out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7241out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7242out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7243out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7244out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7245out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7246out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7247out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7248out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7249out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7250out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7251out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7252out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7253out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7254out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7255out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7256out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 23)\n",
            "shape:  (40, 16)\n",
            "shape:  (40, 23)\n",
            "shape:  (40, 22)\n",
            "shape:  (40, 128)\n",
            "7261out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7262out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7263out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7264out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7265out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7266out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7267out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7268out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7269out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7270out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7271out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7272out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7273out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7274out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7275out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7276out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7277out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7278out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7279out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7280out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7281out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7282out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7283out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7284out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7285out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7286out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7287out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7288out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7289out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7290out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7291out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7292out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7293out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7294out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7295out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7296out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7297out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7298out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7299out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7300out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7301out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7302out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7303out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7304out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7305out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7306out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7307out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7308out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7309out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7310out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7311out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 69)\n",
            "shape:  (40, 27)\n",
            "shape:  (40, 61)\n",
            "shape:  (40, 33)\n",
            "shape:  (40, 128)\n",
            "7316out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7317out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7318out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7319out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7320out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7321out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7322out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7323out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7324out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7325out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7326out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7327out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7328out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 105)\n",
            "shape:  (40, 128)\n",
            "7330out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7331out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7332out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7333out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 70)\n",
            "shape:  (40, 109)\n",
            "shape:  (40, 128)\n",
            "7336out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7337out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7338out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 93)\n",
            "shape:  (40, 128)\n",
            "7340out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7341out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7342out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7343out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7344out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7345out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7346out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 19)\n",
            "shape:  (40, 128)\n",
            "7348out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7349out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7350out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7351out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7352out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7353out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7354out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7355out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7356out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7357out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7358out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7359out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7360out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7361out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7362out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7363out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7364out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 93)\n",
            "shape:  (40, 110)\n",
            "shape:  (40, 97)\n",
            "shape:  (40, 47)\n",
            "shape:  (40, 128)\n",
            "7369out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7370out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7371out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7372out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 63)\n",
            "shape:  (40, 67)\n",
            "shape:  (40, 69)\n",
            "shape:  (40, 97)\n",
            "shape:  (40, 59)\n",
            "shape:  (40, 77)\n",
            "shape:  (40, 61)\n",
            "shape:  (40, 53)\n",
            "shape:  (40, 51)\n",
            "shape:  (40, 52)\n",
            "shape:  (40, 58)\n",
            "shape:  (40, 84)\n",
            "shape:  (40, 128)\n",
            "7385out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 36)\n",
            "shape:  (40, 128)\n",
            "7387out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 118)\n",
            "shape:  (40, 95)\n",
            "shape:  (40, 43)\n",
            "shape:  (40, 53)\n",
            "shape:  (40, 23)\n",
            "shape:  (40, 62)\n",
            "shape:  (40, 43)\n",
            "shape:  (40, 57)\n",
            "shape:  (40, 78)\n",
            "shape:  (40, 128)\n",
            "7397out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 72)\n",
            "shape:  (40, 95)\n",
            "shape:  (40, 128)\n",
            "7400out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 35)\n",
            "shape:  (40, 128)\n",
            "7402out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 112)\n",
            "shape:  (40, 35)\n",
            "shape:  (40, 128)\n",
            "7405out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7406out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7407out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7408out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7409out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7410out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7411out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7412out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7413out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7414out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7415out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7416out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7417out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7418out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7419out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7420out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 97)\n",
            "shape:  (40, 100)\n",
            "shape:  (40, 128)\n",
            "7423out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7424out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7425out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7426out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7427out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7428out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7429out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7430out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7431out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7432out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7433out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7434out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7435out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7436out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7437out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7438out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7439out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7440out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7441out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7442out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7443out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7444out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7445out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7446out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7447out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7448out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 20)\n",
            "shape:  (40, 14)\n",
            "shape:  (40, 128)\n",
            "7451out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7452out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7453out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7454out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 60)\n",
            "shape:  (40, 9)\n",
            "shape:  (40, 41)\n",
            "shape:  (40, 24)\n",
            "shape:  (40, 128)\n",
            "7459out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7460out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7461out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7462out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7463out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7464out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7465out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7466out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7467out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7468out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7469out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7470out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7471out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7472out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7473out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7474out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7475out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7476out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7477out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7478out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7479out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7480out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7481out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7482out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7483out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7484out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7485out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7486out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7487out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7488out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7489out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7490out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7491out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7492out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7493out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7494out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7495out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7496out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7497out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7498out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7499out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7500out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7501out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7502out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7503out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7504out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7505out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7506out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7507out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7508out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7509out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7510out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7511out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7512out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7513out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7514out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7515out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7516out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7517out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7518out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7519out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7520out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7521out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7522out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7523out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7524out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7525out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7526out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7527out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7528out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7529out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7530out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7531out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7532out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7533out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7534out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7535out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7536out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7537out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7538out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7539out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7540out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7541out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7542out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7543out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7544out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7545out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7546out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7547out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7548out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7549out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7550out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7551out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7552out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7553out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7554out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7555out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7556out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7557out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7558out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7559out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7560out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7561out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7562out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7563out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7564out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7565out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7566out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7567out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7568out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7569out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7570out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 91)\n",
            "shape:  (40, 128)\n",
            "7572out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7573out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7574out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7575out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7576out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7577out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7578out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7579out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7580out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7581out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7582out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7583out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7584out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7585out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7586out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7587out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7588out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7589out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7590out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7591out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7592out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7593out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 50)\n",
            "shape:  (40, 128)\n",
            "7595out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7596out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7597out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7598out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7599out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7600out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7601out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7602out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7603out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7604out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7605out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7606out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7607out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 61)\n",
            "shape:  (40, 128)\n",
            "7609out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7610out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7611out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7612out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7613out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7614out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7615out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 29)\n",
            "shape:  (40, 45)\n",
            "shape:  (40, 37)\n",
            "shape:  (40, 128)\n",
            "7619out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7620out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7621out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7622out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7623out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7624out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 127)\n",
            "shape:  (40, 128)\n",
            "7626out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7627out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7628out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7629out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7630out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7631out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7632out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7633out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7634out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7635out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7636out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7637out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7638out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7639out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7640out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7641out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7642out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7643out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7644out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7645out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7646out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7647out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7648out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7649out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7650out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7651out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 83)\n",
            "shape:  (40, 128)\n",
            "7653out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7654out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 87)\n",
            "shape:  (40, 128)\n",
            "7656out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 54)\n",
            "shape:  (40, 96)\n",
            "shape:  (40, 95)\n",
            "shape:  (40, 128)\n",
            "7660out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7661out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7662out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7663out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7664out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7665out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7666out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7667out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7668out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7669out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7670out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7671out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7672out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7673out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7674out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7675out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7676out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7677out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7678out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7679out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7680out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7681out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7682out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7683out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7684out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7685out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7686out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7687out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7688out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7689out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7690out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7691out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7692out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7693out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7694out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7695out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7696out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7697out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7698out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7699out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7700out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7701out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7702out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7703out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7704out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7705out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7706out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7707out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7708out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7709out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7710out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7711out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7712out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7713out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7714out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7715out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7716out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7717out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7718out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7719out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7720out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7721out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7722out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7723out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7724out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7725out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7726out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7727out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7728out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7729out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7730out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7731out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7732out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7733out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7734out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7735out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7736out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7737out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7738out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7739out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7740out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7741out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7742out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7743out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7744out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7745out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7746out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7747out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7748out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7749out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7750out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7751out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7752out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7753out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7754out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7755out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7756out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7757out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7758out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7759out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7760out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7761out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7762out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7763out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7764out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7765out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7766out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7767out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7768out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7769out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7770out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7771out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7772out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7773out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7774out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7775out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7776out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7777out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7778out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7779out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7780out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7781out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7782out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7783out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7784out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7785out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7786out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7787out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7788out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7789out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7790out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7791out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7792out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7793out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7794out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7795out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7796out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7797out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7798out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7799out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7800out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7801out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7802out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7803out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7804out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7805out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7806out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7807out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7808out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7809out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7810out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7811out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7812out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7813out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7814out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7815out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7816out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7817out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7818out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7819out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7820out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7821out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7822out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7823out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7824out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7825out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7826out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7827out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7828out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7829out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7830out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7831out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7832out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7833out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7834out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7835out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7836out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7837out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7838out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7839out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7840out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7841out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7842out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7843out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7844out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7845out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7846out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7847out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7848out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7849out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7850out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7851out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7852out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7853out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7854out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7855out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7856out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7857out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7858out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7859out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7860out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7861out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7862out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7863out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7864out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7865out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7866out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7867out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7868out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7869out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7870out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7871out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7872out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7873out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7874out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7875out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7876out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7877out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7878out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7879out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7880out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7881out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7882out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7883out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7884out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7885out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7886out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7887out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7888out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7889out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7890out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7891out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7892out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7893out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7894out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7895out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7896out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7897out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7898out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7899out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7900out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7901out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7902out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7903out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7904out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7905out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7906out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7907out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7908out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7909out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7910out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7911out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7912out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7913out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7914out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7915out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7916out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7917out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7918out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7919out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7920out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7921out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7922out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7923out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7924out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7925out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7926out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7927out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7928out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7929out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7930out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7931out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7932out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7933out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 25)\n",
            "shape:  (40, 21)\n",
            "shape:  (40, 16)\n",
            "shape:  (40, 18)\n",
            "shape:  (40, 18)\n",
            "shape:  (40, 9)\n",
            "shape:  (40, 8)\n",
            "shape:  (40, 8)\n",
            "shape:  (40, 27)\n",
            "shape:  (40, 38)\n",
            "shape:  (40, 28)\n",
            "shape:  (40, 40)\n",
            "shape:  (40, 45)\n",
            "shape:  (40, 128)\n",
            "7947out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7948out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7949out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7950out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7951out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7952out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7953out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7954out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7955out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7956out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7957out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7958out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7959out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7960out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7961out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7962out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7963out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7964out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7965out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7966out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7967out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7968out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7969out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7970out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7971out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7972out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7973out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7974out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7975out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7976out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7977out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7978out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7979out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7980out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7981out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7982out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7983out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 58)\n",
            "shape:  (40, 28)\n",
            "shape:  (40, 26)\n",
            "shape:  (40, 128)\n",
            "7987out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7988out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7989out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7990out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7991out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7992out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7993out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7994out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7995out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7996out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 52)\n",
            "shape:  (40, 128)\n",
            "7998out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "7999out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8000out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8001out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8002out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8003out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8004out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8005out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8006out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8007out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8008out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8009out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8010out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8011out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 82)\n",
            "shape:  (40, 128)\n",
            "8013out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8014out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8015out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8016out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8017out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8018out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8019out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8020out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8021out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8022out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8023out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8024out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8025out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8026out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8027out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8028out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8029out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8030out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8031out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8032out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8033out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8034out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8035out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8036out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8037out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8038out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8039out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8040out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8041out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8042out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8043out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8044out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8045out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8046out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8047out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8048out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8049out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8050out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8051out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8052out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8053out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8054out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8055out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8056out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8057out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8058out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8059out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8060out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8061out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8062out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8063out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8064out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8065out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8066out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8067out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8068out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8069out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8070out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8071out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8072out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8073out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8074out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8075out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8076out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8077out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8078out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8079out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8080out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8081out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8082out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8083out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8084out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8085out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8086out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8087out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8088out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8089out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8090out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8091out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8092out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8093out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8094out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8095out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8096out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8097out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8098out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8099out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 109)\n",
            "shape:  (40, 128)\n",
            "8101out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8102out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8103out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8104out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8105out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8106out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8107out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8108out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8109out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8110out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8111out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8112out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8113out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8114out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8115out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8116out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8117out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8118out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8119out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8120out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8121out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8122out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8123out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8124out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8125out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8126out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8127out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 43)\n",
            "shape:  (40, 33)\n",
            "shape:  (40, 34)\n",
            "shape:  (40, 31)\n",
            "shape:  (40, 128)\n",
            "8132out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8133out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8134out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8135out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8136out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8137out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8138out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8139out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8140out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8141out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 59)\n",
            "shape:  (40, 81)\n",
            "shape:  (40, 127)\n",
            "shape:  (40, 52)\n",
            "shape:  (40, 128)\n",
            "8146out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8147out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8148out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8149out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8150out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8151out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8152out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8153out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8154out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8155out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8156out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8157out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8158out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8159out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8160out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8161out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8162out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8163out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8164out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8165out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8166out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 116)\n",
            "shape:  (40, 128)\n",
            "8168out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8169out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8170out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8171out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8172out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8173out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8174out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8175out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8176out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8177out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8178out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8179out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8180out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8181out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8182out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8183out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8184out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8185out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8186out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8187out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8188out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8189out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8190out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8191out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8192out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8193out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8194out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 58)\n",
            "shape:  (40, 128)\n",
            "8196out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8197out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8198out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8199out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8200out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8201out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8202out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8203out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8204out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8205out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8206out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8207out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8208out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8209out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8210out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8211out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8212out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8213out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8214out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 107)\n",
            "shape:  (40, 128)\n",
            "8216out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8217out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8218out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8219out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8220out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8221out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8222out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8223out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8224out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8225out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8226out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8227out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8228out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8229out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8230out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8231out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8232out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8233out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8234out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8235out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 23)\n",
            "shape:  (40, 25)\n",
            "shape:  (40, 13)\n",
            "shape:  (40, 128)\n",
            "8239out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8240out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8241out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8242out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8243out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8244out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8245out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8246out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8247out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8248out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8249out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8250out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8251out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8252out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8253out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8254out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8255out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8256out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8257out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8258out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8259out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8260out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8261out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8262out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8263out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8264out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8265out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8266out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8267out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8268out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8269out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8270out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 46)\n",
            "shape:  (40, 108)\n",
            "shape:  (40, 128)\n",
            "8273out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8274out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8275out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8276out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8277out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8278out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8279out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 54)\n",
            "shape:  (40, 63)\n",
            "shape:  (40, 99)\n",
            "shape:  (40, 89)\n",
            "shape:  (40, 57)\n",
            "shape:  (40, 66)\n",
            "shape:  (40, 74)\n",
            "shape:  (40, 128)\n",
            "8287out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8288out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8289out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8290out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8291out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8292out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8293out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8294out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 99)\n",
            "shape:  (40, 128)\n",
            "8296out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 43)\n",
            "shape:  (40, 128)\n",
            "8298out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 59)\n",
            "shape:  (40, 128)\n",
            "8300out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 83)\n",
            "shape:  (40, 128)\n",
            "8302out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8303out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8304out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8305out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8306out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8307out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8308out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8309out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8310out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8311out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8312out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8313out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8314out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8315out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 50)\n",
            "shape:  (40, 53)\n",
            "shape:  (40, 91)\n",
            "shape:  (40, 28)\n",
            "shape:  (40, 59)\n",
            "shape:  (40, 49)\n",
            "shape:  (40, 128)\n",
            "8322out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8323out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 78)\n",
            "shape:  (40, 7)\n",
            "shape:  (40, 3)\n",
            "shape:  (40, 3)\n",
            "shape:  (40, 3)\n",
            "shape:  (40, 3)\n",
            "shape:  (40, 5)\n",
            "shape:  (40, 128)\n",
            "8331out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8332out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8333out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8334out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8335out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 48)\n",
            "shape:  (40, 84)\n",
            "shape:  (40, 72)\n",
            "shape:  (40, 128)\n",
            "8339out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8340out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8341out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8342out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8343out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8344out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8345out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8346out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8347out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8348out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 16)\n",
            "shape:  (40, 89)\n",
            "shape:  (40, 90)\n",
            "shape:  (40, 82)\n",
            "shape:  (40, 57)\n",
            "shape:  (40, 70)\n",
            "shape:  (40, 128)\n",
            "8355out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8356out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8357out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8358out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8359out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8360out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8361out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8362out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8363out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8364out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8365out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8366out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 56)\n",
            "shape:  (40, 33)\n",
            "shape:  (40, 128)\n",
            "8369out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8370out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8371out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8372out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8373out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8374out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8375out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8376out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8377out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8378out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8379out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8380out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8381out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8382out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8383out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8384out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8385out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8386out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8387out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8388out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8389out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8390out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8391out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8392out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8393out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8394out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8395out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8396out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 18)\n",
            "shape:  (40, 99)\n",
            "shape:  (40, 75)\n",
            "shape:  (40, 36)\n",
            "shape:  (40, 16)\n",
            "shape:  (40, 27)\n",
            "shape:  (40, 40)\n",
            "shape:  (40, 57)\n",
            "shape:  (40, 128)\n",
            "8405out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8406out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8407out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8408out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8409out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8410out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8411out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8412out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8413out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8414out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8415out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8416out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8417out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8418out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8419out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8420out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8421out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8422out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8423out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8424out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8425out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8426out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8427out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8428out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8429out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8430out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8431out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8432out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8433out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8434out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 63)\n",
            "shape:  (40, 128)\n",
            "8436out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8437out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8438out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8439out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8440out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8441out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8442out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8443out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8444out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8445out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8446out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8447out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8448out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8449out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8450out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8451out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8452out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8453out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8454out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8455out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8456out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8457out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8458out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8459out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8460out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8461out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 96)\n",
            "shape:  (40, 128)\n",
            "8463out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8464out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8465out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8466out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8467out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8468out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8469out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8470out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 48)\n",
            "shape:  (40, 128)\n",
            "8472out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8473out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8474out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8475out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8476out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8477out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8478out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8479out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8480out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8481out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8482out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8483out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8484out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8485out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8486out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8487out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8488out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8489out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8490out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8491out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8492out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8493out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8494out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8495out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8496out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8497out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8498out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8499out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8500out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8501out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8502out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8503out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8504out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8505out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8506out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8507out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8508out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8509out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8510out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8511out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8512out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8513out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8514out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8515out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8516out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8517out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8518out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8519out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8520out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8521out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8522out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8523out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8524out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8525out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8526out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8527out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8528out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8529out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8530out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8531out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8532out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8533out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8534out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 90)\n",
            "shape:  (40, 16)\n",
            "shape:  (40, 17)\n",
            "shape:  (40, 16)\n",
            "shape:  (40, 128)\n",
            "8539out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8540out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8541out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8542out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8543out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8544out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8545out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8546out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8547out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8548out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8549out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8550out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8551out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8552out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 66)\n",
            "shape:  (40, 119)\n",
            "shape:  (40, 128)\n",
            "8555out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8556out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8557out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 47)\n",
            "shape:  (40, 128)\n",
            "8559out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 25)\n",
            "shape:  (40, 128)\n",
            "8561out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8562out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8563out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8564out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8565out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8566out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8567out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8568out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8569out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8570out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8571out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8572out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8573out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8574out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8575out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8576out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8577out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8578out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8579out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8580out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8581out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8582out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8583out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8584out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8585out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8586out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8587out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8588out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8589out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8590out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8591out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8592out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8593out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8594out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8595out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8596out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8597out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8598out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8599out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8600out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8601out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8602out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8603out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8604out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8605out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8606out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8607out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8608out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8609out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8610out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 120)\n",
            "shape:  (40, 128)\n",
            "8612out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 120)\n",
            "shape:  (40, 122)\n",
            "shape:  (40, 66)\n",
            "shape:  (40, 72)\n",
            "shape:  (40, 72)\n",
            "shape:  (40, 50)\n",
            "shape:  (40, 128)\n",
            "8619out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8620out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8621out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8622out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8623out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8624out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 110)\n",
            "shape:  (40, 128)\n",
            "8626out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 43)\n",
            "shape:  (40, 128)\n",
            "8628out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 123)\n",
            "shape:  (40, 70)\n",
            "shape:  (40, 96)\n",
            "shape:  (40, 70)\n",
            "shape:  (40, 96)\n",
            "shape:  (40, 86)\n",
            "shape:  (40, 64)\n",
            "shape:  (40, 128)\n",
            "8636out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8637out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8638out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8639out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8640out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8641out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8642out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 59)\n",
            "shape:  (40, 128)\n",
            "8644out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8645out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8646out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8647out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8648out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8649out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8650out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8651out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8652out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8653out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8654out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8655out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 87)\n",
            "shape:  (40, 128)\n",
            "8657out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8658out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8659out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8660out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8661out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8662out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8663out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8664out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8665out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8666out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8667out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8668out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8669out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8670out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8671out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8672out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8673out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8674out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8675out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8676out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8677out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8678out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8679out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8680out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 27)\n",
            "shape:  (40, 128)\n",
            "8682out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8683out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8684out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8685out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8686out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8687out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8688out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8689out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8690out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8691out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8692out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8693out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8694out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8695out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8696out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8697out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8698out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8699out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8700out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8701out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8702out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8703out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8704out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8705out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8706out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8707out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8708out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8709out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8710out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8711out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8712out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8713out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8714out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8715out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8716out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8717out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8718out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8719out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8720out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8721out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8722out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8723out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8724out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8725out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8726out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 128)\n",
            "8727out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 93)\n",
            "shape:  (40, 128)\n",
            "8729out of 8732\n",
            "shape:  (40, 128)\n",
            "shape:  (40, 109)\n",
            "shape:  (40, 109)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# D=[]\n",
        "# for i in range(8732):\n",
        "#   try:\n",
        "#     file_name = '/content/drive/MyDrive/Thesis_Keras/UrbanSound8K/audio/fold' + str(df[\"fold\"][i]) + '/' + df[\"slice_file_name\"][i]\n",
        "#     class_id = df[\"classID\"][i]\n",
        "\n",
        "#     X, sample_rate = librosa.load(file_name, res_type='kaiser_fast', duration=2.97)\n",
        "#     # print(f\"{i}out of 8732\")\n",
        "#     # if i == 4803 or i==6246:\n",
        "#     #   continue\n",
        "#     # x = np.pad(X,(0,88200-X.shape[0]) if (0,88200-X.shape[0]>0) else (0,-88200+X.shape[0]),'constant')\n",
        "#     # print(f\"{i}out of 8732\")\n",
        "\n",
        "#     mels = librosa.feature.melspectrogram(X, sr=sample_rate,n_mels=40)\n",
        "#     print('shape: ',mels.shape)\n",
        "#     if mels.shape != (40, 128): \n",
        "#       continue\n",
        "#     print(f\"{i}out of 8732\")\n",
        "#     print('shape: ',mels.shape)\n",
        "    \n",
        "#     feature = mels\n",
        "#     label = class_id\n",
        "#     D.append((feature,label)) \n",
        "#   except Exception:\n",
        "#     print(\"Error encountered while parsing file: \", file_name)\n",
        "#     mfccs,class_id = None, None\n",
        "  \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0cmia9NzrlZR",
        "outputId": "1d8c25cf-c1cb-49f6-c0fc-1822feaf2a96"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "7478\n"
          ]
        }
      ],
      "source": [
        "# print(len(X))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I2WlOelTzUJN",
        "outputId": "db5b6ad3-5a00-4d82-a994-05c25d5e6506"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ji5f61mMzGlG"
      },
      "outputs": [],
      "source": [
        "# import tensorflow as tf\n",
        "\n",
        "# X_train = np.array([x.reshape((40, 128, 1)) for x in x_train])\n",
        "# X_test = np.array([x.reshape((40, 128, 1)) for x in x_test])\n",
        "\n",
        "# Y_train = np.array(tf.keras.utils.to_categorical(y_train, 10))\n",
        "# Y_test = np.array(tf.keras.utils.to_categorical(y_test, 10))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_dfncTfQd-UU"
      },
      "outputs": [],
      "source": [
        "# X,Y=zip(*D)\n",
        "# x_train, x_test, y_train, y_test = train_test_split(X, Y,test_size = 0.2, random_state = 114514)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import os\n",
        "# import librosa\n",
        "# import pandas as pd\n",
        "# import numpy as np\n",
        "# import random\n",
        "# import keras\n",
        "# from scipy import signal\n",
        "# from sklearn.model_selection import train_test_split\n",
        "# from tqdm import tqdm\n",
        "# from tqdm._tqdm import trange\n",
        "# from keras.utils import np_utils\n",
        "\n",
        "# def readFromCsv(csvpth):\n",
        "#     # 生成数据列表\n",
        "#     # 读取wav文件函数\n",
        "#     #data = pd.read_csv('metadata/UrbanSound8K.csv')\n",
        "#     data = pd.read_csv(csvpth)\n",
        "#     valid_data = data[['slice_file_name', 'fold', 'classID', 'class']]\n",
        "#     valid_data['path'] = 'fold' + valid_data['fold'].astype('str') + '/' + valid_data['slice_file_name'].astype(\n",
        "#         'str')\n",
        "#     return valid_data\n",
        "\n",
        "\n",
        "# def splitData(current):\n",
        "  \n",
        "#   D=[]\n",
        "#   csvPth = '/content/drive/MyDrive/Thesis_Keras/UrbanSound8K/metadata/UrbanSound8K.csv'\n",
        "#   #df=pd.read_csv(csvPth)\n",
        "#   #valid_data=readFromCsv(csvPth)\n",
        "#   i=1\n",
        "\n",
        "#   for row in tqdm(current.itertuples(),total=current.shape[0]):\n",
        "#         #print(row.path)\n",
        "#         #print(row.classID)\n",
        "#         #print(f\"{i} out of {len(current)}\")\n",
        "#         X, sample_rate = librosa.load(\"/content/drive/MyDrive/Thesis_Keras/UrbanSound8K/audio/\" + row.path, res_type='kaiser_fast', duration=2.97)\n",
        "#         # print(f\"{i}out of 8732\")\n",
        "#         # if i == 4803 or i==6246:\n",
        "#         #   continue\n",
        "#         # x = np.pad(X,(0,88200-X.shape[0]) if (0,88200-X.shape[0]>0) else (0,-88200+X.shape[0]),'constant')\n",
        "#         # print(f\"{i}out of 8732\")\n",
        "\n",
        "#         mels = librosa.feature.melspectrogram(X, sr=sample_rate,n_mels=40)\n",
        "#         #print('shape: ',mels.shape)\n",
        "#         if mels.shape != (40, 128): \n",
        "#           continue\n",
        "#         #print(f\"{i}out of 8732\")\n",
        "#         #print('shape: ',mels.shape)\n",
        "#         i+=1\n",
        "#         D.append((mels, row.classID))\n",
        "#   dataset = D\n",
        "#   X,y=zip(*dataset)\n",
        "  \n",
        "#   print(\"type of X is:\",type(X))\n",
        "#   y=np.array(y).astype(np.int64)\n",
        "#   y = np.array(np_utils.to_categorical(y, 10))\n",
        "\n",
        "#   return  X,y\n",
        "\n",
        "\n",
        "# def save_npy(nparr,modelName,featureName,subDataset,fold):\n",
        "#     import os\n",
        "#     dirs = \"drive/MyDrive/Thesis_Keras/TenFoldDataset/datasetnpy\"+'/'+modelName+'/'+featureName+'/'+fold\n",
        "    \n",
        "#     #Create a directory to place the dataset npy files.\n",
        "#     if not os.path.exists(dirs):\n",
        "#         os.makedirs(dirs)\n",
        "#         print(f\"Created directory:{dirs}\")\n",
        "    \n",
        "#     subDataset+='.npy'\n",
        "#     print(subDataset)\n",
        "#     subsetPth=os.path.join(dirs,subDataset)\n",
        "#     #with open(subsetPth, 'w') as f:\n",
        "#     np.save(subsetPth, nparr)\n",
        "#     print(f\"save {subDataset} done\")\n",
        "#     print(f\"Path:{subsetPth}\")"
      ],
      "metadata": {
        "id": "W0r4OswKnVUI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def Ten_fold():\n",
        "#     csvPth = '/content/drive/MyDrive/Thesis_Keras/UrbanSound8K/metadata/UrbanSound8K.csv'\n",
        "#     #df=pd.read_csv(csvPth)\n",
        "#     valid_data=readFromCsv(csvPth)\n",
        "#     #valid_data = df[['slice_file_name', 'fold', 'classID', 'class']][df['end'] - df['start']]\n",
        "#     # valid_data['path'] = 'fold' + valid_data['fold'].astype('str') + '/' + valid_data['slice_file_name'].astype(\n",
        "#     #     'str')\n",
        "#     for i in range(10):#Folder : \"fold1\" to \"fold10\"\n",
        "#         print(f\"fold:{i+1} out of 10\")\n",
        "#         current=valid_data[valid_data['fold'] == i+1]\n",
        "#         X,y = splitData(current)\n",
        "#         print(\"Dataset split done!\")\n",
        "#         print(\"Saving subsets to .npy files!\")\n",
        "        \n",
        "#         save_npy(X, 'Trivedi', 'mel40x128', 'X',f\"fold{i+1}\")\n",
        "#         save_npy(y, 'Trivedi', 'mel40x128', 'y',f\"fold{i+1}\")"
      ],
      "metadata": {
        "id": "fgjoa31onbqg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ten_fold()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "aTeQqPlhoNd1",
        "outputId": "b04b5a59-3608-4495-e470-c129b163692e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:20: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold:1 out of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 95%|█████████▌| 833/873 [06:04<00:14,  2.83it/s]/usr/local/lib/python3.7/dist-packages/librosa/core/spectrum.py:224: UserWarning: n_fft=2048 is too small for input signal of length=1103\n",
            "  n_fft, y.shape[-1]\n",
            " 96%|█████████▌| 835/873 [06:05<00:12,  3.08it/s]/usr/local/lib/python3.7/dist-packages/librosa/core/spectrum.py:224: UserWarning: n_fft=2048 is too small for input signal of length=1323\n",
            "  n_fft, y.shape[-1]\n",
            " 96%|█████████▌| 836/873 [06:05<00:12,  3.05it/s]/usr/local/lib/python3.7/dist-packages/librosa/core/spectrum.py:224: UserWarning: n_fft=2048 is too small for input signal of length=1523\n",
            "  n_fft, y.shape[-1]\n",
            "100%|██████████| 873/873 [06:19<00:00,  2.30it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "type of X is: <class 'tuple'>\n",
            "Dataset split done!\n",
            "Saving subsets to .npy files!\n",
            "Created directory:drive/MyDrive/Thesis_Keras/TenFoldDataset/datasetnpy/Trivedi/mel40x128/fold1\n",
            "X.npy\n",
            "save X.npy done\n",
            "Path:drive/MyDrive/Thesis_Keras/TenFoldDataset/datasetnpy/Trivedi/mel40x128/fold1/X.npy\n",
            "y.npy\n",
            "save y.npy done\n",
            "Path:drive/MyDrive/Thesis_Keras/TenFoldDataset/datasetnpy/Trivedi/mel40x128/fold1/y.npy\n",
            "fold:2 out of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 888/888 [06:12<00:00,  2.38it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "type of X is: <class 'tuple'>\n",
            "Dataset split done!\n",
            "Saving subsets to .npy files!\n",
            "Created directory:drive/MyDrive/Thesis_Keras/TenFoldDataset/datasetnpy/Trivedi/mel40x128/fold2\n",
            "X.npy\n",
            "save X.npy done\n",
            "Path:drive/MyDrive/Thesis_Keras/TenFoldDataset/datasetnpy/Trivedi/mel40x128/fold2/X.npy\n",
            "y.npy\n",
            "save y.npy done\n",
            "Path:drive/MyDrive/Thesis_Keras/TenFoldDataset/datasetnpy/Trivedi/mel40x128/fold2/y.npy\n",
            "fold:3 out of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 925/925 [06:19<00:00,  2.44it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "type of X is: <class 'tuple'>\n",
            "Dataset split done!\n",
            "Saving subsets to .npy files!\n",
            "Created directory:drive/MyDrive/Thesis_Keras/TenFoldDataset/datasetnpy/Trivedi/mel40x128/fold3\n",
            "X.npy\n",
            "save X.npy done\n",
            "Path:drive/MyDrive/Thesis_Keras/TenFoldDataset/datasetnpy/Trivedi/mel40x128/fold3/X.npy\n",
            "y.npy\n",
            "save y.npy done\n",
            "Path:drive/MyDrive/Thesis_Keras/TenFoldDataset/datasetnpy/Trivedi/mel40x128/fold3/y.npy\n",
            "fold:4 out of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 990/990 [07:07<00:00,  2.31it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "type of X is: <class 'tuple'>\n",
            "Dataset split done!\n",
            "Saving subsets to .npy files!\n",
            "Created directory:drive/MyDrive/Thesis_Keras/TenFoldDataset/datasetnpy/Trivedi/mel40x128/fold4\n",
            "X.npy\n",
            "save X.npy done\n",
            "Path:drive/MyDrive/Thesis_Keras/TenFoldDataset/datasetnpy/Trivedi/mel40x128/fold4/X.npy\n",
            "y.npy\n",
            "save y.npy done\n",
            "Path:drive/MyDrive/Thesis_Keras/TenFoldDataset/datasetnpy/Trivedi/mel40x128/fold4/y.npy\n",
            "fold:5 out of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 936/936 [06:42<00:00,  2.33it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "type of X is: <class 'tuple'>\n",
            "Dataset split done!\n",
            "Saving subsets to .npy files!\n",
            "Created directory:drive/MyDrive/Thesis_Keras/TenFoldDataset/datasetnpy/Trivedi/mel40x128/fold5\n",
            "X.npy\n",
            "save X.npy done\n",
            "Path:drive/MyDrive/Thesis_Keras/TenFoldDataset/datasetnpy/Trivedi/mel40x128/fold5/X.npy\n",
            "y.npy\n",
            "save y.npy done\n",
            "Path:drive/MyDrive/Thesis_Keras/TenFoldDataset/datasetnpy/Trivedi/mel40x128/fold5/y.npy\n",
            "fold:6 out of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 70%|███████   | 580/823 [03:47<01:35,  2.54it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-7e62337dd5be>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mTen_fold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-12-79b3fa2dfc87>\u001b[0m in \u001b[0;36mTen_fold\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"fold:{i+1} out of 10\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mcurrent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalid_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvalid_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'fold'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msplitData\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurrent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Dataset split done!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Saving subsets to .npy files!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-11-68a67367b423>\u001b[0m in \u001b[0;36msplitData\u001b[0;34m(current)\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0;31m#print(row.classID)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0;31m#print(f\"{i} out of {len(current)}\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_rate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlibrosa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/drive/MyDrive/Thesis_Keras/UrbanSound8K/audio/\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mres_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'kaiser_fast'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mduration\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2.97\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m         \u001b[0;31m# print(f\"{i}out of 8732\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0;31m# if i == 4803 or i==6246:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(path, sr, mono, offset, duration, dtype, res_type)\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0msf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSoundFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msf_desc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    150\u001b[0m             \u001b[0msr_native\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msf_desc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msamplerate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0moffset\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/soundfile.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, file, mode, samplerate, channels, subtype, endian, format, closefd)\u001b[0m\n\u001b[1;32m    627\u001b[0m         self._info = _create_info_struct(file, mode, samplerate, channels,\n\u001b[1;32m    628\u001b[0m                                          format, subtype, endian)\n\u001b[0;32m--> 629\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode_int\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclosefd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    630\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0missuperset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'r+'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseekable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    631\u001b[0m             \u001b[0;31m# Move write position to 0 (like in Python file objects)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/soundfile.py\u001b[0m in \u001b[0;36m_open\u001b[0;34m(self, file, mode_int, closefd)\u001b[0m\n\u001b[1;32m   1173\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1174\u001b[0m                     \u001b[0mfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_sys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetfilesystemencoding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1175\u001b[0;31m             \u001b[0mfile_ptr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopenfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode_int\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1176\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1177\u001b[0m             \u001b[0mfile_ptr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_snd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msf_open_fd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode_int\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclosefd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uvgwlHz9d-cx"
      },
      "outputs": [],
      "source": [
        "# def save_npy(nparr,folder,featureName,subDataset):\n",
        "#     import os\n",
        "#     dirs = root+folder+\"/data/datasetnpy\"+'/'+featureName\n",
        "    \n",
        "#     #Create a directory to place the dataset npy files.\n",
        "#     if not os.path.exists(dirs):\n",
        "#         os.makedirs(dirs)\n",
        "#         print(f\"Created directory:{dirs}\")\n",
        "    \n",
        "#     subDataset+='.npy'\n",
        "#     print(subDataset)\n",
        "#     subsetPth=os.path.join(dirs,subDataset)\n",
        "#     #with open(subsetPth, 'w') as f:\n",
        "#     np.save(subsetPth, nparr)\n",
        "#     print(f\"save {subDataset} done\")\n",
        "#     print(f\"Path:{subsetPth}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fN-FUPaPd-fN",
        "outputId": "13120ab4-7897-4462-a071-72f8ae20e3ac"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Created directory:/content/drive/MyDrive/Thesis_Keras/TrivediCNN/data/datasetnpy/melspectro\n",
            "x_train.npy\n",
            "save x_train.npy done\n",
            "Path:/content/drive/MyDrive/Thesis_Keras/TrivediCNN/data/datasetnpy/melspectro/x_train.npy\n",
            "x_test.npy\n",
            "save x_test.npy done\n",
            "Path:/content/drive/MyDrive/Thesis_Keras/TrivediCNN/data/datasetnpy/melspectro/x_test.npy\n",
            "y_train.npy\n",
            "save y_train.npy done\n",
            "Path:/content/drive/MyDrive/Thesis_Keras/TrivediCNN/data/datasetnpy/melspectro/y_train.npy\n",
            "y_test.npy\n",
            "save y_test.npy done\n",
            "Path:/content/drive/MyDrive/Thesis_Keras/TrivediCNN/data/datasetnpy/melspectro/y_test.npy\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# folderName=\"TrivediCNN\"\n",
        "\n",
        "# save_npy(X_train, folderName, 'melspectro','x_train')\n",
        "# save_npy(X_test, folderName, 'melspectro','x_test')\n",
        "# save_npy(Y_train, folderName, 'melspectro','y_train')\n",
        "# save_npy(Y_test, folderName, 'melspectro', 'y_test')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6_mrZWgwd-hI"
      },
      "outputs": [],
      "source": [
        "# import sys, os, random\n",
        "# import tensorflow as tf\n",
        "# X = np.load('/content/drive/MyDrive/Thesis_Keras/TrivediCNN/data/datasetnpy/melspectro/x_train.npy')\n",
        "# Y = np.load('/content/drive/MyDrive/Thesis_Keras/TrivediCNN/data/datasetnpy/melspectro/y_train.npy')\n",
        "\n",
        "# x_train, x_val, Y_train, Y_val = train_test_split(X, Y, test_size=0.1, random_state=1)\n",
        "# input_length = x_train[0].shape[0]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L1BL9kEbMciI",
        "outputId": "7ae6edeb-1cce-4b1e-cdeb-dc16659c2ad3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(5383, 40, 128, 1)\n",
            "(1496, 40, 128, 1)\n",
            "(599, 40, 128, 1)\n"
          ]
        }
      ],
      "source": [
        "# x_test=np.load('/content/drive/MyDrive/Thesis_Keras/TrivediCNN/data/datasetnpy/melspectro/x_test.npy',allow_pickle=True)\n",
        "# Y_test = np.load('/content/drive/MyDrive/Thesis_Keras/TrivediCNN/data/datasetnpy/melspectro/y_test.npy')\n",
        "\n",
        "# # X_train = np.array([tf.image.resize(x, [60,41]) for x in x_train])\n",
        "# # X_test = np.array([tf.image.resize(x,[60,41]) for x in x_test])\n",
        "# # X_val = np.array([tf.image.resize(x,[60,41]) for x in x_val])\n",
        "\n",
        "# X_train = x_train\n",
        "# X_test = x_test\n",
        "# X_val = x_val\n",
        "# print(X_train.shape)\n",
        "# print(X_test.shape)\n",
        "# print(X_val.shape)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}